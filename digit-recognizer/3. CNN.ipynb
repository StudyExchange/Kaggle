{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: DigitRecognizer_Preprocess_20190407_220457\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'DigitRecognizer'\n",
    "step_name = 'Preprocess'\n",
    "date_str = time.strftime(\"%Y%m%d\", time.localtime())\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = '%s_%s_%s' % (project_name, step_name, time_str)\n",
    "print('run_name: %s' % run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_count:\t 4\n",
      "batch_size:\t 8\n",
      "random_state:\t 2019\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "batch_size = 8\n",
    "random_state = 2019\n",
    "\n",
    "print('cpu_count:\\t', cpu_count())\n",
    "print('batch_size:\\t', batch_size)\n",
    "print('random_state:\\t', random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\tD:\\Kaggle\\digit-recognizer\\input\n",
      "log_folder: \t\tD:\\Kaggle\\digit-recognizer\\log\n",
      "model_folder: \t\tD:\\Kaggle\\digit-recognizer\\model\n",
      "output_folder: \t\tD:\\Kaggle\\digit-recognizer\\output\n",
      "\n",
      "train_csv_file: \tD:\\Kaggle\\digit-recognizer\\input\\train.csv\n",
      "test_csv_file: \t\tD:\\Kaggle\\digit-recognizer\\input\\test.csv\n",
      "processed_data_file: \tD:\\Kaggle\\digit-recognizer\\input\\DigitRecognizer_Preprocess.p\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "print('input_folder: \\t\\t%s' % input_folder)\n",
    "print('log_folder: \\t\\t%s' % log_folder)\n",
    "print('model_folder: \\t\\t%s' % model_folder)\n",
    "print('output_folder: \\t\\t%s'% output_folder)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "print('\\ntrain_csv_file: \\t%s' % train_csv_file)\n",
    "print('test_csv_file: \\t\\t%s' % test_csv_file)\n",
    "\n",
    "processed_data_file = os.path.join(input_folder, '%s_%s.p' % (project_name, step_name))\n",
    "print('processed_data_file: \\t%s' % processed_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_images(rows, fig_column, y_data, *args):\n",
    "    columns = len(args)\n",
    "    figs, axes = plt.subplots(rows, columns, figsize=(rows, fig_column*columns))\n",
    "    print(axes.shape)\n",
    "    for i, ax in enumerate(axes):\n",
    "        y_data_str = ''\n",
    "        if type(y_data) != type(None):\n",
    "            y_data_str =  '_' + str(y_data[i])\n",
    "        ax[0].set_title('28x28' + y_data_str)\n",
    "        for j, arg in enumerate(args):\n",
    "            ax[j].imshow(arg[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n",
      "(28000, 784)\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_data = np.loadtxt(train_csv_file, skiprows=1, dtype='int', delimiter=',')\n",
    "x_data = raw_data[:,1:]\n",
    "y_data = raw_data[:,0]\n",
    "\n",
    "x_test = np.loadtxt(test_csv_file, skiprows=1, dtype='int', delimiter=',')\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5a5dd17a2b0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_data_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "x_data = x_data/255.\n",
    "x_test = x_test/255.\n",
    "y_data_cat = to_categorical(y_data)\n",
    "\n",
    "describe(x_data)\n",
    "describe(x_test)\n",
    "describe(y_data)\n",
    "describe(y_data_cat)\n",
    "\n",
    "x_data = x_data.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "describe(x_data)\n",
    "describe(x_test)\n",
    "\n",
    "# print(x_data[0])\n",
    "print(y_data[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "ax[0, 0].plot(x_data[index].reshape(784,))\n",
    "ax[0, 0].set_title('784x1 data')\n",
    "ax[0, 1].imshow(x_data[index].reshape(28, 28), cmap='gray')\n",
    "ax[0, 1].set_title('28x28 data => ' + str(y_data[index]))\n",
    "\n",
    "ax[1, 0].plot(x_test[index].reshape(784,))\n",
    "ax[1, 0].set_title('784x1 data')\n",
    "ax[1, 1].imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "ax[1, 1].set_title('28x28 data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_data, y_data_cat, test_size=0.1, random_state=random_state)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train_cat.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', padding = 'Same', input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # Block 2\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Output\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(x_train.shape[1:])\n",
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 20,\n",
    "    height_shift_range = 0.2,\n",
    "    width_shift_range = 0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annealer = LearningRateScheduler(lambda x: 1e-4 * 0.995 ** x)\n",
    "\n",
    "def get_lr(x):\n",
    "    if x <= 10:\n",
    "        return 1e-4\n",
    "    elif x <= 20:\n",
    "        return 3e-5\n",
    "    else:\n",
    "        return 1e-5\n",
    "[print(get_lr(x), end=' ') for x in range(1, 31)]\n",
    "\n",
    "annealer = LearningRateScheduler(get_lr)\n",
    "callbacks = [annealer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "steps_per_epoch = x_train.shape[0] / batch_size\n",
    "print('steps_per_epoch:\\t', steps_per_epoch)\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    train_datagen.flow(x_train, y_train_cat, batch_size=batch_size, seed=random_state),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=2, #Increase this when not on Kaggle kernel\n",
    "    verbose=1,  #1 for ETA, 0 for silent\n",
    "    callbacks=callbacks,\n",
    "    max_queue_size=batch_size*4,\n",
    "    workers=cpu_count(),\n",
    "    validation_steps=100,\n",
    "    validation_data=val_datagen.flow(x_val, y_val_cat, batch_size=batch_size, seed=random_state)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
