{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FeatureExtraction_from_VGG16_InceptionResNetV2\n",
    "\n",
    "References:\n",
    "- https://github.com/ypwhs/dogs_vs_cats\n",
    "- https://www.kaggle.com/yangpeiwen/keras-inception-xception-0-47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: ic_furniture2018_FeatureExtraction_20180415_131901\n"
     ]
    }
   ],
   "source": [
    "project_name = 'ic_furniture2018'\n",
    "step_name = 'FeatureExtraction'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 使用预训练权重的VGG16、VGG19、ResNet50、Xception、InceptionV3和InceptionResNetV2模型提取特征¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(MODEL, image_size, date_str, lambda_func=None, batch_size=1, is_aug=False, cropping_rate=0.05):\n",
    "    print('{0} start.'.format(MODEL.__name__))\n",
    "    print(image_size, date_str, batch_size, is_aug)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    cropping_size = int(image_size[0] * cropping_rate)\n",
    "    print('cropping_size: \\t%s' % cropping_size)\n",
    "    cpu_amount = cpu_count()\n",
    "    print('cpu_amount: \\t%s' % cpu_amount)\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    folder_path = os.path.join(cwd, 'feature')\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "        print('Created folder: %s' % folder_path)\n",
    "    else:\n",
    "        print('Existed folder: %s' % folder_path)\n",
    "    file_name = os.path.join(folder_path, 'feature_%s_%s_%s.h5' % (MODEL.__name__, image_size[0], date_str))\n",
    "    print(file_name)\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    print('input_tensor: ', type(input_tensor))\n",
    "    print(input_tensor.shape)\n",
    "    \n",
    "    x = input_tensor\n",
    "    x = Cropping2D(cropping=((cropping_size, cropping_size), (cropping_size, cropping_size)))(x)\n",
    "    if lambda_func:\n",
    "        print(lambda_func.__name__)\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    print('x: ', type(x))\n",
    "    print(x.shape)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', input_shape=(height, width, 3), include_top=False)\n",
    "    \n",
    "    print('base_model.input: ', type(base_model.input))\n",
    "    print(base_model.input.shape)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    \n",
    "    data_train_path = os.path.join(cwd, 'input', 'data_train')\n",
    "    data_val_path = os.path.join(cwd, 'input', 'data_val')\n",
    "    data_test_path  = os.path.join(cwd, 'input', 'data_test')\n",
    "    \n",
    "    if is_aug:\n",
    "        print('have augumentation')\n",
    "        gen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 width_shift_range = 0.1,\n",
    "#                                  horizontal_flip = True,\n",
    "#                                  vertical_flip = True,\n",
    "                                 fill_mode = 'wrap',\n",
    "                                 rotation_range = 10)\n",
    "    else:\n",
    "        print('do not have augumentation')\n",
    "        gen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = gen.flow_from_directory(data_train_path, image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    val_generator = gen.flow_from_directory(data_val_path, image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    test_generator  = gen.flow_from_directory(data_test_path,  image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "    print('train_generator')\n",
    "    print(len(train_generator.filenames))\n",
    "    train_generator_steps = math.ceil(len(train_generator.filenames)/batch_size)\n",
    "    print('train_generator_steps=%d' % train_generator_steps)\n",
    "    train = model.predict_generator(train_generator, verbose=1, steps=train_generator_steps, max_queue_size=batch_size*10, workers=cpu_amount)\n",
    "    \n",
    "    print('val_generator')\n",
    "    print(len(val_generator.filenames))\n",
    "    val_generator_steps = math.ceil(len(val_generator.filenames)/batch_size)\n",
    "    print('val_generator_steps=%d' % val_generator_steps)\n",
    "    val = model.predict_generator(val_generator, verbose=1, steps=val_generator_steps, max_queue_size=batch_size*10, workers=cpu_amount)\n",
    "    \n",
    "    print('test_generator')\n",
    "    print(len(test_generator.filenames))\n",
    "    test_generator_steps = math.ceil(len(test_generator.filenames)/batch_size)\n",
    "    print('test_generator_steps=%d' % test_generator_steps)\n",
    "    test = model.predict_generator(test_generator, verbose=1, steps=test_generator_steps, max_queue_size=batch_size*10, workers=cpu_amount)\n",
    "\n",
    "    \n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"train_labels\", data=train_generator.classes)\n",
    "        h.create_dataset(\"val\", data=val)\n",
    "        h.create_dataset(\"val_labels\", data=val_generator.classes)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(train_generator.classes)\n",
    "    print(val.shape)\n",
    "    print(val_generator.classes)\n",
    "    print(test.shape)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Spend time: {0} s'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(batch_size=1, image_width=299, is_aug=False):\n",
    "    time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    print(time_str)\n",
    "\n",
    "#     get_features(MobileNet, (224, 224), time_str, mobilenet.preprocess_input, batch_size, is_aug)\n",
    "\n",
    "#     get_features(VGG16, (224, 224), time_str, vgg16.preprocess_input, batch_size, is_aug)\n",
    "#     get_features(VGG19, (224, 224), time_str, vgg19.preprocess_input, batch_size, is_aug)\n",
    "#     get_features(ResNet50, (224, 224), time_str, resnet50.preprocess_input, batch_size, is_aug)\n",
    "    \n",
    "#     get_features(DenseNet121, (224, 224), time_str, densenet.preprocess_input, batch_size, is_aug)\n",
    "#     get_features(DenseNet169, (224, 224), time_str, densenet.preprocess_input, batch_size, is_aug)\n",
    "#     get_features(DenseNet201, (224, 224), time_str, densenet.preprocess_input, batch_size, is_aug)\n",
    "    \n",
    "    get_features(Xception, (image_width, image_width), time_str, xception.preprocess_input, batch_size, is_aug)\n",
    "    get_features(InceptionV3, (image_width, image_width), time_str, inception_v3.preprocess_input, batch_size, is_aug)\n",
    "    get_features(InceptionResNetV2, (image_width, image_width), time_str, inception_resnet_v2.preprocess_input, batch_size, is_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180415-131901\n",
      "Xception start.\n",
      "(150, 150) 20180415-131901 64 False\n",
      "cropping_size: \t7\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_150_20180415-131901.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 150, 150, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 136, 136, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 150, 150, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 871s 291ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 29s 293ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 58s 294ms/step\n",
      "(191261, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 2048)\n",
      "Spend time: 979.7288615703583 s\n",
      "InceptionV3 start.\n",
      "(150, 150) 20180415-131901 64 False\n",
      "cropping_size: \t7\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_150_20180415-131901.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 150, 150, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 136, 136, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 150, 150, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 864s 289ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 29s 298ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 60s 304ms/step\n",
      "(191261, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 2048)\n",
      "Spend time: 983.5697405338287 s\n",
      "InceptionResNetV2 start.\n",
      "(150, 150) 20180415-131901 64 False\n",
      "cropping_size: \t7\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_150_20180415-131901.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 150, 150, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 136, 136, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 150, 150, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 876s 293ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 30s 306ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 61s 308ms/step\n",
      "(191261, 1536)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 1536)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 1536)\n",
      "Spend time: 1023.1211292743683 s\n"
     ]
    }
   ],
   "source": [
    "get_all_features(64, 150, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180415-140848\n",
      "Xception start.\n",
      "(200, 200) 20180415-140848 64 False\n",
      "cropping_size: \t10\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_200_20180415-140848.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 200, 200, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 180, 180, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 200, 200, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 895s 299ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 30s 301ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 60s 301ms/step\n",
      "(191261, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 2048)\n",
      "Spend time: 1011.91717004776 s\n",
      "InceptionV3 start.\n",
      "(200, 200) 20180415-140848 64 False\n",
      "cropping_size: \t10\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_200_20180415-140848.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 200, 200, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 180, 180, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 200, 200, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 885s 296ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 30s 308ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 59s 300ms/step\n",
      "(191261, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 2048)\n",
      "Spend time: 1013.8661961555481 s\n",
      "InceptionResNetV2 start.\n",
      "(200, 200) 20180415-140848 64 False\n",
      "cropping_size: \t10\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_200_20180415-140848.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 200, 200, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 180, 180, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 200, 200, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 901s 301ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 31s 315ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 63s 319ms/step\n",
      "(191261, 1536)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 1536)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 1536)\n",
      "Spend time: 1068.4006469249725 s\n"
     ]
    }
   ],
   "source": [
    "get_all_features(64, 200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180415-150022\n",
      "Xception start.\n",
      "(300, 300) 20180415-150022 64 False\n",
      "cropping_size: \t15\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_300_20180415-150022.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 300, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 270, 270, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 300, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 1030s 345ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 35s 358ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 72s 362ms/step\n",
      "(191261, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 2048)\n",
      "Spend time: 1174.2563228607178 s\n",
      "InceptionV3 start.\n",
      "(300, 300) 20180415-150022 64 False\n",
      "cropping_size: \t15\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_300_20180415-150022.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 300, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 270, 270, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 300, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 1004s 336ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 34s 341ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 69s 348ms/step\n",
      "(191261, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 2048)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 2048)\n",
      "Spend time: 1158.8335719108582 s\n",
      "InceptionResNetV2 start.\n",
      "(300, 300) 20180415-150022 64 False\n",
      "cropping_size: \t15\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_300_20180415-150022.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 300, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 270, 270, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 300, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "2989/2989 [==============================] - 1046s 350ms/step\n",
      "val_generator\n",
      "6301\n",
      "val_generator_steps=99\n",
      "99/99 [==============================] - 36s 368ms/step\n",
      "test_generator\n",
      "12652\n",
      "test_generator_steps=198\n",
      "198/198 [==============================] - 72s 364ms/step\n",
      "(191261, 1536)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(6301, 1536)\n",
      "[  0   0   0 ... 127 127 127]\n",
      "(12652, 1536)\n",
      "Spend time: 1245.7666971683502 s\n"
     ]
    }
   ],
   "source": [
    "get_all_features(64, 300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print('*'*80, end='  ')\n",
    "#     print('%s' % i)\n",
    "#     get_all_features(256, 300, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180415-160702\n",
      "Xception start.\n",
      "(600, 600) 20180415-160702 64 False\n",
      "cropping_size: \t30\n",
      "cpu_amount: \t8\n",
      "Existed folder: /data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "/data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_600_20180415-160702.h5\n",
      "input_tensor:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 600, 600, 3)\n",
      "preprocess_input\n",
      "x:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 540, 540, 3)\n",
      "base_model.input:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 600, 600, 3)\n",
      "do not have augumentation\n",
      "Found 191261 images belonging to 128 classes.\n",
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n",
      "train_generator\n",
      "191261\n",
      "train_generator_steps=2989\n",
      "  78/2989 [..............................] - ETA: 56:19"
     ]
    }
   ],
   "source": [
    "get_all_features(64, 600, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_features(64, 450, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('*'*80, end='  ')\n",
    "    print('%s' % i)\n",
    "    get_all_features(64, 600, True)\n",
    "    get_all_features(64, 450, True)\n",
    "    get_all_features(64, 300, True)\n",
    "    get_all_features(64, 200, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
