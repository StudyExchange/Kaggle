{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Repredict\n",
    "\n",
    "\n",
    "Abstract\n",
    "- 加载CNN model，并使用data_generator预测多次，然后ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: ic_furniture2018_Repredict_20180507_114547\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'ic_furniture2018'\n",
    "step_name = 'Repredict'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improtant Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_mean (224, 224) 32\n"
     ]
    }
   ],
   "source": [
    "statistics_type = 'val_mean'\n",
    "\n",
    "target_size = (224, 224) # default\n",
    "batch_size = 32 # default\n",
    "\n",
    "print(statistics_type, target_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cpu_amount = cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input\n",
      "output_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/output\n",
      "model_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/model\n",
      "feature_folder: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "post_pca_feature_folder: \t/data1/kaggle/imaterialist-challenge-furniture-2018/post_pca_feature\n",
      "log_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/log\n",
      "\n",
      "train_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.json\n",
      "val_json_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.json\n",
      "test_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.json\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.csv\n",
      "val_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.csv\n",
      "\n",
      "sample_submission_csv_file: \t/data1/kaggle/imaterialist-challenge-furniture-2018/input/sample_submission_randomlabel.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "post_pca_feature_folder = os.path.join(cwd, 'post_pca_feature')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('post_pca_feature_folder: \\t%s' % post_pca_feature_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_val_folder = os.path.join(input_folder, 'org_val')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "if not os.path.exists(post_pca_feature_folder):\n",
    "    os.mkdir(post_pca_feature_folder)\n",
    "    print('Create folder: %s' % post_pca_feature_folder)\n",
    "\n",
    "train_json_file = os.path.join(input_folder, 'train.json')\n",
    "val_json_file = os.path.join(input_folder, 'validation.json')\n",
    "test_json_file = os.path.join(input_folder, 'test.json')\n",
    "print('\\ntrain_json_file: \\t\\t%s' % train_json_file)\n",
    "print('val_json_file: \\t\\t\\t%s' % val_json_file)\n",
    "print('test_json_file: \\t\\t%s' % test_json_file)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "val_csv_file = os.path.join(input_folder, 'validation.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('val_csv_file: \\t\\t\\t%s' % val_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission_randomlabel.csv')\n",
    "print('\\nsample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (194828, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t2857/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.tengdakeli.cn/350/timg01/uploaded/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1         5  https://img13.360buyimg.com/imgzone/jfs/t2857/...\n",
       "1         2         5  http://www.tengdakeli.cn/350/timg01/uploaded/i..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_csv.shape is (6400, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>http://www.ghs.net/public/images/fb/3d/51/3beb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>https://img.alicdn.com/imgextra/TB2chFei9YH8KJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1        38  http://www.ghs.net/public/images/fb/3d/51/3beb...\n",
       "1         2        63  https://img.alicdn.com/imgextra/TB2chFei9YH8KJ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "val_csv = pd.read_csv(val_csv_file)\n",
    "print('val_csv.shape is {0}.'.format(val_csv.shape))\n",
    "display(val_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "print('sample_submission_csv.shape is {0}.'.format(sample_submission_csv.shape))\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_train_label_id_dict)=194828\n",
      "id: 1, \tlandmark_id:5\n",
      "id: 2, \tlandmark_id:5\n",
      "2_5.jpg\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['image_id']\n",
    "train_label_id = train_csv['label_id']\n",
    "\n",
    "id_2_train_label_id_dict = dict(zip(train_id, train_label_id))\n",
    "print('len(id_2_train_label_id_dict)=%d' % len(id_2_train_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (train_id[index], id_2_train_label_id_dict[train_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_val_label_id_dict)=6400\n",
      "id: 1, \tlandmark_id:38\n",
      "id: 2, \tlandmark_id:63\n",
      "2_63.jpg\n"
     ]
    }
   ],
   "source": [
    "val_id = val_csv['image_id']\n",
    "val_label_id = val_csv['label_id']\n",
    "\n",
    "id_2_val_label_id_dict = dict(zip(val_id, val_label_id))\n",
    "print('len(id_2_val_label_id_dict)=%d' % len(id_2_val_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (val_id[index], id_2_val_label_id_dict[val_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "id: 2\n",
      "2.jpg\n"
     ]
    }
   ],
   "source": [
    "test_id = test_csv['image_id']\n",
    "\n",
    "index = 0\n",
    "print('id: %s' % (test_id[index]))\n",
    "index = 1\n",
    "print('id: %s' % (test_id[index]))\n",
    "\n",
    "image_file = '%s.jpg' % (test_id[index])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='wrap'\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='wrap'\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='wrap'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = os.path.join(input_folder, 'data_train')\n",
    "data_val_path = os.path.join(input_folder, 'data_val')\n",
    "data_test_path = os.path.join(input_folder, 'data_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6301 images belonging to 128 classes.\n",
      "Found 12652 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_generator = train_gen.flow_from_directory(data_train_path, target_size, shuffle=True, batch_size=batch_size)\n",
    "val_generator = val_gen.flow_from_directory(data_val_path, target_size, shuffle=False, batch_size=batch_size)\n",
    "test_generator = test_gen.flow_from_directory(data_test_path, target_size, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "['test/1.jpg', 'test/10.jpg', 'test/100.jpg', 'test/1000.jpg', 'test/10000.jpg', 'test/10001.jpg', 'test/10002.jpg', 'test/10003.jpg', 'test/10004.jpg', 'test/10005.jpg']\n"
     ]
    }
   ],
   "source": [
    "# print(train_generator.classes[:10])\n",
    "print(val_generator.classes[:10])\n",
    "print(test_generator.classes[:10])\n",
    "\n",
    "print(test_generator.filenames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val_generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: ic_furniture2018_TrainPredict_FineTune1_20180505_091959_8284.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180422_163907_8367.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.h5\n",
      "File exists: ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.h5\n"
     ]
    }
   ],
   "source": [
    "model_files = [\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_053404_7941.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_061203_7987.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_070425_8115.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_071659_8120.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_072816_8131.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_075023_8175.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_080533_8136.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_Train-Predict_Mix3model_20180415_081948_8214.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_TrainPredict_Mix3model_20180429_100055_8077.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_TrainPredict_Mix3model_20180429_102052_8077.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_TrainPredict_Mix3model_20180429_103656_8060.h5'},\n",
    "#     { 'model_name': 'ic_furniture2018_TrainPredict_Mix3model_20180429_110955_8066.h5'},\n",
    "    \n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune1_20180505_091959_8284.h5', 'image_size': 224},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.h5', 'image_size': 299},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.h5', 'image_size': 299},\n",
    "#     { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180419_141628_2393.h5', 'image_size': 450},\n",
    "#     { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180419_141628_8255.h5', 'image_size': 450},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.h5', 'image_size': 224},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180422_163907_8367.h5', 'image_size': 300},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.h5', 'image_size': 300},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.h5', 'image_size': 200},\n",
    "    { 'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.h5', 'image_size': 300},\n",
    "]\n",
    "\n",
    "\n",
    "# load_model(filepath)\n",
    "\n",
    "for model_file in model_files:\n",
    "    if os.path.exists(os.path.join(model_folder, model_file['model_name'])):\n",
    "        print('File exists: %s' % model_file['model_name'])\n",
    "    else:\n",
    "        print('***File do not exists: %s' % model_file['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_acc(model, generator, epoch=10, y_data=None):\n",
    "    print('|', end='')\n",
    "    y_data_probas = []\n",
    "    y_data_accs = []\n",
    "    for i in range(epoch):\n",
    "        print('*', end='')\n",
    "        epoch_start = time.time()\n",
    "        y_data_proba_temp = model.predict_generator(\n",
    "            generator,\n",
    "            max_queue_size=128,\n",
    "            workers=cpu_amount,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        if y_data is not None:\n",
    "            y_data_pred_temp = np.argmax(y_data_proba_temp, -1)\n",
    "            acc = accuracy_score(y_data, y_data_pred_temp)\n",
    "            y_data_accs = y_data_accs + acc\n",
    "        y_data_probas.append(y_data_proba_temp)\n",
    "        print(' %.1fs ' % (time.time() - epoch_start), end='')\n",
    "    print('|', end='')\n",
    "    print(len(y_data_probas), end=' ')\n",
    "    print(y_data_probas[0].shape, end=' ')\n",
    "    return y_data_probas, y_data_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/kaggle/imaterialist-challenge-furniture-2018/model/generator.dat\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune1_20180505_091959_8284.h5', 'image_size': 224}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 49.9s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.h5', 'image_size': 299}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 66.6s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.h5', 'image_size': 299}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 67.9s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.h5', 'image_size': 224}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 60.8s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180422_163907_8367.h5', 'image_size': 300}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 69.1s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.h5', 'image_size': 300}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 75.6s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.h5', 'image_size': 200}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 69.2s |1 (6301, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.h5', 'image_size': 300}\n",
      "Found 6301 images belonging to 128 classes.\n",
      "|* 99.6s |1 (6301, 128) []\n"
     ]
    }
   ],
   "source": [
    "def predict(model_files, gen, data_path, is_test=False, epoch=1, batch_size=32):\n",
    "    y_data_probas = []\n",
    "    for model_dict in model_files:\n",
    "        print(model_dict)\n",
    "        model_file = os.path.join(model_folder, model_dict['model_name'])\n",
    "        target_size = (model_dict['image_size'], model_dict['image_size'])\n",
    "        generator = gen.flow_from_directory(data_path, target_size, shuffle=False, batch_size=batch_size)\n",
    "        y_data = None\n",
    "        if is_test is not True:\n",
    "            y_data = generator.classes\n",
    "        model = load_model(model_file, custom_objects={'imagenet_utils': imagenet_utils})\n",
    "        try:\n",
    "            y_data_proba_single, y_data_acc_single = predict_acc(model, generator, epoch, y_data)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            continue\n",
    "        print(y_data_acc_single)\n",
    "        y_data_probas = y_data_probas + y_data_proba_single\n",
    "    return y_data_probas\n",
    "\n",
    "import pickle\n",
    "generator_file = os.path.join(model_folder, \"generator.dat\")\n",
    "print(generator_file)\n",
    "pickle.dump(val_gen, open(generator_file, \"wb\"), True)\n",
    "val_gen1 = pickle.load(open(generator_file, \"rb\"))\n",
    "\n",
    "y_val_probas = predict(model_files, val_gen1, data_val_path, False, 1, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic statistical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(6301, 128)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_val_probas))\n",
    "print(y_val_probas[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_pred, y_proba):\n",
    "    max_indexes = np.argmax(y_proba, -1)\n",
    "    return accuracy_score(y_pred ,max_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********probas_mean.shape: \t (6301, 128)\n",
      "CPU times: user 52 ms, sys: 20 ms, total: 72 ms\n",
      "Wall time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_mean(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_mean = np.mean(probas_newaxis, axis=-1)\n",
    "    print('probas_mean.shape: \\t', probas_mean.shape)\n",
    "    return probas_mean\n",
    "\n",
    "ensemble_res['val_mean'] = get_acc(y_val ,get_mean(y_val_probas))\n",
    "# y_test_proba_mean = get_mean(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********probas_max.shape: \t (6301, 128)\n",
      "CPU times: user 60 ms, sys: 4 ms, total: 64 ms\n",
      "Wall time: 60.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_max(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_max = np.max(probas_newaxis, axis=-1)\n",
    "    print('probas_max.shape: \\t', probas_max.shape)\n",
    "    return probas_max\n",
    "\n",
    "ensemble_res['val_max'] = get_acc(y_val ,get_max(y_val_probas))\n",
    "# y_test_proba_max = get_max(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_mean  \t0.8605\tval_max  \t0.8405\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(ensemble_res.keys()):\n",
    "    if i % 2 == 0:\n",
    "        print('%s  \\t%.4f' % (key, ensemble_res[key]), end='\\t')\n",
    "    else:\n",
    "        print('%s  \\t%.4f' % (key, ensemble_res[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune1_20180505_091959_8284.h5', 'image_size': 224}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 139.8s * 127.2s * 127.3s * 96.7s * 97.9s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.h5', 'image_size': 299}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 181.9s * 169.0s * 131.0s * 130.6s * 130.8s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.h5', 'image_size': 299}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 197.6s * 131.2s * 131.5s * 131.1s * 131.0s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.h5', 'image_size': 224}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 174.1s * 128.5s * 128.2s * 99.2s * 99.3s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180422_163907_8367.h5', 'image_size': 300}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 207.6s * 167.3s * 124.9s * 127.7s * 165.5s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.h5', 'image_size': 300}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 214.8s * 128.8s * 129.2s * 129.3s * 128.8s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.h5', 'image_size': 200}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 199.2s * 92.1s * 90.5s * 92.0s * 118.8s |5 (12652, 128) []\n",
      "{'model_name': 'ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.h5', 'image_size': 300}\n",
      "Found 12652 images belonging to 1 classes.\n",
      "|* 281.8s * 131.9s * 132.1s * 131.7s * 132.3s |5 (12652, 128) []\n"
     ]
    }
   ],
   "source": [
    "y_test_probas = predict(model_files, test_gen, data_test_path, False, 5, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "(12652, 128)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test_probas))\n",
    "print(y_test_probas[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************probas_mean.shape: \t (12652, 128)\n",
      "****************************************probas_max.shape: \t (12652, 128)\n"
     ]
    }
   ],
   "source": [
    "y_test_proba_mean = get_mean(y_test_probas)\n",
    "y_test_proba_max = get_max(y_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 20.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if statistics_type == 'val_mean':\n",
    "    max_indexes = np.argmax(y_test_proba_mean, -1)\n",
    "elif statistics_type == 'val_min':\n",
    "    max_indexes = np.argmax(y_test_proba_min, -1)\n",
    "elif statistics_type == 'val_max':\n",
    "    max_indexes = np.argmax(y_test_proba_max, -1)\n",
    "else: \n",
    "    # statistics_type == 'val_median'\n",
    "    max_indexes = np.argmax(y_test_proba_median, -1)\n",
    "# print(xg_test_pred.shape)\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "test_dict = {}\n",
    "for pair in zip(test_filenames, max_indexes):\n",
    "    image_name, indx = pair[0], int(pair[1])\n",
    "    image_name = image_name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print(pair[0], image_name, image_id, indx, indx+1, type(image_id), type(indx))\n",
    "    test_dict[image_id] = indx + 1\n",
    "\n",
    "#确认图片的id是否能与ImageDataGenerator()对应上\n",
    "for name in test_filenames[:10]:\n",
    "    image_name = name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print('%s\\t%s\\t%s' % (name, image_id, test_dict[image_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(len_sample_submission_csv)=12800\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         12\n",
       "1   2         71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 0 ns, total: 10.9 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sample_submission_csv = len(sample_submission_csv)\n",
    "print('len(len_sample_submission_csv)=%d' % len_sample_submission_csv)\n",
    "count = 0\n",
    "for i in range(len_sample_submission_csv):\n",
    "    image_id = int(sample_submission_csv.iloc[i, 0])\n",
    "    if image_id in test_dict:\n",
    "        pred_label = test_dict[image_id]\n",
    "#         print('%s\\t%s' % (image_id, pred_label))\n",
    "        sample_submission_csv.iloc[i, 1] = pred_label\n",
    "    else:\n",
    "#         print('%s\\t%s' % (image_id, 20))\n",
    "        sample_submission_csv.iloc[i, 1] = 20 # 属于20的类最多，所以全都设置成这个类，可能会比设置成其他得到的结果好\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(int(count/1000), end=' ')\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(sample_submission_csv['predicted'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_furniture2018_Repredict_20180507_114547_8604\n"
     ]
    }
   ],
   "source": [
    "run_name_acc = run_name + '_' + str(int(ensemble_res[statistics_type]*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "sample_submission_csv.to_csv(pred_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 12959.18 s\n",
      "val_mean\n",
      "ic_furniture2018_Repredict_20180507_114547_8604\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "print(statistics_type)\n",
    "\n",
    "print(run_name_acc)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
