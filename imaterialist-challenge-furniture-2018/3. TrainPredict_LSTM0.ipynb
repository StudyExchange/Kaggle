{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TrainPredict_LSTM0\n",
    "## Result:\n",
    "- Kaggle score: 0.99270\n",
    "\n",
    "## Tensorboard:\n",
    "- Input at command: tensorboard --logdir=./log\n",
    "- Input at browser: http://127.0.0.1:6006\n",
    "\n",
    "## Reference:\n",
    "- https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: ic_furniture2018_TrainPredict_LSTM0_20180416_134642\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'ic_furniture2018'\n",
    "step_name = 'TrainPredict_LSTM0'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import zipfile\n",
    "import pickle\n",
    "import math\n",
    "import pdb\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input\n",
      "output_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/output\n",
      "model_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/model\n",
      "feature_folder: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "post_pca_feature_folder: \t/data1/kaggle/imaterialist-challenge-furniture-2018/post_pca_feature\n",
      "log_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/log\n",
      "\n",
      "train_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.json\n",
      "val_json_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.json\n",
      "test_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.json\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.csv\n",
      "val_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.csv\n",
      "\n",
      "sample_submission_csv_file: \t/data1/kaggle/imaterialist-challenge-furniture-2018/input/sample_submission_randomlabel.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "post_pca_feature_folder = os.path.join(cwd, 'post_pca_feature')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('post_pca_feature_folder: \\t%s' % post_pca_feature_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_val_folder = os.path.join(input_folder, 'org_val')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "if not os.path.exists(post_pca_feature_folder):\n",
    "    os.mkdir(post_pca_feature_folder)\n",
    "    print('Create folder: %s' % post_pca_feature_folder)\n",
    "\n",
    "train_json_file = os.path.join(input_folder, 'train.json')\n",
    "val_json_file = os.path.join(input_folder, 'validation.json')\n",
    "test_json_file = os.path.join(input_folder, 'test.json')\n",
    "print('\\ntrain_json_file: \\t\\t%s' % train_json_file)\n",
    "print('val_json_file: \\t\\t\\t%s' % val_json_file)\n",
    "print('test_json_file: \\t\\t%s' % test_json_file)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "val_csv_file = os.path.join(input_folder, 'validation.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('val_csv_file: \\t\\t\\t%s' % val_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission_randomlabel.csv')\n",
    "print('\\nsample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (194828, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t2857/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.tengdakeli.cn/350/timg01/uploaded/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1         5  https://img13.360buyimg.com/imgzone/jfs/t2857/...\n",
       "1         2         5  http://www.tengdakeli.cn/350/timg01/uploaded/i..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_csv.shape is (6400, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>http://www.ghs.net/public/images/fb/3d/51/3beb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>https://img.alicdn.com/imgextra/TB2chFei9YH8KJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1        38  http://www.ghs.net/public/images/fb/3d/51/3beb...\n",
       "1         2        63  https://img.alicdn.com/imgextra/TB2chFei9YH8KJ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "val_csv = pd.read_csv(val_csv_file)\n",
    "print('val_csv.shape is {0}.'.format(val_csv.shape))\n",
    "display(val_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "print('sample_submission_csv.shape is {0}.'.format(sample_submission_csv.shape))\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_train_label_id_dict)=194828\n",
      "id: 1, \tlandmark_id:5\n",
      "id: 2, \tlandmark_id:5\n",
      "2_5.jpg\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['image_id']\n",
    "train_label_id = train_csv['label_id']\n",
    "\n",
    "id_2_train_label_id_dict = dict(zip(train_id, train_label_id))\n",
    "print('len(id_2_train_label_id_dict)=%d' % len(id_2_train_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (train_id[index], id_2_train_label_id_dict[train_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_val_label_id_dict)=6400\n",
      "id: 1, \tlandmark_id:38\n",
      "id: 2, \tlandmark_id:63\n",
      "2_63.jpg\n"
     ]
    }
   ],
   "source": [
    "val_id = val_csv['image_id']\n",
    "val_label_id = val_csv['label_id']\n",
    "\n",
    "id_2_val_label_id_dict = dict(zip(val_id, val_label_id))\n",
    "print('len(id_2_val_label_id_dict)=%d' % len(id_2_val_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (val_id[index], id_2_val_label_id_dict[val_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "id: 2\n",
      "2.jpg\n"
     ]
    }
   ],
   "source": [
    "test_id = test_csv['image_id']\n",
    "\n",
    "index = 0\n",
    "print('id: %s' % (test_id[index]))\n",
    "index = 1\n",
    "print('id: %s' % (test_id[index]))\n",
    "\n",
    "image_file = '%s.jpg' % (test_id[index])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 0 ns, total: 56 ms\n",
      "Wall time: 51.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "\n",
    "def load_h5_data(data_str, feature_folder, file_reg, model_name, time_str):\n",
    "    x_data = {}\n",
    "    y_data = {}\n",
    "    \n",
    "    feature_model = os.path.join(feature_folder, file_reg % (model_name, time_str))\n",
    "    for filename in [feature_model]:\n",
    "        with h5py.File(filename, 'r') as h:\n",
    "            x_data = np.array(h[data_str])\n",
    "            y_data = np.array(h['%s_labels' % data_str])\n",
    "    return x_data, y_data\n",
    "\n",
    "def load_h5_test(feature_folder, file_reg, model_name, time_str):\n",
    "    x_test = {}\n",
    "    \n",
    "    feature_model = os.path.join(feature_folder, file_reg % (model_name, time_str))\n",
    "    for filename in [feature_model]:\n",
    "        with h5py.File(filename, 'r') as h:\n",
    "            x_test = np.array(h['test'])\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_MobileNet_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG16_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG19_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_ResNet50_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet121_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet169_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet201_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_20180331-163122.h5\n",
      "True\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n",
      "  20180331-163122\n"
     ]
    }
   ],
   "source": [
    "def is_files_existed(feature_folder, file_reg, model_names, time_strs):\n",
    "    for model_name in model_names:\n",
    "        for time_str in time_strs:\n",
    "            file_name = file_reg % (model_name, time_str)\n",
    "            file_path = os.path.join(feature_folder, file_name)\n",
    "            if not os.path.exists(file_path):\n",
    "                print('File not existed: %s' % file_path)\n",
    "                return False\n",
    "            else:\n",
    "                print('File existed: %s' % file_path)\n",
    "    return True\n",
    "\n",
    "# Test\n",
    "file_reg = 'feature_%s_%s.h5'\n",
    "model_names = ['MobileNet', \n",
    "               'VGG16',\n",
    "               'VGG19',\n",
    "               'ResNet50',\n",
    "               'DenseNet121',\n",
    "               'DenseNet169',\n",
    "               'DenseNet201',\n",
    "               'Xception', \n",
    "               'InceptionV3', \n",
    "               'InceptionResNetV2']\n",
    "time_strs = ['20180331-163122']\n",
    "\n",
    "print(is_files_existed(feature_folder, file_reg, model_names, time_strs))\n",
    "\n",
    "\n",
    "def time_str_generator(time_strs):\n",
    "    while(1):\n",
    "        for time_str in time_strs:\n",
    "            print('  ' + time_str)\n",
    "            yield time_str\n",
    "            \n",
    "# Test\n",
    "time_str_gen = time_str_generator(time_strs)\n",
    "for i in range(10):\n",
    "    next(time_str_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 128\n",
      "************************************************************\n",
      "timesteps: 10\n",
      "len(train_data): 194828\n",
      "batch_size: 128\n",
      "steps_per_epoch_train: 1520\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_MobileNet_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG16_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG19_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_ResNet50_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet121_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet169_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet201_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_20180331-163122.h5\n",
      "  20180331-163122\n",
      "(128, 10, 2048) (128, 128)\n",
      "(128, 10, 2048) (128, 128)\n",
      "************************************************************\n",
      "len(val_data): 6400\n",
      "batch_size: 128\n",
      "steps_per_epoch_val: 50\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_MobileNet_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG16_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG19_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_ResNet50_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet121_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet169_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet201_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_20180331-163122.h5\n",
      "  20180331-163122\n",
      "(128, 10, 2048) (128, 128)\n",
      "(128, 10, 2048) (128, 128)\n",
      "********************************************************************************\n",
      "data_dim: 2048\n",
      "CPU times: user 12.3 s, sys: 29.6 s, total: 42 s\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_time_str_feature_data(data_str, feature_folder, file_reg, model_names, time_str):\n",
    "    x_data_time_strs = []\n",
    "    y_data_time_strs = None\n",
    "    for model_name in model_names:\n",
    "        x_data_time_str, y_data_time_str = load_h5_data(data_str, feature_folder, file_reg, model_name, time_str)\n",
    "\n",
    "        x_data_time_strs.append(x_data_time_str)\n",
    "        y_data_time_strs = y_data_time_str\n",
    "    \n",
    "    # Get max dimension\n",
    "    max_dim = 0\n",
    "    for data in x_data_time_strs:\n",
    "        data_dim = data.shape[-1]\n",
    "#         print('data_dim=%s' % data_dim)\n",
    "        if max_dim < data_dim:\n",
    "            max_dim = data_dim\n",
    "#     print('max_dim=%s' % max_dim)\n",
    "    \n",
    "    # Align to max dimension\n",
    "    for i, data in enumerate(x_data_time_strs):\n",
    "        data_dim = data.shape[-1]\n",
    "#         print(data.shape)\n",
    "#         print('data_dim=%s' % data_dim)\n",
    "        \n",
    "        if data_dim < max_dim:\n",
    "            new_datas = []\n",
    "            end_dim = 0\n",
    "            for j in range(int(max_dim/data_dim) + 1):\n",
    "                end_dim += data_dim\n",
    "#                 print('end_dim=%s' % end_dim)\n",
    "#                 pdb.set_trace()\n",
    "                if end_dim <= max_dim:\n",
    "#                     print(0, data_dim)\n",
    "                    temp = np.array(data[:, 0: data_dim], copy=True)\n",
    "                else:\n",
    "#                     print(0, end_dim - max_dim)\n",
    "                    temp = np.array(data[:, 0: (max_dim - (end_dim - data_dim))], copy=True)\n",
    "#                 print(temp.shape)\n",
    "                    \n",
    "#                     pdb.set_trace()\n",
    "                new_datas.append(temp)\n",
    "#             pdb.set_trace()\n",
    "            x_data_time_strs[i] = np.concatenate(new_datas, axis=-1)\n",
    "#             print(x_data_time_strs[i].shape)\n",
    "#             print('*'*20)\n",
    "        x_data_time_strs[i] = x_data_time_strs[i][:, np.newaxis, :]\n",
    "#         print(x_data_time_strs[i].shape)\n",
    "#         print('*'*40)\n",
    "    x_data_time_strs = np.concatenate(x_data_time_strs, axis=1)\n",
    "#     print(x_data_time_strs.shape)\n",
    "#     print(y_data_time_strs.shape)\n",
    "#     print('*'*40)\n",
    "    return x_data_time_strs, y_data_time_strs\n",
    "\n",
    "def data_generator_folder(data_str, feature_folder, file_reg, model_names, time_strs, batch_size, num_classes):\n",
    "    assert is_files_existed(feature_folder, file_reg, model_names, time_strs)\n",
    "\n",
    "    time_str_gen = time_str_generator(time_strs)\n",
    "    x_data, y_data = load_time_str_feature_data(data_str, feature_folder, file_reg, model_names, next(time_str_gen))\n",
    "    len_x_data = len(x_data)\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    while(1):\n",
    "        end_index = start_index + batch_size\n",
    "        if end_index < len_x_data:\n",
    "#             print(start_index, end_index, end=' ')\n",
    "            x_batch = x_data[start_index: end_index, :]\n",
    "            y_batch = y_data[start_index: end_index]\n",
    "            y_batch_cat = to_categorical(y_batch, num_classes)\n",
    "            \n",
    "            start_index = start_index + batch_size\n",
    "#             print(x_batch.shape, y_batch_cat.shape)\n",
    "            yield x_batch, y_batch_cat\n",
    "        else:\n",
    "            end_index = end_index-len_x_data\n",
    "#             print(start_index, end_index, end=' ')\n",
    "            x_data_old = np.array(x_data[start_index:, :], copy=True)\n",
    "            y_data_old = np.array(y_data[start_index:], copy=True)\n",
    "            # Load new datas\n",
    "            x_data, y_data = load_time_str_feature_data(data_str, feature_folder, file_reg, model_names, next(time_str_gen))\n",
    "            x_data, y_data = shuffle(x_data, y_data, random_state=2018)\n",
    "            len_x_data = len(x_data)\n",
    "            gc.collect()\n",
    "            x_batch = np.vstack((x_data_old, x_data[:end_index, :]))\n",
    "            y_batch = np.concatenate([y_data_old, y_data[:end_index]])\n",
    "            y_batch_cat = to_categorical(y_batch, num_classes)\n",
    "            \n",
    "            start_index = end_index\n",
    "#             print(x_batch.shape, y_batch_cat.shape)\n",
    "            yield x_batch, y_batch_cat\n",
    "        \n",
    "    \n",
    "# x_train = np.concatenate([x_train_Xception, x_train_InceptionV3, x_train_InceptionResNetV2], axis=-1)\n",
    "\n",
    "num_classes = len(list(set(train_label_id)))\n",
    "print('num_classes: %s' % num_classes)\n",
    "\n",
    "file_reg = 'feature_%s_%s.h5'\n",
    "model_names = [\n",
    "    'MobileNet', \n",
    "    'VGG16',\n",
    "    'VGG19',\n",
    "    'ResNet50',\n",
    "    'DenseNet121',\n",
    "    'DenseNet169',\n",
    "    'DenseNet201',\n",
    "    'Xception',\n",
    "    'InceptionV3',\n",
    "    'InceptionResNetV2'\n",
    "]\n",
    "\n",
    "time_strs = ['20180331-163122']\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "print('*' * 60)\n",
    "timesteps = len(model_names)\n",
    "len_train_csv = train_csv.shape[0]\n",
    "steps_per_epoch_train = int(len_train_csv/batch_size) - 2\n",
    "print('timesteps: %s' % timesteps)\n",
    "print('len(train_data): %s' % len_train_csv)\n",
    "print('batch_size: %s' % batch_size)\n",
    "print('steps_per_epoch_train: %s' % steps_per_epoch_train)\n",
    "\n",
    "train_gen = data_generator_folder('train', feature_folder, file_reg, model_names, time_strs, batch_size, num_classes)\n",
    "batch_data = next(train_gen)\n",
    "print(batch_data[0].shape, batch_data[1].shape)\n",
    "batch_data = next(train_gen)\n",
    "print(batch_data[0].shape, batch_data[1].shape)\n",
    "# for i in range(steps_per_epoch_train*5):\n",
    "#     next(train_gen)\n",
    "\n",
    "print('*' * 60)\n",
    "len_val_csv = val_csv.shape[0]\n",
    "steps_per_epoch_val = int(len_val_csv/batch_size)\n",
    "print('len(val_data): %s' % len_val_csv)\n",
    "print('batch_size: %s' % batch_size)\n",
    "print('steps_per_epoch_val: %s' % steps_per_epoch_val)\n",
    "val_gen = data_generator_folder('val', feature_folder, file_reg, model_names, time_strs, batch_size, num_classes)\n",
    "batch_data = next(val_gen)\n",
    "print(batch_data[0].shape, batch_data[1].shape)\n",
    "batch_data = next(val_gen)\n",
    "print(batch_data[0].shape, batch_data[1].shape)\n",
    "\n",
    "print('*' * 80)\n",
    "data_dim = batch_data[0].shape[-1]\n",
    "print('data_dim: %s' % data_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "len(test_test): 12800\n",
      "batch_size: 128\n",
      "steps_per_epoch_test: 99\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_MobileNet_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG16_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_VGG19_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_ResNet50_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet121_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet169_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_DenseNet201_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_Xception_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionV3_20180331-163122.h5\n",
      "File existed: /data1/kaggle/imaterialist-challenge-furniture-2018/feature/feature_InceptionResNetV2_20180331-163122.h5\n",
      "  20180331-163122\n",
      "(10, 2048) (10, 2048)\n",
      "(10, 2048) (10, 2048)\n",
      "(12652, 10, 2048)\n",
      "CPU times: user 1.93 s, sys: 4.53 s, total: 6.46 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_time_str_feature_test(feature_folder, file_reg, model_names, time_str):\n",
    "    x_test_time_strs = []\n",
    "    for model_name in model_names:\n",
    "        x_test_time_str = load_h5_test(feature_folder, file_reg, model_name, time_str)\n",
    "\n",
    "        x_test_time_strs.append(x_test_time_str)\n",
    "    \n",
    "    # Get max dimension\n",
    "    max_dim = 0\n",
    "    for test in x_test_time_strs:\n",
    "        test_dim = test.shape[-1]\n",
    "#         print('test_dim=%s' % test_dim)\n",
    "        if max_dim < test_dim:\n",
    "            max_dim = test_dim\n",
    "#     print('max_dim=%s' % max_dim)\n",
    "    \n",
    "    # Align to max dimension\n",
    "    for i, test in enumerate(x_test_time_strs):\n",
    "        test_dim = test.shape[-1]\n",
    "#         print(test.shape)\n",
    "#         print('test_dim=%s' % test_dim)\n",
    "        \n",
    "        if test_dim < max_dim:\n",
    "            new_tests = []\n",
    "            end_dim = 0\n",
    "            for j in range(int(max_dim/test_dim) + 1):\n",
    "                end_dim += test_dim\n",
    "#                 print('end_dim=%s' % end_dim)\n",
    "#                 pdb.set_trace()\n",
    "                if end_dim <= max_dim:\n",
    "#                     print(0, test_dim)\n",
    "                    temp = np.array(test[:, 0: test_dim], copy=True)\n",
    "                else:\n",
    "#                     print(0, end_dim - max_dim)\n",
    "                    temp = np.array(test[:, 0: (max_dim - (end_dim - test_dim))], copy=True)\n",
    "#                 print(temp.shape)\n",
    "                    \n",
    "#                     pdb.set_trace()\n",
    "                new_tests.append(temp)\n",
    "#             pdb.set_trace()\n",
    "            x_test_time_strs[i] = np.concatenate(new_tests, axis=-1)\n",
    "#             print(x_test_time_strs[i].shape)\n",
    "#             print('*'*20)\n",
    "        x_test_time_strs[i] = x_test_time_strs[i][:, np.newaxis, :]\n",
    "#         print(x_test_time_strs[i].shape)\n",
    "#         print('*'*40)\n",
    "    x_test_time_strs = np.concatenate(x_test_time_strs, axis=1)\n",
    "#     print(x_test_time_strs.shape)\n",
    "#     print('*'*40)\n",
    "    return x_test_time_strs\n",
    "\n",
    "def test_generator_folder(feature_folder, file_reg, model_names, time_strs, batch_size, num_classes):\n",
    "    assert is_files_existed(feature_folder, file_reg, model_names, time_strs)\n",
    "\n",
    "    time_str_gen = time_str_generator(time_strs)\n",
    "    x_test = load_time_str_feature_test(feature_folder, file_reg, model_names, next(time_str_gen))\n",
    "    len_x_test = len(x_test)\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    while(1):\n",
    "        end_index = start_index + batch_size\n",
    "        if end_index < len_x_test:\n",
    "#             print(start_index, end_index, end=' ')\n",
    "            x_batch = x_test[start_index: end_index, :]\n",
    "            \n",
    "            start_index = start_index + batch_size\n",
    "#             print(x_batch.shape)\n",
    "            yield x_batch\n",
    "        else:\n",
    "            end_index = end_index-len_x_test\n",
    "#             print(start_index, end_index, end=' ')\n",
    "            x_test_old = np.array(x_test[start_index:, :], copy=True)\n",
    "            # Load new tests\n",
    "            x_test = load_time_str_feature_test(feature_folder, file_reg, model_names, next(time_str_gen))\n",
    "            len_x_test = len(x_test)\n",
    "            gc.collect()\n",
    "            x_batch = np.vstack((x_test_old, x_test[:end_index, :]))\n",
    "            \n",
    "            start_index = end_index\n",
    "#             print(x_batch.shape)\n",
    "            yield x_batch\n",
    "        \n",
    "\n",
    "print('*' * 60)\n",
    "len_test_csv = test_csv.shape[0]\n",
    "steps_per_epoch_test = int(len_test_csv/batch_size) - 1\n",
    "print('len(test_test): %s' % len_test_csv)\n",
    "print('batch_size: %s' % batch_size)\n",
    "print('steps_per_epoch_test: %s' % steps_per_epoch_test)\n",
    "\n",
    "test_gen = test_generator_folder(feature_folder, file_reg, model_names, time_strs, batch_size, num_classes)\n",
    "batch_test = next(test_gen)\n",
    "print(batch_test[0].shape, batch_test[1].shape)\n",
    "batch_test = next(test_gen)\n",
    "print(batch_test[0].shape, batch_test[1].shape)\n",
    "\n",
    "\n",
    "x_test = load_time_str_feature_test(feature_folder, file_reg, model_names, time_strs[0])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LSTM, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001  0.0001 9.6e-05  9.6e-05 9.2e-05  9.2e-05 8.8e-05  8.8e-05 8.5e-05  8.5e-05 8.2e-05  8.2e-05 7.8e-05  7.8e-05 7.5e-05  7.5e-05 7.2e-05  7.2e-05 6.9e-05  6.9e-05 6.6e-05  6.6e-05 6.4e-05  6.4e-05 6.1e-05  6.1e-05 5.9e-05  5.9e-05 5.6e-05  5.6e-05 5.4e-05  5.4e-05 5.2e-05  5.2e-05 5e-05  5e-05 4.8e-05  4.8e-05 4.6e-05  4.6e-05 4.4e-05  4.4e-05 4.2e-05  4.2e-05 4.1e-05  4.1e-05 3.9e-05  3.9e-05 3.8e-05  3.8e-05 3.6e-05  3.6e-05 3.5e-05  3.5e-05 3.3e-05  3.3e-05 3.2e-05  3.2e-05 3.1e-05  3.1e-05 \n",
      "log_dir:/data1/kaggle/imaterialist-challenge-furniture-2018/log/ic_furniture2018_Train-Predict_Mix10model_20180401_102538\n"
     ]
    }
   ],
   "source": [
    "def get_lr(x):\n",
    "    lr = round(1e-4 * 0.96 ** x, 6)\n",
    "    if lr < 1e-5:\n",
    "        lr = 1e-5\n",
    "    print(lr, end='  ')\n",
    "    return lr\n",
    "\n",
    "for i in range(30):\n",
    "    print(get_lr(i), end=' ')\n",
    "# annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "annealer = LearningRateScheduler(get_lr)\n",
    "\n",
    "\n",
    "log_dir = os.path.join(log_folder, run_name)\n",
    "print('\\nlog_dir:' + log_dir)\n",
    "tensorBoard = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 10, 2048)          25174016  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 2048)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10, 1024)          10489856  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 10, 1024)          6295552   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 10, 1024)          6295552   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "=================================================================\n",
      "Total params: 54,681,728\n",
      "Trainable params: 54,681,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(1024, return_sequences=True), input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(512)))  # return a single vector of dimension 32\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer=Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1490/1520 [============================>.] - ETA: 16s - loss: 4.2751 - acc: 0.2026  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 4.2869 - acc: 0.1989  20180331-163122\n",
      "1520/1520 [==============================] - 911s 599ms/step - loss: 4.2873 - acc: 0.1988 - val_loss: 4.9067 - val_acc: 0.0088\n",
      "Epoch 2/30\n",
      "1464/1520 [===========================>..] - ETA: 31s - loss: 4.7850 - acc: 0.0179  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 4.7842 - acc: 0.0179  20180331-163122\n",
      "1520/1520 [==============================] - 993s 653ms/step - loss: 4.7842 - acc: 0.0179 - val_loss: 4.9486 - val_acc: 0.0078\n",
      "Epoch 3/30\n",
      "1438/1520 [===========================>..] - ETA: 45s - loss: 4.7657 - acc: 0.0205  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 4.7655 - acc: 0.0205  20180331-163122\n",
      "1520/1520 [==============================] - 1004s 660ms/step - loss: 4.7655 - acc: 0.0205 - val_loss: 4.9532 - val_acc: 0.0077\n",
      "Epoch 4/30\n",
      "1412/1520 [==========================>...] - ETA: 59s - loss: 4.7601 - acc: 0.0209   20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 4.7217 - acc: 0.0253  20180331-163122\n",
      "1520/1520 [==============================] - 1010s 664ms/step - loss: 4.7211 - acc: 0.0254 - val_loss: 3.8876 - val_acc: 0.1047\n",
      "Epoch 5/30\n",
      "1387/1520 [==========================>...] - ETA: 1:13 - loss: 1.6417 - acc: 0.5346  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 1.5924 - acc: 0.5469  20180331-163122\n",
      "1520/1520 [==============================] - 1005s 661ms/step - loss: 1.5921 - acc: 0.5469 - val_loss: 1.2029 - val_acc: 0.6448\n",
      "Epoch 6/30\n",
      "1361/1520 [=========================>....] - ETA: 1:28 - loss: 0.9433 - acc: 0.7174  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.9314 - acc: 0.7209  20180331-163122\n",
      "1520/1520 [==============================] - 985s 648ms/step - loss: 0.9314 - acc: 0.7209 - val_loss: 0.9945 - val_acc: 0.7031\n",
      "Epoch 7/30\n",
      "1335/1520 [=========================>....] - ETA: 1:42 - loss: 0.7714 - acc: 0.7672  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.7626 - acc: 0.7694  20180331-163122\n",
      "1520/1520 [==============================] - 992s 653ms/step - loss: 0.7625 - acc: 0.7694 - val_loss: 0.9409 - val_acc: 0.7247\n",
      "Epoch 8/30\n",
      "1309/1520 [========================>.....] - ETA: 1:57 - loss: 0.6672 - acc: 0.7955  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.6585 - acc: 0.7977  20180331-163122\n",
      "1520/1520 [==============================] - 995s 654ms/step - loss: 0.6584 - acc: 0.7977 - val_loss: 0.8919 - val_acc: 0.7392\n",
      "Epoch 9/30\n",
      "1284/1520 [========================>.....] - ETA: 2:10 - loss: 0.5862 - acc: 0.8196  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.8212  20180331-163122\n",
      "1520/1520 [==============================] - 983s 647ms/step - loss: 0.5788 - acc: 0.8212 - val_loss: 0.8661 - val_acc: 0.7492\n",
      "Epoch 10/30\n",
      "1258/1520 [=======================>......] - ETA: 2:25 - loss: 0.5177 - acc: 0.8390  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.8403  20180331-163122\n",
      "1520/1520 [==============================] - 998s 657ms/step - loss: 0.5119 - acc: 0.8403 - val_loss: 0.8448 - val_acc: 0.7606\n",
      "Epoch 11/30\n",
      "1232/1520 [=======================>......] - ETA: 2:39 - loss: 0.4614 - acc: 0.8550  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8570  20180331-163122\n",
      "1520/1520 [==============================] - 997s 656ms/step - loss: 0.4548 - acc: 0.8570 - val_loss: 0.8542 - val_acc: 0.7611\n",
      "Epoch 12/30\n",
      "1206/1520 [======================>.......] - ETA: 2:54 - loss: 0.4141 - acc: 0.8687  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8703  20180331-163122\n",
      "1520/1520 [==============================] - 982s 646ms/step - loss: 0.4084 - acc: 0.8702 - val_loss: 0.8383 - val_acc: 0.7742\n",
      "Epoch 13/30\n",
      "1180/1520 [======================>.......] - ETA: 3:08 - loss: 0.3707 - acc: 0.8822  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8839  20180331-163122\n",
      "1520/1520 [==============================] - 999s 657ms/step - loss: 0.3641 - acc: 0.8839 - val_loss: 0.8561 - val_acc: 0.7684\n",
      "Epoch 14/30\n",
      "1155/1520 [=====================>........] - ETA: 3:22 - loss: 0.3304 - acc: 0.8956  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.8962  20180331-163122\n",
      "1520/1520 [==============================] - 988s 650ms/step - loss: 0.3264 - acc: 0.8962 - val_loss: 0.8871 - val_acc: 0.7697\n",
      "Epoch 15/30\n",
      "1129/1520 [=====================>........] - ETA: 3:37 - loss: 0.2990 - acc: 0.9038  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.2944 - acc: 0.9051  20180331-163122\n",
      "1520/1520 [==============================] - 979s 644ms/step - loss: 0.2943 - acc: 0.9051 - val_loss: 0.8578 - val_acc: 0.7842\n",
      "Epoch 16/30\n",
      "1103/1520 [====================>.........] - ETA: 3:51 - loss: 0.2696 - acc: 0.9125  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.2649 - acc: 0.9139  20180331-163122\n",
      "1520/1520 [==============================] - 989s 651ms/step - loss: 0.2648 - acc: 0.9139 - val_loss: 0.8794 - val_acc: 0.7847\n",
      "Epoch 17/30\n",
      "1077/1520 [====================>.........] - ETA: 4:05 - loss: 0.2427 - acc: 0.9209  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9223  20180331-163122\n",
      "1520/1520 [==============================] - 993s 653ms/step - loss: 0.2381 - acc: 0.9223 - val_loss: 0.9099 - val_acc: 0.7837\n",
      "Epoch 18/30\n",
      "1052/1520 [===================>..........] - ETA: 4:19 - loss: 0.2222 - acc: 0.9275  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9292  20180331-163122\n",
      "  20180331-163122\n",
      "1520/1520 [==============================] - 985s 648ms/step - loss: 0.2169 - acc: 0.9292 - val_loss: 0.9232 - val_acc: 0.7780\n",
      "Epoch 19/30\n",
      "1026/1520 [===================>..........] - ETA: 4:34 - loss: 0.2021 - acc: 0.9336  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9353  20180331-163122\n",
      "1520/1520 [==============================] - 996s 655ms/step - loss: 0.1970 - acc: 0.9353 - val_loss: 0.9442 - val_acc: 0.7828\n",
      "Epoch 20/30\n",
      "1000/1520 [==================>...........] - ETA: 4:48 - loss: 0.1822 - acc: 0.9407  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9426  20180331-163122\n",
      "1520/1520 [==============================] - 995s 654ms/step - loss: 0.1769 - acc: 0.9426 - val_loss: 0.9708 - val_acc: 0.7867\n",
      "Epoch 21/30\n",
      " 974/1520 [==================>...........] - ETA: 5:03 - loss: 0.1646 - acc: 0.9468  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9482  20180331-163122\n",
      "1520/1520 [==============================] - 980s 645ms/step - loss: 0.1600 - acc: 0.9482 - val_loss: 0.9944 - val_acc: 0.7797\n",
      "Epoch 22/30\n",
      " 948/1520 [=================>............] - ETA: 5:17 - loss: 0.1456 - acc: 0.9536  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9538  20180331-163122\n",
      "1520/1520 [==============================] - 997s 656ms/step - loss: 0.1439 - acc: 0.9538 - val_loss: 1.0038 - val_acc: 0.7866\n",
      "Epoch 23/30\n",
      " 923/1520 [=================>............] - ETA: 5:31 - loss: 0.1324 - acc: 0.9573  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9577  20180331-163122\n",
      "1520/1520 [==============================] - 998s 656ms/step - loss: 0.1301 - acc: 0.9577 - val_loss: 1.0303 - val_acc: 0.7844\n",
      "Epoch 24/30\n",
      " 897/1520 [================>.............] - ETA: 5:45 - loss: 0.1230 - acc: 0.9605  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9615  20180331-163122\n",
      "1520/1520 [==============================] - 985s 648ms/step - loss: 0.1196 - acc: 0.9615 - val_loss: 1.0177 - val_acc: 0.7897\n",
      "Epoch 25/30\n",
      " 871/1520 [================>.............] - ETA: 6:00 - loss: 0.1135 - acc: 0.9632  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9641  20180331-163122\n",
      "1520/1520 [==============================] - 997s 656ms/step - loss: 0.1100 - acc: 0.9641 - val_loss: 1.0340 - val_acc: 0.7913\n",
      "Epoch 26/30\n",
      " 845/1520 [===============>..............] - ETA: 6:15 - loss: 0.1012 - acc: 0.9672  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9681  20180331-163122\n",
      "1520/1520 [==============================] - 995s 654ms/step - loss: 0.0975 - acc: 0.9682 - val_loss: 1.0642 - val_acc: 0.7883\n",
      "Epoch 27/30\n",
      " 820/1520 [===============>..............] - ETA: 6:28 - loss: 0.0914 - acc: 0.9710  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9712  20180331-163122\n",
      "1520/1520 [==============================] - 982s 646ms/step - loss: 0.0894 - acc: 0.9712 - val_loss: 1.0899 - val_acc: 0.7914\n",
      "Epoch 28/30\n",
      " 794/1520 [==============>...............] - ETA: 6:43 - loss: 0.0856 - acc: 0.9725  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9739  20180331-163122\n",
      "1520/1520 [==============================] - 999s 657ms/step - loss: 0.0815 - acc: 0.9739 - val_loss: 1.1080 - val_acc: 0.7958\n",
      "Epoch 29/30\n",
      " 768/1520 [==============>...............] - ETA: 6:57 - loss: 0.0804 - acc: 0.9745  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9760  20180331-163122\n",
      "1520/1520 [==============================] - 995s 655ms/step - loss: 0.0751 - acc: 0.9760 - val_loss: 1.1483 - val_acc: 0.7909\n",
      "Epoch 30/30\n",
      " 742/1520 [=============>................] - ETA: 7:12 - loss: 0.0712 - acc: 0.9775  20180331-163122\n",
      "1519/1520 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9782  20180331-163122\n",
      "1520/1520 [==============================] - 984s 648ms/step - loss: 0.0681 - acc: 0.9782 - val_loss: 1.1383 - val_acc: 0.7980\n",
      "CPU times: user 6h 23min 8s, sys: 1h 47min 37s, total: 8h 10min 46s\n",
      "Wall time: 8h 14min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = model.fit_generator(train_gen,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=30, #Increase this when not on Kaggle kernel\n",
    "    verbose=1,  #1 for ETA, 0 for silent\n",
    "    callbacks=[annealer],\n",
    "    max_queue_size=2,\n",
    "    workers=4,\n",
    "    use_multiprocessing=False,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20180331-163122\n",
      "Final loss: 1.1461, final accuracy: 0.7964\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate_generator(val_gen, steps=steps_per_epoch_val)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_furniture2018_Train-Predict_LSTM_20180401_184549_7964\n"
     ]
    }
   ],
   "source": [
    "run_name_acc = run_name + '_' + str(int(final_acc*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acc', 'loss', 'val_acc', 'val_loss', 'epoch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "histories = pd.DataFrame(hist.history)\n",
    "histories['epoch'] = hist.epoch\n",
    "print(histories.columns)\n",
    "histories_file = os.path.join(model_folder, run_name_acc + '.csv')\n",
    "histories.to_csv(histories_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(model, run_name):\n",
    "    cwd = os.getcwd()\n",
    "    modelPath = os.path.join(cwd, 'model')\n",
    "    if not os.path.isdir(modelPath):\n",
    "        os.mkdir(modelPath)\n",
    "    weigthsFile = os.path.join(modelPath, run_name + '.h5')\n",
    "    model.save(weigthsFile)\n",
    "save_network(model, run_name_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20180331-163122\n",
      "(12672, 128)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_gen, steps=steps_per_epoch_test)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8362.jpg', '4226.jpg', '12692.jpg', '4545.jpg', '5860.jpg', '1628.jpg', '6360.jpg', '11927.jpg', '10832.jpg', '12667.jpg']\n"
     ]
    }
   ],
   "source": [
    "# os.listdir()list\n",
    "files = os.listdir(os.path.join(cwd, 'input', 'data_test', 'test'))\n",
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12652 images belonging to 1 classes.\n",
      "test_generator\n",
      "12652\n",
      "['test/1.jpg', 'test/10.jpg', 'test/100.jpg', 'test/1000.jpg', 'test/10000.jpg', 'test/10001.jpg', 'test/10002.jpg', 'test/10003.jpg', 'test/10004.jpg', 'test/10005.jpg']\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator()list\n",
    "gen = ImageDataGenerator()\n",
    "image_size = (299, 299)\n",
    "test_generator  = gen.flow_from_directory(test_folder, image_size, shuffle=False, batch_size=batch_size)\n",
    "print('test_generator')\n",
    "print(len(test_generator.filenames))\n",
    "print(test_generator.filenames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12672,)\n",
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 19.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_indexes = np.argmax(y_pred, -1)\n",
    "print(max_indexes.shape)\n",
    "\n",
    "test_dict = {}\n",
    "for pair in zip(test_generator.filenames, max_indexes):\n",
    "    image_name, indx = pair[0], int(pair[1])\n",
    "    image_name = image_name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print(pair[0], image_name, image_id, indx, indx+1, type(image_id), type(indx))\n",
    "    test_dict[image_id] = indx + 1\n",
    "\n",
    "#idImageDataGenerator()\n",
    "for name in test_generator.filenames[:10]:\n",
    "    image_name = name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print('%s\\t%s\\t%s' % (name, image_id, test_dict[image_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1        101\n",
       "1   2        126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(len_sample_submission_csv)=12800\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         84\n",
       "1   2         96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 0 ns, total: 11.5 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sample_submission_csv = len(sample_submission_csv)\n",
    "print('len(len_sample_submission_csv)=%d' % len_sample_submission_csv)\n",
    "count = 0\n",
    "for i in range(len_sample_submission_csv):\n",
    "    image_id = int(sample_submission_csv.iloc[i, 0])\n",
    "    if image_id in test_dict:\n",
    "        pred_label = test_dict[image_id]\n",
    "#         print('%s\\t%s' % (image_id, pred_label))\n",
    "        sample_submission_csv.iloc[i, 1] = pred_label\n",
    "    else:\n",
    "#         print('%s\\t%s' % (image_id, 20))\n",
    "        sample_submission_csv.iloc[i, 1] = 20 # 20\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(int(count/1000), end=' ')\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(sample_submission_csv['predicted'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = os.path.join(output_folder, 'pred_' + run_name_acc + '.csv')\n",
    "sample_submission_csv.to_csv(pred_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_furniture2018_Train-Predict_LSTM_20180401_184549_7964\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(run_name_acc)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
