{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ensemble_XGBoostGPU_GSCV\n",
    "Kaggle score: \n",
    "\n",
    "Conclusion: 即使是只有两个结果，进行简单的加权平均，也可以使结果得到提升。本结论还需要进一步的实验验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: ic_furniture2018_Ensemble_XGBoostGPU_GSCV_20180428_233857\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'ic_furniture2018'\n",
    "step_name = 'Ensemble_XGBoostGPU_GSCV'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_num:  2332\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "statistics_type = 'val_max'\n",
    "\n",
    "random_num = random.randint(1, 10000)\n",
    "print('random_num: ', random_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import zipfile\n",
    "import h5py\n",
    "import pickle\n",
    "import math\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "cpu_amount = cpu_count()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input\n",
      "output_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/output\n",
      "model_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/model\n",
      "feature_folder: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "post_pca_feature_folder: \t/data1/kaggle/imaterialist-challenge-furniture-2018/post_pca_feature\n",
      "log_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/log\n",
      "\n",
      "train_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.json\n",
      "val_json_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.json\n",
      "test_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.json\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.csv\n",
      "val_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.csv\n",
      "\n",
      "sample_submission_csv_file: \t/data1/kaggle/imaterialist-challenge-furniture-2018/input/sample_submission_randomlabel.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "post_pca_feature_folder = os.path.join(cwd, 'post_pca_feature')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('post_pca_feature_folder: \\t%s' % post_pca_feature_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_val_folder = os.path.join(input_folder, 'org_val')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "if not os.path.exists(post_pca_feature_folder):\n",
    "    os.mkdir(post_pca_feature_folder)\n",
    "    print('Create folder: %s' % post_pca_feature_folder)\n",
    "\n",
    "train_json_file = os.path.join(input_folder, 'train.json')\n",
    "val_json_file = os.path.join(input_folder, 'validation.json')\n",
    "test_json_file = os.path.join(input_folder, 'test.json')\n",
    "print('\\ntrain_json_file: \\t\\t%s' % train_json_file)\n",
    "print('val_json_file: \\t\\t\\t%s' % val_json_file)\n",
    "print('test_json_file: \\t\\t%s' % test_json_file)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "val_csv_file = os.path.join(input_folder, 'validation.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('val_csv_file: \\t\\t\\t%s' % val_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission_randomlabel.csv')\n",
    "print('\\nsample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (194828, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t2857/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.tengdakeli.cn/350/timg01/uploaded/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1         5  https://img13.360buyimg.com/imgzone/jfs/t2857/...\n",
       "1         2         5  http://www.tengdakeli.cn/350/timg01/uploaded/i..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_csv.shape is (6400, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>http://www.ghs.net/public/images/fb/3d/51/3beb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>https://img.alicdn.com/imgextra/TB2chFei9YH8KJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1        38  http://www.ghs.net/public/images/fb/3d/51/3beb...\n",
       "1         2        63  https://img.alicdn.com/imgextra/TB2chFei9YH8KJ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "val_csv = pd.read_csv(val_csv_file)\n",
    "print('val_csv.shape is {0}.'.format(val_csv.shape))\n",
    "display(val_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "print('sample_submission_csv.shape is {0}.'.format(sample_submission_csv.shape))\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_train_label_id_dict)=194828\n",
      "id: 1, \tlandmark_id:5\n",
      "id: 2, \tlandmark_id:5\n",
      "2_5.jpg\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['image_id']\n",
    "train_label_id = train_csv['label_id']\n",
    "\n",
    "id_2_train_label_id_dict = dict(zip(train_id, train_label_id))\n",
    "print('len(id_2_train_label_id_dict)=%d' % len(id_2_train_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (train_id[index], id_2_train_label_id_dict[train_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_val_label_id_dict)=6400\n",
      "id: 1, \tlandmark_id:38\n",
      "id: 2, \tlandmark_id:63\n",
      "2_63.jpg\n"
     ]
    }
   ],
   "source": [
    "val_id = val_csv['image_id']\n",
    "val_label_id = val_csv['label_id']\n",
    "\n",
    "id_2_val_label_id_dict = dict(zip(val_id, val_label_id))\n",
    "print('len(id_2_val_label_id_dict)=%d' % len(id_2_val_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (val_id[index], id_2_val_label_id_dict[val_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "id: 2\n",
      "2.jpg\n"
     ]
    }
   ],
   "source": [
    "test_id = test_csv['image_id']\n",
    "\n",
    "index = 0\n",
    "print('id: %s' % (test_id[index]))\n",
    "index = 1\n",
    "print('id: %s' % (test_id[index]))\n",
    "\n",
    "image_file = '%s.jpg' % (test_id[index])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12652 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "data_test_path = os.path.join(input_folder, 'data_test')\n",
    "\n",
    "image_size = 299\n",
    "width = height = 299\n",
    "target_size = (width, height)\n",
    "batch_size = 128\n",
    "\n",
    "test_generator = test_gen.flow_from_directory(data_test_path, target_size, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predict probability files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_053404_7941.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_061203_7987.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_070425_8115.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_071659_8120.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_072816_8131.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_075023_8175.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_080533_8136.p\n",
      "File exists: proba_ic_furniture2018_Train-Predict_Mix3model_20180415_081948_8214.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.p\n"
     ]
    }
   ],
   "source": [
    "ori_proba_files = [\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_053404_7941.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_061203_7987.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_070425_8115.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_071659_8120.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_072816_8131.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_075023_8175.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_080533_8136.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_081948_8214.p'},\n",
    "    { 'file_name': 'proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p', 'kaggle_score': 0.17812},\n",
    "    { 'file_name': 'proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p', 'kaggle_score': 0.17890},\n",
    "    { 'file_name': 'proba_ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.p', 'kaggle_score': 0.17994},\n",
    "    { 'file_name': 'proba_ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.p', 'kaggle_score': 0.17395},\n",
    "    { 'file_name': 'proba_ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.p', 'kaggle_score': 0.19479},\n",
    "    { 'file_name': 'proba_ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.p', 'kaggle_score': 0.18203},\n",
    "]\n",
    "\n",
    "for file in ori_proba_files:\n",
    "    if os.path.exists(os.path.join(model_folder, file['file_name'])):\n",
    "        print('File exists: %s' % file['file_name'])\n",
    "    else:\n",
    "        print('***File do not exists: %s' % file['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_053404_7941.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_061203_7987.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_070425_8115.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_071659_8120.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_072816_8131.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_075023_8175.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_080533_8136.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_Train-Predict_Mix3model_20180415_081948_8214.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.p\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_053404_7941.p 0.8908 0.7923\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_061203_7987.p 0.9533 0.8000\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_070425_8115.p 0.9272 0.8146\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_071659_8120.p 0.9166 0.8075\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_072816_8131.p 0.9531 0.8110\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_075023_8175.p 0.9512 0.8130\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_080533_8136.p 0.9517 0.8167\n",
      "proba_ic_furniture2018_Train-Predict_Mix3model_20180415_081948_8214.p 0.9455 0.8178\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p 0.9598 0.8334\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p 0.9347 0.8292\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180422_041707_8300.p 0.9605 0.8292\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180423_134043_8426.p 0.9669 0.8415\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180424_143948_8278.p 0.9505 0.8267\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180427_122315_8392.p 0.9337 0.8383\n",
      "CPU times: user 868 ms, sys: 936 ms, total: 1.8 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def save_proba(y_train_proba, y_train, y_val_proba, y_val, y_test_proba, test_filenames, file_name):\n",
    "    test_filenames = [n.encode('utf8') for n in test_filenames]\n",
    "    print(test_filenames[:10])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('y_train_proba', data=y_train_proba)\n",
    "        h.create_dataset('y_train', data=y_train)\n",
    "        h.create_dataset('y_val_proba', data=y_val_proba)\n",
    "        h.create_dataset('y_val', data=y_val)\n",
    "        h.create_dataset('y_test_proba', data=y_test_proba)\n",
    "        h.create_dataset('test_filenames', data=test_filenames)\n",
    "    print('File saved: %s' % file_name)\n",
    "\n",
    "def load_proba(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        y_train_proba = np.array(h['y_train_proba'])\n",
    "        y_train = np.array(h['y_train'])\n",
    "        y_val_proba = np.array(h['y_val_proba'])\n",
    "        y_val = np.array(h['y_val'])\n",
    "        y_test_proba = np.array(h['y_test_proba'])\n",
    "        test_filenames = np.array(h['test_filenames'])\n",
    "    print('File loaded: %s' % file_name)\n",
    "    test_filenames = [n.decode('utf8') for n in test_filenames]\n",
    "#     print(test_filenames[:10])\n",
    "    return y_train_proba, y_train, y_val_proba, y_val, y_test_proba, test_filenames\n",
    "\n",
    "def get_acc(y_pred, y_proba):\n",
    "    max_indexes = np.argmax(y_proba, -1)\n",
    "    return accuracy_score(y_pred ,max_indexes)\n",
    "\n",
    "\n",
    "y_train_probas = []\n",
    "y_trains = []\n",
    "y_val_probas = []\n",
    "y_vas = []\n",
    "y_test_probas = []\n",
    "for file in ori_proba_files:\n",
    "    y_proba_file = os.path.join(model_folder, file['file_name'])\n",
    "    y_train_proba, y_train, y_val_proba, y_val, y_test_proba, test_filenames = load_proba(y_proba_file)\n",
    "#     print(y_train_proba.shape)\n",
    "#     print(y_train.shape)\n",
    "#     print(y_val_proba.shape)\n",
    "#     print(y_val.shape)\n",
    "#     print(y_test_proba.shape)\n",
    "#     print(len(test_filenames))\n",
    "    y_train_probas.append(y_train_proba)\n",
    "    y_val_probas.append(y_val_proba)\n",
    "    y_test_probas.append(y_test_proba)\n",
    "    file['train_acc'] = get_acc(y_train, y_train_proba)\n",
    "    file['val_acc'] = get_acc(y_val, y_val_proba)\n",
    "\n",
    "for f in ori_proba_files:\n",
    "    print(f['file_name'], '%.4f' % f['train_acc'], '%.4f' % f['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic statistical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************probas_mean.shape: \t (191261, 128)\n",
      "**************probas_mean.shape: \t (6301, 128)\n",
      "**************probas_mean.shape: \t (12652, 128)\n",
      "CPU times: user 3.37 s, sys: 348 ms, total: 3.72 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_mean(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_mean = np.mean(probas_newaxis, axis=-1)\n",
    "    print('probas_mean.shape: \\t', probas_mean.shape)\n",
    "    return probas_mean\n",
    "\n",
    "ensemble_res['train_mean'] = get_acc(y_train ,get_mean(y_train_probas))\n",
    "ensemble_res['val_mean'] = get_acc(y_val ,get_mean(y_val_probas))\n",
    "y_test_proba_mean = get_mean(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************probas_min.shape: \t (191261, 128)\n",
      "**************probas_min.shape: \t (6301, 128)\n",
      "**************probas_min.shape: \t (12652, 128)\n",
      "CPU times: user 4.16 s, sys: 364 ms, total: 4.52 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_min(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_min = np.min(probas_newaxis, axis=-1)\n",
    "    print('probas_min.shape: \\t', probas_min.shape)\n",
    "    return probas_min\n",
    "\n",
    "ensemble_res['train_min'] = get_acc(y_train ,get_min(y_train_probas))\n",
    "ensemble_res['val_min'] = get_acc(y_val ,get_min(y_val_probas))\n",
    "y_test_proba_min = get_min(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************probas_max.shape: \t (191261, 128)\n",
      "**************probas_max.shape: \t (6301, 128)\n",
      "**************probas_max.shape: \t (12652, 128)\n",
      "CPU times: user 4.02 s, sys: 360 ms, total: 4.38 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_max(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_max = np.max(probas_newaxis, axis=-1)\n",
    "    print('probas_max.shape: \\t', probas_max.shape)\n",
    "    return probas_max\n",
    "\n",
    "ensemble_res['train_max'] = get_acc(y_train ,get_max(y_train_probas))\n",
    "ensemble_res['val_max'] = get_acc(y_val ,get_max(y_val_probas))\n",
    "y_test_proba_max = get_max(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************probas_median.shape: \t (191261, 128)\n",
      "**************probas_median.shape: \t (6301, 128)\n",
      "**************probas_median.shape: \t (12652, 128)\n",
      "CPU times: user 8.84 s, sys: 696 ms, total: 9.54 s\n",
      "Wall time: 9.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_median(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_median = np.median(probas_newaxis, axis=-1)\n",
    "    print('probas_median.shape: \\t', probas_median.shape)\n",
    "    return probas_median\n",
    "\n",
    "ensemble_res['train_median'] = get_acc(y_train ,get_median(y_train_probas))\n",
    "ensemble_res['val_median'] = get_acc(y_val ,get_median(y_val_probas))\n",
    "y_test_proba_median = get_median(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mean  \t0.9714\tval_mean  \t0.8627\n",
      "train_min  \t0.9736\tval_min  \t0.8553\n",
      "train_max  \t0.9749\tval_max  \t0.8562\n",
      "train_median  \t0.9677\tval_median  \t0.8570\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(ensemble_res.keys()):\n",
    "    if i % 2 == 0:\n",
    "        print('%s  \\t%.4f' % (key, ensemble_res[key]), end='\\t')\n",
    "    else:\n",
    "        print('%s  \\t%.4f' % (key, ensemble_res[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************probas_mean.shape: \t (191261, 128)\n",
      "**************probas_min.shape: \t (191261, 128)\n",
      "**************probas_max.shape: \t (191261, 128)\n",
      "**************probas_median.shape: \t (191261, 128)\n",
      "(191261, 512)\n",
      "**************probas_mean.shape: \t (6301, 128)\n",
      "**************probas_min.shape: \t (6301, 128)\n",
      "**************probas_max.shape: \t (6301, 128)\n",
      "**************probas_median.shape: \t (6301, 128)\n",
      "(6301, 512)\n",
      "**************probas_mean.shape: \t (12652, 128)\n",
      "**************probas_min.shape: \t (12652, 128)\n",
      "**************probas_max.shape: \t (12652, 128)\n",
      "**************probas_median.shape: \t (12652, 128)\n",
      "(12652, 512)\n"
     ]
    }
   ],
   "source": [
    "y_train_probas_sta = np.concatenate([\n",
    "    get_mean(y_train_probas), \n",
    "    get_min(y_train_probas), \n",
    "    get_max(y_train_probas), \n",
    "    get_median(y_train_probas)\n",
    "], axis=-1)\n",
    "print(y_train_probas_sta.shape)\n",
    "\n",
    "y_val_probas_sta = np.concatenate([\n",
    "    get_mean(y_val_probas), \n",
    "    get_min(y_val_probas), \n",
    "    get_max(y_val_probas), \n",
    "    get_median(y_val_probas)\n",
    "], axis=-1)\n",
    "print(y_val_probas_sta.shape)\n",
    "\n",
    "y_test_probas_sta = np.concatenate([\n",
    "    get_mean(y_test_probas), \n",
    "    get_min(y_test_probas), \n",
    "    get_max(y_test_probas), \n",
    "    get_median(y_test_probas)\n",
    "], axis=-1)\n",
    "print(y_test_probas_sta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_probas_sta = y_train_probas_sta.copy()\n",
    "y_train = y_train.copy()\n",
    "y_val_probas_sta = y_val_probas_sta.copy()\n",
    "y_val = y_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=2, reg_lambda=7, total=14.4min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=7 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 15.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... max_depth=3, reg_alpha=2, reg_lambda=7, total=14.5min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=2, reg_lambda=7, total=15.4min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=2, reg_lambda=7, total=18.9min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=2, reg_lambda=15, total=21.5min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=2, reg_lambda=15, total=21.5min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=2, reg_lambda=15, total=21.5min\n",
      "[CV] max_depth=3, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=2, reg_lambda=15, total=21.5min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=5, reg_lambda=7, total=19.4min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=5, reg_lambda=7, total=19.5min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=5, reg_lambda=7, total=19.4min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=3, reg_alpha=5, reg_lambda=7, total=19.5min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=5, reg_lambda=15, total=19.8min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=5, reg_lambda=15, total=20.0min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=5, reg_lambda=15, total=19.7min\n",
      "[CV] max_depth=3, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=3, reg_alpha=5, reg_lambda=15, total=19.8min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=2, reg_lambda=7, total=21.3min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=2, reg_lambda=7, total=19.9min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=2, reg_lambda=7, total=14.8min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=2, reg_lambda=7, total=14.8min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=2, reg_lambda=15, total=15.4min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=2, reg_lambda=15, total=15.5min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=2, reg_lambda=15, total=15.5min\n",
      "[CV] max_depth=4, reg_alpha=2, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=2, reg_lambda=15, total=15.5min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=5, reg_lambda=7, total=13.7min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=5, reg_lambda=7, total=13.7min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=5, reg_lambda=7, total=13.7min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=7 ..........................\n",
      "[CV] ........... max_depth=4, reg_alpha=5, reg_lambda=7, total=13.7min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=5, reg_lambda=15, total=14.0min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=5, reg_lambda=15, total=14.0min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=5, reg_lambda=15, total=14.0min\n",
      "[CV] max_depth=4, reg_alpha=5, reg_lambda=15 .........................\n",
      "[CV] .......... max_depth=4, reg_alpha=5, reg_lambda=15, total=14.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 569.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.3,\n",
       "       colsample_bytree=0.3, eval_metric=['merror', 'mlogloss'], gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, n_jobs=2,\n",
       "       nthread=None, num_boost_round=50, objective='gpu:multi:softmax',\n",
       "       random_state=2332, reg_alpha=1, reg_lambda=5, scale_pos_weight=97,\n",
       "       seed=None, silent=False, subsample=0.7, tree_method='gpu_hist'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, 4], 'reg_alpha': [2, 5], 'reg_lambda': [7, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    max_depth=5, \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=1000, \n",
    "    silent=False, \n",
    "    objective='gpu:multi:softmax', \n",
    "    booster='gbtree', \n",
    "    n_jobs=2, \n",
    "    nthread=None, \n",
    "    gamma=0, \n",
    "    min_child_weight=1, \n",
    "    max_delta_step=0, \n",
    "    subsample=0.7, \n",
    "    colsample_bytree=0.3, \n",
    "    colsample_bylevel=0.3, \n",
    "    reg_alpha=1, \n",
    "    reg_lambda=5, \n",
    "    scale_pos_weight=97, \n",
    "    base_score=0.5, \n",
    "    random_state=random_num, \n",
    "    seed=None, \n",
    "    missing=None,\n",
    "    # booster params\n",
    "    num_boost_round=50,\n",
    "#     early_stopping_rounds=10,\n",
    "    tree_method='gpu_hist',\n",
    "#     predictor='gpu_predictor',\n",
    "    eval_metric=['merror', 'mlogloss']\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 4],\n",
    "#     'learning_rate': [0.1],\n",
    "    'reg_alpha': [2, 5],\n",
    "    'reg_lambda': [7, 15],\n",
    "#     'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameters, verbose=2, cv=4, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(y_train_probas_sta, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: 0.9988\n",
      "acc_val:   0.8588\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = grid_search.best_estimator_.predict(y_train_probas_sta)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print('acc_train: %.4f' % acc_train)\n",
    "\n",
    "y_val_pred = grid_search.best_estimator_.predict(y_val_probas_sta)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print('acc_val:   %.4f' % acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 938.33511233, 1277.94097418, 1159.06597   , 1180.42398602,\n",
      "       1053.33004445,  918.38501424,  816.7370851 ,  831.9159106 ]), 'std_fit_time': array([109.54486491,   2.09033681,   2.81745731,   5.2441876 ,\n",
      "       175.69834952,   1.83368512,   0.3174895 ,   0.59048733]), 'mean_score_time': array([10.19818813, 12.15772617,  6.74033827,  7.62453556,  9.19881332,\n",
      "       11.20709366,  5.97306985,  6.86691344]), 'std_score_time': array([0.0816641 , 0.0500262 , 0.04629395, 0.0434975 , 0.05391329,\n",
      "       0.08134516, 0.03083515, 0.03779967]), 'param_max_depth': masked_array(data=[3, 3, 3, 3, 4, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_alpha': masked_array(data=[2, 2, 5, 5, 2, 2, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_lambda': masked_array(data=[7, 15, 7, 15, 7, 15, 7, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 7}, {'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 15}, {'max_depth': 3, 'reg_alpha': 5, 'reg_lambda': 7}, {'max_depth': 3, 'reg_alpha': 5, 'reg_lambda': 15}, {'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 7}, {'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 15}, {'max_depth': 4, 'reg_alpha': 5, 'reg_lambda': 7}, {'max_depth': 4, 'reg_alpha': 5, 'reg_lambda': 15}], 'split0_test_score': array([0.97411362, 0.9747613 , 0.97375844, 0.97417629, 0.97352861,\n",
      "       0.9741554 , 0.97281825, 0.9738629 ]), 'split1_test_score': array([0.97595802, 0.9762298 , 0.97474547, 0.97583258, 0.97579077,\n",
      "       0.97599983, 0.97482909, 0.97539356]), 'split2_test_score': array([0.97529237, 0.97577355, 0.97476935, 0.97577355, 0.97491579,\n",
      "       0.97537605, 0.97443461, 0.9750204 ]), 'split3_test_score': array([0.97450069, 0.9742704 , 0.97374702, 0.97441695, 0.97353766,\n",
      "       0.97414479, 0.97303521, 0.97418666]), 'mean_test_score': array([0.97496615, 0.97525894, 0.97425508, 0.9750498 , 0.9744433 ,\n",
      "       0.97491909, 0.97377929, 0.97461584]), 'std_test_score': array([0.00071318, 0.0007797 , 0.00050242, 0.00075837, 0.00096129,\n",
      "       0.00079999, 0.00086738, 0.00061648]), 'rank_test_score': array([3, 1, 7, 2, 6, 4, 8, 5], dtype=int32), 'split0_train_score': array([0.99889817, 0.99881449, 0.99581584, 0.99551598, 0.99890515,\n",
      "       0.99883541, 0.99649925, 0.99635978]), 'split1_train_score': array([0.99885657, 0.99879382, 0.99567727, 0.99534958, 0.9988984 ,\n",
      "       0.99880776, 0.9963954 , 0.99619321]), 'split2_train_score': array([0.9989126 , 0.99883593, 0.99564345, 0.99535766, 0.99891957,\n",
      "       0.99884987, 0.99634049, 0.99632655]), 'split3_train_score': array([0.99887104, 0.99876651, 0.99563748, 0.9953866 , 0.99889892,\n",
      "       0.99886407, 0.99650162, 0.99619499]), 'mean_train_score': array([0.9988846 , 0.99880269, 0.99569351, 0.99540245, 0.99890551,\n",
      "       0.99883928, 0.99643419, 0.99626863]), 'std_train_score': array([2.20113182e-05, 2.56508262e-05, 7.22400498e-05, 6.69719564e-05,\n",
      "       8.54318646e-06, 2.08267303e-05, 6.90350886e-05, 7.54562916e-05])}\n",
      "[mean: 0.97497, std: 0.00071, params: {'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 7}, mean: 0.97526, std: 0.00078, params: {'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 15}, mean: 0.97426, std: 0.00050, params: {'max_depth': 3, 'reg_alpha': 5, 'reg_lambda': 7}, mean: 0.97505, std: 0.00076, params: {'max_depth': 3, 'reg_alpha': 5, 'reg_lambda': 15}, mean: 0.97444, std: 0.00096, params: {'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 7}, mean: 0.97492, std: 0.00080, params: {'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 15}, mean: 0.97378, std: 0.00087, params: {'max_depth': 4, 'reg_alpha': 5, 'reg_lambda': 7}, mean: 0.97462, std: 0.00062, params: {'max_depth': 4, 'reg_alpha': 5, 'reg_lambda': 15}]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.3,\n",
      "       colsample_bytree=0.3, eval_metric=['merror', 'mlogloss'], gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=1000, n_jobs=2,\n",
      "       nthread=None, num_boost_round=50, objective='multi:softprob',\n",
      "       random_state=2332, reg_alpha=2, reg_lambda=15, scale_pos_weight=97,\n",
      "       seed=None, silent=False, subsample=0.7, tree_method='gpu_hist')\n",
      "0.9752589393551221\n",
      "{'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 15}\n",
      "make_scorer(accuracy_score)\n",
      "************************************************************\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "['_Booster', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_estimator_type', '_features_count', '_get_param_names', '_le', 'apply', 'base_score', 'booster', 'classes_', 'colsample_bylevel', 'colsample_bytree', 'evals_result', 'feature_importances_', 'fit', 'gamma', 'get_booster', 'get_params', 'get_xgb_params', 'kwargs', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_classes_', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'predict', 'predict_proba', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'score', 'seed', 'set_params', 'silent', 'subsample']\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.cv_results_)\n",
    "print(grid_search.grid_scores_ )\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.scorer_)\n",
    "print('*' * 60)\n",
    "print(type(grid_search.best_estimator_))\n",
    "print(dir(grid_search.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>938.335112</td>\n",
       "      <td>10.198188</td>\n",
       "      <td>0.974966</td>\n",
       "      <td>0.998885</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 7}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.975292</td>\n",
       "      <td>0.998913</td>\n",
       "      <td>0.974501</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>109.544865</td>\n",
       "      <td>0.081664</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1277.940974</td>\n",
       "      <td>12.157726</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 3, 'reg_alpha': 2, 'reg_lambda':...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976230</td>\n",
       "      <td>0.998794</td>\n",
       "      <td>0.975774</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.974270</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>2.090337</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1159.065970</td>\n",
       "      <td>6.740338</td>\n",
       "      <td>0.974255</td>\n",
       "      <td>0.995694</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 3, 'reg_alpha': 5, 'reg_lambda': 7}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974745</td>\n",
       "      <td>0.995677</td>\n",
       "      <td>0.974769</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>0.973747</td>\n",
       "      <td>0.995637</td>\n",
       "      <td>2.817457</td>\n",
       "      <td>0.046294</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1180.423986</td>\n",
       "      <td>7.624536</td>\n",
       "      <td>0.975050</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 3, 'reg_alpha': 5, 'reg_lambda':...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.974176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975833</td>\n",
       "      <td>0.995350</td>\n",
       "      <td>0.975774</td>\n",
       "      <td>0.995358</td>\n",
       "      <td>0.974417</td>\n",
       "      <td>0.995387</td>\n",
       "      <td>5.244188</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1053.330044</td>\n",
       "      <td>9.198813</td>\n",
       "      <td>0.974443</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 7}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975791</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.974916</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.973538</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>175.698350</td>\n",
       "      <td>0.053913</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>918.385014</td>\n",
       "      <td>11.207094</td>\n",
       "      <td>0.974919</td>\n",
       "      <td>0.998839</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 4, 'reg_alpha': 2, 'reg_lambda':...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.998808</td>\n",
       "      <td>0.975376</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.974145</td>\n",
       "      <td>0.998864</td>\n",
       "      <td>1.833685</td>\n",
       "      <td>0.081345</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>816.737085</td>\n",
       "      <td>5.973070</td>\n",
       "      <td>0.973779</td>\n",
       "      <td>0.996434</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 4, 'reg_alpha': 5, 'reg_lambda': 7}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.972818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974829</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.974435</td>\n",
       "      <td>0.996340</td>\n",
       "      <td>0.973035</td>\n",
       "      <td>0.996502</td>\n",
       "      <td>0.317489</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>831.915911</td>\n",
       "      <td>6.866913</td>\n",
       "      <td>0.974616</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 4, 'reg_alpha': 5, 'reg_lambda':...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.973863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.996193</td>\n",
       "      <td>0.975020</td>\n",
       "      <td>0.996327</td>\n",
       "      <td>0.974187</td>\n",
       "      <td>0.996195</td>\n",
       "      <td>0.590487</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0     938.335112        10.198188         0.974966          0.998885   \n",
       "1    1277.940974        12.157726         0.975259          0.998803   \n",
       "2    1159.065970         6.740338         0.974255          0.995694   \n",
       "3    1180.423986         7.624536         0.975050          0.995402   \n",
       "4    1053.330044         9.198813         0.974443          0.998906   \n",
       "5     918.385014        11.207094         0.974919          0.998839   \n",
       "6     816.737085         5.973070         0.973779          0.996434   \n",
       "7     831.915911         6.866913         0.974616          0.996269   \n",
       "\n",
       "  param_max_depth param_reg_alpha param_reg_lambda  \\\n",
       "0               3               2                7   \n",
       "1               3               2               15   \n",
       "2               3               5                7   \n",
       "3               3               5               15   \n",
       "4               4               2                7   \n",
       "5               4               2               15   \n",
       "6               4               5                7   \n",
       "7               4               5               15   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 7}                3   \n",
       "1  {'max_depth': 3, 'reg_alpha': 2, 'reg_lambda':...                1   \n",
       "2  {'max_depth': 3, 'reg_alpha': 5, 'reg_lambda': 7}                7   \n",
       "3  {'max_depth': 3, 'reg_alpha': 5, 'reg_lambda':...                2   \n",
       "4  {'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 7}                6   \n",
       "5  {'max_depth': 4, 'reg_alpha': 2, 'reg_lambda':...                4   \n",
       "6  {'max_depth': 4, 'reg_alpha': 5, 'reg_lambda': 7}                8   \n",
       "7  {'max_depth': 4, 'reg_alpha': 5, 'reg_lambda':...                5   \n",
       "\n",
       "   split0_test_score       ...         split1_test_score  split1_train_score  \\\n",
       "0           0.974114       ...                  0.975958            0.998857   \n",
       "1           0.974761       ...                  0.976230            0.998794   \n",
       "2           0.973758       ...                  0.974745            0.995677   \n",
       "3           0.974176       ...                  0.975833            0.995350   \n",
       "4           0.973529       ...                  0.975791            0.998898   \n",
       "5           0.974155       ...                  0.976000            0.998808   \n",
       "6           0.972818       ...                  0.974829            0.996395   \n",
       "7           0.973863       ...                  0.975394            0.996193   \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.975292            0.998913           0.974501   \n",
       "1           0.975774            0.998836           0.974270   \n",
       "2           0.974769            0.995643           0.973747   \n",
       "3           0.975774            0.995358           0.974417   \n",
       "4           0.974916            0.998920           0.973538   \n",
       "5           0.975376            0.998850           0.974145   \n",
       "6           0.974435            0.996340           0.973035   \n",
       "7           0.975020            0.996327           0.974187   \n",
       "\n",
       "   split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.998871    109.544865        0.081664        0.000713   \n",
       "1            0.998767      2.090337        0.050026        0.000780   \n",
       "2            0.995637      2.817457        0.046294        0.000502   \n",
       "3            0.995387      5.244188        0.043497        0.000758   \n",
       "4            0.998899    175.698350        0.053913        0.000961   \n",
       "5            0.998864      1.833685        0.081345        0.000800   \n",
       "6            0.996502      0.317489        0.030835        0.000867   \n",
       "7            0.996195      0.590487        0.037800        0.000616   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.000022  \n",
       "1         0.000026  \n",
       "2         0.000072  \n",
       "3         0.000067  \n",
       "4         0.000009  \n",
       "5         0.000021  \n",
       "6         0.000069  \n",
       "7         0.000075  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "display(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12652,)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = grid_search.predict(y_test_probas_sta)\n",
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 18.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# if statistics_type == 'val_mean':\n",
    "#     max_indexes = np.argmax(y_test_proba_mean, -1)\n",
    "# elif statistics_type == 'val_min':\n",
    "#     max_indexes = np.argmax(y_test_proba_min, -1)\n",
    "# elif statistics_type == 'val_max':\n",
    "#     max_indexes = np.argmax(y_test_proba_max, -1)\n",
    "# else: \n",
    "#     # statistics_type == 'val_median'\n",
    "#     max_indexes = np.argmax(y_test_proba_median, -1)\n",
    "# print(xg_test_pred.shape)\n",
    "\n",
    "test_dict = {}\n",
    "for pair in zip(test_filenames, y_test_pred):\n",
    "    image_name, indx = pair[0], int(pair[1])\n",
    "    image_name = image_name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print(pair[0], image_name, image_id, indx, indx+1, type(image_id), type(indx))\n",
    "    test_dict[image_id] = indx + 1\n",
    "\n",
    "#确认图片的id是否能与ImageDataGenerator()对应上\n",
    "for name in test_filenames[:10]:\n",
    "    image_name = name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print('%s\\t%s\\t%s' % (name, image_id, test_dict[image_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(len_sample_submission_csv)=12800\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         12\n",
       "1   2         61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 868 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sample_submission_csv = len(sample_submission_csv)\n",
    "print('len(len_sample_submission_csv)=%d' % len_sample_submission_csv)\n",
    "count = 0\n",
    "for i in range(len_sample_submission_csv):\n",
    "    image_id = int(sample_submission_csv.iloc[i, 0])\n",
    "    if image_id in test_dict:\n",
    "        pred_label = test_dict[image_id]\n",
    "#         print('%s\\t%s' % (image_id, pred_label))\n",
    "        sample_submission_csv.iloc[i, 1] = pred_label\n",
    "    else:\n",
    "#         print('%s\\t%s' % (image_id, 20))\n",
    "        sample_submission_csv.iloc[i, 1] = 20 # 属于20的类最多，所以全都设置成这个类，可能会比设置成其他得到的结果好\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(int(count/1000), end=' ')\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(sample_submission_csv['predicted'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_furniture2018_Ensemble_XGBoostGPU_GSCV_20180428_233857_8587\n"
     ]
    }
   ],
   "source": [
    "run_name_acc = run_name + '_' + str(int(acc_val*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "sample_submission_csv.to_csv(pred_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 35501.47 s\n",
      "val_max\n",
      "ic_furniture2018_Ensemble_XGBoostGPU_GSCV_20180428_233857_8587\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "print(statistics_type)\n",
    "\n",
    "print(run_name_acc)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
