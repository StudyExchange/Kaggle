{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ensemble_Mix3model\n",
    "Kaggle score: \n",
    "\n",
    "Conclusion: 即使是只有两个结果，进行简单的加权平均，也可以使结果得到提升。本结论还需要进一步的实验验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import zipfile\n",
    "import h5py\n",
    "import pickle\n",
    "import math\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: ic_furniture2018_Ensemble_Mix3model_20180419_114513\n"
     ]
    }
   ],
   "source": [
    "project_name = 'ic_furniture2018'\n",
    "step_name = 'Ensemble_Mix3model'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input\n",
      "output_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/output\n",
      "model_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/model\n",
      "feature_folder: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/feature\n",
      "post_pca_feature_folder: \t/data1/kaggle/imaterialist-challenge-furniture-2018/post_pca_feature\n",
      "log_folder: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/log\n",
      "\n",
      "train_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.json\n",
      "val_json_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.json\n",
      "test_json_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.json\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/train.csv\n",
      "val_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/validation.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/imaterialist-challenge-furniture-2018/input/test.csv\n",
      "\n",
      "sample_submission_csv_file: \t/data1/kaggle/imaterialist-challenge-furniture-2018/input/sample_submission_randomlabel.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "post_pca_feature_folder = os.path.join(cwd, 'post_pca_feature')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('post_pca_feature_folder: \\t%s' % post_pca_feature_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_val_folder = os.path.join(input_folder, 'org_val')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "if not os.path.exists(post_pca_feature_folder):\n",
    "    os.mkdir(post_pca_feature_folder)\n",
    "    print('Create folder: %s' % post_pca_feature_folder)\n",
    "\n",
    "train_json_file = os.path.join(input_folder, 'train.json')\n",
    "val_json_file = os.path.join(input_folder, 'validation.json')\n",
    "test_json_file = os.path.join(input_folder, 'test.json')\n",
    "print('\\ntrain_json_file: \\t\\t%s' % train_json_file)\n",
    "print('val_json_file: \\t\\t\\t%s' % val_json_file)\n",
    "print('test_json_file: \\t\\t%s' % test_json_file)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "val_csv_file = os.path.join(input_folder, 'validation.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('val_csv_file: \\t\\t\\t%s' % val_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission_randomlabel.csv')\n",
    "print('\\nsample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (194828, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t2857/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.tengdakeli.cn/350/timg01/uploaded/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1         5  https://img13.360buyimg.com/imgzone/jfs/t2857/...\n",
       "1         2         5  http://www.tengdakeli.cn/350/timg01/uploaded/i..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_csv.shape is (6400, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>http://www.ghs.net/public/images/fb/3d/51/3beb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>https://img.alicdn.com/imgextra/TB2chFei9YH8KJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label_id                                                url\n",
       "0         1        38  http://www.ghs.net/public/images/fb/3d/51/3beb...\n",
       "1         2        63  https://img.alicdn.com/imgextra/TB2chFei9YH8KJ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t13174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://img35.ddimg.cn/79/22/1258168705-1_u.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                                url\n",
       "0         1  https://img13.360buyimg.com/imgzone/jfs/t13174...\n",
       "1         2     http://img35.ddimg.cn/79/22/1258168705-1_u.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_csv.shape is (12800, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "val_csv = pd.read_csv(val_csv_file)\n",
    "print('val_csv.shape is {0}.'.format(val_csv.shape))\n",
    "display(val_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))\n",
    "\n",
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "print('sample_submission_csv.shape is {0}.'.format(sample_submission_csv.shape))\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_train_label_id_dict)=194828\n",
      "id: 1, \tlandmark_id:5\n",
      "id: 2, \tlandmark_id:5\n",
      "2_5.jpg\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['image_id']\n",
    "train_label_id = train_csv['label_id']\n",
    "\n",
    "id_2_train_label_id_dict = dict(zip(train_id, train_label_id))\n",
    "print('len(id_2_train_label_id_dict)=%d' % len(id_2_train_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_train_label_id_dict[train_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (train_id[index], id_2_train_label_id_dict[train_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_2_val_label_id_dict)=6400\n",
      "id: 1, \tlandmark_id:38\n",
      "id: 2, \tlandmark_id:63\n",
      "2_63.jpg\n"
     ]
    }
   ],
   "source": [
    "val_id = val_csv['image_id']\n",
    "val_label_id = val_csv['label_id']\n",
    "\n",
    "id_2_val_label_id_dict = dict(zip(val_id, val_label_id))\n",
    "print('len(id_2_val_label_id_dict)=%d' % len(id_2_val_label_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (val_id[index], id_2_val_label_id_dict[val_id[index]]))\n",
    "\n",
    "image_file = '%s_%s.jpg' % (val_id[index], id_2_val_label_id_dict[val_id[index]])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "id: 2\n",
      "2.jpg\n"
     ]
    }
   ],
   "source": [
    "test_id = test_csv['image_id']\n",
    "\n",
    "index = 0\n",
    "print('id: %s' % (test_id[index]))\n",
    "index = 1\n",
    "print('id: %s' % (test_id[index]))\n",
    "\n",
    "image_file = '%s.jpg' % (test_id[index])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12652 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "data_test_path = os.path.join(input_folder, 'data_test')\n",
    "\n",
    "image_size = 299\n",
    "width = height = 299\n",
    "target_size = (width, height)\n",
    "batch_size = 128\n",
    "\n",
    "test_generator = test_gen.flow_from_directory(data_test_path, target_size, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predict probability files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p\n",
      "File exists: proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p\n"
     ]
    }
   ],
   "source": [
    "ori_proba_files = [\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_053404_7941.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_061203_7987.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_070425_8115.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_071659_8120.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_072816_8131.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_075023_8175.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_080533_8136.p'},\n",
    "#     { 'file_name': 'proba_ic_furniture2018_Train-Predict_Mix3model_20180415_081948_8214.p'},\n",
    "]\n",
    "\n",
    "for file in ori_proba_files:\n",
    "    if os.path.exists(os.path.join(model_folder, file['file_name'])):\n",
    "        print('File exists: %s' % file['file_name'])\n",
    "    else:\n",
    "        print('***File do not exists: %s' % file['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p\n",
      "File loaded: /data1/kaggle/imaterialist-challenge-furniture-2018/model/proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180417_170937_8341.p 0.9598 0.8334\n",
      "proba_ic_furniture2018_TrainPredict_FineTune_20180418_130955_8303.p 0.9347 0.8292\n",
      "CPU times: user 156 ms, sys: 224 ms, total: 380 ms\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def save_proba(y_train_proba, y_train, y_val_proba, y_val, y_test_proba, test_filenames, file_name):\n",
    "    test_filenames = [n.encode('utf8') for n in test_filenames]\n",
    "    print(test_filenames[:10])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('y_train_proba', data=y_train_proba)\n",
    "        h.create_dataset('y_train', data=y_train)\n",
    "        h.create_dataset('y_val_proba', data=y_val_proba)\n",
    "        h.create_dataset('y_val', data=y_val)\n",
    "        h.create_dataset('y_test_proba', data=y_test_proba)\n",
    "        h.create_dataset('test_filenames', data=test_filenames)\n",
    "    print('File saved: %s' % file_name)\n",
    "\n",
    "def load_proba(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        y_train_proba = np.array(h['y_train_proba'])\n",
    "        y_train = np.array(h['y_train'])\n",
    "        y_val_proba = np.array(h['y_val_proba'])\n",
    "        y_val = np.array(h['y_val'])\n",
    "        y_test_proba = np.array(h['y_test_proba'])\n",
    "        test_filenames = np.array(h['test_filenames'])\n",
    "    print('File loaded: %s' % file_name)\n",
    "    test_filenames = [n.decode('utf8') for n in test_filenames]\n",
    "#     print(test_filenames[:10])\n",
    "    return y_train_proba, y_train, y_val_proba, y_val, y_test_proba, test_filenames\n",
    "\n",
    "def get_acc(y_pred, y_proba):\n",
    "    max_indexes = np.argmax(y_proba, -1)\n",
    "    return accuracy_score(y_pred ,max_indexes)\n",
    "\n",
    "\n",
    "y_train_probas = []\n",
    "y_trains = []\n",
    "y_val_probas = []\n",
    "y_vas = []\n",
    "y_test_probas = []\n",
    "for file in ori_proba_files:\n",
    "    y_proba_file = os.path.join(model_folder, file['file_name'])\n",
    "    y_train_proba, y_train, y_val_proba, y_val, y_test_proba, test_filenames = load_proba(y_proba_file)\n",
    "#     print(y_train_proba.shape)\n",
    "#     print(y_train.shape)\n",
    "#     print(y_val_proba.shape)\n",
    "#     print(y_val.shape)\n",
    "#     print(y_test_proba.shape)\n",
    "#     print(len(test_filenames))\n",
    "    y_train_probas.append(y_train_proba)\n",
    "    y_val_probas.append(y_val_proba)\n",
    "    y_test_probas.append(y_test_proba)\n",
    "    file['train_acc'] = get_acc(y_train, y_train_proba)\n",
    "    file['val_acc'] = get_acc(y_val, y_val_proba)\n",
    "\n",
    "for f in ori_proba_files:\n",
    "    print(f['file_name'], '%.4f' % f['train_acc'], '%.4f' % f['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic statistical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**probas_mean.shape: \t (191261, 128)\n",
      "**probas_mean.shape: \t (6301, 128)\n",
      "**probas_mean.shape: \t (12652, 128)\n",
      "CPU times: user 468 ms, sys: 120 ms, total: 588 ms\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_mean(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_mean = np.mean(probas_newaxis, axis=-1)\n",
    "    print('probas_mean.shape: \\t', probas_mean.shape)\n",
    "    return probas_mean\n",
    "\n",
    "ensemble_res['train_mean'] = get_acc(y_train ,get_mean(y_train_probas))\n",
    "ensemble_res['val_mean'] = get_acc(y_val ,get_mean(y_val_probas))\n",
    "y_test_proba_mean = get_mean(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**probas_min.shape: \t (191261, 128)\n",
      "**probas_min.shape: \t (6301, 128)\n",
      "**probas_min.shape: \t (12652, 128)\n",
      "CPU times: user 204 ms, sys: 116 ms, total: 320 ms\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_min(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_min = np.min(probas_newaxis, axis=-1)\n",
    "    print('probas_min.shape: \\t', probas_min.shape)\n",
    "    return probas_min\n",
    "\n",
    "ensemble_res['train_min'] = get_acc(y_train ,get_min(y_train_probas))\n",
    "ensemble_res['val_min'] = get_acc(y_val ,get_min(y_val_probas))\n",
    "y_test_proba_min = get_min(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**probas_max.shape: \t (191261, 128)\n",
      "**probas_max.shape: \t (6301, 128)\n",
      "**probas_max.shape: \t (12652, 128)\n",
      "CPU times: user 200 ms, sys: 124 ms, total: 324 ms\n",
      "Wall time: 321 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_max(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_max = np.max(probas_newaxis, axis=-1)\n",
    "    print('probas_max.shape: \\t', probas_max.shape)\n",
    "    return probas_max\n",
    "\n",
    "ensemble_res['train_max'] = get_acc(y_train ,get_max(y_train_probas))\n",
    "ensemble_res['val_max'] = get_acc(y_val ,get_max(y_val_probas))\n",
    "y_test_proba_max = get_max(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**probas_median.shape: \t (191261, 128)\n",
      "**probas_median.shape: \t (6301, 128)\n",
      "**probas_median.shape: \t (12652, 128)\n",
      "CPU times: user 1.37 s, sys: 192 ms, total: 1.56 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_median(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, :, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_median = np.median(probas_newaxis, axis=-1)\n",
    "    print('probas_median.shape: \\t', probas_median.shape)\n",
    "    return probas_median\n",
    "\n",
    "ensemble_res['train_median'] = get_acc(y_train ,get_median(y_train_probas))\n",
    "ensemble_res['val_median'] = get_acc(y_val ,get_median(y_val_probas))\n",
    "y_test_proba_median = get_median(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mean  \t0.9665\tval_mean  \t0.8470\n",
      "train_min  \t0.9664\tval_min  \t0.8480\n",
      "train_max  \t0.9654\tval_max  \t0.8459\n",
      "train_median  \t0.9665\tval_median  \t0.8470\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(ensemble_res.keys()):\n",
    "    if i % 2 == 0:\n",
    "        print('%s  \\t%.4f' % (key, ensemble_res[key]), end='\\t')\n",
    "    else:\n",
    "        print('%s  \\t%.4f' % (key, ensemble_res[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**probas_mean.shape: \t (191261, 128)\n",
      "**probas_min.shape: \t (191261, 128)\n",
      "**probas_max.shape: \t (191261, 128)\n",
      "**probas_median.shape: \t (191261, 128)\n",
      "(191261, 512)\n",
      "**probas_mean.shape: \t (6301, 128)\n",
      "**probas_min.shape: \t (6301, 128)\n",
      "**probas_max.shape: \t (6301, 128)\n",
      "**probas_median.shape: \t (6301, 128)\n",
      "(6301, 512)\n",
      "**probas_mean.shape: \t (12652, 128)\n",
      "**probas_min.shape: \t (12652, 128)\n",
      "**probas_max.shape: \t (12652, 128)\n",
      "**probas_median.shape: \t (12652, 128)\n",
      "(12652, 512)\n"
     ]
    }
   ],
   "source": [
    "y_train_probas_sta = np.concatenate([\n",
    "    get_mean(y_train_probas), \n",
    "    get_min(y_train_probas), \n",
    "    get_max(y_train_probas), \n",
    "    get_median(y_train_probas)\n",
    "], axis=-1)\n",
    "print(y_train_probas_sta.shape)\n",
    "\n",
    "y_val_probas_sta = np.concatenate([\n",
    "    get_mean(y_val_probas), \n",
    "    get_min(y_val_probas), \n",
    "    get_max(y_val_probas), \n",
    "    get_median(y_val_probas)\n",
    "], axis=-1)\n",
    "print(y_val_probas_sta.shape)\n",
    "\n",
    "y_test_probas_sta = np.concatenate([\n",
    "    get_mean(y_test_probas), \n",
    "    get_min(y_test_probas), \n",
    "    get_max(y_test_probas), \n",
    "    get_median(y_test_probas)\n",
    "], axis=-1)\n",
    "print(y_test_probas_sta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import xgboost as xgb\n",
    "\n",
    "# xg_train = xgb.DMatrix(y_train_probas_sta, label=y_train)\n",
    "# xg_val = xgb.DMatrix(y_val_probas_sta, label=y_val)\n",
    "# xg_test = xgb.DMatrix(y_test_probas_sta)\n",
    "\n",
    "# # setup parameters for xgboost\n",
    "# param = {}\n",
    "# # use softmax multi-class classification\n",
    "# # param['objective'] = 'binary:logistic'\n",
    "# param['objective'] = 'multi:softmax'\n",
    "# # scale weight of positive examples\n",
    "# param['eta'] = 0.1\n",
    "# param['max_depth'] = 9\n",
    "# param['silent'] = False\n",
    "# param['nthread'] = 6\n",
    "# param['num_class'] = 128\n",
    "# param['learning_rate'] = 0.05\n",
    "# param['n_estimators'] = 2000\n",
    "\n",
    "\n",
    "# watchlist = [(xg_train, 'train'), (xg_val, 'val')]\n",
    "# num_round = 20\n",
    "# bst = xgb.train(param, xg_train, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get prediction\n",
    "# xg_val_pred = bst.predict(xg_val)\n",
    "# print(xg_val_pred.shape)\n",
    "# print(xg_val_pred[0:5])\n",
    "# print('val_acc: %s' % accuracy_score(y_val, xg_val_pred))\n",
    "\n",
    "# xg_test_pred = bst.predict(xg_test)\n",
    "# print(xg_test_pred.shape)\n",
    "# print(xg_test_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_indexes = np.argmax(y_test_proba_mean, -1)\n",
    "# print(xg_test_pred.shape)\n",
    "\n",
    "test_dict = {}\n",
    "for pair in zip(test_filenames, max_indexes):\n",
    "    image_name, indx = pair[0], int(pair[1])\n",
    "    image_name = image_name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print(pair[0], image_name, image_id, indx, indx+1, type(image_id), type(indx))\n",
    "    test_dict[image_id] = indx + 1\n",
    "\n",
    "#确认图片的id是否能与ImageDataGenerator()对应上\n",
    "for name in test_filenames[:10]:\n",
    "    image_name = name.split('/')[-1]\n",
    "    image_id = int(image_name.split('.')[0])\n",
    "#     print('%s\\t%s\\t%s' % (name, image_id, test_dict[image_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         57\n",
       "1   2         74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(len_sample_submission_csv)=12800\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         12\n",
       "1   2         71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 760 ms, total: 12 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "len_sample_submission_csv = len(sample_submission_csv)\n",
    "print('len(len_sample_submission_csv)=%d' % len_sample_submission_csv)\n",
    "count = 0\n",
    "for i in range(len_sample_submission_csv):\n",
    "    image_id = int(sample_submission_csv.iloc[i, 0])\n",
    "    if image_id in test_dict:\n",
    "        pred_label = test_dict[image_id]\n",
    "#         print('%s\\t%s' % (image_id, pred_label))\n",
    "        sample_submission_csv.iloc[i, 1] = pred_label\n",
    "    else:\n",
    "#         print('%s\\t%s' % (image_id, 20))\n",
    "        sample_submission_csv.iloc[i, 1] = 20 # 属于20的类最多，所以全都设置成这个类，可能会比设置成其他得到的结果好\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(int(count/1000), end=' ')\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(sample_submission_csv['predicted'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_furniture2018_Ensemble_Mix3model_20180419_114513_8470\n"
     ]
    }
   ],
   "source": [
    "run_name_acc = run_name + '_' + str(int(ensemble_res['val_mean']*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "sample_submission_csv.to_csv(pred_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_furniture2018_Ensemble_Mix3model_20180419_114513_8470\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(run_name_acc)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
