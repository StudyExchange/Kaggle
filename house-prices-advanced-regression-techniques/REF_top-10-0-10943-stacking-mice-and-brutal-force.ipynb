{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REF_top-10-0-10943-stacking-mice-and-brutal-force\n",
    "\n",
    "参考:\n",
    "- https://www.kaggle.com/agehsbarg/top-10-0-10943-stacking-mice-and-brutal-force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "input_folder = os.path.join(CWD, 'input')\n",
    "output_folder = os.path.join(CWD, 'output')\n",
    "model_folder = os.path.join(CWD, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle\\house-prices-advanced-regression-techniques\\input\\train.csv\n",
      "D:\\Kaggle\\house-prices-advanced-regression-techniques\\input\\test.csv\n",
      "D:\\Kaggle\\house-prices-advanced-regression-techniques\\input\\sample_submission.csv\n",
      "D:\\Kaggle\\house-prices-advanced-regression-techniques\\output\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "train_csv = os.path.join(input_folder, 'train.csv')\n",
    "test_csv = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_csv = os.path.join(input_folder, 'sample_submission.csv')\n",
    "submission_csv = os.path.join(output_folder, 'submission.csv')\n",
    "\n",
    "print(train_csv)\n",
    "print(test_csv)\n",
    "print(sample_submission_csv)\n",
    "print(submission_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities      ...       ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0         Lvl    AllPub      ...               120        0    NaN  MnPrv   \n",
       "1         Lvl    AllPub      ...                 0        0    NaN    NaN   \n",
       "\n",
       "  MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0      6    2010        WD         Normal  \n",
       "1        Gar2   12500      6    2010        WD         Normal  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "display(train_df.shape, train_df.head(2))\n",
    "display(test_df.shape, test_df.head(2))\n",
    "# display(train_df.columns)\n",
    "# display(test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning data(remove outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As suggested by many participants, we remove several outliers\n",
    "train_df.drop(train_df[(train_df['OverallQual']<5) & (train_df['SalePrice']>200000)].index, inplace=True)\n",
    "train_df.drop(train_df[(train_df['GrLivArea']>4000) & (train_df['SalePrice']<300000)].index, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Some of the non-numeric predictors are stored as numbers; we convert them into strings \n",
    "train_df['MSSubClass'] = train_df['MSSubClass'].apply(str)\n",
    "train_df['YrSold'] = train_df['YrSold'].astype(str)\n",
    "train_df['MoSold'] = train_df['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to fill in missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create funtion which fills all the missing values\n",
    "# Pay attention that some of the missing values of numeric predictors first are filled in with zeros and then \n",
    "# small values are filled in with median/average (and indicator variables are created to account for such change: \n",
    "# for each variable we create  which are equal to one);\n",
    "\n",
    "def fill_missings(res):\n",
    "\n",
    "    res['Alley'] = res['Alley'].fillna('missing')\n",
    "    res['PoolQC'] = res['PoolQC'].fillna(res['PoolQC'].mode()[0])\n",
    "    res['MasVnrType'] = res['MasVnrType'].fillna('None')\n",
    "    res['BsmtQual'] = res['BsmtQual'].fillna(res['BsmtQual'].mode()[0])\n",
    "    res['BsmtCond'] = res['BsmtCond'].fillna(res['BsmtCond'].mode()[0])\n",
    "    res['FireplaceQu'] = res['FireplaceQu'].fillna(res['FireplaceQu'].mode()[0])\n",
    "    res['GarageType'] = res['GarageType'].fillna('missing')\n",
    "    res['GarageFinish'] = res['GarageFinish'].fillna(res['GarageFinish'].mode()[0])\n",
    "    res['GarageQual'] = res['GarageQual'].fillna(res['GarageQual'].mode()[0])\n",
    "    res['GarageCond'] = res['GarageCond'].fillna('missing')\n",
    "    res['Fence'] = res['Fence'].fillna('missing')\n",
    "    res['Street'] = res['Street'].fillna('missing')\n",
    "    res['LotShape'] = res['LotShape'].fillna('missing')\n",
    "    res['LandContour'] = res['LandContour'].fillna('missing')\n",
    "    res['BsmtExposure'] = res['BsmtExposure'].fillna(res['BsmtExposure'].mode()[0])\n",
    "    res['BsmtFinType1'] = res['BsmtFinType1'].fillna('missing')\n",
    "    res['BsmtFinType2'] = res['BsmtFinType2'].fillna('missing')\n",
    "    res['CentralAir'] = res['CentralAir'].fillna('missing')\n",
    "    res['Electrical'] = res['Electrical'].fillna(res['Electrical'].mode()[0])\n",
    "    res['MiscFeature'] = res['MiscFeature'].fillna('missing')\n",
    "    res['MSZoning'] = res['MSZoning'].fillna(res['MSZoning'].mode()[0])    \n",
    "    res['Utilities'] = res['Utilities'].fillna('missing')\n",
    "    res['Exterior1st'] = res['Exterior1st'].fillna(res['Exterior1st'].mode()[0])\n",
    "    res['Exterior2nd'] = res['Exterior2nd'].fillna(res['Exterior2nd'].mode()[0])    \n",
    "    res['KitchenQual'] = res['KitchenQual'].fillna(res['KitchenQual'].mode()[0])\n",
    "    res[\"Functional\"] = res[\"Functional\"].fillna(\"Typ\")\n",
    "    res['SaleType'] = res['SaleType'].fillna(res['SaleType'].mode()[0])\n",
    "    res['SaleCondition'] = res['SaleCondition'].fillna('missing')\n",
    "    \n",
    "    flist = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                     'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                     'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                     'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                     'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal']\n",
    "    for fl in flist:\n",
    "        res[fl] = res[fl].fillna(0)\n",
    "        \n",
    "    res['TotalBsmtSF'] = res['TotalBsmtSF'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\n",
    "    res['2ndFlrSF'] = res['2ndFlrSF'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\n",
    "    res['GarageArea'] = res['GarageArea'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\n",
    "    res['GarageCars'] = res['GarageCars'].apply(lambda x: 0 if x <= 0.0 else x)\n",
    "    res['LotFrontage'] = res['LotFrontage'].apply(lambda x: np.exp(4.2) if x <= 0.0 else x)\n",
    "    res['MasVnrArea'] = res['MasVnrArea'].apply(lambda x: np.exp(4) if x <= 0.0 else x)\n",
    "    res['BsmtFinSF1'] = res['BsmtFinSF1'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\n",
    "    \n",
    "      \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing values, re-coding ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running function to fill in missings\n",
    "train_df = fill_missings(train_df)\n",
    "train_df['TotalSF'] = train_df['TotalBsmtSF'] + train_df['1stFlrSF'] + train_df['2ndFlrSF']\n",
    "\n",
    "# Working with ordinal predictors\n",
    "def QualToInt(x):\n",
    "    if(x=='Ex'):\n",
    "        r = 0\n",
    "    elif(x=='Gd'):\n",
    "        r = 1\n",
    "    elif(x=='TA'):\n",
    "        r = 2\n",
    "    elif(x=='Fa'):\n",
    "        r = 3\n",
    "    elif(x=='missing'):\n",
    "        r = 4\n",
    "    else:\n",
    "        r = 5\n",
    "    return r\n",
    "\n",
    "train_df['ExterQual'] = train_df['ExterQual'].apply(QualToInt)\n",
    "train_df['ExterCond'] = train_df['ExterCond'].apply(QualToInt)\n",
    "train_df['KitchenQual'] = train_df['KitchenQual'].apply(QualToInt)\n",
    "train_df['HeatingQC'] = train_df['HeatingQC'].apply(QualToInt)\n",
    "train_df['BsmtQual'] = train_df['BsmtQual'].apply(QualToInt)\n",
    "train_df['BsmtCond'] = train_df['BsmtCond'].apply(QualToInt)\n",
    "train_df['FireplaceQu'] = train_df['FireplaceQu'].apply(QualToInt)\n",
    "train_df['GarageQual'] = train_df['GarageQual'].apply(QualToInt)\n",
    "train_df['PoolQC'] = train_df['PoolQC'].apply(QualToInt)\n",
    "\n",
    "def SlopeToInt(x):\n",
    "    if(x=='Gtl'):\n",
    "        r = 0\n",
    "    elif(x=='Mod'):\n",
    "        r = 1\n",
    "    elif(x=='Sev'):\n",
    "        r = 2\n",
    "    else:\n",
    "        r = 3\n",
    "    return r\n",
    "\n",
    "train_df['LandSlope'] = train_df['LandSlope'].apply(SlopeToInt)\n",
    "train_df['CentralAir'] = train_df['CentralAir'].apply( lambda x: 0 if x == 'N' else 1) \n",
    "train_df['Street'] = train_df['Street'].apply( lambda x: 0 if x == 'Pave' else 1) \n",
    "train_df['PavedDrive'] = train_df['PavedDrive'].apply( lambda x: 0 if x == 'Y' else 1)\n",
    "\n",
    "def GFinishToInt(x):\n",
    "    if(x=='Fin'):\n",
    "        r = 0\n",
    "    elif(x=='RFn'):\n",
    "        r = 1\n",
    "    elif(x=='Unf'):\n",
    "        r = 2\n",
    "    else:\n",
    "        r = 3\n",
    "    return r\n",
    "\n",
    "train_df['GarageFinish'] = train_df['GarageFinish'].apply(GFinishToInt)\n",
    "\n",
    "def BsmtExposureToInt(x):\n",
    "    if(x=='Gd'):\n",
    "        r = 0\n",
    "    elif(x=='Av'):\n",
    "        r = 1\n",
    "    elif(x=='Mn'):\n",
    "        r = 2\n",
    "    elif(x=='No'):\n",
    "        r = 3\n",
    "    else:\n",
    "        r = 4\n",
    "    return r\n",
    "train_df['BsmtExposure'] = train_df['BsmtExposure'].apply(BsmtExposureToInt)\n",
    "\n",
    "def FunctionalToInt(x):\n",
    "    if(x=='Typ'):\n",
    "        r = 0\n",
    "    elif(x=='Min1'):\n",
    "        r = 1\n",
    "    elif(x=='Min2'):\n",
    "        r = 1\n",
    "    else:\n",
    "        r = 2\n",
    "    return r\n",
    "\n",
    "train_df['Functional_int'] = train_df['Functional'].apply(FunctionalToInt)\n",
    "\n",
    "\n",
    "def HouseStyleToInt(x):\n",
    "    if(x=='1.5Unf'):\n",
    "        r = 0\n",
    "    elif(x=='SFoyer'):\n",
    "        r = 1\n",
    "    elif(x=='1.5Fin'):\n",
    "        r = 2\n",
    "    elif(x=='2.5Unf'):\n",
    "        r = 3\n",
    "    elif(x=='SLvl'):\n",
    "        r = 4\n",
    "    elif(x=='1Story'):\n",
    "        r = 5\n",
    "    elif(x=='2Story'):\n",
    "        r = 6  \n",
    "    elif(x==' 2.5Fin'):\n",
    "        r = 7          \n",
    "    else:\n",
    "        r = 8\n",
    "    return r\n",
    "\n",
    "train_df['HouseStyle_int'] = train_df['HouseStyle'].apply(HouseStyleToInt)\n",
    "train_df['HouseStyle_1st'] = 1*(train_df['HouseStyle'] == '1Story')\n",
    "train_df['HouseStyle_2st'] = 1*(train_df['HouseStyle'] == '2Story')\n",
    "train_df['HouseStyle_15st'] = 1*(train_df['HouseStyle'] == '1.5Fin')\n",
    "\n",
    "def FoundationToInt(x):\n",
    "    if(x=='PConc'):\n",
    "        r = 3\n",
    "    elif(x=='CBlock'):\n",
    "        r = 2\n",
    "    elif(x=='BrkTil'):\n",
    "        r = 1        \n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "train_df['Foundation_int'] = train_df['Foundation'].apply(FoundationToInt)\n",
    "\n",
    "def MasVnrTypeToInt(x):\n",
    "    if(x=='Stone'):\n",
    "        r = 3\n",
    "    elif(x=='BrkFace'):\n",
    "        r = 2\n",
    "    elif(x=='BrkCmn'):\n",
    "        r = 1        \n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "train_df['MasVnrType_int'] = train_df['MasVnrType'].apply(MasVnrTypeToInt)\n",
    "\n",
    "def BsmtFinType1ToInt(x):\n",
    "    if(x=='GLQ'):\n",
    "        r = 6\n",
    "    elif(x=='ALQ'):\n",
    "        r = 5\n",
    "    elif(x=='BLQ'):\n",
    "        r = 4\n",
    "    elif(x=='Rec'):\n",
    "        r = 3   \n",
    "    elif(x=='LwQ'):\n",
    "        r = 2\n",
    "    elif(x=='Unf'):\n",
    "        r = 1        \n",
    "    else:\n",
    "        r = 0\n",
    "    return r\n",
    "\n",
    "train_df['BsmtFinType1_int'] = train_df['BsmtFinType1'].apply(BsmtFinType1ToInt)\n",
    "train_df['BsmtFinType1_Unf'] = 1*(train_df['BsmtFinType1'] == 'Unf')\n",
    "train_df['HasWoodDeck'] = (train_df['WoodDeckSF'] == 0) * 1\n",
    "train_df['HasOpenPorch'] = (train_df['OpenPorchSF'] == 0) * 1\n",
    "train_df['HasEnclosedPorch'] = (train_df['EnclosedPorch'] == 0) * 1\n",
    "train_df['Has3SsnPorch'] = (train_df['3SsnPorch'] == 0) * 1\n",
    "train_df['HasScreenPorch'] = (train_df['ScreenPorch'] == 0) * 1\n",
    "train_df['YearsSinceRemodel'] = train_df['YrSold'].astype(int) - train_df['YearRemodAdd'].astype(int)\n",
    "train_df['Total_Home_Quality'] = train_df['OverallQual'] + train_df['OverallCond']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding log-transformed predictors to raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlogs(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        res = res.assign(newcol=pd.Series(np.log(1.01+res[l])).values)   \n",
    "        res.columns.values[m] = l + '_log'\n",
    "        m += 1\n",
    "    return res\n",
    "\n",
    "loglist = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                 'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                 'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                 'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                 'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','YearRemodAdd','TotalSF']\n",
    "\n",
    "train_df = addlogs(train_df, loglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset for training: adding dummies, adding numeric predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdummies(res, ls):\n",
    "    def encode(encode_df):\n",
    "        encode_df = np.array(encode_df)\n",
    "        enc = OneHotEncoder()\n",
    "        le = LabelEncoder()\n",
    "        le.fit(encode_df)\n",
    "        res1 = le.transform(encode_df).reshape(-1, 1)\n",
    "        enc.fit(res1)\n",
    "        return pd.DataFrame(enc.transform(res1).toarray()), le, enc\n",
    "\n",
    "    decoder = []\n",
    "    outres = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for l in ls:\n",
    "        cat, le, enc = encode(res[l])\n",
    "        cat.columns = [l+str(x) for x in cat.columns]\n",
    "        outres.reset_index(drop=True, inplace=True)\n",
    "        outres = pd.concat([outres, cat], axis = 1)\n",
    "        decoder.append([le,enc])     \n",
    "    \n",
    "    return (outres, decoder)\n",
    "\n",
    "catpredlist = ['MSSubClass','MSZoning','LotShape','LandContour','LotConfig',\n",
    "               'Neighborhood','Condition1','Condition2','BldgType',\n",
    "               'RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n",
    "               'BsmtFinType2','Heating','HouseStyle','Foundation','MasVnrType','BsmtFinType1',\n",
    "               'Electrical','Functional','GarageType','Alley','Utilities',\n",
    "               'GarageCond','Fence','MiscFeature','SaleType','SaleCondition','LandSlope','CentralAir',\n",
    "               'GarageFinish','BsmtExposure','Street']\n",
    "\n",
    "# Applying function to get dummies\n",
    "# Saving decoder - function which can be used to transform new data  \n",
    "res = getdummies(train_df[catpredlist],catpredlist)\n",
    "df = res[0]\n",
    "decoder = res[1]\n",
    "\n",
    "# Adding real valued features\n",
    "floatpredlist = ['LotFrontage_log',\n",
    "                 'LotArea_log',\n",
    "                 'MasVnrArea_log','BsmtFinSF1_log','BsmtFinSF2_log','BsmtUnfSF_log',\n",
    "                 'TotalBsmtSF_log','1stFlrSF_log','2ndFlrSF_log','LowQualFinSF_log','GrLivArea_log',\n",
    "                 'BsmtFullBath_log','BsmtHalfBath_log','FullBath_log','HalfBath_log','BedroomAbvGr_log','KitchenAbvGr_log',\n",
    "                 'TotRmsAbvGrd_log','Fireplaces_log','GarageCars_log','GarageArea_log',\n",
    "                 'PoolArea_log','MiscVal_log',\n",
    "                 'YearRemodAdd','TotalSF_log','OverallQual','OverallCond','ExterQual','ExterCond','KitchenQual',\n",
    "                 'HeatingQC','BsmtQual','BsmtCond','FireplaceQu','GarageQual','PoolQC','PavedDrive',\n",
    "                 'HasWoodDeck', 'HasOpenPorch','HasEnclosedPorch', 'Has3SsnPorch', 'HasScreenPorch']\n",
    "df = pd.concat([df,train_df[floatpredlist]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset for training: using function which creates squared predictors and adding them to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSquared(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        res = res.assign(newcol=pd.Series(res[l]*res[l]).values)   \n",
    "        res.columns.values[m] = l + '_sq'\n",
    "        m += 1\n",
    "    return res \n",
    "\n",
    "sqpredlist = ['YearRemodAdd', 'LotFrontage_log', \n",
    "              'TotalBsmtSF_log', '1stFlrSF_log', '2ndFlrSF_log', 'GrLivArea_log',\n",
    "              'GarageCars_log', 'GarageArea_log',\n",
    "              'OverallQual','ExterQual','BsmtQual','GarageQual','FireplaceQu','KitchenQual']\n",
    "df = addSquared(df, sqpredlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df)\n",
    "X = np.delete(X, 0, axis=1)\n",
    "y = np.log(1+np.array(train_df['SalePrice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "- 30-fold cross-validation.\n",
    "- Stacking: on each run of cross-validation I fit 5 models (l2, l1, GBR, ENet and LGB).\n",
    "- Then we make 5 predictions using these models on left-out fold and add geometric mean of these predictions.\n",
    "- Finally, use lasso on these six predictors to forecast values on the left-out fold.\n",
    "- Save all the models (in total we have 30*6=180 models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1\n",
      "fold:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3\n",
      "fold:  4\n",
      "fold:  5\n",
      "fold:  6\n",
      "fold:  7\n",
      "fold:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  9\n",
      "fold:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  11\n",
      "fold:  12\n",
      "fold:  13\n",
      "fold:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  15\n",
      "fold:  16\n",
      "fold:  17\n",
      "fold:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  19\n",
      "fold:  20\n"
     ]
    }
   ],
   "source": [
    "nF = 20\n",
    "\n",
    "kf = KFold(n_splits=nF, random_state=241, shuffle=True)\n",
    "\n",
    "test_errors_l2 = []\n",
    "train_errors_l2 = []\n",
    "test_errors_l1 = []\n",
    "train_errors_l1 = []\n",
    "test_errors_GBR = []\n",
    "train_errors_GBR = []\n",
    "test_errors_ENet = []\n",
    "test_errors_LGB = []\n",
    "test_errors_stack = []\n",
    "test_errors_ens = []\n",
    "train_errors_ens = []\n",
    "\n",
    "models = []\n",
    "\n",
    "pred_all = []\n",
    "\n",
    "ifold = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold: ',ifold)\n",
    "    ifold = ifold + 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # ridge\n",
    "    l2Regr = Ridge(alpha=9.0, fit_intercept = True)\n",
    "    l2Regr.fit(X_train, y_train)\n",
    "    pred_train_l2 = l2Regr.predict(X_train)\n",
    "    pred_test_l2 = l2Regr.predict(X_test)\n",
    "    \n",
    "    # lasso\n",
    "    l1Regr = make_pipeline(RobustScaler(), Lasso(alpha = 0.0003, random_state=1, max_iter=50000))\n",
    "    l1Regr.fit(X_train, y_train)\n",
    "    pred_train_l1 = l1Regr.predict(X_train)\n",
    "    pred_test_l1 = l1Regr.predict(X_test)\n",
    "    \n",
    "    # GBR      \n",
    "    myGBR = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.02,\n",
    "                                      max_depth=4, max_features='sqrt',\n",
    "                                      min_samples_leaf=15, min_samples_split=50,\n",
    "                                      loss='huber', random_state = 5) \n",
    "    \n",
    "    myGBR.fit(X_train,y_train)\n",
    "    pred_train_GBR = myGBR.predict(X_train)\n",
    "\n",
    "    pred_test_GBR = myGBR.predict(X_test)\n",
    "    \n",
    "    # ENet\n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=4.0, l1_ratio=0.005, random_state=3))\n",
    "    ENet.fit(X_train, y_train)\n",
    "    pred_train_ENet = ENet.predict(X_train)\n",
    "    pred_test_ENet = ENet.predict(X_test) \n",
    "    \n",
    "    # LGB\n",
    "    myLGB = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=600,\n",
    "                              max_bin = 50, bagging_fraction = 0.6,\n",
    "                              bagging_freq = 5, feature_fraction = 0.25,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf = 6, min_sum_hessian_in_leaf = 11)\n",
    "    myLGB.fit(X_train, y_train)\n",
    "    pred_train_LGB = myLGB.predict(X_train)\n",
    "    pred_test_LGB = myLGB.predict(X_test)      \n",
    "    \n",
    "    # Stacking\n",
    "    stackedset = pd.DataFrame({'A' : []})\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_l2)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_l1)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_GBR)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_ENet)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_LGB)],axis=1)\n",
    "    prod = (pred_test_l2*pred_test_l1*pred_test_GBR*pred_test_ENet*pred_test_LGB) ** (1.0/5.0)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(prod)],axis=1)\n",
    "    Xstack = np.array(stackedset)\n",
    "    Xstack = np.delete(Xstack, 0, axis=1)\n",
    "    l1_staked = Lasso(alpha = 0.0001,fit_intercept = True)\n",
    "    l1_staked.fit(Xstack, y_test)\n",
    "    pred_test_stack = l1_staked.predict(Xstack)\n",
    "    \n",
    "    models.append([l2Regr,l1Regr,myGBR,ENet,myLGB,l1_staked])\n",
    "    \n",
    "    test_errors_l2.append(np.square(pred_test_l2 - y_test).mean() ** 0.5)\n",
    "    test_errors_l1.append(np.square(pred_test_l1 - y_test).mean() ** 0.5)\n",
    "    test_errors_GBR.append(np.square(pred_test_GBR - y_test).mean() ** 0.5)\n",
    "    test_errors_ENet.append(np.square(pred_test_ENet - y_test).mean() ** 0.5)\n",
    "    test_errors_LGB.append(np.square(pred_test_LGB - y_test).mean() ** 0.5)\n",
    "    test_errors_stack.append(np.square(pred_test_stack - y_test).mean() ** 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of test set errors; they should be lower then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10914198827966848\n",
      "0.10890105888453805\n",
      "0.11084442248774302\n",
      "0.21631250938730026\n",
      "0.11658068641611444\n",
      "0.09805831828206504\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(test_errors_l2))\n",
    "print(np.mean(test_errors_l1))\n",
    "print(np.mean(test_errors_GBR))\n",
    "print(np.mean(test_errors_ENet))\n",
    "print(np.mean(test_errors_LGB))\n",
    "print(np.mean(test_errors_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring: predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredata = pd.read_csv(test_csv)\n",
    "\n",
    "scoredata['MSSubClass'] = scoredata['MSSubClass'].apply(str)\n",
    "scoredata['YrSold'] = scoredata['YrSold'].astype(str)\n",
    "scoredata['MoSold'] = scoredata['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing values, re-coding ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredata = fill_missings(scoredata)\n",
    "\n",
    "scoredata['ExterQual'] = scoredata['ExterQual'].apply(QualToInt)\n",
    "scoredata['ExterCond'] = scoredata['ExterCond'].apply(QualToInt)\n",
    "scoredata['KitchenQual'] = scoredata['KitchenQual'].apply(QualToInt)\n",
    "scoredata['HeatingQC'] = scoredata['HeatingQC'].apply(QualToInt)\n",
    "scoredata['BsmtQual'] = scoredata['BsmtQual'].apply(QualToInt)\n",
    "scoredata['BsmtCond'] = scoredata['BsmtCond'].apply(QualToInt)\n",
    "scoredata['FireplaceQu'] = scoredata['FireplaceQu'].apply(QualToInt)\n",
    "scoredata['GarageQual'] = scoredata['GarageQual'].apply(QualToInt)\n",
    "scoredata['PoolQC'] = scoredata['PoolQC'].apply(QualToInt)\n",
    "scoredata['LandSlope'] = scoredata['LandSlope'].apply(SlopeToInt)\n",
    "scoredata['CentralAir'] = scoredata['CentralAir'].apply( lambda x: 0 if x == 'N' else 1) \n",
    "scoredata['Street'] = scoredata['Street'].apply( lambda x: 0 if x == 'Grvl' else 1) \n",
    "scoredata['GarageFinish'] = scoredata['GarageFinish'].apply(GFinishToInt)\n",
    "scoredata['BsmtExposure'] = scoredata['BsmtExposure'].apply(BsmtExposureToInt)\n",
    "\n",
    "scoredata['TotalSF'] = scoredata['TotalBsmtSF'] + scoredata['1stFlrSF'] + scoredata['2ndFlrSF']\n",
    "scoredata['TotalSF'] = scoredata['TotalSF'].fillna(0)\n",
    "\n",
    "scoredata['Functional_int'] = scoredata['Functional'].apply(FunctionalToInt)\n",
    "scoredata['HouseStyle_int'] = scoredata['HouseStyle'].apply(HouseStyleToInt)\n",
    "scoredata['HouseStyle_1st'] = 1*(scoredata['HouseStyle'] == '1Story')\n",
    "scoredata['HouseStyle_2st'] = 1*(scoredata['HouseStyle'] == '2Story')\n",
    "scoredata['HouseStyle_15st'] = 1*(scoredata['HouseStyle'] == '1.5Fin')\n",
    "scoredata['Foundation_int'] = scoredata['Foundation'].apply(FoundationToInt)\n",
    "scoredata['MasVnrType_int'] = scoredata['MasVnrType'].apply(MasVnrTypeToInt)\n",
    "scoredata['BsmtFinType1_int'] = scoredata['BsmtFinType1'].apply(BsmtFinType1ToInt)\n",
    "scoredata['BsmtFinType1_Unf'] = 1*(scoredata['BsmtFinType1'] == 'Unf')\n",
    "scoredata['PavedDrive'] = scoredata['PavedDrive'].apply( lambda x: 0 if x == 'Y' else 1)\n",
    "\n",
    "scoredata['HasWoodDeck'] = (scoredata['WoodDeckSF'] == 0) * 1\n",
    "scoredata['HasOpenPorch'] = (scoredata['OpenPorchSF'] == 0) * 1\n",
    "scoredata['HasEnclosedPorch'] = (scoredata['EnclosedPorch'] == 0) * 1\n",
    "scoredata['Has3SsnPorch'] = (scoredata['3SsnPorch'] == 0) * 1\n",
    "scoredata['HasScreenPorch'] = (scoredata['ScreenPorch'] == 0) * 1\n",
    "scoredata['Total_Home_Quality'] = scoredata['OverallQual'] + scoredata['OverallCond']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing newly appeared values for some predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredata['MSSubClass'] = scoredata['MSSubClass'].apply(lambda x: '20' if x == '150' else x)\n",
    "scoredata['MSZoning'] = scoredata['MSZoning'].apply(lambda x: 'RL' if x == 'missing' else x)\n",
    "scoredata['Utilities'] = scoredata['Utilities'].apply(lambda x: 'AllPub' if x == 'missing' else x)\n",
    "scoredata['Exterior1st'] = scoredata['Exterior1st'].apply(lambda x: 'VinylSd' if x == 'missing' else x)\n",
    "scoredata['Exterior2nd'] = scoredata['Exterior2nd'].apply(lambda x: 'VinylSd' if x == 'missing' else x)\n",
    "scoredata['Functional'] = scoredata['Functional'].apply(lambda x: 'Typ' if x == 'missing' else x)\n",
    "scoredata['SaleType'] = scoredata['SaleType'].apply(lambda x: 'WD' if x == 'missing' else x)\n",
    "scoredata['SaleCondition'] = scoredata['SaleCondition'].apply(lambda x: 'Normal' if x == 'missing' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding log-transformed predictors to raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredata = addlogs(scoredata, loglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset for training: dummies, adding numeric variables, adding squared predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdummies_transform(res, ls, decoder):\n",
    "    def encode(encode_df, le_df, enc_df):\n",
    "        encode_df = np.array(encode_df)\n",
    "        res1 = le_df.transform(encode_df).reshape(-1, 1)\n",
    "        return pd.DataFrame(enc_df.transform(res1).toarray())\n",
    "    \n",
    "    L = len(ls)\n",
    "    outres = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for j in range(L):\n",
    "        l = ls[j]\n",
    "        le = decoder[j][0]\n",
    "        enc = decoder[j][1]\n",
    "        cat = encode(res[l], le, enc)\n",
    "        cat.columns = [l+str(x) for x in cat.columns]\n",
    "        outres.reset_index(drop=True, inplace=True)\n",
    "        outres = pd.concat([outres, cat], axis = 1)\n",
    "    \n",
    "    return outres\n",
    "\n",
    "df_scores = getdummies_transform(scoredata, catpredlist, decoder)\n",
    "df_scores = pd.concat([df_scores,scoredata[floatpredlist]],axis=1)\n",
    "df_scores = addSquared(df_scores, sqpredlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score = np.array(df_scores)\n",
    "X_score = np.delete(X_score, 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = X_score.shape[0]\n",
    "scores_fin = 1+np.zeros(M)\n",
    "\n",
    "for md in models:\n",
    "    l2 = md[0]\n",
    "    l1 = md[1]\n",
    "    GBR = md[2]\n",
    "    ENet = md[3]\n",
    "    LGB = md[4]\n",
    "    l1_stacked = md[5]\n",
    "    \n",
    "    l2_scores = l2.predict(X_score)\n",
    "    l1_scores = l1.predict(X_score)\n",
    "    GBR_scores = GBR.predict(X_score)\n",
    "    ENet_scores = ENet.predict(X_score)\n",
    "    LGB_scores = LGB.predict(X_score)\n",
    "    \n",
    "    stackedsets = pd.DataFrame({'A' : []})\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(l2_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(l1_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(GBR_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(ENet_scores)],axis=1)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(LGB_scores)],axis=1)\n",
    "    prod = (l2_scores*l1_scores*GBR_scores*ENet_scores*LGB_scores) ** (1.0/5.0)\n",
    "    stackedsets = pd.concat([stackedsets,pd.DataFrame(prod)],axis=1)    \n",
    "    Xstacks = np.array(stackedsets)\n",
    "    Xstacks = np.delete(Xstacks, 0, axis=1)\n",
    "    scores_fin = scores_fin * l1_stacked.predict(Xstacks)\n",
    "scores_fin = scores_fin ** (1/nF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/svm-solution-32/svm_solution_32.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-699542383725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msvm_solution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/svm-solution-32/svm_solution_32.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msvm_solution_ln\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_solution\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Averaging stacked and SVM predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfin_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_fin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msvm_solution_ln\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/svm-solution-32/svm_solution_32.csv' does not exist"
     ]
    }
   ],
   "source": [
    "svm_solution = pd.read_csv('../input/svm-solution-32/svm_solution_32.csv')\n",
    "svm_solution_ln = np.log(svm_solution['SalePrice'])\n",
    "\n",
    "# Averaging stacked and SVM predictions\n",
    "fin_score = np.sqrt(scores_fin * svm_solution_ln)\n",
    "\n",
    "Id = scoredata['Id']\n",
    "fin_score = pd.DataFrame({'SalePrice': np.exp(fin_score)-1})\n",
    "fin_data = pd.concat([Id,fin_score],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brutal approach to deal with predictions close to outer range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fin_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2c41aa9efce5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0042\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mq2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfin_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mq1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.77\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfin_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mq2\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fin_data' is not defined"
     ]
    }
   ],
   "source": [
    "q1 = fin_data['SalePrice'].quantile(0.0042)\n",
    "q2 = fin_data['SalePrice'].quantile(0.99)\n",
    "\n",
    "fin_data['SalePrice'] = fin_data['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "fin_data['SalePrice'] = fin_data['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing dataset for submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.to_csv('House_Prices_submit.csv', sep=',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
