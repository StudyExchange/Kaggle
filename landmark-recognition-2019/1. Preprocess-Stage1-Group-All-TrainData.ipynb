{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess-Stage1-Group-All-TrainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google-LandMark-Rec2019_1-Preprocess-Stage1-Group-All-TrainData_20190503-052200\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "project_name = 'Google-LandMark-Rec2019'\n",
    "step_name = '1-Preprocess-Stage1-Group-All-TrainData'\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  2\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "# train_tar_count = 500\n",
    "train_data_ratio = 0.95\n",
    "\n",
    "# print('train_tar_count:', train_tar_count)\n",
    "print('cpu_amount: ', cpu_amount)\n",
    "print(train_data_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os, sys, gc, math, shutil, zipfile, pickle, h5py, re, tarfile\n",
    "import urllib, xlsxwriter\n",
    "from tqdm import tqdm\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create folder: /data/landmark-recognition-2019/input/data_train\n",
      "create folder: /data/landmark-recognition-2019/input/data_val\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "md5sum_folder = os.path.join(input_folder, 'md5sum')\n",
    "if not os.path.exists(md5sum_folder):\n",
    "    os.mkdir(md5sum_folder)\n",
    "    print('create folder:', md5sum_folder)\n",
    "    \n",
    "train_tar_folder = os.path.join(input_folder, 'train_tar')\n",
    "if not os.path.exists(train_tar_folder):\n",
    "    os.mkdir(train_tar_folder)\n",
    "    print('create folder:', train_tar_folder)\n",
    "    \n",
    "train_untar_folder = os.path.join(input_folder, 'train_untar')\n",
    "if not os.path.exists(train_untar_folder):\n",
    "    os.mkdir(train_untar_folder)\n",
    "    print('create folder:', train_untar_folder)\n",
    "    \n",
    "all_image_folder = os.path.join(input_folder, 'all_image')\n",
    "if not os.path.exists(all_image_folder):\n",
    "    os.mkdir(all_image_folder)\n",
    "    print('create folder:', all_image_folder)\n",
    "    \n",
    "data_train_folder = os.path.join(input_folder, 'data_train')\n",
    "if not os.path.exists(data_train_folder):\n",
    "    os.mkdir(data_train_folder)\n",
    "    print('create folder:', data_train_folder)\n",
    "    \n",
    "data_val_folder = os.path.join(input_folder, 'data_val')\n",
    "if not os.path.exists(data_val_folder):\n",
    "    os.mkdir(data_val_folder)\n",
    "    print('create folder:', data_val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019\n",
      "total 1.7G\n",
      "drwxr-xr-x   2 root   root   160M May  2 21:14 all_image\n",
      "drwxr-xr-x   2 root   root   4.0K May  3 05:22 data_train\n",
      "drwxr-xr-x   2 root   root   4.0K May  3 05:22 data_val\n",
      "-rw-rw-r--   1 ubuntu ubuntu 108M May  1 17:18 google-landmarks-dataset.zip\n",
      "drwxr-xr-x   2 root   root    24K May  1 17:29 md5sum\n",
      "----------   1 root   root   3.0M Apr  8 02:17 recognition_sample_submission.csv\n",
      "-rw-r--r--   1 root   root   1.3M May  3 05:08 recognition_sample_submission.csv.zip\n",
      "-rw-r--r--   1 root   root   965M Apr  5 21:54 train_attribution.csv\n",
      "-rw-r--r--   1 root   root   502M Apr  5 21:57 train.csv\n",
      "drwxr-xr-x   2 root   root    20K May  2 20:39 train_tar\n",
      "drwxr-xr-x 502 root   root    20K May  2 20:39 train_untar\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls ./input -hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e42936e3627d8989.jpg\n",
      "96d0f4fec18d8c84.jpg\n",
      "02fd1c4af95765fd.jpg\n",
      "37bdd02aebba82a6.jpg\n",
      "b732241b0be6a043.jpg\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls ./input/all_image/ -U|head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/google-landmark/metadata/train.csv\n",
    "# !wget https://s3.amazonaws.com/google-landmark/metadata/train_attribution.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/input/train.csv\n",
      "/data/landmark-recognition-2019/input/test.csv\n",
      "/data/landmark-recognition-2019/input/google_landmark_boxes_split1.csv\n",
      "/data/landmark-recognition-2019/input/google_landmark_boxes_split2.csv\n",
      "/data/landmark-recognition-2019/input/recognition_sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "train_csv = os.path.join(input_folder, 'train.csv')\n",
    "test_csv = os.path.join(input_folder, 'test.csv')\n",
    "boxes_split1_csv = os.path.join(input_folder, 'google_landmark_boxes_split1.csv')\n",
    "boxes_split2_csv = os.path.join(input_folder, 'google_landmark_boxes_split2.csv')\n",
    "recognition_sample_submission_csv = os.path.join(input_folder, 'recognition_sample_submission.csv')\n",
    "\n",
    "print(train_csv)\n",
    "print(test_csv)\n",
    "print(boxes_split1_csv)\n",
    "print(boxes_split2_csv)\n",
    "print(recognition_sample_submission_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4132914, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e158a47eb2ca3f6</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>142820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202cd79556f30760</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>104169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "1  202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "\n",
       "   landmark_id  \n",
       "0       142820  \n",
       "1       104169  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 1.09 s, total: 18.5 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(train_csv, engine='python', nrows=None)\n",
    "display(train_df.shape, train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3926268, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210540</th>\n",
       "      <td>cbb444c0030bfa4b</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>108049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860659</th>\n",
       "      <td>4d646b4d708774ac</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>144088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                                url  \\\n",
       "210540   cbb444c0030bfa4b  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "2860659  4d646b4d708774ac  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "         landmark_id  \n",
       "210540        108049  \n",
       "2860659       144088  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(206646, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110858</th>\n",
       "      <td>7de387b44621a7af</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>176343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756123</th>\n",
       "      <td>bea8782edec2c797</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>39511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                                url  \\\n",
       "1110858  7de387b44621a7af  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "1756123  bea8782edec2c797  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "\n",
       "         landmark_id  \n",
       "1110858       176343  \n",
       "1756123        39511  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train_df, data_val_df = train_test_split(train_df, train_size=train_data_ratio)\n",
    "display(data_train_df.shape, data_train_df.head(2))\n",
    "display(data_val_df.shape, data_val_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group all categories by creating soft link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************************************************************************************|\n",
      "*********************************************************************************|\n",
      "******************************************************************************************************************|\n",
      "**********************data_train_invalid_count: 0\n",
      "data_train_softlink_count: 3926268\n",
      "CPU times: user 16min 41s, sys: 5min 38s, total: 22min 20s\n",
      "Wall time: 4h 13min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data_train\n",
    "data_train_invalid_count = 0\n",
    "data_train_softlink_count = 0\n",
    "for idx, row in data_train_df.iterrows():\n",
    "    src_image_path = os.path.join(all_image_folder, '%s.jpg' % row['id'])\n",
    "#     print(src_image_path)\n",
    "    if not os.path.exists(src_image_path):\n",
    "        data_train_invalid_count += 1\n",
    "        continue\n",
    "#     print(src_image_path)\n",
    "    target_image_folder = os.path.join(data_train_folder, '%06d' % row['landmark_id'])\n",
    "#     print(target_image_folder)\n",
    "    if not os.path.exists(target_image_folder):\n",
    "        os.mkdir(target_image_folder)\n",
    "#         print('Folder created:', target_image_folder)\n",
    "    target_image_path = os.path.join(target_image_folder, '%s.jpg' % row['id'])\n",
    "    if not os.path.exists(target_image_path):\n",
    "        data_train_softlink_count += 1\n",
    "        os.symlink(src_image_path, target_image_path)\n",
    "    if (idx+1) % 10000 == 0:\n",
    "        print('*', end='')\n",
    "    if (idx+1) % 1000000 == 0:\n",
    "        print('|')\n",
    "\n",
    "print('data_train_invalid_count:', data_train_invalid_count)\n",
    "print('data_train_softlink_count:', data_train_softlink_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********|\n",
      "**************|\n",
      "**data_val_invalid_count: 0\n",
      "data_val_softlink_count: 206646\n",
      "CPU times: user 47.9 s, sys: 21.5 s, total: 1min 9s\n",
      "Wall time: 10min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data_val\n",
    "data_val_invalid_count = 0\n",
    "data_val_softlink_count = 0\n",
    "for idx, row in data_val_df.iterrows():\n",
    "    src_image_path = os.path.join(all_image_folder, '%s.jpg' % row['id'])\n",
    "#     print(src_image_path)\n",
    "    if not os.path.exists(src_image_path):\n",
    "        data_val_invalid_count += 1\n",
    "        continue\n",
    "#     print(src_image_path)\n",
    "    target_image_folder = os.path.join(data_val_folder, '%06d' % row['landmark_id'])\n",
    "#     print(target_image_folder)\n",
    "    if not os.path.exists(target_image_folder):\n",
    "        os.mkdir(target_image_folder)\n",
    "#         print('Folder created:', target_image_folder)\n",
    "    target_image_path = os.path.join(target_image_folder, '%s.jpg' % row['id'])\n",
    "    if not os.path.exists(target_image_path):\n",
    "        data_val_softlink_count += 1\n",
    "        os.symlink(src_image_path, target_image_path)\n",
    "    if (idx+1) % 10000 == 0:\n",
    "        print('*', end='')\n",
    "    if (idx+1) % 100000 == 0:\n",
    "        print('|')\n",
    "\n",
    "print('data_val_invalid_count:', data_val_invalid_count)\n",
    "print('data_val_softlink_count:', data_val_softlink_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 15826.4s\n",
      "Google-LandMark-Rec2019_1-Preprocess-Stage1-Group-All-TrainData_20190503-052200\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed: %.1fs' % (time.time() - t0))\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
