{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess-Stage1-Group-All-TrainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google-LandMark-Rec2019_1-Preprocess-Stage1-Group-All-TrainData_20190424-152705\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "project_name = 'Google-LandMark-Rec2019'\n",
    "step_name = '1-Preprocess-Stage1-Group-All-TrainData'\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "# train_tar_count = 500\n",
    "\n",
    "# print('train_tar_count:', train_tar_count)\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os, sys, gc, math, shutil, zipfile, pickle, h5py, re, tarfile\n",
    "import urllib, xlsxwriter\n",
    "from tqdm import tqdm\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "md5sum_folder = os.path.join(input_folder, 'md5sum')\n",
    "if not os.path.exists(md5sum_folder):\n",
    "    os.mkdir(md5sum_folder)\n",
    "    print('create folder:', md5sum_folder)\n",
    "    \n",
    "train_tar_folder = os.path.join(input_folder, 'train_tar')\n",
    "if not os.path.exists(train_tar_folder):\n",
    "    os.mkdir(train_tar_folder)\n",
    "    print('create folder:', train_tar_folder)\n",
    "    \n",
    "train_untar_folder = os.path.join(input_folder, 'train_untar')\n",
    "if not os.path.exists(train_untar_folder):\n",
    "    os.mkdir(train_untar_folder)\n",
    "    print('create folder:', train_untar_folder)\n",
    "    \n",
    "all_image_folder = os.path.join(input_folder, 'all_image')\n",
    "if not os.path.exists(all_image_folder):\n",
    "    os.mkdir(all_image_folder)\n",
    "    print('create folder:', all_image_folder)\n",
    "    \n",
    "all_train_data_folder = os.path.join(input_folder, 'all_train_data')\n",
    "if not os.path.exists(all_train_data_folder):\n",
    "    os.mkdir(all_train_data_folder)\n",
    "    print('create folder:', all_train_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019\n",
      "total 1.1G\n",
      "drwxrwxr-x   2 ubuntu ubuntu 161M Apr 24 14:23 all_image\n",
      "drwxrwxr-x   2 ubuntu ubuntu 4.0K Apr 24 14:42 all_train_data\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 127M Apr 20 12:00 data_train.csv\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 108M Apr 21 09:40 google-landmarks-dataset.zip\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 1.9M Apr 20 12:00 google_landmark_boxes_split1.csv\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 1.2M Apr 20 12:00 google_landmark_boxes_split2.csv\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 108M Apr 20 12:00 index.csv\n",
      "drwxrwxrwx   2 ubuntu ubuntu  20K Apr 21 10:10 md5sum\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 3.0M Apr  8 02:17 recognition_sample_submission.csv\n",
      "-rwxrwxrwx   1 ubuntu ubuntu 1.3M Apr 21 09:25 recognition_sample_submission.csv.zip\n",
      "-rwxrwxrwx   1 ubuntu ubuntu  15M Apr 20 12:00 test.csv\n",
      "-rw-rw-r--   1 ubuntu ubuntu 502M Apr  5 21:57 train.csv\n",
      "drwxrwxrwx   2 ubuntu ubuntu  20K Apr 23 16:04 train_tar\n",
      "drwxrwxrwx 502 ubuntu ubuntu  20K Apr 22 22:57 train_untar\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls ./input -hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls ./input/all_image/ -l|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/google-landmark/metadata/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/input/train.csv\n",
      "/data/landmark-recognition-2019/input/test.csv\n",
      "/data/landmark-recognition-2019/input/google_landmark_boxes_split1.csv\n",
      "/data/landmark-recognition-2019/input/google_landmark_boxes_split2.csv\n",
      "/data/landmark-recognition-2019/input/recognition_sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "train_csv = os.path.join(input_folder, 'train.csv')\n",
    "test_csv = os.path.join(input_folder, 'test.csv')\n",
    "boxes_split1_csv = os.path.join(input_folder, 'google_landmark_boxes_split1.csv')\n",
    "boxes_split2_csv = os.path.join(input_folder, 'google_landmark_boxes_split2.csv')\n",
    "recognition_sample_submission_csv = os.path.join(input_folder, 'recognition_sample_submission.csv')\n",
    "\n",
    "print(train_csv)\n",
    "print(test_csv)\n",
    "print(boxes_split1_csv)\n",
    "print(boxes_split2_csv)\n",
    "print(recognition_sample_submission_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e158a47eb2ca3f6</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>142820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202cd79556f30760</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>104169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "1  202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "\n",
       "   landmark_id  \n",
       "0       142820  \n",
       "1       104169  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.24 s, sys: 365 ms, total: 4.61 s\n",
      "Wall time: 9.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(train_csv, engine='python', nrows=200*10000)\n",
    "display(train_df.shape, train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6e158a47eb2ca3f6</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>142820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202cd79556f30760</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>104169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ad87684c99c06e1</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>37914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7f70e9c61e66af3</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>102140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072182eddd0100e</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>2474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "                  landmark_id  \n",
       "id                             \n",
       "6e158a47eb2ca3f6       142820  \n",
       "202cd79556f30760       104169  \n",
       "3ad87684c99c06e1        37914  \n",
       "e7f70e9c61e66af3       102140  \n",
       "4072182eddd0100e         2474  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_train_df = train_df.set_index(['id'], drop=True)\n",
    "display(index_train_df.shape, index_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'6799cb2970362f33' in index_train_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create soft link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 203093\n"
     ]
    }
   ],
   "source": [
    "min_id = min(train_df['landmark_id'])\n",
    "max_id = max(train_df['landmark_id'])\n",
    "print(min_id, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/input/all_image/6e158a47eb2ca3f6.jpg\n",
      "/data/landmark-recognition-2019/input/all_image/6e158a47eb2ca3f6.jpg\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ivalid_image_count = 0\n",
    "for _, row in train_df[:10].iterrows():\n",
    "    src_image_path = os.path.join(all_image_folder, '%s.jpg' % row['id'])\n",
    "    print(src_image_path)\n",
    "    if not os.path.exists(src_image_path):\n",
    "        ivalid_image_count += 1\n",
    "        continue\n",
    "    print(src_image_path)\n",
    "    target_image_folder = os.path.join(all_train_data, '%06d' % row['landmark_id'])\n",
    "    print(target_image_folder)\n",
    "    if not os.path.exists(target_image_folder):\n",
    "#         os.mkdir(target_image_folder)\n",
    "        print('Folder created:')\n",
    "#     target_image_path = \n",
    "\n",
    "print('ivalid_image_count:', ivalid_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ./input/all_image -U|head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6799cb2970362f33.jpg\n",
    "# 6e60619317ab4083.jpg\n",
    "# a2e31f0268dac709.jpg\n",
    "# 1fa63b7e815a5183.jpg\n",
    "# 6b1701ae0accdf44.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/input/all_image/6e158a47eb2ca3f6.jpg\n"
     ]
    }
   ],
   "source": [
    "print(src_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for i in range(train_tar_count):\n",
    "#     image_folder = os.path.join(train_untar_folder, 'images_%03d' % i)\n",
    "#     if os.path.exists(image_folder):\n",
    "#         src_image_arr = get_all_images_from_folder(image_folder)\n",
    "#         for src_image_path in src_image_arr:\n",
    "#             image_name = src_image_path.split('/')[-1]\n",
    "#             target_image_path = os.path.join(all_image_folder, image_name)\n",
    "# #             print(src_image_path, target_image_path)\n",
    "# #         print(image_folder, len(src_image_arr))\n",
    "#             if not os.path.exists(target_image_path):\n",
    "#                 os.symlink(src_image_path, target_image_path)\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('6799cb2970362f33.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('3e92de9660be546b.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 12.4s\n",
      "Google-LandMark-Rec2019_1-Preprocess-Stage1-Group-All-TrainData_20190424-152705\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed: %.1fs' % (time.time() - t0))\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
