{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict-Image-Similar-FCNN-Binary[split]\n",
    "For landmark-recognition-2019 algorithm validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: 4-Predict[split]_Google-LandMark-Rec2019_3-Image-Similar-FCNN-Binary_20190511-164020_8393_20190513-132618\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Google-LandMark-Rec2019'\n",
    "model_name = 'Google-LandMark-Rec2019_3-Image-Similar-FCNN-Binary_20190511-164020_8393'\n",
    "step_name = '4-Predict[split]_%s' % model_name\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  4\n",
      "small_debug_rows:\t 10\n",
      "big_debug_rows:\t 20\n",
      "libary_batch_amount:\t 20\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)\n",
    "\n",
    "small_debug_rows = 10\n",
    "big_debug_rows = 20\n",
    "libary_batch_amount = 20\n",
    "print('small_debug_rows:\\t', small_debug_rows)\n",
    "print('big_debug_rows:\\t', big_debug_rows)\n",
    "print('libary_batch_amount:\\t', libary_batch_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.05\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(session )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/feature/feature_wrapper_171023.h5\n",
      "/data/landmark-recognition-2019/input/train.csv\n",
      "/data/landmark-recognition-2019/input/test.csv\n",
      "/data/landmark-recognition-2019/input/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "vgg16_feature_file = os.path.join(feature_folder, 'feature_wrapper_171023.h5')\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')\n",
    "print(vgg16_feature_file)\n",
    "print(train_csv_file)\n",
    "print(test_csv_file)\n",
    "print(sample_submission_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "/data/landmark-recognition-2019/temp/pickle_demo.pkl\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "def pickle_dump(data, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def pickle_load(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "a = list(range(10))\n",
    "print(a)\n",
    "demo_file = os.path.join(os.getcwd(), 'temp', 'pickle_demo.pkl')\n",
    "print(demo_file)\n",
    "pickle_dump(a, demo_file)\n",
    "new_a = pickle_load(demo_file)\n",
    "print(new_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.63 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_whole_classes_label(class_indices_data, item_classes_data):\n",
    "    indices2class = {}\n",
    "    for i, key in enumerate(class_indices_data.keys()):\n",
    "#         print(key, class_indices_data[key])\n",
    "        indices2class[class_indices_data[key]] = key\n",
    "#         if i >= 5:\n",
    "#             break\n",
    "#     for i, key in enumerate(class_indices_data.keys()):\n",
    "#         print(key, class_indices_data[key], '-->', class_indices_data[key], indices2class[class_indices_data[key]])\n",
    "#         if i >= 10:\n",
    "#             break\n",
    "    print(item_classes_data.shape)\n",
    "    whole_classes_data = np.zeros(item_classes_data.shape)\n",
    "    for i, class_index in enumerate(item_classes_data):\n",
    "        whole_classes_data[i] = indices2class[class_index]\n",
    "#         print(i, class_index, '-->', indices2class[class_index])\n",
    "#         if i >= 10:\n",
    "#             break\n",
    "    return whole_classes_data\n",
    "# get_whole_classes_label(class_indices_train, item_classes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.6G\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 830K May  3 12:19 feature_VGG16_data_val_171023.h5\r\n",
      "-rw-r--r-- 1 root   root     20 May 11 04:24 feature_VGG19_data_test_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 root   root   222M May 11 04:24 feature_VGG19_data_test_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  6 17:05 feature_VGG19_data_train_00_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 17:05 feature_VGG19_data_train_00_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  6 17:30 feature_VGG19_data_train_01_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 17:30 feature_VGG19_data_train_01_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  6 18:01 feature_VGG19_data_train_02_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 18:01 feature_VGG19_data_train_02_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  6 18:33 feature_VGG19_data_train_03_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 18:33 feature_VGG19_data_train_03_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  6 19:06 feature_VGG19_data_train_04_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 19:06 feature_VGG19_data_train_04_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  6 19:37 feature_VGG19_data_train_05_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 19:37 feature_VGG19_data_train_05_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 630K May  6 20:09 feature_VGG19_data_train_06_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 20:09 feature_VGG19_data_train_06_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  6 20:41 feature_VGG19_data_train_07_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 20:41 feature_VGG19_data_train_07_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  6 21:13 feature_VGG19_data_train_08_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 21:13 feature_VGG19_data_train_08_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  6 21:43 feature_VGG19_data_train_09_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 21:43 feature_VGG19_data_train_09_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  6 22:13 feature_VGG19_data_train_10_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 22:13 feature_VGG19_data_train_10_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  6 22:46 feature_VGG19_data_train_11_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 22:46 feature_VGG19_data_train_11_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  6 23:18 feature_VGG19_data_train_12_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 23:18 feature_VGG19_data_train_12_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  6 23:50 feature_VGG19_data_train_13_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  6 23:50 feature_VGG19_data_train_13_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  7 00:21 feature_VGG19_data_train_14_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 00:21 feature_VGG19_data_train_14_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  7 00:51 feature_VGG19_data_train_15_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 00:51 feature_VGG19_data_train_15_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  7 01:22 feature_VGG19_data_train_16_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 01:22 feature_VGG19_data_train_16_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  7 01:54 feature_VGG19_data_train_17_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 01:54 feature_VGG19_data_train_17_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  7 02:26 feature_VGG19_data_train_18_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 02:26 feature_VGG19_data_train_18_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 637K May  7 02:58 feature_VGG19_data_train_19_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 02:58 feature_VGG19_data_train_19_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  7 03:30 feature_VGG19_data_train_20_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 03:30 feature_VGG19_data_train_20_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  7 04:03 feature_VGG19_data_train_21_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 04:03 feature_VGG19_data_train_21_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 637K May  7 22:38 feature_VGG19_data_train_22_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 22:38 feature_VGG19_data_train_22_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  7 23:07 feature_VGG19_data_train_23_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 23:07 feature_VGG19_data_train_23_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  7 23:36 feature_VGG19_data_train_24_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 23:36 feature_VGG19_data_train_24_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 00:06 feature_VGG19_data_train_25_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 00:06 feature_VGG19_data_train_25_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 00:36 feature_VGG19_data_train_26_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 00:36 feature_VGG19_data_train_26_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  8 01:06 feature_VGG19_data_train_27_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 01:06 feature_VGG19_data_train_27_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  8 01:36 feature_VGG19_data_train_28_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 01:36 feature_VGG19_data_train_28_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  8 02:06 feature_VGG19_data_train_29_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 02:06 feature_VGG19_data_train_29_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 02:35 feature_VGG19_data_train_30_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 02:35 feature_VGG19_data_train_30_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  8 03:05 feature_VGG19_data_train_31_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 03:05 feature_VGG19_data_train_31_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  8 03:35 feature_VGG19_data_train_32_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 03:35 feature_VGG19_data_train_32_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  8 04:07 feature_VGG19_data_train_33_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 04:07 feature_VGG19_data_train_33_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 637K May  8 04:37 feature_VGG19_data_train_34_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 04:37 feature_VGG19_data_train_34_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  8 05:07 feature_VGG19_data_train_35_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 05:07 feature_VGG19_data_train_35_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  8 05:39 feature_VGG19_data_train_36_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 05:39 feature_VGG19_data_train_36_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  8 06:09 feature_VGG19_data_train_37_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 06:09 feature_VGG19_data_train_37_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 06:39 feature_VGG19_data_train_38_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 06:39 feature_VGG19_data_train_38_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 07:09 feature_VGG19_data_train_39_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 07:09 feature_VGG19_data_train_39_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  8 07:39 feature_VGG19_data_train_40_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 07:39 feature_VGG19_data_train_40_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  8 08:10 feature_VGG19_data_train_41_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 08:10 feature_VGG19_data_train_41_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  8 08:40 feature_VGG19_data_train_42_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 08:40 feature_VGG19_data_train_42_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  8 09:09 feature_VGG19_data_train_43_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 09:09 feature_VGG19_data_train_43_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  8 09:41 feature_VGG19_data_train_44_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 09:41 feature_VGG19_data_train_44_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 10:10 feature_VGG19_data_train_45_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 10:10 feature_VGG19_data_train_45_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  8 10:41 feature_VGG19_data_train_46_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 10:41 feature_VGG19_data_train_46_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  8 11:12 feature_VGG19_data_train_47_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 11:12 feature_VGG19_data_train_47_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  8 11:42 feature_VGG19_data_train_48_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 11:42 feature_VGG19_data_train_48_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  8 12:13 feature_VGG19_data_train_49_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  8 12:13 feature_VGG19_data_train_49_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 11:49 feature_VGG19_data_train_50_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 11:49 feature_VGG19_data_train_50_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  5 12:02 feature_VGG19_data_train_51_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 12:02 feature_VGG19_data_train_51_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  5 12:15 feature_VGG19_data_train_52_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 12:15 feature_VGG19_data_train_52_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  5 12:27 feature_VGG19_data_train_53_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 12:27 feature_VGG19_data_train_53_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 630K May  5 12:40 feature_VGG19_data_train_54_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 12:40 feature_VGG19_data_train_54_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  5 12:53 feature_VGG19_data_train_55_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 12:53 feature_VGG19_data_train_55_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  5 13:06 feature_VGG19_data_train_56_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 13:06 feature_VGG19_data_train_56_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  5 13:18 feature_VGG19_data_train_57_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 13:18 feature_VGG19_data_train_57_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  5 13:31 feature_VGG19_data_train_58_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 13:31 feature_VGG19_data_train_58_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  5 13:44 feature_VGG19_data_train_59_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 13:44 feature_VGG19_data_train_59_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 13:57 feature_VGG19_data_train_60_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 13:57 feature_VGG19_data_train_60_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 636K May  5 14:10 feature_VGG19_data_train_61_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 14:10 feature_VGG19_data_train_61_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  5 14:23 feature_VGG19_data_train_62_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 14:23 feature_VGG19_data_train_62_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 14:36 feature_VGG19_data_train_63_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 14:36 feature_VGG19_data_train_63_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 14:49 feature_VGG19_data_train_64_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 14:49 feature_VGG19_data_train_64_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  5 15:02 feature_VGG19_data_train_65_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 15:02 feature_VGG19_data_train_65_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  5 15:15 feature_VGG19_data_train_66_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 15:15 feature_VGG19_data_train_66_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 638K May  5 15:28 feature_VGG19_data_train_67_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 15:28 feature_VGG19_data_train_67_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 631K May  5 15:41 feature_VGG19_data_train_68_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 15:41 feature_VGG19_data_train_68_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 632K May  5 15:54 feature_VGG19_data_train_69_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 15:54 feature_VGG19_data_train_69_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 16:07 feature_VGG19_data_train_70_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 16:07 feature_VGG19_data_train_70_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 630K May  5 16:20 feature_VGG19_data_train_71_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 16:20 feature_VGG19_data_train_71_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 16:33 feature_VGG19_data_train_72_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 16:33 feature_VGG19_data_train_72_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  5 16:47 feature_VGG19_data_train_73_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 16:47 feature_VGG19_data_train_73_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  5 16:59 feature_VGG19_data_train_74_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 16:59 feature_VGG19_data_train_74_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 17:12 feature_VGG19_data_train_75_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 17:12 feature_VGG19_data_train_75_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  5 17:25 feature_VGG19_data_train_76_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 17:25 feature_VGG19_data_train_76_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  5 17:38 feature_VGG19_data_train_77_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  98M May  5 17:38 feature_VGG19_data_train_77_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 381K May  5 17:46 feature_VGG19_data_train_78_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  52M May  5 17:46 feature_VGG19_data_train_78_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  7 16:35 feature_VGG19_data_val_00_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 16:35 feature_VGG19_data_val_00_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 634K May  7 17:06 feature_VGG19_data_val_01_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 17:06 feature_VGG19_data_val_01_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 635K May  7 17:37 feature_VGG19_data_val_02_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 17:37 feature_VGG19_data_val_02_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 633K May  7 18:09 feature_VGG19_data_val_03_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  99M May  7 18:09 feature_VGG19_data_val_03_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 113K May  7 18:13 feature_VGG19_data_val_04_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu  14M May  7 18:13 feature_VGG19_data_val_04_171023.h5\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 405M May  3 16:25 feature_VGG19_data_val_171023.h5\r\n",
      "-rw-r--r-- 1 root   root      6 May 10 13:53 feature_VGG19_test_image_171023_class_indices.pkl\r\n",
      "-rw-r--r-- 1 root   root   1.7K May 10 13:53 feature_VGG19_test_image_171023.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./feature -hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature(data_set_name, model_name, date_str, feature_amount):\n",
    "#     data_set_name = 'train'\n",
    "#     model_name = 'VGG19'\n",
    "#     date_str = '171023'\n",
    "    x_data_arr = []\n",
    "    classes_data_arr = []\n",
    "    index_data_arr = []\n",
    "    for i in range(feature_amount):\n",
    "        folder_name = 'data_%s_%02d' % (data_set_name, i)\n",
    "        class_indices_file = os.path.join(cwd, 'feature', 'feature_{0}_{1}_{2}_class_indices.pkl'.format(model_name, folder_name, date_str))\n",
    "        h5py_file_name = os.path.join(cwd, 'feature', 'feature_{0}_{1}_{2}.h5'.format(model_name, folder_name, date_str))\n",
    "        if not os.path.exists(class_indices_file):\n",
    "            print('File not exists', class_indices_file)\n",
    "            continue\n",
    "        if not os.path.exists(h5py_file_name):\n",
    "            print('File not exists', h5py_file_name)\n",
    "            continue\n",
    "        print(class_indices_file)\n",
    "        print(h5py_file_name)\n",
    "        class_indices_data = pickle_load(class_indices_file)\n",
    "        print(len(class_indices_data))\n",
    "\n",
    "        with h5py.File(h5py_file_name, 'r') as h:\n",
    "            item_x_data = np.array(h['x_data_%s_%02d' % (data_set_name, i)])\n",
    "            item_classes_data = np.array(h['classes_data_%s_%02d' % (data_set_name, i)])\n",
    "            item_index_data = np.array(h['index_data_%s_%02d' % (data_set_name, i)])\n",
    "        print(item_x_data.shape)\n",
    "        x_data_arr.append(item_x_data)\n",
    "        item_y_data = get_whole_classes_label(class_indices_data, item_classes_data)\n",
    "        print(item_y_data.shape, item_y_data[:10])\n",
    "        classes_data_arr.append(item_y_data)\n",
    "        index_data_arr.append(item_index_data)\n",
    "    x_data = np.concatenate(x_data_arr, axis=0)\n",
    "    y_data = np.concatenate(classes_data_arr, axis=0)\n",
    "    idx_data = np.concatenate(index_data_arr, axis=0)\n",
    "    print('*' * 60)\n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    print(idx_data.shape)\n",
    "    return x_data, y_data, idx_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_00_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_00_171023.h5\n",
      "34008\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 0.  3. 24. 25. 27. 27. 27. 27. 48. 52.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_01_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_01_171023.h5\n",
      "34214\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1. 12. 27. 27. 27. 27. 27. 27. 27. 37.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_02_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_02_171023.h5\n",
      "34203\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [12. 17. 18. 27. 27. 27. 27. 27. 30. 35.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_03_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_03_171023.h5\n",
      "34051\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1.  5.  9. 10. 12. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_04_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_04_171023.h5\n",
      "34181\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 9. 27. 27. 27. 30. 48. 50. 66. 76. 79.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_05_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_05_171023.h5\n",
      "34080\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [11. 12. 23. 27. 27. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_06_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_06_171023.h5\n",
      "33985\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 0.  0.  1.  9. 22. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_07_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_07_171023.h5\n",
      "34108\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 0.  3. 12. 22. 23. 24. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_08_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_08_171023.h5\n",
      "34194\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1. 11. 15. 20. 20. 23. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_09_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_09_171023.h5\n",
      "34235\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 9. 10. 27. 27. 27. 27. 27. 27. 27. 36.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_10_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_10_171023.h5\n",
      "34159\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [11. 11. 22. 27. 27. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_11_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_11_171023.h5\n",
      "34103\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 0. 24. 27. 27. 27. 27. 27. 27. 27. 43.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_12_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_12_171023.h5\n",
      "34125\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 7. 10. 18. 22. 23. 26. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_13_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_13_171023.h5\n",
      "34256\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [10. 12. 12. 22. 24. 27. 27. 27. 27. 32.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_14_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_14_171023.h5\n",
      "34100\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 0.  1.  3.  5. 10. 11. 20. 23. 24. 26.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_15_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_15_171023.h5\n",
      "34262\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1.  9. 10. 23. 27. 27. 27. 27. 33. 43.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_16_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_16_171023.h5\n",
      "34107\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1.  9. 10. 23. 25. 26. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_17_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_17_171023.h5\n",
      "34109\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [20. 27. 27. 27. 27. 27. 27. 27. 27. 32.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_18_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_18_171023.h5\n",
      "34190\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 6. 12. 27. 27. 27. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_19_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_train_19_171023.h5\n",
      "34332\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 0.  1.  3.  9. 12. 12. 23. 27. 27. 27.]\n",
      "************************************************************\n",
      "(1000000, 512)\n",
      "(1000000,)\n",
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, idx_train = load_feature('train', 'VGG19', '171023', libary_batch_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_00_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_00_171023.h5\n",
      "34160\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1. 12. 20. 27. 27. 27. 27. 27. 27. 32.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_01_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_01_171023.h5\n",
      "34196\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 9. 11. 24. 27. 27. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_02_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_02_171023.h5\n",
      "34264\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1. 10. 11. 12. 27. 27. 27. 27. 27. 27.]\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_03_171023_class_indices.pkl\n",
      "/data/landmark-recognition-2019/feature/feature_VGG19_data_val_03_171023.h5\n",
      "34155\n",
      "(50000, 512)\n",
      "(50000,)\n",
      "(50000,) [ 1.  2. 10. 11. 13. 24. 27. 27. 27. 27.]\n",
      "************************************************************\n",
      "(200000, 512)\n",
      "(200000,)\n",
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val, idx_val = load_feature('val', 'VGG19', '171023', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/landmark-recognition-2019/model/Google-LandMark-Rec2019_3-Image-Similar-FCNN-Binary_20190511-164020_8393.h5\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model_file = os.path.join(model_folder, '%s.h5' % model_name)\n",
    "print(model_file)\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "library_input (InputLayer)      (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           main_input[0][0]                 \n",
      "                                                                 library_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1024, 1)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024, 1)      4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1024, 2)      4           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1024, 2)      6           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024, 2)      8           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 262,423\n",
      "Trainable params: 262,417\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 --> 0 [143204, 106644, 88680, 126637, 71016, 27725, 46205, 131056, 71615, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "item_main_x = np.array([x_train[idx]]*x_train.shape[0])\n",
    "item_x_train = {\n",
    "    'main_input': item_main_x,\n",
    "    'library_input': x_train\n",
    "}\n",
    "y_proba = model.predict(item_x_train, batch_size=1024)\n",
    "print(int(y_train[idx]), np.argmax(y_proba), '-->', int(y_train[np.argmax(y_proba)]), [int(y_train[item[0]]) for item in np.argsort(y_proba, axis=0)[-10:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.92s 0 --> 0 [143204, 106644, 88680, 126637, 71016, 27725, 46205, 131056, 71615, 0]\n",
      "7.97s 3 --> 74134 [151179, 192124, 107386, 176349, 40014, 132226, 166269, 3, 43351, 74134]\n",
      "7.95s 24 --> 24 [11321, 32165, 193550, 138389, 129902, 201374, 163866, 112956, 109349, 24]\n",
      "7.97s 25 --> 25 [86869, 202063, 244, 121194, 182724, 154318, 65855, 113168, 9604, 25]\n",
      "7.97s 27 --> 27 [138760, 27, 88517, 27, 27, 27, 27, 27, 27, 27]\n",
      "7.99s 27 --> 27 [27, 27, 27, 193759, 50990, 27, 68177, 27, 27, 27]\n",
      "7.96s 27 --> 27 [122096, 27, 113636, 44570, 27, 27, 23830, 27, 27, 27]\n",
      "7.96s 27 --> 27 [19095, 52773, 27, 77203, 48701, 27, 27, 27, 37837, 27]\n",
      "7.96s 48 --> 48 [141654, 55177, 161939, 71555, 150738, 100982, 59663, 99546, 155715, 48]\n",
      "7.97s 52 --> 52 [67091, 65218, 150691, 17212, 20740, 41648, 191292, 108327, 5561, 52]\n",
      "********************************************************************************\n",
      "9 0.90\n",
      "10 1.00\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "amount = small_debug_rows\n",
    "top1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    t0 = time.time()\n",
    "    item_main_x = np.array([x_train[idx]]*x_train.shape[0])\n",
    "    item_x_train = {\n",
    "        'main_input': item_main_x,\n",
    "        'library_input': x_train\n",
    "    }\n",
    "    y_proba = model.predict(item_x_train, batch_size=1024)\n",
    "    item_y_train = int(y_train[idx])\n",
    "    top1_pred = int(y_train[np.argmax(y_proba)])\n",
    "    topn_pred_arr = [int(y_train[item[0]]) for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    if item_y_train == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_train in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    t1 = time.time()\n",
    "    print('%4.2fs' % (t1 - t0), item_y_train, '-->', top1_pred, topn_pred_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]] <class 'numpy.ndarray'>\n",
      "6\n",
      "[0 0 1 1 2 2] <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 2, 1], [0.3, 0.4, 0.5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weight_topn(y_proba, topn, y_data):\n",
    "    y_proba_argsorted = [(y_data[item[0]], y_proba[item[0]][0]) for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    class_score_dict = {}\n",
    "    for item_class, item_proba in y_proba_argsorted:\n",
    "        if item_class in class_score_dict:\n",
    "            class_score_dict[item_class] += item_proba\n",
    "        else:\n",
    "            class_score_dict[item_class] = item_proba\n",
    "    class_score_arr = list(class_score_dict.items())\n",
    "    class_score_arr = sorted(class_score_arr, key=lambda x: x[1])\n",
    "    topn_pred_arr = [int(item[0]) for item in class_score_arr]\n",
    "    class_score_arr = [round(item[1], 3) for item in class_score_arr]\n",
    "    return topn_pred_arr, class_score_arr\n",
    "\n",
    "y_proba = np.array([[0.1], [0.2], [0.3], [0.2], [0.2], [0.2]])\n",
    "topn = 6\n",
    "y_data = np.array([0, 0, 1, 1, 2, 2])\n",
    "print(y_proba, type(y_proba))\n",
    "print(topn)\n",
    "print(y_data, type(y_data))\n",
    "get_weight_topn(y_proba, topn, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 0 \t 0 [143204, 106644, 88680, 126637, 71016, 27725, 46205, 131056, 71615, 0] [0.978, 0.979, 0.98, 0.981, 0.981, 0.981, 0.982, 0.984, 0.986, 0.99]\n",
      "3 --> 74134 \t 74134 [151179, 192124, 107386, 176349, 40014, 132226, 166269, 3, 43351, 74134] [0.974, 0.975, 0.975, 0.976, 0.976, 0.976, 0.977, 0.979, 0.98, 0.981]\n",
      "24 --> 24 \t 24 [11321, 32165, 193550, 138389, 129902, 201374, 163866, 112956, 109349, 24] [0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999]\n",
      "25 --> 25 \t 25 [86869, 202063, 244, 121194, 182724, 154318, 65855, 113168, 9604, 25] [0.991, 0.992, 0.992, 0.992, 0.992, 0.993, 0.994, 0.994, 0.995, 0.997]\n",
      "27 --> 27 \t 27 [138760, 88517, 27] [0.997, 0.997, 7.981]\n",
      "27 --> 27 \t 27 [193759, 50990, 68177, 27] [0.996, 0.996, 0.998, 6.98]\n",
      "27 --> 27 \t 27 [122096, 113636, 44570, 23830, 27] [0.99, 0.99, 0.991, 0.992, 5.96]\n",
      "27 --> 27 \t 27 [19095, 52773, 77203, 48701, 37837, 27] [0.995, 0.995, 0.996, 0.996, 0.997, 4.984]\n",
      "48 --> 48 \t 48 [141654, 55177, 161939, 71555, 150738, 100982, 59663, 99546, 155715, 48] [0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.996, 0.997, 0.998]\n",
      "52 --> 52 \t 52 [67091, 65218, 150691, 17212, 20740, 41648, 191292, 108327, 5561, 52] [0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.996, 0.998]\n",
      "********************************************************************************\n",
      "9 0.90\n",
      "9 0.90\n",
      "10 1.00\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "amount = small_debug_rows\n",
    "top1_count = 0\n",
    "topn_1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    item_main_x = np.array([x_train[idx]]*x_train.shape[0])\n",
    "    item_x_train = {\n",
    "        'main_input': item_main_x,\n",
    "        'library_input': x_train\n",
    "    }\n",
    "    y_proba = model.predict(item_x_train, batch_size=1024)\n",
    "    item_y_train = int(y_train[idx])\n",
    "    top1_pred = int(y_train[np.argmax(y_proba)])\n",
    "#     topn_pred_arr = [y_train[item[0]] for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    topn_pred_arr, class_score_arr = get_weight_topn(y_proba, topn, y_train)\n",
    "    topn_1_pred = topn_pred_arr[-1]\n",
    "    if item_y_train == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_train == topn_1_pred:\n",
    "        topn_1_count += 1\n",
    "    if item_y_train in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_train, '-->', top1_pred, '\\t', topn_1_pred, topn_pred_arr, class_score_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_1_count, '%.2f' % (topn_1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encupsolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0, [143204, 106644, 88680, 126637, 71016, 27725, 46205, 131056, 71615, 0], 0, [143204, 106644, 88680, 126637, 71016, 27725, 46205, 131056, 71615, 0], [0.978, 0.979, 0.98, 0.981, 0.981, 0.981, 0.982, 0.984, 0.986, 0.99])\n",
      "1 (169233, [62074, 198944, 165771, 4822, 188696, 185275, 176528, 156620, 196838, 169233], 169233, [62074, 198944, 165771, 4822, 188696, 185275, 176528, 156620, 196838, 169233], [0.971, 0.972, 0.972, 0.973, 0.974, 0.975, 0.975, 0.976, 0.976, 0.98])\n"
     ]
    }
   ],
   "source": [
    "def get_single_pred(idx, main_x, libary_x, topn, batch_size=1024):\n",
    "    item_main_x = np.array([main_x[idx]]*libary_x.shape[0])\n",
    "    item_x = {\n",
    "        'main_input': item_main_x,\n",
    "        'library_input': libary_x\n",
    "    }\n",
    "    y_proba = model.predict(item_x, batch_size=batch_size)\n",
    "    top1_pred = int(y_train[np.argmax(y_proba)])\n",
    "    topn_pred_arr = [int(y_train[item[0]]) for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    weighted_topn_pred_arr, class_score_arr = get_weight_topn(y_proba, topn, y_train)\n",
    "    weighted_top1_pred = weighted_topn_pred_arr[-1]\n",
    "    return top1_pred, topn_pred_arr, weighted_top1_pred, weighted_topn_pred_arr, class_score_arr\n",
    "\n",
    "idx = 0\n",
    "topn = 10\n",
    "# train\n",
    "print(int(y_train[idx]), get_single_pred(idx, x_train, x_train, topn, batch_size=1024))\n",
    "# val\n",
    "print(int(y_val[idx]), get_single_pred(idx, x_val, x_train, topn, batch_size=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 0 27725 \t [160721, 162324, 45274, 45952, 104519, 115348, 128393, 33626, 114491, 3236, 90412, 25980, 165649, 55305, 92225, 47144, 14915, 186280, 160768, 124545, 135395, 43832, 185205, 89142, 15557, 81674, 136093, 158745, 132226, 43959, 28503, 184786, 57892, 118952, 112774, 173056, 40182, 49649, 179924, 190660, 199923, 173007, 102867, 111689, 152017, 4317, 78361, 22943, 33023, 55347, 137616, 106318, 114058, 7851, 64963, 150881, 107706, 152980, 50798, 129975, 47551, 38610, 8444, 26105, 35221, 6131, 99702, 43175, 57505, 73879, 1706, 7907, 44765, 62554, 194505, 146359, 76815, 44368, 14905, 88680, 126637, 71016, 46205, 131056, 71615, 0, 167988, 39592, 127989, 143204, 189620, 106644, 27725] [0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.974, 0.974, 0.974, 0.974, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.976, 0.976, 0.976, 0.977, 0.977, 0.977, 0.98, 0.981, 0.981, 0.982, 0.984, 0.986, 0.99, 1.936, 1.943, 1.945, 1.945, 1.946, 1.952, 1.953]\n",
      "3 --> 74134 100505 \t [75213, 162042, 138766, 110718, 91414, 25972, 190687, 16835, 71208, 173960, 71844, 129555, 144654, 185409, 109434, 25296, 32979, 163638, 164138, 56011, 106793, 91816, 27021, 50833, 79667, 8741, 6103, 185491, 16090, 198556, 118519, 16786, 89249, 102042, 25330, 192925, 108815, 122533, 163604, 19089, 40074, 35551, 159727, 27248, 92795, 152837, 71615, 31948, 57381, 78812, 38364, 14567, 109572, 85613, 137910, 129857, 9486, 100934, 12923, 158338, 77645, 166222, 24433, 47146, 136756, 202, 44491, 2013, 65247, 196950, 94381, 85807, 174205, 10903, 164240, 117783, 63141, 48298, 79836, 118810, 152531, 87674, 151179, 192124, 107386, 176349, 40014, 132226, 166269, 3, 43351, 74134, 108557, 138982, 152331, 100505] [0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.971, 0.971, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.973, 0.973, 0.974, 0.975, 0.975, 0.976, 0.976, 0.976, 0.977, 0.979, 0.98, 0.981, 1.931, 1.933, 1.933, 1.934]\n",
      "24 --> 24 30443 \t [63328, 120588, 82515, 93390, 19605, 71646, 197161, 59360, 92619, 59446, 111547, 164036, 195877, 169838, 42363, 175934, 32824, 188881, 58818, 60349, 128484, 163289, 106207, 71352, 177485, 181267, 2167, 109237, 63334, 126991, 10979, 171249, 167150, 107014, 7502, 35379, 145013, 4882, 151280, 90655, 115001, 158953, 150428, 93509, 52116, 50388, 59590, 192331, 63316, 29509, 3705, 126948, 37199, 162646, 98500, 65625, 201201, 48081, 134643, 133508, 176437, 193391, 141067, 50412, 100891, 188934, 149338, 29429, 60912, 151684, 54178, 11321, 32165, 138389, 201374, 163866, 112956, 109349, 24, 80488, 1585, 49209, 2957, 100740, 21925, 129902, 193550, 30443] [0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 1.996, 1.996, 1.996, 1.996, 1.996, 1.996, 1.997, 2.994, 3.992]\n",
      "25 --> 25 62074 \t [70463, 48195, 184313, 169701, 182343, 18780, 102807, 155679, 75944, 196940, 198515, 55623, 50228, 73476, 106406, 115000, 72662, 40427, 124471, 172016, 80019, 188554, 44509, 107024, 79892, 51726, 104466, 69807, 193380, 111545, 173764, 84081, 106130, 45465, 62917, 138955, 149676, 165689, 52176, 16604, 18310, 160110, 76038, 59150, 58203, 142991, 162929, 49035, 99647, 186108, 17062, 138972, 169288, 24380, 186900, 37126, 117004, 53521, 168098, 20400, 123357, 117078, 107917, 160944, 8527, 5543, 95788, 47712, 161131, 35164, 124953, 138921, 107750, 61907, 22112, 98516, 48979, 4683, 86869, 202063, 244, 121194, 182724, 154318, 65855, 113168, 9604, 25, 202388, 66481, 142948, 62074] [0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.99, 0.99, 0.99, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.993, 0.994, 0.994, 0.995, 0.997, 1.968, 1.97, 1.974, 5.916]\n",
      "27 --> 27 27 \t [156375, 175524, 59770, 43868, 86062, 178704, 91839, 99486, 70909, 164019, 198507, 6846, 123738, 199333, 56319, 23830, 69890, 98959, 179486, 180838, 171303, 69835, 133728, 52547, 16637, 84487, 146675, 127664, 15880, 125130, 195552, 36736, 193759, 82794, 49790, 189081, 84645, 202080, 50990, 49960, 151165, 48409, 88517, 31898, 67925, 196692, 68177, 138760, 80299, 64792, 88483, 189907, 27] [0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.996, 0.996, 0.997, 0.997, 0.997, 0.997, 1.987, 1.99, 2.983, 2.985, 2.986, 4.969, 4.971, 6.961, 6.97, 19.922]\n",
      "27 --> 27 27 \t [190350, 179572, 175431, 115529, 151306, 127664, 125130, 85306, 62193, 180087, 28410, 152851, 79449, 138760, 179775, 3036, 106739, 33515, 92846, 6190, 107801, 35291, 194377, 171303, 37837, 11854, 18814, 145990, 70909, 65555, 196692, 47035, 199999, 102002, 174636, 35650, 115347, 15880, 147381, 65494, 6223, 151165, 40111, 162179, 57000, 98724, 67925, 49960, 175202, 114361, 32013, 39515, 193759, 68177, 77203, 189010, 50990, 76824, 189907, 64792, 52547, 27] [0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.99, 0.99, 0.99, 0.99, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.994, 0.994, 0.995, 0.996, 0.998, 1.974, 1.977, 1.984, 1.985, 3.951, 3.953, 8.904, 20.854]\n",
      "27 --> 27 27 \t [185190, 11043, 11719, 175469, 132915, 175402, 68177, 34572, 173511, 100955, 165962, 124838, 136842, 19095, 176899, 198124, 37363, 56677, 132635, 70336, 48409, 154026, 113162, 64522, 56877, 82883, 34411, 25229, 50260, 41892, 62702, 85646, 137447, 98724, 7053, 16912, 102680, 47378, 75655, 61505, 10419, 168493, 138442, 104858, 198912, 67259, 88483, 84194, 164975, 70276, 132395, 109928, 56126, 80299, 125130, 192979, 201174, 9070, 37837, 116312, 162987, 24028, 139256, 164423, 134316, 64792, 122096, 44570, 23830, 44939, 111105, 49960, 145949, 194377, 183170, 113636, 27] [0.98, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.99, 0.99, 0.991, 0.992, 1.965, 1.97, 1.971, 1.974, 2.952, 2.961, 2.961, 13.843]\n",
      "27 --> 27 27 \t [122019, 64792, 85306, 8749, 85791, 52547, 16361, 38090, 178451, 60730, 150198, 147381, 123171, 74153, 201294, 127668, 81611, 116312, 72441, 82117, 195366, 117076, 138760, 31639, 196692, 62799, 184907, 175524, 50990, 39203, 76453, 28444, 3996, 44570, 163477, 200231, 190283, 57370, 55219, 177854, 148724, 159626, 121190, 194725, 177409, 113162, 192090, 98724, 194377, 19095, 48701, 76824, 183170, 191292, 107164, 7112, 50260, 37837, 131853, 52773, 77203, 113636, 189907, 27] [0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 1.985, 1.985, 1.985, 1.986, 1.986, 1.987, 1.99, 2.976, 2.978, 3.976, 4.963, 4.963, 14.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 --> 48 161939 \t [18346, 96986, 90736, 26882, 20946, 158745, 179793, 189201, 9775, 62742, 33716, 167169, 14567, 129135, 33966, 7492, 167121, 177870, 104616, 92419, 42071, 27493, 1860, 93073, 162027, 159192, 30030, 121873, 50049, 159094, 113227, 106109, 158804, 74025, 34512, 76537, 188159, 8064, 1078, 181774, 126637, 87774, 48333, 2948, 110718, 199506, 11048, 155802, 105759, 5138, 87420, 200380, 106716, 34866, 9744, 174827, 120552, 119699, 155042, 162300, 179550, 142211, 17312, 47923, 182506, 197667, 105214, 18318, 191296, 157486, 15968, 22237, 114187, 116228, 169572, 162005, 95821, 176137, 122827, 123211, 81039, 141654, 71555, 150738, 100982, 59663, 155715, 48, 42307, 121055, 73510, 55177, 99546, 161939] [0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.997, 0.998, 1.983, 1.983, 1.985, 1.986, 1.988, 1.99]\n",
      "52 --> 52 42123 \t [43142, 15138, 90042, 197631, 21546, 35776, 58421, 109819, 184919, 39848, 148314, 156916, 174817, 59810, 198912, 73455, 146545, 2854, 20864, 139439, 67980, 127514, 4563, 107513, 110505, 104335, 76475, 97821, 36123, 75930, 166650, 50271, 176956, 90902, 70156, 164328, 201589, 77711, 183541, 167441, 26781, 66467, 109169, 78927, 30365, 191934, 150175, 128336, 14274, 153980, 191868, 10656, 84197, 156160, 33577, 178884, 188973, 190466, 191153, 46629, 51637, 90021, 67091, 65218, 150691, 17212, 20740, 41648, 191292, 108327, 52, 80138, 47842, 74821, 19937, 51272, 168227, 5561, 44609, 196358, 42123] [0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.998, 1.978, 1.979, 1.979, 1.981, 1.984, 2.975, 2.979, 3.959, 3.96, 4.955]\n",
      "52 --> 52 15427 \t [63764, 83607, 170239, 198103, 24760, 51270, 24059, 135255, 169033, 63312, 200827, 178016, 1423, 134311, 167282, 92798, 18309, 6570, 148365, 156681, 85044, 10329, 100533, 75086, 78791, 58644, 103719, 120041, 109573, 142210, 160559, 160243, 106476, 123313, 108327, 75998, 148742, 67109, 111100, 198417, 82314, 171670, 60357, 70034, 139706, 170039, 165708, 126062, 144980, 12734, 20064, 104335, 9630, 58421, 34514, 138866, 168539, 45865, 14616, 180475, 183236, 161519, 114570, 198781, 46980, 2076, 170101, 63347, 89317, 101083, 28017, 99959, 163706, 149917, 79892, 28230, 57215, 60912, 52, 35098, 76871, 165917, 24036, 134783, 202555, 15427] [0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.99, 0.99, 0.99, 0.99, 0.991, 0.991, 0.991, 0.993, 0.993, 0.994, 0.996, 1.973, 1.977, 1.978, 1.979, 1.98, 4.94, 5.931]\n",
      "58 --> 58 195235 \t [137458, 95864, 69932, 199498, 176357, 74273, 161408, 179909, 102670, 34681, 140536, 21368, 67952, 189353, 200615, 190879, 174225, 18864, 41504, 5106, 180456, 137167, 113926, 112697, 164316, 130153, 167512, 133454, 163133, 188070, 112839, 30196, 97670, 156134, 157326, 202188, 93368, 96333, 34347, 96113, 27004, 76157, 38879, 52464, 52109, 124243, 11717, 35864, 43427, 120270, 196733, 6337, 52773, 48423, 28211, 17021, 157753, 151070, 131266, 198880, 80091, 37271, 188329, 65460, 79576, 171878, 171167, 198916, 69743, 171061, 139996, 198804, 199247, 76148, 42127, 171906, 107931, 159771, 114609, 146785, 142176, 42547, 47955, 148367, 105782, 21629, 131429, 47304, 2184, 58, 70644, 94759, 44284, 189000, 195235] [0.94, 0.94, 0.94, 0.94, 0.94, 0.94, 0.941, 0.941, 0.941, 0.941, 0.941, 0.941, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.943, 0.943, 0.943, 0.943, 0.943, 0.943, 0.943, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.945, 0.945, 0.945, 0.945, 0.945, 0.945, 0.945, 0.945, 0.945, 0.946, 0.946, 0.946, 0.946, 0.947, 0.947, 0.947, 0.948, 0.948, 0.949, 0.949, 0.949, 0.949, 0.949, 0.949, 0.949, 0.95, 0.95, 0.95, 0.951, 0.951, 0.952, 0.952, 0.954, 0.954, 0.954, 0.954, 0.955, 0.955, 0.955, 0.956, 0.957, 0.957, 0.957, 0.958, 0.959, 0.96, 0.96, 0.961, 0.964, 0.964, 0.965, 0.968, 0.976, 1.889, 1.894, 1.897, 1.903, 1.906]\n",
      "75 --> 75 192931 \t [86809, 93808, 189324, 139706, 24931, 132356, 135577, 169337, 84689, 169233, 119773, 190134, 170457, 121736, 195601, 66798, 67189, 53057, 154168, 107332, 34828, 68122, 52568, 60595, 125957, 191397, 68504, 12683, 123101, 200004, 76875, 44595, 33528, 5543, 168583, 93993, 159641, 112637, 85040, 57378, 11497, 19671, 59178, 91374, 66517, 166739, 41869, 107651, 129597, 123944, 31405, 146058, 7618, 67029, 121146, 2273, 121267, 168763, 157501, 174925, 129801, 182973, 166088, 73772, 153517, 108624, 95166, 128556, 139534, 75403, 174253, 88451, 95685, 33132, 192929, 76347, 4149, 70935, 128457, 184767, 114702, 113657, 61412, 28591, 47650, 22192, 122201, 203071, 146813, 75, 192931] [0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.99, 0.991, 1.971, 1.972, 1.973, 1.975, 1.982, 4.933]\n",
      "86 --> 86 138982 \t [87416, 70801, 190587, 104245, 162569, 175431, 155194, 47035, 8766, 20516, 99133, 51639, 3657, 48186, 75296, 186032, 69379, 126171, 75285, 26516, 164862, 145268, 133534, 196699, 28444, 35639, 186438, 200931, 31568, 28341, 102850, 33700, 194377, 175432, 174730, 114046, 33636, 68096, 8745, 145949, 35378, 179486, 59051, 146359, 85791, 128447, 16912, 173825, 117874, 148799, 118985, 44939, 41167, 150977, 192910, 141388, 185909, 100793, 31413, 45993, 143362, 170064, 86, 79922, 119371, 73018, 142674, 44991, 72162, 170494, 11153, 108429, 163896, 174321, 54387, 130930, 14065, 122228, 138982] [0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.996, 0.998, 1.983, 1.983, 1.985, 1.985, 1.986, 1.986, 1.986, 1.986, 1.987, 1.988, 1.988, 1.99, 1.991, 2.98, 3.97, 3.977]\n",
      "88 --> 88 114327 \t [100474, 52006, 144963, 127814, 91180, 122515, 144292, 173336, 139982, 76393, 58230, 37858, 194172, 171188, 10514, 80019, 56827, 135660, 34247, 151054, 72986, 63800, 80961, 89458, 31272, 175273, 97701, 179541, 109876, 146562, 89138, 186645, 75967, 9658, 18496, 159145, 170469, 201563, 21120, 23184, 13297, 113211, 156750, 183505, 91153, 125618, 84483, 27685, 166222, 123454, 1155, 172723, 48891, 101070, 101318, 33963, 75725, 83504, 196106, 141591, 29342, 97565, 42217, 65643, 71358, 196607, 155360, 88802, 99003, 148568, 111663, 37723, 62302, 24596, 113490, 99678, 81277, 96085, 28867, 46284, 102856, 88, 74556, 144734, 119270, 162042, 202085, 113473, 146370, 169557, 114327] [0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.991, 0.991, 0.991, 0.992, 0.993, 0.993, 0.993, 0.993, 0.996, 1.965, 1.968, 1.973, 1.973, 1.974, 1.977, 1.978, 1.979, 1.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 --> 98 138982 \t [88546, 103588, 36798, 191009, 72615, 116321, 161668, 156657, 91412, 97548, 140248, 36290, 29060, 111699, 191292, 87005, 147369, 167988, 57015, 131040, 23582, 202225, 198232, 20168, 28163, 380, 141326, 150105, 154320, 19369, 82579, 52492, 188206, 119199, 93521, 188787, 200945, 119931, 131030, 139858, 103859, 2586, 141327, 50973, 23051, 176457, 37835, 113750, 189967, 11393, 40877, 3494, 51018, 73879, 173078, 193610, 198824, 120986, 79844, 186645, 129769, 196974, 147843, 124149, 43847, 187463, 117041, 75805, 124726, 88802, 100764, 56827, 32075, 3057, 167957, 96943, 169250, 98, 144201, 48580, 181151, 150591, 138982] [0.933, 0.933, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.935, 0.936, 0.936, 0.936, 0.937, 0.937, 0.937, 0.937, 0.937, 0.937, 0.937, 0.938, 0.938, 0.938, 0.939, 0.939, 0.939, 0.939, 0.939, 0.94, 0.94, 0.941, 0.941, 0.941, 0.941, 0.942, 0.942, 0.943, 0.943, 0.943, 0.943, 0.943, 0.943, 0.943, 0.944, 0.944, 0.944, 0.944, 0.945, 0.945, 0.946, 0.947, 0.948, 0.949, 0.949, 0.95, 0.95, 0.95, 0.951, 0.951, 0.951, 0.953, 0.953, 0.955, 0.955, 0.956, 0.956, 0.956, 0.956, 0.957, 0.958, 0.958, 0.96, 0.961, 0.963, 0.964, 0.965, 0.984, 1.892, 1.894, 2.818, 2.829, 11.286]\n",
      "109 --> 78176 83144 \t [44400, 62798, 99332, 21608, 83900, 72141, 96224, 100087, 62240, 121572, 178687, 50495, 199886, 119211, 161641, 146813, 10851, 76008, 98385, 118480, 86856, 86593, 74520, 46290, 59516, 196241, 146480, 78922, 73570, 187209, 10821, 132830, 58016, 24170, 200523, 16541, 43235, 173347, 127523, 41808, 200100, 106713, 150790, 27514, 177734, 47733, 1025, 114440, 20080, 157511, 161448, 190498, 158844, 166503, 85758, 39650, 43283, 2727, 155673, 148895, 132943, 63204, 25953, 69027, 731, 68033, 155585, 80972, 189026, 67572, 191583, 134307, 188968, 139197, 32347, 113750, 102712, 109, 181072, 78176, 35509, 166739, 49712, 86869, 83144] [0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.942, 0.943, 0.943, 0.943, 0.943, 0.943, 0.943, 0.943, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.945, 0.945, 0.945, 0.945, 0.945, 0.946, 0.946, 0.946, 0.946, 0.946, 0.946, 0.946, 0.946, 0.947, 0.947, 0.947, 0.947, 0.947, 0.947, 0.947, 0.947, 0.948, 0.948, 0.949, 0.949, 0.949, 0.949, 0.95, 0.95, 0.95, 0.95, 0.951, 0.951, 0.951, 0.952, 0.953, 0.955, 0.955, 0.955, 0.955, 0.956, 0.956, 0.957, 0.958, 0.958, 0.958, 0.961, 0.962, 0.964, 0.965, 0.966, 0.968, 1.896, 1.91, 1.934, 2.862, 10.416]\n",
      "111 --> 89597 66774 \t [130341, 4009, 82876, 31531, 60502, 697, 21077, 138491, 63344, 107342, 22923, 128980, 154617, 102534, 158766, 133850, 180997, 176467, 3307, 17530, 200144, 112747, 146013, 80416, 9685, 190740, 21130, 182908, 95491, 147828, 17110, 27890, 151263, 70816, 188234, 30879, 182546, 89803, 114489, 143537, 49090, 144080, 67219, 32961, 89317, 110247, 44067, 11354, 125911, 24606, 51699, 190010, 69311, 23477, 81919, 35490, 190993, 143716, 50101, 35883, 133066, 63334, 132631, 44470, 50162, 38791, 27304, 19745, 194699, 21603, 200443, 195766, 163331, 32305, 18482, 16654, 60349, 111, 89597, 63122, 41377, 189945, 107813, 92919, 176528, 59793, 12746, 165524, 66774] [0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.987, 0.987, 0.988, 0.988, 1.958, 1.96, 1.96, 1.962, 1.964, 1.965, 1.968, 1.968, 1.971, 2.941]\n",
      "111 --> 111 56519 \t [100825, 196220, 183466, 110247, 185655, 105688, 22697, 75181, 97114, 161545, 5866, 98177, 4747, 170620, 71959, 162436, 21925, 1059, 89803, 148557, 21211, 72859, 142537, 166812, 56770, 43256, 149957, 38984, 57925, 184999, 32895, 7016, 197268, 58609, 30712, 169358, 39283, 21135, 104906, 155701, 50341, 90989, 106735, 116208, 169894, 21603, 63344, 134544, 179524, 69506, 85771, 141060, 192889, 82734, 36913, 125886, 88559, 184458, 8657, 170350, 93767, 28858, 125233, 13007, 174181, 164773, 65907, 67043, 104107, 9087, 55655, 135606, 138471, 187956, 159040, 182160, 108910, 140541, 159768, 118190, 130843, 70338, 10756, 81044, 8351, 111, 13738, 125397, 2037, 2462, 110320, 9606, 56519] [0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.99, 0.99, 0.991, 0.991, 0.992, 0.995, 1.968, 1.969, 1.97, 1.97, 1.971, 1.971, 1.972]\n",
      "113 --> 113 195248 \t [24650, 75666, 189880, 56230, 203062, 180260, 42197, 166820, 61976, 18901, 132979, 118783, 76590, 13753, 193775, 31538, 83625, 92452, 41255, 870, 51300, 94024, 156254, 107358, 2180, 121572, 118111, 150733, 184607, 139690, 21843, 4920, 92762, 160974, 159122, 195426, 160821, 74776, 34927, 161448, 74290, 29626, 97008, 158078, 120269, 62798, 34242, 126518, 81895, 15390, 139534, 139386, 50776, 27043, 91653, 167673, 165488, 161564, 14860, 137523, 135569, 16767, 80972, 75005, 23661, 104111, 165940, 183275, 180635, 129580, 42219, 99007, 201662, 165771, 11616, 178519, 49720, 78176, 160240, 28056, 95081, 91179, 25287, 191183, 4728, 67400, 77428, 181072, 122804, 113, 83144, 52905, 86869, 195248] [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.951, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.954, 0.954, 0.954, 0.955, 0.955, 0.955, 0.955, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.957, 0.957, 0.957, 0.957, 0.957, 0.957, 0.957, 0.958, 0.958, 0.958, 0.958, 0.958, 0.958, 0.959, 0.959, 0.959, 0.959, 0.96, 0.96, 0.96, 0.96, 0.961, 0.961, 0.962, 0.962, 0.963, 0.965, 0.966, 0.966, 0.968, 0.97, 0.974, 0.975, 0.982, 1.91, 1.918, 1.92, 3.823]\n",
      "********************************************************************************\n",
      "17 0.85\n",
      "4 0.20\n",
      "20 1.00\n"
     ]
    }
   ],
   "source": [
    "topn = 100\n",
    "amount = big_debug_rows\n",
    "top1_count = 0\n",
    "topn_1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    top1_pred, topn_pred_arr, weighted_top1_pred, weighted_topn_pred_arr, class_score_arr = get_single_pred(idx, x_train, x_train, topn, batch_size=1024)\n",
    "    \n",
    "    item_y_data = int(y_train[idx])\n",
    "    if item_y_data == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_data == weighted_top1_pred:\n",
    "        topn_1_count += 1\n",
    "    if item_y_data in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_data, '-->', top1_pred, weighted_top1_pred, '\\t', weighted_topn_pred_arr, class_score_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_1_count, '%.2f' % (topn_1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> 169233 62074 \t [68899, 191845, 172766, 9425, 80019, 109382, 52382, 119301, 107917, 189304, 102898, 62798, 119521, 137270, 42169, 73772, 71023, 188916, 166977, 142452, 36557, 130978, 158782, 23209, 153354, 185311, 164038, 155585, 157120, 196640, 198527, 166015, 64897, 4728, 162549, 198958, 98057, 180441, 68644, 157352, 5719, 145055, 70294, 2419, 194264, 76602, 118092, 57688, 148494, 126755, 78801, 100511, 21079, 167917, 178300, 66438, 27043, 134582, 131841, 178826, 139442, 186868, 123202, 82259, 157541, 41505, 5234, 1497, 148648, 107332, 201723, 177987, 51641, 199945, 186080, 198944, 4822, 188696, 185275, 176528, 156620, 196838, 169233, 144313, 184313, 47712, 4891, 92881, 88596, 165771, 62074] [0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.966, 0.966, 0.966, 0.966, 0.967, 0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.972, 0.973, 0.974, 0.975, 0.975, 0.976, 0.976, 0.98, 1.924, 1.926, 1.928, 1.928, 1.932, 1.935, 1.935, 2.901]\n",
      "12 --> 12 25287 \t [45691, 121850, 9147, 75005, 182200, 70716, 179677, 100706, 109382, 176163, 143863, 131469, 29868, 122443, 25186, 27646, 30048, 86623, 21419, 110424, 69546, 115883, 35858, 132623, 127303, 84470, 77900, 56969, 189050, 5514, 176521, 140010, 6517, 49171, 18392, 34966, 139153, 21143, 178297, 120660, 166820, 4027, 191228, 129494, 7573, 158775, 32325, 102002, 32696, 105354, 149505, 152779, 194613, 146420, 146887, 63067, 3732, 200889, 169829, 146058, 141051, 150608, 84935, 150433, 77475, 45428, 59473, 145200, 50216, 6254, 45814, 103168, 75222, 84269, 9295, 109654, 181530, 31527, 9128, 152219, 146981, 202886, 11544, 160240, 64503, 67737, 56460, 45429, 47194, 12, 111133, 65199, 195426, 52905, 25287] [0.969, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.973, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.976, 0.976, 0.976, 0.977, 0.977, 0.977, 0.977, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.979, 0.979, 0.979, 0.98, 0.98, 0.981, 0.981, 0.982, 0.982, 0.982, 0.983, 0.984, 0.984, 0.988, 0.994, 1.943, 1.949, 1.952, 1.955, 1.958]\n",
      "20 --> 20 41808 \t [168452, 106693, 104458, 61995, 119775, 149275, 146996, 158078, 194223, 153069, 33992, 140815, 147330, 197905, 188625, 10618, 187487, 55472, 23117, 199864, 111239, 18562, 150858, 170814, 149661, 79184, 4149, 38743, 10949, 121225, 35909, 97932, 120469, 65224, 178422, 112873, 42219, 21665, 49712, 77563, 165664, 156978, 128003, 57505, 85758, 22037, 123202, 168769, 62711, 96224, 99983, 30267, 68122, 116431, 149659, 61412, 174974, 26164, 20, 62798, 181631, 169165, 157502, 25953, 193380, 139706, 100028, 11410, 192931, 86869, 84689, 146813, 173450, 41808] [0.976, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.977, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.984, 0.984, 0.985, 0.986, 0.992, 1.953, 1.954, 1.959, 1.959, 1.961, 1.963, 1.965, 1.968, 1.969, 2.945, 2.948, 3.916, 3.919, 3.919, 4.903]\n",
      "27 --> 68177 27 \t [11854, 149419, 10419, 21703, 111813, 108625, 45993, 91839, 81809, 125130, 64131, 6446, 47900, 50260, 56877, 82883, 110797, 31437, 162666, 98724, 9070, 189081, 162179, 132896, 69890, 79449, 128934, 51246, 31508, 170269, 23830, 30591, 133848, 164975, 76824, 15880, 175402, 44570, 6595, 156375, 199689, 127310, 32013, 50990, 31898, 196692, 64792, 138760, 113636, 6190, 48409, 68177, 189907, 88483, 27] [0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.996, 0.997, 1.988, 1.989, 1.989, 1.99, 1.992, 2.984, 2.986, 3.985, 5.972, 7.956, 21.881]\n",
      "27 --> 27 124806 \t [45149, 175929, 1138, 149254, 131812, 29767, 200688, 29602, 152708, 62809, 60045, 104950, 83131, 105634, 123619, 2856, 87895, 187788, 52354, 102274, 65675, 149591, 137447, 153652, 188473, 105496, 40214, 39215, 86122, 188113, 185182, 7738, 72724, 39696, 3087, 157797, 87665, 124838, 70255, 63174, 79110, 46452, 19643, 199450, 183899, 126712, 50083, 202852, 138775, 156853, 126780, 56786, 50213, 24535, 175238, 122077, 11954, 41924, 37700, 104016, 123281, 151999, 23719, 97935, 11997, 55377, 85346, 107801, 60456, 122202, 131527, 106205, 88599, 147048, 73954, 12475, 156932, 79754, 75001, 50260, 38140, 2618, 24311, 193041, 168578, 69097, 168946, 10932, 182654, 67353, 111774, 27, 124806] [0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.992, 1.967, 1.968, 1.969, 1.979, 3.947]\n",
      "27 --> 27 124745 \t [123281, 187095, 162569, 86122, 69576, 66589, 185272, 130404, 115643, 51692, 24448, 181075, 110885, 52547, 69308, 85423, 75655, 86213, 81281, 101952, 136496, 126378, 192090, 57370, 58929, 130832, 10419, 18890, 200954, 85791, 163337, 192125, 107695, 189937, 168338, 22164, 184907, 122228, 116097, 138252, 182828, 139782, 74584, 48701, 70633, 29520, 85505, 74282, 7738, 77417, 29169, 50260, 146209, 46734, 84750, 100879, 20516, 116211, 179884, 190960, 153775, 27, 20760, 135503, 4116, 57943, 66941, 149328, 111608, 56723, 39938, 38090, 145949, 102375, 105496, 176899, 60730, 124745] [0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.995, 0.995, 0.997, 0.998, 1.981, 1.982, 1.982, 1.983, 1.983, 1.984, 1.984, 1.984, 1.985, 1.985, 1.988, 2.973, 2.977, 2.98, 2.983, 3.97]\n",
      "27 --> 38090 124745 \t [163477, 193135, 149641, 148724, 199585, 99844, 108611, 140067, 113462, 140536, 201709, 143131, 146902, 171525, 114646, 10117, 2012, 46257, 104858, 77203, 22164, 64267, 104007, 59257, 145949, 149233, 74153, 136000, 128069, 142147, 61505, 184907, 116312, 100966, 106847, 159490, 200231, 85213, 33515, 50260, 8010, 126999, 30365, 32954, 149328, 18890, 159185, 48701, 163321, 124722, 24261, 32685, 192090, 32325, 190218, 27, 149978, 34411, 105496, 107344, 191292, 182828, 45600, 111608, 177870, 196206, 155910, 32338, 100879, 198912, 11997, 10419, 169404, 39938, 19095, 31639, 124675, 94626, 149591, 85791, 77355, 103207, 57370, 38090, 176899, 56723, 148314, 107801, 113636, 60730, 124745] [0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.973, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.974, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 0.976, 0.976, 0.977, 0.977, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.979, 0.979, 0.98, 0.982, 0.982, 0.985, 1.938, 1.939, 1.939, 1.946, 1.948, 1.952, 3.895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 --> 47035 27 \t [163321, 107219, 193759, 64183, 180346, 171344, 184025, 202429, 454, 156993, 57927, 17721, 149487, 153608, 58966, 154026, 80831, 176899, 191603, 70909, 45639, 143319, 52090, 196104, 124000, 61505, 114361, 122096, 104039, 174512, 32338, 145990, 87157, 178480, 33515, 130293, 118979, 4783, 18950, 31898, 127664, 156045, 189907, 10419, 190665, 115209, 92369, 42547, 152837, 89833, 48409, 2003, 166934, 84194, 150977, 64792, 60894, 87707, 101936, 151408, 196812, 185510, 190929, 47378, 132192, 197047, 86283, 196886, 49960, 183170, 175431, 145949, 202080, 199450, 135054, 142558, 123738, 143362, 76200, 174834, 47035, 27] [0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.966, 0.966, 0.966, 0.966, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.971, 0.972, 0.972, 0.972, 0.972, 0.972, 0.973, 0.973, 0.973, 0.974, 0.974, 0.974, 0.979, 0.981, 0.983, 1.928, 1.929, 1.929, 1.93, 1.931, 1.934, 1.941, 1.944, 1.947, 2.903, 2.904, 2.919, 3.866]\n",
      "27 --> 50990 64792 \t [88483, 156134, 6190, 29520, 58339, 47880, 39334, 11883, 90756, 80801, 189715, 199999, 51692, 76303, 109564, 95275, 95310, 79011, 196699, 35650, 5522, 173083, 124311, 143373, 60730, 67933, 101043, 31508, 87514, 83438, 174731, 6595, 127310, 121132, 92846, 44570, 140326, 132896, 180087, 66218, 129724, 110481, 26516, 52941, 36945, 81809, 82883, 64131, 56877, 98724, 31437, 55780, 187749, 189907, 48409, 15880, 32013, 50990, 132256, 127668, 76824, 155104, 30591, 68177, 196692, 99133, 194377, 52547, 27, 64792] [0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.996, 0.996, 0.996, 0.998, 0.999, 1.984, 1.986, 1.989, 1.99, 1.991, 1.991, 1.992, 2.983, 2.989, 5.962, 5.966, 9.943]\n",
      "32 --> 76525 184907 \t [132415, 135096, 176018, 5788, 164545, 77679, 107164, 25327, 93468, 20262, 194037, 21908, 167686, 144611, 164137, 58737, 170458, 71760, 20746, 141456, 42692, 32776, 121572, 90692, 121745, 156892, 185383, 10400, 30640, 134360, 41751, 201010, 183901, 27428, 154103, 146167, 163132, 132075, 120841, 78973, 148426, 40205, 86542, 147156, 21329, 104280, 99753, 16879, 117764, 183325, 131042, 141874, 91491, 39892, 191941, 32104, 185279, 150024, 21722, 39545, 116097, 82156, 86947, 22704, 169132, 38482, 56964, 25731, 20702, 10468, 139451, 28955, 127444, 76305, 82666, 146067, 177626, 35223, 168227, 89263, 72446, 196023, 77472, 125831, 190553, 152730, 3927, 158318, 9070, 45447, 52773, 61352, 166888, 47018, 76525, 90966, 184907] [0.96, 0.96, 0.96, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.966, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.971, 0.972, 0.972, 0.972, 0.973, 0.973, 0.975, 0.976, 0.976, 0.983, 1.934, 2.886]\n",
      "41 --> 62831 93154 \t [149659, 39970, 197963, 136573, 142343, 101902, 65619, 127516, 103950, 100614, 99582, 181298, 195319, 141116, 92941, 83024, 196736, 49660, 49947, 161384, 99756, 138033, 58608, 39438, 13007, 193804, 33961, 27186, 181490, 143221, 184847, 124796, 19449, 181421, 134543, 181631, 142268, 139894, 100028, 138270, 71101, 169349, 133066, 17993, 193478, 105878, 192655, 10821, 181185, 17050, 134587, 139706, 110398, 41808, 124923, 183151, 107750, 62831, 93198, 33992, 85758, 67416, 192931, 93154] [0.965, 0.965, 0.965, 0.965, 0.965, 0.966, 0.966, 0.966, 0.966, 0.966, 0.967, 0.967, 0.967, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.972, 0.972, 0.973, 0.974, 0.974, 0.974, 0.974, 0.975, 0.975, 0.976, 0.976, 0.977, 0.977, 0.977, 0.978, 0.978, 0.979, 0.979, 0.98, 0.982, 1.933, 1.94, 1.943, 1.948, 1.949, 1.951, 2.925, 2.93, 2.931, 3.889, 3.89, 4.846, 7.759, 7.784]\n",
      "43 --> 111281 108472 \t [45332, 172109, 60782, 126220, 58179, 120144, 85791, 117041, 57943, 51637, 32325, 3732, 160465, 194130, 136409, 22599, 14307, 47561, 3747, 196338, 154835, 104169, 49231, 68106, 110894, 29399, 151271, 35910, 37419, 192891, 22687, 29891, 116101, 148223, 192349, 202738, 90966, 198912, 111347, 106546, 92154, 98773, 95086, 116441, 60708, 189999, 179021, 34698, 114148, 186771, 21867, 38494, 109169, 38646, 154243, 52897, 80808, 188474, 82364, 93459, 164191, 193102, 97257, 75038, 153034, 111281, 165596, 9070, 200994, 120891, 5564, 4928, 66971, 67497, 170717, 135591, 89794, 108472] [0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 0.996, 0.996, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 1.986, 1.986, 1.987, 1.988, 1.989, 1.989, 1.99, 2.981, 2.983, 3.977, 4.968, 4.969]\n",
      "47 --> 166651 184313 \t [145087, 160441, 6615, 42308, 109720, 170814, 94611, 140815, 66854, 124923, 187134, 150037, 188609, 26393, 10886, 186921, 26724, 11410, 99890, 108218, 9116, 123260, 168784, 91249, 117509, 122488, 84905, 170650, 43881, 122556, 156699, 111311, 173948, 50273, 38959, 35376, 9848, 115517, 106432, 53341, 174307, 81790, 35223, 148941, 169748, 22980, 161387, 37567, 191168, 133306, 179748, 22475, 2474, 130401, 111779, 161287, 24996, 12029, 68033, 69340, 166136, 107044, 27997, 137576, 136700, 112907, 63873, 9969, 2050, 60028, 146297, 185937, 78142, 100914, 192265, 179582, 155087, 136923, 156020, 182430, 193739, 88844, 181564, 84661, 146813, 142738, 70825, 19655, 47445, 180719, 139706, 54277, 1864, 166651, 1127, 184313] [0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.962, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.963, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.964, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.965, 0.966, 0.966, 0.966, 0.966, 0.967, 0.967, 0.967, 0.968, 0.968, 0.968, 0.968, 0.968, 0.968, 0.969, 0.969, 0.969, 0.969, 0.97, 0.97, 0.97, 0.97, 0.971, 0.971, 0.971, 0.971, 0.971, 0.972, 0.972, 0.973, 0.973, 0.974, 0.974, 0.975, 0.975, 0.975, 0.976, 0.976, 0.976, 0.977, 0.981, 0.983, 0.985, 1.936, 3.871]\n",
      "81 --> 152131 133454 \t [84194, 178803, 18489, 10419, 181688, 17263, 52897, 166169, 181322, 87080, 3578, 81755, 172324, 1268, 51106, 124624, 183531, 20652, 37154, 94259, 199209, 69021, 188787, 190230, 90864, 171629, 55766, 189349, 35910, 188812, 22687, 42604, 21738, 29215, 141926, 196337, 102917, 56859, 153104, 134316, 28786, 28986, 25109, 5880, 113253, 28119, 86672, 190830, 148314, 174321, 158970, 95963, 126046, 26717, 80249, 10086, 70452, 76635, 48717, 132215, 44991, 147275, 88228, 169043, 154835, 16457, 132915, 175913, 52116, 21613, 56553, 44958, 14307, 49231, 89814, 94109, 121222, 152131, 183867, 154430, 198217, 185116, 9070, 178007, 25529, 133454] [0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.988, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.995, 0.995, 0.996, 1.978, 1.979, 1.981, 1.982, 1.984, 2.963, 3.95, 4.946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 --> 87 175431 \t [47880, 11719, 64673, 200231, 121008, 194406, 30130, 171303, 70336, 27947, 200068, 155286, 120556, 13471, 201982, 98724, 133454, 75285, 11656, 88483, 62843, 46113, 80866, 49952, 28444, 194151, 33636, 150977, 60820, 99772, 83631, 20755, 198124, 104245, 192497, 62914, 14065, 131755, 91563, 107386, 114464, 179486, 192401, 198912, 16963, 69379, 172952, 109928, 128748, 5205, 15880, 52640, 188344, 64792, 151635, 165596, 149446, 175360, 201051, 165692, 20516, 30305, 124838, 173511, 161718, 201174, 185909, 19172, 41167, 31927, 75655, 34698, 28410, 134316, 87, 67619, 183170, 92349, 21613, 113636, 163896, 145949, 175402, 176899, 60730, 175431] [0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.986, 0.987, 0.987, 0.987, 0.987, 0.988, 0.988, 0.989, 0.989, 0.99, 0.992, 0.997, 1.964, 1.964, 1.965, 1.966, 1.967, 1.967, 1.972, 1.972, 1.975, 2.952, 3.945]\n",
      "90 --> 90 176528 \t [8161, 1586, 16396, 142250, 141500, 86199, 23477, 48481, 99065, 104107, 9966, 22667, 124275, 1593, 193436, 27845, 194891, 141707, 144080, 141497, 108327, 179380, 86175, 10367, 49324, 81621, 2957, 57879, 153364, 113747, 164845, 82336, 14862, 99800, 110379, 172341, 146146, 150898, 33943, 74527, 238, 107488, 40633, 145426, 137412, 154941, 178579, 86874, 154965, 69790, 41670, 124882, 176328, 161384, 150190, 179677, 42848, 126721, 26153, 6180, 1234, 14654, 185396, 60912, 27781, 186270, 144886, 195760, 142889, 63122, 41381, 22597, 132973, 39243, 202291, 7732, 90, 186064, 63764, 8507, 52020, 7038, 283, 51699, 2185, 138982, 176528] [0.978, 0.978, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.987, 0.99, 1.959, 1.961, 1.961, 1.961, 1.963, 1.964, 1.965, 1.972, 2.947, 3.923]\n",
      "104 --> 188232 171683 \t [153890, 7499, 182824, 172948, 101460, 101179, 73489, 48698, 183684, 47207, 37858, 91180, 138982, 103456, 192762, 82704, 136776, 193229, 70838, 167038, 15904, 14794, 166033, 73689, 175070, 63617, 176163, 136008, 168645, 194071, 103493, 114925, 5251, 106404, 200523, 17584, 109897, 10541, 150643, 22703, 99019, 116985, 51344, 101032, 132928, 11853, 33660, 7357, 16591, 172669, 99260, 7294, 112605, 146468, 57381, 3458, 132791, 104, 75703, 38802, 195966, 153014, 38069, 97150, 23247, 4379, 133632, 15928, 130102, 195819, 54484, 113300, 132585, 35691, 146928, 107854, 58554, 177869, 100719, 46941, 144633, 47580, 104376, 118950, 181298, 128835, 20270, 138625, 26212, 16820, 188232, 46500, 11031, 132625, 171683] [0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.978, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.979, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.986, 0.986, 0.987, 0.987, 0.988, 0.988, 0.989, 1.961, 1.962, 1.97, 2.944]\n",
      "111 --> 138471 114289 \t [52238, 41679, 182622, 180689, 8878, 180988, 190515, 75181, 5866, 76898, 26064, 1468, 81392, 6005, 195189, 8161, 110255, 139114, 37892, 188511, 186230, 119068, 46275, 134662, 150365, 194156, 28193, 130588, 106735, 118149, 158344, 156380, 28506, 157771, 44980, 115164, 182831, 93824, 72628, 192207, 200858, 186656, 110247, 53796, 19218, 166056, 15686, 17961, 149692, 43087, 104906, 12243, 49142, 145785, 87962, 65907, 73775, 92072, 185419, 24983, 177194, 71560, 104724, 14562, 68339, 21247, 20394, 159036, 112987, 91294, 14328, 6341, 196145, 126850, 7038, 185077, 180233, 138471, 61680, 108517, 103913, 1575, 106834, 164773, 98262, 190234, 115927, 114289] [0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.991, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.992, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.993, 0.994, 0.994, 0.994, 0.994, 0.994, 0.994, 0.995, 0.995, 0.995, 0.995, 0.995, 0.995, 0.996, 1.982, 1.982, 1.983, 1.983, 1.984, 1.985, 1.985, 1.986, 2.973, 2.978]\n",
      "111 --> 67043 67043 \t [26815, 96741, 47756, 93948, 187819, 121700, 59789, 59691, 122234, 163104, 145054, 110440, 43309, 162604, 108221, 130843, 185165, 122658, 43757, 173828, 160071, 120110, 68109, 149953, 136956, 44630, 63122, 158953, 70822, 98177, 82215, 180622, 161514, 169363, 178579, 125631, 81630, 20260, 178641, 9683, 161384, 71959, 194263, 70338, 19605, 151768, 125346, 116689, 152447, 154941, 140263, 51699, 26648, 180577, 106485, 104804, 158155, 13171, 122761, 50636, 14052, 145466, 2957, 164999, 135169, 100825, 35933, 35417, 45366, 26801, 5853, 137026, 26804, 9706, 198401, 101634, 139150, 63897, 151675, 147446, 150054, 143361, 189811, 144791, 104107, 128435, 174181, 51946, 143253, 138982, 67043] [0.979, 0.979, 0.979, 0.979, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.981, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.982, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.983, 0.984, 0.984, 0.984, 0.984, 0.984, 0.984, 0.985, 0.985, 0.985, 0.985, 0.985, 0.986, 0.987, 0.987, 0.988, 1.959, 1.961, 1.961, 1.962, 1.962, 1.963, 1.964, 1.968, 1.972]\n",
      "113 --> 102375 102375 \t [45017, 45222, 152671, 28743, 54107, 191408, 139542, 194337, 98375, 7861, 124177, 32638, 136752, 77367, 23184, 109919, 43223, 60919, 27248, 134210, 113603, 144220, 166293, 76567, 154677, 27524, 123509, 145534, 98849, 4641, 121864, 65460, 54576, 74910, 78072, 177986, 47378, 12052, 64207, 2178, 60894, 19112, 201051, 2045, 3485, 8552, 178286, 20409, 26143, 114791, 14308, 9742, 93287, 92607, 200708, 158448, 131107, 200910, 180901, 184025, 63032, 122096, 152527, 185085, 197160, 116507, 5418, 67125, 101708, 188892, 129737, 161376, 67742, 6517, 179021, 29341, 176439, 458, 156804, 33087, 143362, 26403, 101075, 47685, 66858, 55459, 16323, 97465, 85807, 33197, 173511, 165596, 102375] [0.896, 0.896, 0.896, 0.897, 0.897, 0.897, 0.897, 0.897, 0.897, 0.897, 0.897, 0.897, 0.897, 0.897, 0.898, 0.898, 0.899, 0.899, 0.899, 0.899, 0.899, 0.899, 0.899, 0.899, 0.899, 0.899, 0.899, 0.9, 0.9, 0.9, 0.9, 0.901, 0.901, 0.901, 0.901, 0.901, 0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.902, 0.903, 0.903, 0.903, 0.903, 0.903, 0.903, 0.904, 0.904, 0.904, 0.904, 0.905, 0.905, 0.905, 0.905, 0.905, 0.905, 0.907, 0.907, 0.907, 0.908, 0.908, 0.909, 0.909, 0.91, 0.91, 0.91, 0.91, 0.91, 0.912, 0.912, 0.914, 0.914, 0.914, 0.916, 0.918, 0.919, 0.919, 0.923, 0.924, 0.925, 0.926, 0.93, 0.931, 0.932, 1.8, 1.807, 1.814, 2.746, 2.749]\n",
      "********************************************************************************\n",
      "6 0.30\n",
      "2 0.10\n",
      "11 0.55\n"
     ]
    }
   ],
   "source": [
    "topn = 100\n",
    "amount = big_debug_rows\n",
    "top1_count = 0\n",
    "topn_1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    top1_pred, topn_pred_arr, weighted_top1_pred, weighted_topn_pred_arr, class_score_arr = get_single_pred(idx, x_val, x_train, topn, batch_size=1024)\n",
    "    \n",
    "    item_y_data = int(y_val[idx])\n",
    "    if item_y_data == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_data == weighted_top1_pred:\n",
    "        topn_1_count += 1\n",
    "    if item_y_data in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_data, '-->', top1_pred, weighted_top1_pred, '\\t', weighted_topn_pred_arr, class_score_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_1_count, '%.2f' % (topn_1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-Predict[split]_Google-LandMark-Rec2019_3-Image-Similar-FCNN-Binary_20190511-164020_8393_20190513-132618_5500\n"
     ]
    }
   ],
   "source": [
    "acc10000 = int(topn_count/amount*10000)\n",
    "# acc10000 = 10000 # for test\n",
    "# print(acc10000)\n",
    "if acc10000 == 10000:\n",
    "    run_name_acc = '%s_%05d' % (run_name, acc10000)\n",
    "else:\n",
    "    run_name_acc = '%s_%04d' % (run_name, acc10000)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 433.5s\n",
      "4-Predict[split]_Google-LandMark-Rec2019_3-Image-Similar-FCNN-Binary_20190511-164020_8393_20190513-132618_5500\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed: %.1fs' % (time.time() - t0))\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
