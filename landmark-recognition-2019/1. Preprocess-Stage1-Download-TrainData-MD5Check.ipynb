{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess-Stage1-Download-TrainData-MD5Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google-LandMark-Rec2019_1-Preprocess-Stage1-Download-TrainData-MD5Check_20190422-125359\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "project_name = 'Google-LandMark-Rec2019'\n",
    "step_name = '1-Preprocess-Stage1-Download-TrainData-MD5Check'\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tar_count: 500\n",
      "cpu_amount:  1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "train_tar_count = 500\n",
    "\n",
    "print('train_tar_count:', train_tar_count)\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os, sys, gc, math, shutil, zipfile, pickle, h5py, re\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "md5sum_folder = os.path.join(input_folder, 'md5sum')\n",
    "if not os.path.exists(md5sum_folder):\n",
    "    os.mkdir(md5sum_folder)\n",
    "    print('create folder:', md5sum_folder)\n",
    "    \n",
    "train_tar_folder = os.path.join(input_folder, 'train_tar')\n",
    "if not os.path.exists(train_tar_folder):\n",
    "    os.mkdir(train_tar_folder)\n",
    "    print('create folder:', train_tar_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD5 Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Crypto.Hash import MD5\n",
    "\n",
    "def get_MD5(file_path):\n",
    "    chunk_size = 8192\n",
    "    h = MD5.new()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if len(chunk):\n",
    "                h.update(chunk)\n",
    "            else:\n",
    "                break\n",
    "    return h.hexdigest()\n",
    "\n",
    "# get_MD5('/data/landmark-recognition-2019/input/train_tar/images_001.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('825975950b2e22f0f66aa8fd26c1f153', 'images_000.tar')\n"
     ]
    }
   ],
   "source": [
    "def get_info_from_md5sum(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        line = file.readline()\n",
    "    splited = line.split(' ')\n",
    "    md5_val, train_tar_name = splited[0], splited[-1].strip()\n",
    "    return md5_val, train_tar_name\n",
    "index = 0\n",
    "print(get_info_from_md5sum(os.path.join(md5sum_folder, 'md5.images_%03d.txt' % index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "000\n"
     ]
    }
   ],
   "source": [
    "def get_filename_from_path(path):\n",
    "    splited = re.split(r'[_\\.]', path, 10)\n",
    "    filename = splited[-2]\n",
    "    return filename\n",
    "\n",
    "index = 0\n",
    "print(get_filename_from_path(os.path.join(train_tar_folder, 'images_%03d.tar' % index)))\n",
    "print(get_filename_from_path(os.path.join(md5sum_folder, 'md5.images_%03d.txt' % index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************CPU times: user 19min 43s, sys: 4min 18s, total: 24min 1s\n",
      "Wall time: 8h 32min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(train_tar_count):\n",
    "    md5sum_file = os.path.join(md5sum_folder, 'md5.images_%03d.txt' % i)\n",
    "    train_tar_file = os.path.join(train_tar_folder, 'images_%03d.tar' % i)\n",
    "    if not os.path.exists(md5sum_file):\n",
    "        print('File not exists:', md5sum_file)\n",
    "        continue\n",
    "    if not os.path.exists(train_tar_file):\n",
    "        print('File not exists:', train_tar_file)\n",
    "        continue\n",
    "    md5_val, _ = get_info_from_md5sum(md5sum_file)\n",
    "    train_tar_md5 = get_MD5(train_tar_file)\n",
    "    if md5_val == train_tar_md5:\n",
    "        print('*', end='')\n",
    "    else:\n",
    "        print(md5_val, md5sum_file)\n",
    "        print(train_tar_md5, train_tar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 30730.5s\n",
      "Google-LandMark-Rec2019_1-Preprocess-Stage1-Download-TrainData-MD5Check_20190422-125359\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed: %.1fs' % (time.time() - t0))\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
