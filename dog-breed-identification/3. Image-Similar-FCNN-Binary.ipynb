{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image-Similar-FCNN-Binary\n",
    "For landmark-recognition-2019 algorithm validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Dog-Breed_3-Image-Similar-FCNN-Binary_20190507-211416\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Dog-Breed'\n",
    "step_name = '3-Image-Similar-FCNN-Binary'\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle\\dog-breed-identification\\feature\\feature_wrapper_171023.h5\n",
      "D:\\Kaggle\\dog-breed-identification\\input\\train.csv\n",
      "D:\\Kaggle\\dog-breed-identification\\input\\test.csv\n",
      "D:\\Kaggle\\dog-breed-identification\\input\\sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "vgg16_feature_file = os.path.join(feature_folder, 'feature_wrapper_171023.h5')\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')\n",
    "print(vgg16_feature_file)\n",
    "print(train_csv_file)\n",
    "print(test_csv_file)\n",
    "print(sample_submission_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(vgg16_feature_file, 'r') as h:\n",
    "    x_train = np.array(h['train'])\n",
    "    y_train = np.array(h['train_label'])\n",
    "    x_val = np.array(h['val'])\n",
    "    y_val = np.array(h['val_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9199, 512)\n",
      "(9199,)\n",
      "(1023, 512)\n",
      "(1023,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[10, 11, 12, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(range(10)))\n",
    "import copy\n",
    "a = list(range(10, 20))\n",
    "print(a)\n",
    "a.remove(13)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ImageSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageSequence(Sequence):\n",
    "#     def __init__(self, x, y, batch_size, times_for_1_image, positive_rate):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "#         self.batch_size = batch_size\n",
    "#         self.times_for_1_image = times_for_1_image\n",
    "#         self.positive_rate = positive_rate\n",
    "        \n",
    "#         self.len_x = self.x.shape[0]\n",
    "#         self.index = list(range(self.len_x))\n",
    "#         self.group = {}\n",
    "#         self.classes = list(set(self.y))\n",
    "#         self.classes.sort()\n",
    "#         for c in self.classes:\n",
    "#             self.group[c] = []\n",
    "#         for i, y_i in enumerate(self.y):\n",
    "#             temp_arr = self.group[y_i]\n",
    "#             temp_arr.append(i)\n",
    "#             self.group[y_i] = temp_arr\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         # times_for_1_image: the times to train one image\n",
    "#         # 2: positive example and negative example\n",
    "#         return self.times_for_1_image * 2 * (math.ceil(self.len_x/self.batch_size))\n",
    "#     def __getitem__(self, idx):\n",
    "#         batch_main_x = []\n",
    "#         batch_libary_x = []\n",
    "#         batch_x = {}\n",
    "#         batch_y = [] # 0 or 1\n",
    "#         for i in range(self.batch_size):\n",
    "#             # prepare main image\n",
    "#             item_main_image_idx = random.choice(self.index) # random choice one image from all train images\n",
    "#             item_main_image_y = self.y[item_main_image_idx]\n",
    "            \n",
    "#             # prepare libary image\n",
    "#             is_positive = random.random() < self.positive_rate\n",
    "#             if is_positive: # chioce a positive image as libary_x\n",
    "#                 # choice one image from itself group\n",
    "#                 item_libary_image_idx = random.choice(self.group[item_main_image_y]) # don't exclude item_main_image_idx, so it could choice a idx same to item_main_image_idx.\n",
    "#             else: # chioce a negative image as libary_x\n",
    "#                 # choice group\n",
    "#                 new_class = copy.deepcopy(self.classes)\n",
    "#                 new_class.remove(item_main_image_y)\n",
    "#                 item_libary_image_group_num = random.choice(new_class)\n",
    "#                 # choice one image from group\n",
    "#                 item_libary_image_idx = random.choice(self.group[item_libary_image_group_num])\n",
    "#             # add item data to batch\n",
    "#             batch_main_x.append(self.x[item_main_image_idx])\n",
    "#             batch_libary_x.append(self.x[item_libary_image_idx])\n",
    "#             batch_y.append(int(is_positive))\n",
    "#         # concatenate array to np.array\n",
    "#         batch_x = {\n",
    "#             'main_input': np.array(batch_main_x),\n",
    "#             'library_input': np.array(batch_libary_x)\n",
    "#         }\n",
    "#         batch_y = np.array(batch_y)\n",
    "#         return batch_x, batch_y\n",
    "\n",
    "# demo_sequence = ImageSequence(x_train[:200], y_train[:200], 128, 3, 0.1)\n",
    "# print(len(demo_sequence))\n",
    "# print(type(demo_sequence))\n",
    "\n",
    "# batch_index = 0\n",
    "# demo_batch = demo_sequence[batch_index]\n",
    "# demo_batch_x = demo_batch[0]\n",
    "# demo_batch_y = demo_batch[1]\n",
    "# print(type(demo_batch_x))\n",
    "# print(type(demo_batch_y))\n",
    "\n",
    "# demo_main_input = demo_batch_x['main_input']\n",
    "# demo_library_input = demo_batch_x['library_input']\n",
    "# print(demo_main_input.shape)\n",
    "# print(demo_library_input.shape)\n",
    "# print(demo_batch_y.shape)\n",
    "\n",
    "# # print(demo_main_input[0])\n",
    "# print(demo_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "<class '__main__.ImageSequence'>\n",
      "<class 'dict'>\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 512)\n",
      "(128, 512)\n",
      "(128,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "class ImageSequence(Sequence):\n",
    "    def __init__(self, x, y, batch_size, times_for_1_image, positive_rate):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.times_for_1_image = times_for_1_image\n",
    "        self.positive_rate = positive_rate\n",
    "        \n",
    "        self.len_x = self.x.shape[0]\n",
    "        self.index = list(range(self.len_x))\n",
    "        self.group = {}\n",
    "        self.classes = list(set(self.y))\n",
    "        self.classes.sort()\n",
    "        for c in self.classes:\n",
    "            self.group[c] = []\n",
    "        for i, y_i in enumerate(self.y):\n",
    "            temp_arr = self.group[y_i]\n",
    "            temp_arr.append(i)\n",
    "            self.group[y_i] = temp_arr\n",
    "        \n",
    "    def __len__(self):\n",
    "        # times_for_1_image: the times to train one image\n",
    "        # 2: positive example and negative example\n",
    "        return self.times_for_1_image * 2 * (math.ceil(self.len_x/self.batch_size))\n",
    "    def __getitem__(self, idx):\n",
    "        batch_main_x = np.zeros((self.batch_size, self.x.shape[1]))\n",
    "        batch_libary_x = np.zeros((self.batch_size, self.x.shape[1]))\n",
    "        batch_x = {}\n",
    "        batch_y = [] # 0 or 1\n",
    "        for i in range(self.batch_size):\n",
    "            # prepare main image\n",
    "            item_main_image_idx = random.choice(self.index) # random choice one image from all train images\n",
    "            item_main_image_y = self.y[item_main_image_idx]\n",
    "            \n",
    "            # prepare libary image\n",
    "            is_positive = random.random() < self.positive_rate\n",
    "            if is_positive: # chioce a positive image as libary_x\n",
    "                # choice one image from itself group\n",
    "                item_libary_image_idx = random.choice(self.group[item_main_image_y]) # don't exclude item_main_image_idx, so it could choice a idx same to item_main_image_idx.\n",
    "            else: # chioce a negative image as libary_x\n",
    "                # choice group\n",
    "                new_class = copy.deepcopy(self.classes)\n",
    "                new_class.remove(item_main_image_y)\n",
    "                item_libary_image_group_num = random.choice(new_class)\n",
    "                # choice one image from group\n",
    "                item_libary_image_idx = random.choice(self.group[item_libary_image_group_num])\n",
    "            # add item data to batch\n",
    "            batch_main_x[i] = self.x[item_main_image_idx]\n",
    "            batch_libary_x[i] = self.x[item_libary_image_idx]\n",
    "            batch_y.append(int(is_positive))\n",
    "        # concatenate array to np.array\n",
    "        batch_x = {\n",
    "            'main_input': batch_main_x,\n",
    "            'library_input': batch_libary_x\n",
    "        }\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "demo_sequence = ImageSequence(x_train[:200], y_train[:200], 128, 3, 0.1)\n",
    "print(len(demo_sequence))\n",
    "print(type(demo_sequence))\n",
    "\n",
    "batch_index = 0\n",
    "demo_batch = demo_sequence[batch_index]\n",
    "demo_batch_x = demo_batch[0]\n",
    "demo_batch_y = demo_batch[1]\n",
    "print(type(demo_batch_x))\n",
    "print(type(demo_batch_y))\n",
    "\n",
    "demo_main_input = demo_batch_x['main_input']\n",
    "demo_library_input = demo_batch_x['library_input']\n",
    "print(demo_main_input.shape)\n",
    "print(demo_library_input.shape)\n",
    "print(demo_batch_y.shape)\n",
    "\n",
    "# print(demo_main_input[0])\n",
    "print(demo_batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = ImageSequence(x_train, y_train, 32, 3, 0.5)\n",
    "val_sequence = ImageSequence(x_val, y_val, 32, 3, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\study\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "main_input = Input((x_train.shape[1],), dtype='float32', name='main_input')\n",
    "library_input = Input((x_train.shape[1],), dtype='float32', name='library_input')\n",
    "\n",
    "x = keras.layers.concatenate([main_input, library_input])\n",
    "x = Dense(x_train.shape[1]*2, activation='sigmoid')(x)\n",
    "\n",
    "x = Dense(1024, activation='sigmoid')(x)\n",
    "x = Dense(1024, activation='sigmoid')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, library_input], outputs=[output])\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "library_input (InputLayer)      (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           main_input[0][0]                 \n",
      "                                                                 library_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         1049600     dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1025        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,149,825\n",
      "Trainable params: 3,149,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\study\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "128/128 [==============================] - ETA: 2:43 - loss: 0.7173 - acc: 0.437 - ETA: 1:27 - loss: 0.7095 - acc: 0.484 - ETA: 1:02 - loss: 0.6981 - acc: 0.520 - ETA: 49s - loss: 0.7058 - acc: 0.515 - ETA: 41s - loss: 0.7066 - acc: 0.50 - ETA: 36s - loss: 0.7042 - acc: 0.51 - ETA: 32s - loss: 0.7079 - acc: 0.50 - ETA: 30s - loss: 0.7043 - acc: 0.51 - ETA: 28s - loss: 0.7039 - acc: 0.52 - ETA: 26s - loss: 0.7075 - acc: 0.52 - ETA: 24s - loss: 0.7068 - acc: 0.52 - ETA: 23s - loss: 0.7026 - acc: 0.53 - ETA: 22s - loss: 0.7027 - acc: 0.52 - ETA: 21s - loss: 0.7017 - acc: 0.52 - ETA: 20s - loss: 0.7013 - acc: 0.51 - ETA: 19s - loss: 0.7007 - acc: 0.51 - ETA: 19s - loss: 0.7004 - acc: 0.50 - ETA: 18s - loss: 0.7001 - acc: 0.50 - ETA: 18s - loss: 0.6996 - acc: 0.50 - ETA: 17s - loss: 0.6988 - acc: 0.51 - ETA: 17s - loss: 0.6981 - acc: 0.51 - ETA: 16s - loss: 0.6983 - acc: 0.51 - ETA: 16s - loss: 0.6973 - acc: 0.51 - ETA: 15s - loss: 0.6991 - acc: 0.51 - ETA: 15s - loss: 0.6983 - acc: 0.51 - ETA: 15s - loss: 0.7007 - acc: 0.51 - ETA: 14s - loss: 0.7009 - acc: 0.50 - ETA: 14s - loss: 0.7010 - acc: 0.50 - ETA: 14s - loss: 0.7016 - acc: 0.50 - ETA: 13s - loss: 0.7014 - acc: 0.50 - ETA: 13s - loss: 0.7023 - acc: 0.50 - ETA: 13s - loss: 0.7010 - acc: 0.50 - ETA: 13s - loss: 0.7008 - acc: 0.50 - ETA: 12s - loss: 0.7009 - acc: 0.50 - ETA: 12s - loss: 0.7007 - acc: 0.50 - ETA: 12s - loss: 0.7004 - acc: 0.50 - ETA: 12s - loss: 0.7002 - acc: 0.50 - ETA: 11s - loss: 0.6993 - acc: 0.50 - ETA: 11s - loss: 0.6981 - acc: 0.51 - ETA: 11s - loss: 0.6992 - acc: 0.51 - ETA: 11s - loss: 0.7010 - acc: 0.50 - ETA: 11s - loss: 0.7012 - acc: 0.51 - ETA: 10s - loss: 0.7014 - acc: 0.51 - ETA: 10s - loss: 0.7007 - acc: 0.51 - ETA: 10s - loss: 0.7005 - acc: 0.51 - ETA: 10s - loss: 0.7001 - acc: 0.51 - ETA: 10s - loss: 0.6998 - acc: 0.51 - ETA: 10s - loss: 0.6997 - acc: 0.51 - ETA: 9s - loss: 0.6997 - acc: 0.5159 - ETA: 9s - loss: 0.7003 - acc: 0.511 - ETA: 9s - loss: 0.7002 - acc: 0.510 - ETA: 9s - loss: 0.6999 - acc: 0.512 - ETA: 9s - loss: 0.7005 - acc: 0.510 - ETA: 9s - loss: 0.7003 - acc: 0.511 - ETA: 9s - loss: 0.6999 - acc: 0.512 - ETA: 8s - loss: 0.7002 - acc: 0.512 - ETA: 8s - loss: 0.6998 - acc: 0.513 - ETA: 8s - loss: 0.6995 - acc: 0.514 - ETA: 8s - loss: 0.6996 - acc: 0.514 - ETA: 8s - loss: 0.6993 - acc: 0.515 - ETA: 8s - loss: 0.6988 - acc: 0.517 - ETA: 8s - loss: 0.6991 - acc: 0.516 - ETA: 7s - loss: 0.6989 - acc: 0.516 - ETA: 7s - loss: 0.6987 - acc: 0.516 - ETA: 7s - loss: 0.6985 - acc: 0.517 - ETA: 7s - loss: 0.6988 - acc: 0.516 - ETA: 7s - loss: 0.6988 - acc: 0.516 - ETA: 7s - loss: 0.6987 - acc: 0.517 - ETA: 7s - loss: 0.6986 - acc: 0.517 - ETA: 6s - loss: 0.6977 - acc: 0.520 - ETA: 6s - loss: 0.6980 - acc: 0.520 - ETA: 6s - loss: 0.6984 - acc: 0.519 - ETA: 6s - loss: 0.6984 - acc: 0.519 - ETA: 6s - loss: 0.6984 - acc: 0.518 - ETA: 6s - loss: 0.6986 - acc: 0.516 - ETA: 6s - loss: 0.6987 - acc: 0.515 - ETA: 6s - loss: 0.6994 - acc: 0.512 - ETA: 6s - loss: 0.6997 - acc: 0.510 - ETA: 5s - loss: 0.6995 - acc: 0.510 - ETA: 5s - loss: 0.6995 - acc: 0.508 - ETA: 5s - loss: 0.6993 - acc: 0.509 - ETA: 5s - loss: 0.6989 - acc: 0.510 - ETA: 5s - loss: 0.6992 - acc: 0.509 - ETA: 5s - loss: 0.6996 - acc: 0.509 - ETA: 5s - loss: 0.6996 - acc: 0.509 - ETA: 4s - loss: 0.6994 - acc: 0.510 - ETA: 4s - loss: 0.6993 - acc: 0.510 - ETA: 4s - loss: 0.6996 - acc: 0.509 - ETA: 4s - loss: 0.6995 - acc: 0.509 - ETA: 4s - loss: 0.6995 - acc: 0.508 - ETA: 4s - loss: 0.6995 - acc: 0.507 - ETA: 4s - loss: 0.6997 - acc: 0.506 - ETA: 4s - loss: 0.6997 - acc: 0.506 - ETA: 4s - loss: 0.6996 - acc: 0.505 - ETA: 3s - loss: 0.6996 - acc: 0.506 - ETA: 3s - loss: 0.6995 - acc: 0.505 - ETA: 3s - loss: 0.6994 - acc: 0.505 - ETA: 3s - loss: 0.6994 - acc: 0.505 - ETA: 3s - loss: 0.6997 - acc: 0.503 - ETA: 3s - loss: 0.6996 - acc: 0.503 - ETA: 3s - loss: 0.6994 - acc: 0.505 - ETA: 3s - loss: 0.6994 - acc: 0.504 - ETA: 2s - loss: 0.6996 - acc: 0.504 - ETA: 2s - loss: 0.6994 - acc: 0.505 - ETA: 2s - loss: 0.6992 - acc: 0.505 - ETA: 2s - loss: 0.6995 - acc: 0.504 - ETA: 2s - loss: 0.6996 - acc: 0.503 - ETA: 2s - loss: 0.6996 - acc: 0.504 - ETA: 2s - loss: 0.6996 - acc: 0.503 - ETA: 2s - loss: 0.6994 - acc: 0.504 - ETA: 1s - loss: 0.6992 - acc: 0.505 - ETA: 1s - loss: 0.6994 - acc: 0.505 - ETA: 1s - loss: 0.6996 - acc: 0.504 - ETA: 1s - loss: 0.6994 - acc: 0.505 - ETA: 1s - loss: 0.6990 - acc: 0.506 - ETA: 1s - loss: 0.6992 - acc: 0.505 - ETA: 1s - loss: 0.6989 - acc: 0.506 - ETA: 1s - loss: 0.6988 - acc: 0.507 - ETA: 1s - loss: 0.6989 - acc: 0.505 - ETA: 0s - loss: 0.6989 - acc: 0.505 - ETA: 0s - loss: 0.6990 - acc: 0.505 - ETA: 0s - loss: 0.6990 - acc: 0.505 - ETA: 0s - loss: 0.6991 - acc: 0.504 - ETA: 0s - loss: 0.6991 - acc: 0.503 - ETA: 0s - loss: 0.6991 - acc: 0.504 - ETA: 0s - loss: 0.6991 - acc: 0.503 - ETA: 0s - loss: 0.6991 - acc: 0.502 - 16s 127ms/step - loss: 0.6991 - acc: 0.5029 - val_loss: 0.6899 - val_acc: 0.5381\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.6981 - acc: 0.46 - ETA: 11s - loss: 0.6967 - acc: 0.48 - ETA: 11s - loss: 0.6911 - acc: 0.55 - ETA: 12s - loss: 0.6991 - acc: 0.50 - ETA: 11s - loss: 0.6979 - acc: 0.50 - ETA: 11s - loss: 0.6953 - acc: 0.51 - ETA: 11s - loss: 0.6900 - acc: 0.54 - ETA: 11s - loss: 0.6925 - acc: 0.53 - ETA: 11s - loss: 0.6860 - acc: 0.54 - ETA: 11s - loss: 0.6893 - acc: 0.54 - ETA: 11s - loss: 0.6839 - acc: 0.55 - ETA: 11s - loss: 0.6874 - acc: 0.55 - ETA: 11s - loss: 0.6874 - acc: 0.55 - ETA: 11s - loss: 0.6802 - acc: 0.57 - ETA: 11s - loss: 0.6867 - acc: 0.56 - ETA: 11s - loss: 0.6890 - acc: 0.55 - ETA: 10s - loss: 0.6885 - acc: 0.55 - ETA: 10s - loss: 0.6894 - acc: 0.55 - ETA: 10s - loss: 0.6892 - acc: 0.55 - ETA: 10s - loss: 0.6909 - acc: 0.54 - ETA: 10s - loss: 0.6958 - acc: 0.53 - ETA: 10s - loss: 0.6980 - acc: 0.52 - ETA: 10s - loss: 0.6978 - acc: 0.52 - ETA: 10s - loss: 0.6978 - acc: 0.52 - ETA: 10s - loss: 0.6978 - acc: 0.52 - ETA: 10s - loss: 0.6975 - acc: 0.52 - ETA: 10s - loss: 0.6977 - acc: 0.51 - ETA: 10s - loss: 0.6973 - acc: 0.52 - ETA: 9s - loss: 0.6977 - acc: 0.5183 - ETA: 9s - loss: 0.6967 - acc: 0.524 - ETA: 9s - loss: 0.6961 - acc: 0.525 - ETA: 9s - loss: 0.6963 - acc: 0.522 - ETA: 9s - loss: 0.6968 - acc: 0.520 - ETA: 9s - loss: 0.6961 - acc: 0.522 - ETA: 9s - loss: 0.6957 - acc: 0.525 - ETA: 9s - loss: 0.6954 - acc: 0.527 - ETA: 9s - loss: 0.6954 - acc: 0.526 - ETA: 9s - loss: 0.6953 - acc: 0.527 - ETA: 9s - loss: 0.6949 - acc: 0.530 - ETA: 8s - loss: 0.6947 - acc: 0.531 - ETA: 8s - loss: 0.6945 - acc: 0.532 - ETA: 8s - loss: 0.6940 - acc: 0.535 - ETA: 8s - loss: 0.6942 - acc: 0.534 - ETA: 8s - loss: 0.6950 - acc: 0.531 - ETA: 8s - loss: 0.6959 - acc: 0.528 - ETA: 8s - loss: 0.6954 - acc: 0.529 - ETA: 8s - loss: 0.6948 - acc: 0.533 - ETA: 8s - loss: 0.6945 - acc: 0.533 - ETA: 8s - loss: 0.6951 - acc: 0.530 - ETA: 7s - loss: 0.6946 - acc: 0.532 - ETA: 7s - loss: 0.6946 - acc: 0.530 - ETA: 7s - loss: 0.6943 - acc: 0.531 - ETA: 7s - loss: 0.6944 - acc: 0.531 - ETA: 7s - loss: 0.6943 - acc: 0.528 - ETA: 7s - loss: 0.6940 - acc: 0.530 - ETA: 7s - loss: 0.6940 - acc: 0.530 - ETA: 7s - loss: 0.6936 - acc: 0.533 - ETA: 7s - loss: 0.6938 - acc: 0.530 - ETA: 7s - loss: 0.6939 - acc: 0.531 - ETA: 6s - loss: 0.6936 - acc: 0.530 - ETA: 6s - loss: 0.6940 - acc: 0.527 - ETA: 6s - loss: 0.6940 - acc: 0.525 - ETA: 6s - loss: 0.6939 - acc: 0.526 - ETA: 6s - loss: 0.6936 - acc: 0.528 - ETA: 6s - loss: 0.6934 - acc: 0.528 - ETA: 6s - loss: 0.6937 - acc: 0.527 - ETA: 6s - loss: 0.6938 - acc: 0.527 - ETA: 6s - loss: 0.6941 - acc: 0.526 - ETA: 6s - loss: 0.6945 - acc: 0.524 - ETA: 5s - loss: 0.6943 - acc: 0.525 - ETA: 5s - loss: 0.6942 - acc: 0.525 - ETA: 5s - loss: 0.6944 - acc: 0.524 - ETA: 5s - loss: 0.6945 - acc: 0.524 - ETA: 5s - loss: 0.6944 - acc: 0.525 - ETA: 5s - loss: 0.6942 - acc: 0.525 - ETA: 5s - loss: 0.6942 - acc: 0.525 - ETA: 5s - loss: 0.6937 - acc: 0.526 - ETA: 5s - loss: 0.6935 - acc: 0.527 - ETA: 4s - loss: 0.6937 - acc: 0.526 - ETA: 4s - loss: 0.6938 - acc: 0.526 - ETA: 4s - loss: 0.6940 - acc: 0.525 - ETA: 4s - loss: 0.6941 - acc: 0.524 - ETA: 4s - loss: 0.6940 - acc: 0.525 - ETA: 4s - loss: 0.6941 - acc: 0.525 - ETA: 4s - loss: 0.6942 - acc: 0.525 - ETA: 4s - loss: 0.6939 - acc: 0.526 - ETA: 4s - loss: 0.6947 - acc: 0.525 - ETA: 4s - loss: 0.6945 - acc: 0.525 - ETA: 3s - loss: 0.6949 - acc: 0.524 - ETA: 3s - loss: 0.6950 - acc: 0.524 - ETA: 3s - loss: 0.6950 - acc: 0.523 - ETA: 3s - loss: 0.6948 - acc: 0.525 - ETA: 3s - loss: 0.6948 - acc: 0.525 - ETA: 3s - loss: 0.6947 - acc: 0.525 - ETA: 3s - loss: 0.6951 - acc: 0.524 - ETA: 3s - loss: 0.6953 - acc: 0.524 - ETA: 3s - loss: 0.6955 - acc: 0.524 - ETA: 3s - loss: 0.6953 - acc: 0.524 - ETA: 2s - loss: 0.6953 - acc: 0.524 - ETA: 2s - loss: 0.6951 - acc: 0.525 - ETA: 2s - loss: 0.6953 - acc: 0.524 - ETA: 2s - loss: 0.6953 - acc: 0.525 - ETA: 2s - loss: 0.6951 - acc: 0.525 - ETA: 2s - loss: 0.6950 - acc: 0.526 - ETA: 2s - loss: 0.6949 - acc: 0.526 - ETA: 2s - loss: 0.6950 - acc: 0.525 - ETA: 2s - loss: 0.6951 - acc: 0.524 - ETA: 2s - loss: 0.6949 - acc: 0.525 - ETA: 1s - loss: 0.6947 - acc: 0.526 - ETA: 1s - loss: 0.6946 - acc: 0.526 - ETA: 1s - loss: 0.6944 - acc: 0.527 - ETA: 1s - loss: 0.6945 - acc: 0.526 - ETA: 1s - loss: 0.6947 - acc: 0.525 - ETA: 1s - loss: 0.6946 - acc: 0.525 - ETA: 1s - loss: 0.6945 - acc: 0.526 - ETA: 1s - loss: 0.6944 - acc: 0.527 - ETA: 1s - loss: 0.6943 - acc: 0.528 - ETA: 1s - loss: 0.6942 - acc: 0.529 - ETA: 0s - loss: 0.6941 - acc: 0.529 - ETA: 0s - loss: 0.6941 - acc: 0.529 - ETA: 0s - loss: 0.6940 - acc: 0.529 - ETA: 0s - loss: 0.6940 - acc: 0.528 - ETA: 0s - loss: 0.6942 - acc: 0.527 - ETA: 0s - loss: 0.6940 - acc: 0.528 - ETA: 0s - loss: 0.6941 - acc: 0.528 - ETA: 0s - loss: 0.6940 - acc: 0.528 - ETA: 0s - loss: 0.6939 - acc: 0.528 - 15s 115ms/step - loss: 0.6942 - acc: 0.5273 - val_loss: 0.6989 - val_acc: 0.4902\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 12s - loss: 0.7462 - acc: 0.34 - ETA: 12s - loss: 0.7208 - acc: 0.42 - ETA: 12s - loss: 0.7093 - acc: 0.46 - ETA: 12s - loss: 0.7025 - acc: 0.48 - ETA: 12s - loss: 0.7020 - acc: 0.49 - ETA: 12s - loss: 0.6991 - acc: 0.50 - ETA: 12s - loss: 0.6982 - acc: 0.50 - ETA: 13s - loss: 0.6978 - acc: 0.50 - ETA: 13s - loss: 0.6963 - acc: 0.52 - ETA: 13s - loss: 0.6939 - acc: 0.54 - ETA: 12s - loss: 0.6928 - acc: 0.53 - ETA: 12s - loss: 0.6921 - acc: 0.54 - ETA: 12s - loss: 0.6925 - acc: 0.54 - ETA: 12s - loss: 0.6913 - acc: 0.54 - ETA: 12s - loss: 0.6900 - acc: 0.55 - ETA: 12s - loss: 0.6918 - acc: 0.54 - ETA: 12s - loss: 0.6929 - acc: 0.53 - ETA: 11s - loss: 0.6917 - acc: 0.53 - ETA: 12s - loss: 0.6906 - acc: 0.54 - ETA: 11s - loss: 0.6905 - acc: 0.53 - ETA: 11s - loss: 0.6907 - acc: 0.53 - ETA: 11s - loss: 0.6903 - acc: 0.54 - ETA: 11s - loss: 0.6896 - acc: 0.54 - ETA: 11s - loss: 0.6893 - acc: 0.54 - ETA: 11s - loss: 0.6896 - acc: 0.54 - ETA: 11s - loss: 0.6913 - acc: 0.54 - ETA: 11s - loss: 0.6923 - acc: 0.53 - ETA: 11s - loss: 0.6912 - acc: 0.54 - ETA: 11s - loss: 0.6906 - acc: 0.54 - ETA: 10s - loss: 0.6908 - acc: 0.53 - ETA: 10s - loss: 0.6907 - acc: 0.54 - ETA: 10s - loss: 0.6904 - acc: 0.54 - ETA: 10s - loss: 0.6926 - acc: 0.53 - ETA: 10s - loss: 0.6926 - acc: 0.52 - ETA: 10s - loss: 0.6925 - acc: 0.53 - ETA: 10s - loss: 0.6920 - acc: 0.53 - ETA: 10s - loss: 0.6921 - acc: 0.53 - ETA: 10s - loss: 0.6915 - acc: 0.53 - ETA: 10s - loss: 0.6922 - acc: 0.53 - ETA: 9s - loss: 0.6924 - acc: 0.5289 - ETA: 9s - loss: 0.6918 - acc: 0.530 - ETA: 9s - loss: 0.6924 - acc: 0.526 - ETA: 9s - loss: 0.6921 - acc: 0.529 - ETA: 9s - loss: 0.6917 - acc: 0.529 - ETA: 9s - loss: 0.6914 - acc: 0.531 - ETA: 9s - loss: 0.6915 - acc: 0.531 - ETA: 8s - loss: 0.6925 - acc: 0.529 - ETA: 8s - loss: 0.6912 - acc: 0.532 - ETA: 8s - loss: 0.6924 - acc: 0.531 - ETA: 8s - loss: 0.6930 - acc: 0.529 - ETA: 8s - loss: 0.6922 - acc: 0.531 - ETA: 8s - loss: 0.6923 - acc: 0.531 - ETA: 8s - loss: 0.6923 - acc: 0.530 - ETA: 8s - loss: 0.6921 - acc: 0.530 - ETA: 7s - loss: 0.6922 - acc: 0.529 - ETA: 7s - loss: 0.6919 - acc: 0.530 - ETA: 7s - loss: 0.6918 - acc: 0.530 - ETA: 7s - loss: 0.6919 - acc: 0.529 - ETA: 7s - loss: 0.6928 - acc: 0.526 - ETA: 7s - loss: 0.6933 - acc: 0.524 - ETA: 7s - loss: 0.6930 - acc: 0.524 - ETA: 7s - loss: 0.6928 - acc: 0.525 - ETA: 6s - loss: 0.6929 - acc: 0.523 - ETA: 6s - loss: 0.6927 - acc: 0.523 - ETA: 6s - loss: 0.6924 - acc: 0.525 - ETA: 6s - loss: 0.6936 - acc: 0.522 - ETA: 6s - loss: 0.6935 - acc: 0.522 - ETA: 6s - loss: 0.6933 - acc: 0.523 - ETA: 6s - loss: 0.6933 - acc: 0.523 - ETA: 6s - loss: 0.6936 - acc: 0.521 - ETA: 6s - loss: 0.6935 - acc: 0.523 - ETA: 5s - loss: 0.6935 - acc: 0.523 - ETA: 5s - loss: 0.6938 - acc: 0.521 - ETA: 5s - loss: 0.6943 - acc: 0.519 - ETA: 5s - loss: 0.6941 - acc: 0.520 - ETA: 5s - loss: 0.6940 - acc: 0.519 - ETA: 5s - loss: 0.6937 - acc: 0.521 - ETA: 5s - loss: 0.6936 - acc: 0.522 - ETA: 5s - loss: 0.6934 - acc: 0.524 - ETA: 5s - loss: 0.6930 - acc: 0.527 - ETA: 4s - loss: 0.6927 - acc: 0.528 - ETA: 4s - loss: 0.6928 - acc: 0.527 - ETA: 4s - loss: 0.6926 - acc: 0.527 - ETA: 4s - loss: 0.6923 - acc: 0.527 - ETA: 4s - loss: 0.6923 - acc: 0.526 - ETA: 4s - loss: 0.6923 - acc: 0.526 - ETA: 4s - loss: 0.6920 - acc: 0.527 - ETA: 4s - loss: 0.6919 - acc: 0.527 - ETA: 4s - loss: 0.6918 - acc: 0.528 - ETA: 3s - loss: 0.6916 - acc: 0.529 - ETA: 3s - loss: 0.6918 - acc: 0.528 - ETA: 3s - loss: 0.6917 - acc: 0.527 - ETA: 3s - loss: 0.6915 - acc: 0.529 - ETA: 3s - loss: 0.6909 - acc: 0.532 - ETA: 3s - loss: 0.6905 - acc: 0.533 - ETA: 3s - loss: 0.6909 - acc: 0.532 - ETA: 3s - loss: 0.6908 - acc: 0.532 - ETA: 3s - loss: 0.6912 - acc: 0.531 - ETA: 3s - loss: 0.6916 - acc: 0.530 - ETA: 2s - loss: 0.6914 - acc: 0.530 - ETA: 2s - loss: 0.6913 - acc: 0.529 - ETA: 2s - loss: 0.6913 - acc: 0.530 - ETA: 2s - loss: 0.6912 - acc: 0.530 - ETA: 2s - loss: 0.6912 - acc: 0.530 - ETA: 2s - loss: 0.6910 - acc: 0.531 - ETA: 2s - loss: 0.6909 - acc: 0.532 - ETA: 2s - loss: 0.6909 - acc: 0.532 - ETA: 2s - loss: 0.6907 - acc: 0.531 - ETA: 1s - loss: 0.6906 - acc: 0.531 - ETA: 1s - loss: 0.6906 - acc: 0.532 - ETA: 1s - loss: 0.6907 - acc: 0.531 - ETA: 1s - loss: 0.6906 - acc: 0.531 - ETA: 1s - loss: 0.6905 - acc: 0.532 - ETA: 1s - loss: 0.6905 - acc: 0.532 - ETA: 1s - loss: 0.6901 - acc: 0.534 - ETA: 1s - loss: 0.6901 - acc: 0.533 - ETA: 1s - loss: 0.6898 - acc: 0.533 - ETA: 1s - loss: 0.6900 - acc: 0.532 - ETA: 0s - loss: 0.6900 - acc: 0.532 - ETA: 0s - loss: 0.6898 - acc: 0.533 - ETA: 0s - loss: 0.6895 - acc: 0.535 - ETA: 0s - loss: 0.6894 - acc: 0.535 - ETA: 0s - loss: 0.6893 - acc: 0.535 - ETA: 0s - loss: 0.6890 - acc: 0.536 - ETA: 0s - loss: 0.6889 - acc: 0.537 - ETA: 0s - loss: 0.6886 - acc: 0.537 - ETA: 0s - loss: 0.6882 - acc: 0.538 - 15s 115ms/step - loss: 0.6877 - acc: 0.5393 - val_loss: 0.7218 - val_acc: 0.4973\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 15s - loss: 0.7189 - acc: 0.50 - ETA: 14s - loss: 0.7262 - acc: 0.48 - ETA: 15s - loss: 0.7239 - acc: 0.48 - ETA: 14s - loss: 0.7178 - acc: 0.50 - ETA: 14s - loss: 0.7162 - acc: 0.48 - ETA: 13s - loss: 0.7099 - acc: 0.48 - ETA: 13s - loss: 0.7044 - acc: 0.49 - ETA: 12s - loss: 0.7000 - acc: 0.50 - ETA: 12s - loss: 0.6986 - acc: 0.50 - ETA: 12s - loss: 0.7113 - acc: 0.48 - ETA: 12s - loss: 0.7078 - acc: 0.49 - ETA: 12s - loss: 0.7064 - acc: 0.49 - ETA: 11s - loss: 0.7011 - acc: 0.51 - ETA: 11s - loss: 0.7002 - acc: 0.51 - ETA: 11s - loss: 0.6977 - acc: 0.52 - ETA: 11s - loss: 0.6979 - acc: 0.51 - ETA: 11s - loss: 0.6956 - acc: 0.52 - ETA: 11s - loss: 0.6944 - acc: 0.53 - ETA: 11s - loss: 0.6944 - acc: 0.53 - ETA: 11s - loss: 0.6928 - acc: 0.54 - ETA: 11s - loss: 0.6916 - acc: 0.55 - ETA: 11s - loss: 0.6923 - acc: 0.55 - ETA: 11s - loss: 0.6910 - acc: 0.56 - ETA: 10s - loss: 0.6910 - acc: 0.55 - ETA: 10s - loss: 0.6913 - acc: 0.55 - ETA: 10s - loss: 0.6908 - acc: 0.55 - ETA: 10s - loss: 0.6893 - acc: 0.55 - ETA: 10s - loss: 0.6878 - acc: 0.55 - ETA: 10s - loss: 0.6879 - acc: 0.55 - ETA: 10s - loss: 0.6874 - acc: 0.55 - ETA: 10s - loss: 0.6864 - acc: 0.55 - ETA: 10s - loss: 0.6854 - acc: 0.55 - ETA: 9s - loss: 0.6848 - acc: 0.5568 - ETA: 9s - loss: 0.6848 - acc: 0.557 - ETA: 9s - loss: 0.6852 - acc: 0.556 - ETA: 9s - loss: 0.6853 - acc: 0.557 - ETA: 9s - loss: 0.6848 - acc: 0.559 - ETA: 9s - loss: 0.6850 - acc: 0.557 - ETA: 9s - loss: 0.6850 - acc: 0.558 - ETA: 9s - loss: 0.6842 - acc: 0.563 - ETA: 9s - loss: 0.6846 - acc: 0.561 - ETA: 8s - loss: 0.6854 - acc: 0.558 - ETA: 8s - loss: 0.6852 - acc: 0.557 - ETA: 8s - loss: 0.6852 - acc: 0.556 - ETA: 8s - loss: 0.6849 - acc: 0.554 - ETA: 8s - loss: 0.6843 - acc: 0.557 - ETA: 8s - loss: 0.6838 - acc: 0.559 - ETA: 8s - loss: 0.6830 - acc: 0.563 - ETA: 8s - loss: 0.6828 - acc: 0.563 - ETA: 8s - loss: 0.6825 - acc: 0.564 - ETA: 8s - loss: 0.6826 - acc: 0.562 - ETA: 7s - loss: 0.6817 - acc: 0.567 - ETA: 7s - loss: 0.6815 - acc: 0.567 - ETA: 7s - loss: 0.6814 - acc: 0.567 - ETA: 7s - loss: 0.6813 - acc: 0.566 - ETA: 7s - loss: 0.6808 - acc: 0.567 - ETA: 7s - loss: 0.6806 - acc: 0.566 - ETA: 7s - loss: 0.6805 - acc: 0.566 - ETA: 7s - loss: 0.6795 - acc: 0.567 - ETA: 7s - loss: 0.6790 - acc: 0.567 - ETA: 7s - loss: 0.6792 - acc: 0.565 - ETA: 6s - loss: 0.6794 - acc: 0.564 - ETA: 6s - loss: 0.6790 - acc: 0.567 - ETA: 6s - loss: 0.6790 - acc: 0.567 - ETA: 6s - loss: 0.6788 - acc: 0.568 - ETA: 6s - loss: 0.6785 - acc: 0.569 - ETA: 6s - loss: 0.6780 - acc: 0.573 - ETA: 6s - loss: 0.6775 - acc: 0.574 - ETA: 6s - loss: 0.6772 - acc: 0.575 - ETA: 6s - loss: 0.6778 - acc: 0.573 - ETA: 5s - loss: 0.6777 - acc: 0.573 - ETA: 5s - loss: 0.6778 - acc: 0.572 - ETA: 5s - loss: 0.6778 - acc: 0.573 - ETA: 5s - loss: 0.6774 - acc: 0.575 - ETA: 5s - loss: 0.6771 - acc: 0.576 - ETA: 5s - loss: 0.6771 - acc: 0.576 - ETA: 5s - loss: 0.6770 - acc: 0.577 - ETA: 5s - loss: 0.6771 - acc: 0.579 - ETA: 5s - loss: 0.6772 - acc: 0.579 - ETA: 4s - loss: 0.6769 - acc: 0.578 - ETA: 4s - loss: 0.6765 - acc: 0.579 - ETA: 4s - loss: 0.6760 - acc: 0.581 - ETA: 4s - loss: 0.6757 - acc: 0.582 - ETA: 4s - loss: 0.6758 - acc: 0.582 - ETA: 4s - loss: 0.6761 - acc: 0.581 - ETA: 4s - loss: 0.6761 - acc: 0.581 - ETA: 4s - loss: 0.6766 - acc: 0.580 - ETA: 4s - loss: 0.6765 - acc: 0.580 - ETA: 4s - loss: 0.6763 - acc: 0.580 - ETA: 3s - loss: 0.6759 - acc: 0.582 - ETA: 3s - loss: 0.6755 - acc: 0.584 - ETA: 3s - loss: 0.6754 - acc: 0.584 - ETA: 3s - loss: 0.6755 - acc: 0.583 - ETA: 3s - loss: 0.6752 - acc: 0.583 - ETA: 3s - loss: 0.6757 - acc: 0.581 - ETA: 3s - loss: 0.6753 - acc: 0.583 - ETA: 3s - loss: 0.6749 - acc: 0.584 - ETA: 3s - loss: 0.6749 - acc: 0.584 - ETA: 2s - loss: 0.6746 - acc: 0.585 - ETA: 2s - loss: 0.6747 - acc: 0.585 - ETA: 2s - loss: 0.6750 - acc: 0.585 - ETA: 2s - loss: 0.6750 - acc: 0.584 - ETA: 2s - loss: 0.6750 - acc: 0.584 - ETA: 2s - loss: 0.6747 - acc: 0.585 - ETA: 2s - loss: 0.6745 - acc: 0.586 - ETA: 2s - loss: 0.6744 - acc: 0.586 - ETA: 2s - loss: 0.6743 - acc: 0.586 - ETA: 2s - loss: 0.6742 - acc: 0.585 - ETA: 1s - loss: 0.6739 - acc: 0.587 - ETA: 1s - loss: 0.6741 - acc: 0.586 - ETA: 1s - loss: 0.6738 - acc: 0.588 - ETA: 1s - loss: 0.6734 - acc: 0.588 - ETA: 1s - loss: 0.6731 - acc: 0.589 - ETA: 1s - loss: 0.6729 - acc: 0.590 - ETA: 1s - loss: 0.6726 - acc: 0.590 - ETA: 1s - loss: 0.6727 - acc: 0.589 - ETA: 1s - loss: 0.6725 - acc: 0.589 - ETA: 1s - loss: 0.6728 - acc: 0.588 - ETA: 0s - loss: 0.6731 - acc: 0.586 - ETA: 0s - loss: 0.6728 - acc: 0.588 - ETA: 0s - loss: 0.6723 - acc: 0.588 - ETA: 0s - loss: 0.6720 - acc: 0.589 - ETA: 0s - loss: 0.6716 - acc: 0.589 - ETA: 0s - loss: 0.6727 - acc: 0.588 - ETA: 0s - loss: 0.6728 - acc: 0.587 - ETA: 0s - loss: 0.6731 - acc: 0.586 - ETA: 0s - loss: 0.6732 - acc: 0.586 - 15s 115ms/step - loss: 0.6733 - acc: 0.5859 - val_loss: 0.6474 - val_acc: 0.6326\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 13s - loss: 0.6299 - acc: 0.75 - ETA: 12s - loss: 0.6772 - acc: 0.59 - ETA: 12s - loss: 0.6511 - acc: 0.61 - ETA: 12s - loss: 0.6668 - acc: 0.58 - ETA: 11s - loss: 0.6722 - acc: 0.56 - ETA: 11s - loss: 0.6771 - acc: 0.56 - ETA: 11s - loss: 0.6665 - acc: 0.57 - ETA: 11s - loss: 0.6713 - acc: 0.55 - ETA: 11s - loss: 0.6680 - acc: 0.56 - ETA: 11s - loss: 0.6669 - acc: 0.57 - ETA: 10s - loss: 0.6670 - acc: 0.57 - ETA: 10s - loss: 0.6603 - acc: 0.58 - ETA: 10s - loss: 0.6599 - acc: 0.58 - ETA: 10s - loss: 0.6613 - acc: 0.58 - ETA: 10s - loss: 0.6655 - acc: 0.57 - ETA: 10s - loss: 0.6632 - acc: 0.57 - ETA: 10s - loss: 0.6626 - acc: 0.57 - ETA: 10s - loss: 0.6607 - acc: 0.58 - ETA: 10s - loss: 0.6593 - acc: 0.59 - ETA: 10s - loss: 0.6585 - acc: 0.59 - ETA: 10s - loss: 0.6553 - acc: 0.60 - ETA: 10s - loss: 0.6563 - acc: 0.59 - ETA: 10s - loss: 0.6581 - acc: 0.59 - ETA: 9s - loss: 0.6588 - acc: 0.5924 - ETA: 9s - loss: 0.6573 - acc: 0.592 - ETA: 9s - loss: 0.6573 - acc: 0.595 - ETA: 9s - loss: 0.6573 - acc: 0.593 - ETA: 9s - loss: 0.6566 - acc: 0.598 - ETA: 9s - loss: 0.6567 - acc: 0.598 - ETA: 9s - loss: 0.6570 - acc: 0.594 - ETA: 9s - loss: 0.6564 - acc: 0.596 - ETA: 9s - loss: 0.6561 - acc: 0.598 - ETA: 9s - loss: 0.6559 - acc: 0.597 - ETA: 8s - loss: 0.6561 - acc: 0.597 - ETA: 8s - loss: 0.6549 - acc: 0.598 - ETA: 8s - loss: 0.6541 - acc: 0.598 - ETA: 8s - loss: 0.6537 - acc: 0.598 - ETA: 8s - loss: 0.6535 - acc: 0.596 - ETA: 8s - loss: 0.6541 - acc: 0.595 - ETA: 8s - loss: 0.6535 - acc: 0.596 - ETA: 8s - loss: 0.6539 - acc: 0.594 - ETA: 8s - loss: 0.6516 - acc: 0.597 - ETA: 7s - loss: 0.6509 - acc: 0.598 - ETA: 7s - loss: 0.6514 - acc: 0.597 - ETA: 7s - loss: 0.6511 - acc: 0.597 - ETA: 7s - loss: 0.6497 - acc: 0.599 - ETA: 7s - loss: 0.6516 - acc: 0.596 - ETA: 7s - loss: 0.6530 - acc: 0.594 - ETA: 7s - loss: 0.6523 - acc: 0.596 - ETA: 7s - loss: 0.6526 - acc: 0.596 - ETA: 7s - loss: 0.6531 - acc: 0.593 - ETA: 7s - loss: 0.6542 - acc: 0.591 - ETA: 7s - loss: 0.6549 - acc: 0.589 - ETA: 6s - loss: 0.6546 - acc: 0.588 - ETA: 6s - loss: 0.6543 - acc: 0.590 - ETA: 6s - loss: 0.6536 - acc: 0.593 - ETA: 6s - loss: 0.6543 - acc: 0.592 - ETA: 6s - loss: 0.6546 - acc: 0.591 - ETA: 6s - loss: 0.6562 - acc: 0.588 - ETA: 6s - loss: 0.6550 - acc: 0.590 - ETA: 6s - loss: 0.6558 - acc: 0.589 - ETA: 6s - loss: 0.6560 - acc: 0.588 - ETA: 6s - loss: 0.6560 - acc: 0.589 - ETA: 5s - loss: 0.6554 - acc: 0.591 - ETA: 5s - loss: 0.6547 - acc: 0.592 - ETA: 5s - loss: 0.6542 - acc: 0.594 - ETA: 5s - loss: 0.6536 - acc: 0.594 - ETA: 5s - loss: 0.6525 - acc: 0.596 - ETA: 5s - loss: 0.6527 - acc: 0.594 - ETA: 5s - loss: 0.6525 - acc: 0.594 - ETA: 5s - loss: 0.6518 - acc: 0.596 - ETA: 5s - loss: 0.6514 - acc: 0.597 - ETA: 5s - loss: 0.6519 - acc: 0.595 - ETA: 5s - loss: 0.6514 - acc: 0.597 - ETA: 4s - loss: 0.6512 - acc: 0.597 - ETA: 4s - loss: 0.6504 - acc: 0.598 - ETA: 4s - loss: 0.6511 - acc: 0.596 - ETA: 4s - loss: 0.6505 - acc: 0.597 - ETA: 4s - loss: 0.6495 - acc: 0.600 - ETA: 4s - loss: 0.6489 - acc: 0.603 - ETA: 4s - loss: 0.6493 - acc: 0.602 - ETA: 4s - loss: 0.6497 - acc: 0.601 - ETA: 4s - loss: 0.6509 - acc: 0.599 - ETA: 4s - loss: 0.6503 - acc: 0.599 - ETA: 4s - loss: 0.6502 - acc: 0.598 - ETA: 3s - loss: 0.6500 - acc: 0.598 - ETA: 3s - loss: 0.6497 - acc: 0.599 - ETA: 3s - loss: 0.6493 - acc: 0.600 - ETA: 3s - loss: 0.6498 - acc: 0.600 - ETA: 3s - loss: 0.6503 - acc: 0.599 - ETA: 3s - loss: 0.6510 - acc: 0.598 - ETA: 3s - loss: 0.6512 - acc: 0.598 - ETA: 3s - loss: 0.6507 - acc: 0.599 - ETA: 3s - loss: 0.6501 - acc: 0.600 - ETA: 3s - loss: 0.6496 - acc: 0.601 - ETA: 2s - loss: 0.6493 - acc: 0.601 - ETA: 2s - loss: 0.6478 - acc: 0.603 - ETA: 2s - loss: 0.6482 - acc: 0.602 - ETA: 2s - loss: 0.6480 - acc: 0.602 - ETA: 2s - loss: 0.6480 - acc: 0.600 - ETA: 2s - loss: 0.6476 - acc: 0.602 - ETA: 2s - loss: 0.6474 - acc: 0.602 - ETA: 2s - loss: 0.6473 - acc: 0.603 - ETA: 2s - loss: 0.6470 - acc: 0.603 - ETA: 2s - loss: 0.6471 - acc: 0.603 - ETA: 2s - loss: 0.6475 - acc: 0.602 - ETA: 1s - loss: 0.6471 - acc: 0.602 - ETA: 1s - loss: 0.6467 - acc: 0.604 - ETA: 1s - loss: 0.6463 - acc: 0.604 - ETA: 1s - loss: 0.6459 - acc: 0.605 - ETA: 1s - loss: 0.6459 - acc: 0.605 - ETA: 1s - loss: 0.6460 - acc: 0.605 - ETA: 1s - loss: 0.6456 - acc: 0.606 - ETA: 1s - loss: 0.6452 - acc: 0.607 - ETA: 1s - loss: 0.6443 - acc: 0.609 - ETA: 1s - loss: 0.6440 - acc: 0.610 - ETA: 1s - loss: 0.6440 - acc: 0.610 - ETA: 0s - loss: 0.6439 - acc: 0.610 - ETA: 0s - loss: 0.6447 - acc: 0.608 - ETA: 0s - loss: 0.6449 - acc: 0.607 - ETA: 0s - loss: 0.6447 - acc: 0.607 - ETA: 0s - loss: 0.6446 - acc: 0.607 - ETA: 0s - loss: 0.6438 - acc: 0.608 - ETA: 0s - loss: 0.6436 - acc: 0.609 - ETA: 0s - loss: 0.6437 - acc: 0.609 - ETA: 0s - loss: 0.6436 - acc: 0.609 - ETA: 0s - loss: 0.6437 - acc: 0.609 - 14s 108ms/step - loss: 0.6435 - acc: 0.6108 - val_loss: 0.6052 - val_acc: 0.6926\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 10s - loss: 0.5934 - acc: 0.65 - ETA: 11s - loss: 0.5885 - acc: 0.70 - ETA: 10s - loss: 0.6114 - acc: 0.66 - ETA: 10s - loss: 0.6087 - acc: 0.67 - ETA: 10s - loss: 0.6155 - acc: 0.66 - ETA: 11s - loss: 0.6317 - acc: 0.63 - ETA: 10s - loss: 0.6355 - acc: 0.62 - ETA: 10s - loss: 0.6268 - acc: 0.64 - ETA: 10s - loss: 0.6212 - acc: 0.67 - ETA: 10s - loss: 0.6163 - acc: 0.67 - ETA: 10s - loss: 0.6155 - acc: 0.67 - ETA: 10s - loss: 0.6154 - acc: 0.68 - ETA: 10s - loss: 0.6130 - acc: 0.67 - ETA: 10s - loss: 0.6158 - acc: 0.67 - ETA: 10s - loss: 0.6146 - acc: 0.68 - ETA: 10s - loss: 0.6142 - acc: 0.67 - ETA: 10s - loss: 0.6079 - acc: 0.68 - ETA: 9s - loss: 0.6073 - acc: 0.6823 - ETA: 9s - loss: 0.6085 - acc: 0.679 - ETA: 9s - loss: 0.6059 - acc: 0.682 - ETA: 9s - loss: 0.6070 - acc: 0.680 - ETA: 9s - loss: 0.6079 - acc: 0.681 - ETA: 9s - loss: 0.6114 - acc: 0.678 - ETA: 9s - loss: 0.6085 - acc: 0.681 - ETA: 9s - loss: 0.6072 - acc: 0.680 - ETA: 9s - loss: 0.6065 - acc: 0.680 - ETA: 9s - loss: 0.6048 - acc: 0.684 - ETA: 9s - loss: 0.6077 - acc: 0.679 - ETA: 9s - loss: 0.6074 - acc: 0.682 - ETA: 9s - loss: 0.6071 - acc: 0.683 - ETA: 9s - loss: 0.6067 - acc: 0.686 - ETA: 9s - loss: 0.6062 - acc: 0.690 - ETA: 9s - loss: 0.6066 - acc: 0.688 - ETA: 9s - loss: 0.6054 - acc: 0.693 - ETA: 8s - loss: 0.6067 - acc: 0.689 - ETA: 8s - loss: 0.6087 - acc: 0.686 - ETA: 8s - loss: 0.6098 - acc: 0.681 - ETA: 8s - loss: 0.6077 - acc: 0.684 - ETA: 8s - loss: 0.6092 - acc: 0.681 - ETA: 8s - loss: 0.6080 - acc: 0.682 - ETA: 8s - loss: 0.6113 - acc: 0.677 - ETA: 8s - loss: 0.6132 - acc: 0.673 - ETA: 8s - loss: 0.6136 - acc: 0.672 - ETA: 8s - loss: 0.6131 - acc: 0.671 - ETA: 7s - loss: 0.6118 - acc: 0.672 - ETA: 7s - loss: 0.6128 - acc: 0.669 - ETA: 7s - loss: 0.6156 - acc: 0.667 - ETA: 7s - loss: 0.6163 - acc: 0.665 - ETA: 7s - loss: 0.6163 - acc: 0.662 - ETA: 7s - loss: 0.6152 - acc: 0.663 - ETA: 7s - loss: 0.6154 - acc: 0.663 - ETA: 7s - loss: 0.6168 - acc: 0.661 - ETA: 7s - loss: 0.6190 - acc: 0.658 - ETA: 7s - loss: 0.6183 - acc: 0.659 - ETA: 6s - loss: 0.6185 - acc: 0.659 - ETA: 6s - loss: 0.6190 - acc: 0.659 - ETA: 6s - loss: 0.6197 - acc: 0.658 - ETA: 6s - loss: 0.6206 - acc: 0.657 - ETA: 6s - loss: 0.6186 - acc: 0.658 - ETA: 6s - loss: 0.6178 - acc: 0.658 - ETA: 6s - loss: 0.6185 - acc: 0.655 - ETA: 6s - loss: 0.6195 - acc: 0.655 - ETA: 6s - loss: 0.6186 - acc: 0.656 - ETA: 6s - loss: 0.6174 - acc: 0.656 - ETA: 5s - loss: 0.6168 - acc: 0.656 - ETA: 5s - loss: 0.6169 - acc: 0.654 - ETA: 5s - loss: 0.6161 - acc: 0.656 - ETA: 5s - loss: 0.6166 - acc: 0.655 - ETA: 5s - loss: 0.6160 - acc: 0.656 - ETA: 5s - loss: 0.6138 - acc: 0.660 - ETA: 5s - loss: 0.6140 - acc: 0.658 - ETA: 5s - loss: 0.6139 - acc: 0.660 - ETA: 5s - loss: 0.6130 - acc: 0.662 - ETA: 5s - loss: 0.6131 - acc: 0.662 - ETA: 4s - loss: 0.6129 - acc: 0.663 - ETA: 4s - loss: 0.6119 - acc: 0.664 - ETA: 4s - loss: 0.6115 - acc: 0.664 - ETA: 4s - loss: 0.6106 - acc: 0.665 - ETA: 4s - loss: 0.6102 - acc: 0.666 - ETA: 4s - loss: 0.6099 - acc: 0.666 - ETA: 4s - loss: 0.6096 - acc: 0.667 - ETA: 4s - loss: 0.6089 - acc: 0.668 - ETA: 4s - loss: 0.6098 - acc: 0.667 - ETA: 4s - loss: 0.6096 - acc: 0.668 - ETA: 4s - loss: 0.6090 - acc: 0.668 - ETA: 3s - loss: 0.6085 - acc: 0.669 - ETA: 3s - loss: 0.6087 - acc: 0.669 - ETA: 3s - loss: 0.6094 - acc: 0.667 - ETA: 3s - loss: 0.6092 - acc: 0.667 - ETA: 3s - loss: 0.6101 - acc: 0.665 - ETA: 3s - loss: 0.6091 - acc: 0.665 - ETA: 3s - loss: 0.6096 - acc: 0.664 - ETA: 3s - loss: 0.6091 - acc: 0.664 - ETA: 3s - loss: 0.6089 - acc: 0.664 - ETA: 3s - loss: 0.6085 - acc: 0.664 - ETA: 3s - loss: 0.6089 - acc: 0.663 - ETA: 2s - loss: 0.6095 - acc: 0.663 - ETA: 2s - loss: 0.6087 - acc: 0.664 - ETA: 2s - loss: 0.6075 - acc: 0.665 - ETA: 2s - loss: 0.6079 - acc: 0.665 - ETA: 2s - loss: 0.6087 - acc: 0.664 - ETA: 2s - loss: 0.6083 - acc: 0.664 - ETA: 2s - loss: 0.6080 - acc: 0.664 - ETA: 2s - loss: 0.6073 - acc: 0.664 - ETA: 2s - loss: 0.6081 - acc: 0.663 - ETA: 2s - loss: 0.6088 - acc: 0.661 - ETA: 1s - loss: 0.6095 - acc: 0.660 - ETA: 1s - loss: 0.6093 - acc: 0.659 - ETA: 1s - loss: 0.6099 - acc: 0.658 - ETA: 1s - loss: 0.6095 - acc: 0.658 - ETA: 1s - loss: 0.6092 - acc: 0.658 - ETA: 1s - loss: 0.6097 - acc: 0.658 - ETA: 1s - loss: 0.6090 - acc: 0.659 - ETA: 1s - loss: 0.6092 - acc: 0.658 - ETA: 1s - loss: 0.6087 - acc: 0.659 - ETA: 1s - loss: 0.6079 - acc: 0.660 - ETA: 1s - loss: 0.6089 - acc: 0.658 - ETA: 0s - loss: 0.6088 - acc: 0.658 - ETA: 0s - loss: 0.6090 - acc: 0.659 - ETA: 0s - loss: 0.6094 - acc: 0.659 - ETA: 0s - loss: 0.6090 - acc: 0.659 - ETA: 0s - loss: 0.6092 - acc: 0.659 - ETA: 0s - loss: 0.6089 - acc: 0.660 - ETA: 0s - loss: 0.6081 - acc: 0.661 - ETA: 0s - loss: 0.6076 - acc: 0.661 - ETA: 0s - loss: 0.6081 - acc: 0.661 - ETA: 0s - loss: 0.6075 - acc: 0.661 - 14s 111ms/step - loss: 0.6069 - acc: 0.6624 - val_loss: 0.5722 - val_acc: 0.7080\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.6320 - acc: 0.75 - ETA: 12s - loss: 0.6059 - acc: 0.73 - ETA: 14s - loss: 0.5945 - acc: 0.73 - ETA: 13s - loss: 0.5903 - acc: 0.72 - ETA: 12s - loss: 0.5793 - acc: 0.73 - ETA: 12s - loss: 0.5827 - acc: 0.71 - ETA: 12s - loss: 0.5759 - acc: 0.71 - ETA: 12s - loss: 0.5689 - acc: 0.72 - ETA: 12s - loss: 0.5661 - acc: 0.72 - ETA: 12s - loss: 0.5633 - acc: 0.72 - ETA: 11s - loss: 0.5588 - acc: 0.73 - ETA: 11s - loss: 0.5612 - acc: 0.73 - ETA: 11s - loss: 0.5702 - acc: 0.72 - ETA: 11s - loss: 0.5743 - acc: 0.71 - ETA: 11s - loss: 0.5831 - acc: 0.70 - ETA: 11s - loss: 0.5841 - acc: 0.70 - ETA: 10s - loss: 0.5910 - acc: 0.70 - ETA: 10s - loss: 0.5908 - acc: 0.69 - ETA: 10s - loss: 0.5932 - acc: 0.69 - ETA: 10s - loss: 0.5930 - acc: 0.68 - ETA: 10s - loss: 0.5968 - acc: 0.68 - ETA: 10s - loss: 0.6050 - acc: 0.67 - ETA: 10s - loss: 0.6063 - acc: 0.67 - ETA: 10s - loss: 0.6096 - acc: 0.66 - ETA: 9s - loss: 0.6100 - acc: 0.6675 - ETA: 9s - loss: 0.6105 - acc: 0.665 - ETA: 9s - loss: 0.6138 - acc: 0.663 - ETA: 9s - loss: 0.6121 - acc: 0.665 - ETA: 9s - loss: 0.6142 - acc: 0.663 - ETA: 9s - loss: 0.6131 - acc: 0.664 - ETA: 9s - loss: 0.6107 - acc: 0.666 - ETA: 9s - loss: 0.6116 - acc: 0.666 - ETA: 9s - loss: 0.6135 - acc: 0.665 - ETA: 9s - loss: 0.6120 - acc: 0.668 - ETA: 9s - loss: 0.6114 - acc: 0.667 - ETA: 8s - loss: 0.6094 - acc: 0.671 - ETA: 8s - loss: 0.6083 - acc: 0.670 - ETA: 8s - loss: 0.6078 - acc: 0.669 - ETA: 8s - loss: 0.6078 - acc: 0.669 - ETA: 8s - loss: 0.6081 - acc: 0.671 - ETA: 8s - loss: 0.6061 - acc: 0.673 - ETA: 8s - loss: 0.6045 - acc: 0.674 - ETA: 8s - loss: 0.6027 - acc: 0.674 - ETA: 8s - loss: 0.5986 - acc: 0.676 - ETA: 7s - loss: 0.5988 - acc: 0.677 - ETA: 7s - loss: 0.5972 - acc: 0.678 - ETA: 7s - loss: 0.5973 - acc: 0.676 - ETA: 7s - loss: 0.5948 - acc: 0.679 - ETA: 7s - loss: 0.5922 - acc: 0.681 - ETA: 7s - loss: 0.5939 - acc: 0.677 - ETA: 7s - loss: 0.5951 - acc: 0.675 - ETA: 7s - loss: 0.5931 - acc: 0.679 - ETA: 7s - loss: 0.5924 - acc: 0.679 - ETA: 7s - loss: 0.5928 - acc: 0.677 - ETA: 6s - loss: 0.5917 - acc: 0.678 - ETA: 6s - loss: 0.5944 - acc: 0.676 - ETA: 6s - loss: 0.5951 - acc: 0.675 - ETA: 6s - loss: 0.5950 - acc: 0.674 - ETA: 6s - loss: 0.5957 - acc: 0.673 - ETA: 6s - loss: 0.5956 - acc: 0.674 - ETA: 6s - loss: 0.5953 - acc: 0.674 - ETA: 6s - loss: 0.5960 - acc: 0.675 - ETA: 6s - loss: 0.5966 - acc: 0.675 - ETA: 6s - loss: 0.5962 - acc: 0.676 - ETA: 6s - loss: 0.5957 - acc: 0.677 - ETA: 5s - loss: 0.5946 - acc: 0.677 - ETA: 5s - loss: 0.5945 - acc: 0.677 - ETA: 5s - loss: 0.5931 - acc: 0.678 - ETA: 5s - loss: 0.5933 - acc: 0.679 - ETA: 5s - loss: 0.5933 - acc: 0.681 - ETA: 5s - loss: 0.5926 - acc: 0.680 - ETA: 5s - loss: 0.5936 - acc: 0.679 - ETA: 5s - loss: 0.5925 - acc: 0.680 - ETA: 5s - loss: 0.5933 - acc: 0.679 - ETA: 5s - loss: 0.5948 - acc: 0.677 - ETA: 5s - loss: 0.5944 - acc: 0.677 - ETA: 4s - loss: 0.5958 - acc: 0.675 - ETA: 4s - loss: 0.5972 - acc: 0.673 - ETA: 4s - loss: 0.5960 - acc: 0.674 - ETA: 4s - loss: 0.5967 - acc: 0.673 - ETA: 4s - loss: 0.5961 - acc: 0.674 - ETA: 4s - loss: 0.5962 - acc: 0.673 - ETA: 4s - loss: 0.5955 - acc: 0.674 - ETA: 4s - loss: 0.5957 - acc: 0.674 - ETA: 4s - loss: 0.5959 - acc: 0.675 - ETA: 4s - loss: 0.5959 - acc: 0.675 - ETA: 3s - loss: 0.5950 - acc: 0.676 - ETA: 3s - loss: 0.5940 - acc: 0.676 - ETA: 3s - loss: 0.5940 - acc: 0.677 - ETA: 3s - loss: 0.5935 - acc: 0.678 - ETA: 3s - loss: 0.5933 - acc: 0.678 - ETA: 3s - loss: 0.5925 - acc: 0.678 - ETA: 3s - loss: 0.5915 - acc: 0.679 - ETA: 3s - loss: 0.5914 - acc: 0.680 - ETA: 3s - loss: 0.5910 - acc: 0.680 - ETA: 3s - loss: 0.5908 - acc: 0.680 - ETA: 2s - loss: 0.5897 - acc: 0.681 - ETA: 2s - loss: 0.5899 - acc: 0.680 - ETA: 2s - loss: 0.5912 - acc: 0.678 - ETA: 2s - loss: 0.5913 - acc: 0.679 - ETA: 2s - loss: 0.5912 - acc: 0.678 - ETA: 2s - loss: 0.5901 - acc: 0.680 - ETA: 2s - loss: 0.5899 - acc: 0.679 - ETA: 2s - loss: 0.5897 - acc: 0.679 - ETA: 2s - loss: 0.5891 - acc: 0.680 - ETA: 2s - loss: 0.5890 - acc: 0.680 - ETA: 2s - loss: 0.5895 - acc: 0.680 - ETA: 1s - loss: 0.5890 - acc: 0.680 - ETA: 1s - loss: 0.5892 - acc: 0.680 - ETA: 1s - loss: 0.5889 - acc: 0.681 - ETA: 1s - loss: 0.5885 - acc: 0.681 - ETA: 1s - loss: 0.5874 - acc: 0.682 - ETA: 1s - loss: 0.5867 - acc: 0.683 - ETA: 1s - loss: 0.5867 - acc: 0.684 - ETA: 1s - loss: 0.5862 - acc: 0.684 - ETA: 1s - loss: 0.5848 - acc: 0.686 - ETA: 1s - loss: 0.5835 - acc: 0.688 - ETA: 0s - loss: 0.5838 - acc: 0.688 - ETA: 0s - loss: 0.5832 - acc: 0.688 - ETA: 0s - loss: 0.5840 - acc: 0.687 - ETA: 0s - loss: 0.5844 - acc: 0.687 - ETA: 0s - loss: 0.5841 - acc: 0.687 - ETA: 0s - loss: 0.5834 - acc: 0.687 - ETA: 0s - loss: 0.5840 - acc: 0.686 - ETA: 0s - loss: 0.5836 - acc: 0.686 - ETA: 0s - loss: 0.5832 - acc: 0.686 - ETA: 0s - loss: 0.5830 - acc: 0.686 - 14s 108ms/step - loss: 0.5830 - acc: 0.6863 - val_loss: 0.5566 - val_acc: 0.7053\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 13s - loss: 0.6633 - acc: 0.59 - ETA: 12s - loss: 0.5773 - acc: 0.65 - ETA: 12s - loss: 0.5294 - acc: 0.71 - ETA: 11s - loss: 0.5667 - acc: 0.69 - ETA: 11s - loss: 0.5528 - acc: 0.70 - ETA: 11s - loss: 0.5570 - acc: 0.69 - ETA: 11s - loss: 0.5719 - acc: 0.69 - ETA: 11s - loss: 0.5631 - acc: 0.69 - ETA: 11s - loss: 0.5551 - acc: 0.70 - ETA: 10s - loss: 0.5588 - acc: 0.70 - ETA: 10s - loss: 0.5587 - acc: 0.69 - ETA: 10s - loss: 0.5653 - acc: 0.67 - ETA: 10s - loss: 0.5551 - acc: 0.68 - ETA: 10s - loss: 0.5561 - acc: 0.69 - ETA: 10s - loss: 0.5656 - acc: 0.68 - ETA: 10s - loss: 0.5658 - acc: 0.69 - ETA: 10s - loss: 0.5652 - acc: 0.69 - ETA: 10s - loss: 0.5678 - acc: 0.69 - ETA: 10s - loss: 0.5631 - acc: 0.69 - ETA: 10s - loss: 0.5612 - acc: 0.70 - ETA: 10s - loss: 0.5639 - acc: 0.70 - ETA: 9s - loss: 0.5584 - acc: 0.7031 - ETA: 9s - loss: 0.5557 - acc: 0.705 - ETA: 9s - loss: 0.5586 - acc: 0.705 - ETA: 9s - loss: 0.5575 - acc: 0.710 - ETA: 9s - loss: 0.5569 - acc: 0.705 - ETA: 9s - loss: 0.5546 - acc: 0.707 - ETA: 9s - loss: 0.5515 - acc: 0.708 - ETA: 9s - loss: 0.5508 - acc: 0.708 - ETA: 9s - loss: 0.5515 - acc: 0.708 - ETA: 9s - loss: 0.5536 - acc: 0.704 - ETA: 9s - loss: 0.5515 - acc: 0.709 - ETA: 9s - loss: 0.5524 - acc: 0.706 - ETA: 9s - loss: 0.5545 - acc: 0.705 - ETA: 8s - loss: 0.5543 - acc: 0.708 - ETA: 8s - loss: 0.5547 - acc: 0.708 - ETA: 8s - loss: 0.5561 - acc: 0.707 - ETA: 8s - loss: 0.5577 - acc: 0.705 - ETA: 8s - loss: 0.5551 - acc: 0.707 - ETA: 8s - loss: 0.5544 - acc: 0.710 - ETA: 8s - loss: 0.5557 - acc: 0.710 - ETA: 8s - loss: 0.5539 - acc: 0.710 - ETA: 8s - loss: 0.5524 - acc: 0.712 - ETA: 8s - loss: 0.5541 - acc: 0.710 - ETA: 8s - loss: 0.5571 - acc: 0.709 - ETA: 7s - loss: 0.5586 - acc: 0.706 - ETA: 7s - loss: 0.5573 - acc: 0.708 - ETA: 7s - loss: 0.5583 - acc: 0.707 - ETA: 7s - loss: 0.5590 - acc: 0.706 - ETA: 7s - loss: 0.5573 - acc: 0.708 - ETA: 7s - loss: 0.5569 - acc: 0.709 - ETA: 7s - loss: 0.5582 - acc: 0.708 - ETA: 7s - loss: 0.5562 - acc: 0.710 - ETA: 7s - loss: 0.5554 - acc: 0.711 - ETA: 7s - loss: 0.5555 - acc: 0.711 - ETA: 6s - loss: 0.5552 - acc: 0.712 - ETA: 6s - loss: 0.5562 - acc: 0.714 - ETA: 6s - loss: 0.5556 - acc: 0.716 - ETA: 6s - loss: 0.5574 - acc: 0.715 - ETA: 6s - loss: 0.5579 - acc: 0.715 - ETA: 6s - loss: 0.5569 - acc: 0.716 - ETA: 6s - loss: 0.5572 - acc: 0.714 - ETA: 6s - loss: 0.5572 - acc: 0.713 - ETA: 6s - loss: 0.5560 - acc: 0.714 - ETA: 6s - loss: 0.5561 - acc: 0.714 - ETA: 5s - loss: 0.5564 - acc: 0.714 - ETA: 5s - loss: 0.5553 - acc: 0.715 - ETA: 5s - loss: 0.5546 - acc: 0.715 - ETA: 5s - loss: 0.5569 - acc: 0.713 - ETA: 5s - loss: 0.5572 - acc: 0.712 - ETA: 5s - loss: 0.5577 - acc: 0.712 - ETA: 5s - loss: 0.5592 - acc: 0.710 - ETA: 5s - loss: 0.5579 - acc: 0.711 - ETA: 5s - loss: 0.5568 - acc: 0.713 - ETA: 5s - loss: 0.5578 - acc: 0.712 - ETA: 5s - loss: 0.5565 - acc: 0.713 - ETA: 4s - loss: 0.5555 - acc: 0.715 - ETA: 4s - loss: 0.5561 - acc: 0.713 - ETA: 4s - loss: 0.5572 - acc: 0.712 - ETA: 4s - loss: 0.5564 - acc: 0.713 - ETA: 4s - loss: 0.5562 - acc: 0.713 - ETA: 4s - loss: 0.5563 - acc: 0.713 - ETA: 4s - loss: 0.5572 - acc: 0.712 - ETA: 4s - loss: 0.5579 - acc: 0.711 - ETA: 4s - loss: 0.5566 - acc: 0.712 - ETA: 4s - loss: 0.5561 - acc: 0.712 - ETA: 3s - loss: 0.5574 - acc: 0.712 - ETA: 3s - loss: 0.5573 - acc: 0.712 - ETA: 3s - loss: 0.5571 - acc: 0.712 - ETA: 3s - loss: 0.5572 - acc: 0.713 - ETA: 3s - loss: 0.5581 - acc: 0.712 - ETA: 3s - loss: 0.5576 - acc: 0.713 - ETA: 3s - loss: 0.5569 - acc: 0.713 - ETA: 3s - loss: 0.5562 - acc: 0.714 - ETA: 3s - loss: 0.5567 - acc: 0.713 - ETA: 3s - loss: 0.5575 - acc: 0.711 - ETA: 2s - loss: 0.5574 - acc: 0.711 - ETA: 2s - loss: 0.5576 - acc: 0.711 - ETA: 2s - loss: 0.5575 - acc: 0.710 - ETA: 2s - loss: 0.5574 - acc: 0.710 - ETA: 2s - loss: 0.5568 - acc: 0.710 - ETA: 2s - loss: 0.5559 - acc: 0.711 - ETA: 2s - loss: 0.5568 - acc: 0.710 - ETA: 2s - loss: 0.5565 - acc: 0.710 - ETA: 2s - loss: 0.5561 - acc: 0.710 - ETA: 2s - loss: 0.5554 - acc: 0.712 - ETA: 2s - loss: 0.5548 - acc: 0.712 - ETA: 1s - loss: 0.5547 - acc: 0.712 - ETA: 1s - loss: 0.5544 - acc: 0.712 - ETA: 1s - loss: 0.5538 - acc: 0.712 - ETA: 1s - loss: 0.5544 - acc: 0.712 - ETA: 1s - loss: 0.5538 - acc: 0.712 - ETA: 1s - loss: 0.5541 - acc: 0.712 - ETA: 1s - loss: 0.5549 - acc: 0.712 - ETA: 1s - loss: 0.5544 - acc: 0.712 - ETA: 1s - loss: 0.5548 - acc: 0.711 - ETA: 1s - loss: 0.5548 - acc: 0.711 - ETA: 0s - loss: 0.5542 - acc: 0.711 - ETA: 0s - loss: 0.5539 - acc: 0.711 - ETA: 0s - loss: 0.5545 - acc: 0.710 - ETA: 0s - loss: 0.5538 - acc: 0.712 - ETA: 0s - loss: 0.5541 - acc: 0.712 - ETA: 0s - loss: 0.5533 - acc: 0.712 - ETA: 0s - loss: 0.5533 - acc: 0.712 - ETA: 0s - loss: 0.5530 - acc: 0.712 - ETA: 0s - loss: 0.5537 - acc: 0.712 - ETA: 0s - loss: 0.5542 - acc: 0.711 - 14s 109ms/step - loss: 0.5544 - acc: 0.7119 - val_loss: 0.5796 - val_acc: 0.6853\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.5332 - acc: 0.78 - ETA: 10s - loss: 0.5215 - acc: 0.75 - ETA: 10s - loss: 0.5485 - acc: 0.72 - ETA: 10s - loss: 0.5258 - acc: 0.75 - ETA: 11s - loss: 0.5249 - acc: 0.75 - ETA: 11s - loss: 0.5078 - acc: 0.75 - ETA: 11s - loss: 0.5223 - acc: 0.73 - ETA: 11s - loss: 0.5425 - acc: 0.72 - ETA: 10s - loss: 0.5479 - acc: 0.71 - ETA: 11s - loss: 0.5568 - acc: 0.70 - ETA: 10s - loss: 0.5630 - acc: 0.70 - ETA: 10s - loss: 0.5534 - acc: 0.71 - ETA: 10s - loss: 0.5663 - acc: 0.70 - ETA: 10s - loss: 0.5667 - acc: 0.70 - ETA: 10s - loss: 0.5700 - acc: 0.70 - ETA: 10s - loss: 0.5712 - acc: 0.70 - ETA: 10s - loss: 0.5721 - acc: 0.69 - ETA: 10s - loss: 0.5675 - acc: 0.69 - ETA: 10s - loss: 0.5683 - acc: 0.69 - ETA: 10s - loss: 0.5737 - acc: 0.69 - ETA: 9s - loss: 0.5718 - acc: 0.6949 - ETA: 9s - loss: 0.5789 - acc: 0.691 - ETA: 9s - loss: 0.5765 - acc: 0.690 - ETA: 9s - loss: 0.5779 - acc: 0.687 - ETA: 9s - loss: 0.5820 - acc: 0.685 - ETA: 9s - loss: 0.5838 - acc: 0.681 - ETA: 9s - loss: 0.5824 - acc: 0.684 - ETA: 9s - loss: 0.5920 - acc: 0.678 - ETA: 9s - loss: 0.5922 - acc: 0.676 - ETA: 9s - loss: 0.5936 - acc: 0.671 - ETA: 9s - loss: 0.5937 - acc: 0.671 - ETA: 9s - loss: 0.5932 - acc: 0.670 - ETA: 8s - loss: 0.5908 - acc: 0.670 - ETA: 8s - loss: 0.5895 - acc: 0.670 - ETA: 8s - loss: 0.5952 - acc: 0.663 - ETA: 8s - loss: 0.5939 - acc: 0.665 - ETA: 8s - loss: 0.5883 - acc: 0.671 - ETA: 8s - loss: 0.5879 - acc: 0.672 - ETA: 8s - loss: 0.5822 - acc: 0.677 - ETA: 8s - loss: 0.5853 - acc: 0.674 - ETA: 8s - loss: 0.5868 - acc: 0.673 - ETA: 8s - loss: 0.5863 - acc: 0.672 - ETA: 8s - loss: 0.5862 - acc: 0.673 - ETA: 7s - loss: 0.5850 - acc: 0.674 - ETA: 7s - loss: 0.5866 - acc: 0.673 - ETA: 7s - loss: 0.5823 - acc: 0.677 - ETA: 7s - loss: 0.5830 - acc: 0.676 - ETA: 7s - loss: 0.5848 - acc: 0.675 - ETA: 7s - loss: 0.5893 - acc: 0.672 - ETA: 7s - loss: 0.5910 - acc: 0.670 - ETA: 7s - loss: 0.5923 - acc: 0.667 - ETA: 7s - loss: 0.5909 - acc: 0.668 - ETA: 7s - loss: 0.5942 - acc: 0.667 - ETA: 7s - loss: 0.5969 - acc: 0.666 - ETA: 7s - loss: 0.6006 - acc: 0.665 - ETA: 6s - loss: 0.6016 - acc: 0.664 - ETA: 6s - loss: 0.5992 - acc: 0.666 - ETA: 6s - loss: 0.5975 - acc: 0.666 - ETA: 6s - loss: 0.5966 - acc: 0.667 - ETA: 6s - loss: 0.5959 - acc: 0.667 - ETA: 6s - loss: 0.5951 - acc: 0.668 - ETA: 6s - loss: 0.5936 - acc: 0.668 - ETA: 6s - loss: 0.5933 - acc: 0.668 - ETA: 6s - loss: 0.5928 - acc: 0.669 - ETA: 6s - loss: 0.5906 - acc: 0.670 - ETA: 6s - loss: 0.5897 - acc: 0.673 - ETA: 5s - loss: 0.5890 - acc: 0.673 - ETA: 5s - loss: 0.5884 - acc: 0.673 - ETA: 5s - loss: 0.5874 - acc: 0.675 - ETA: 5s - loss: 0.5893 - acc: 0.673 - ETA: 5s - loss: 0.5867 - acc: 0.675 - ETA: 5s - loss: 0.5865 - acc: 0.676 - ETA: 5s - loss: 0.5861 - acc: 0.676 - ETA: 5s - loss: 0.5864 - acc: 0.676 - ETA: 5s - loss: 0.5847 - acc: 0.678 - ETA: 5s - loss: 0.5831 - acc: 0.680 - ETA: 4s - loss: 0.5838 - acc: 0.679 - ETA: 4s - loss: 0.5830 - acc: 0.680 - ETA: 4s - loss: 0.5817 - acc: 0.682 - ETA: 4s - loss: 0.5820 - acc: 0.681 - ETA: 4s - loss: 0.5817 - acc: 0.681 - ETA: 4s - loss: 0.5813 - acc: 0.682 - ETA: 4s - loss: 0.5802 - acc: 0.683 - ETA: 4s - loss: 0.5789 - acc: 0.684 - ETA: 4s - loss: 0.5780 - acc: 0.685 - ETA: 4s - loss: 0.5767 - acc: 0.686 - ETA: 4s - loss: 0.5763 - acc: 0.686 - ETA: 3s - loss: 0.5771 - acc: 0.685 - ETA: 3s - loss: 0.5770 - acc: 0.685 - ETA: 3s - loss: 0.5763 - acc: 0.685 - ETA: 3s - loss: 0.5769 - acc: 0.684 - ETA: 3s - loss: 0.5778 - acc: 0.684 - ETA: 3s - loss: 0.5780 - acc: 0.684 - ETA: 3s - loss: 0.5780 - acc: 0.685 - ETA: 3s - loss: 0.5761 - acc: 0.687 - ETA: 3s - loss: 0.5742 - acc: 0.690 - ETA: 3s - loss: 0.5748 - acc: 0.690 - ETA: 2s - loss: 0.5739 - acc: 0.691 - ETA: 2s - loss: 0.5725 - acc: 0.691 - ETA: 2s - loss: 0.5728 - acc: 0.691 - ETA: 2s - loss: 0.5724 - acc: 0.691 - ETA: 2s - loss: 0.5724 - acc: 0.691 - ETA: 2s - loss: 0.5733 - acc: 0.690 - ETA: 2s - loss: 0.5734 - acc: 0.690 - ETA: 2s - loss: 0.5736 - acc: 0.691 - ETA: 2s - loss: 0.5728 - acc: 0.692 - ETA: 2s - loss: 0.5739 - acc: 0.691 - ETA: 1s - loss: 0.5739 - acc: 0.691 - ETA: 1s - loss: 0.5746 - acc: 0.690 - ETA: 1s - loss: 0.5749 - acc: 0.690 - ETA: 1s - loss: 0.5756 - acc: 0.690 - ETA: 1s - loss: 0.5762 - acc: 0.689 - ETA: 1s - loss: 0.5763 - acc: 0.689 - ETA: 1s - loss: 0.5775 - acc: 0.689 - ETA: 1s - loss: 0.5766 - acc: 0.689 - ETA: 1s - loss: 0.5761 - acc: 0.689 - ETA: 1s - loss: 0.5756 - acc: 0.690 - ETA: 0s - loss: 0.5748 - acc: 0.690 - ETA: 0s - loss: 0.5754 - acc: 0.690 - ETA: 0s - loss: 0.5752 - acc: 0.690 - ETA: 0s - loss: 0.5747 - acc: 0.690 - ETA: 0s - loss: 0.5736 - acc: 0.691 - ETA: 0s - loss: 0.5736 - acc: 0.691 - ETA: 0s - loss: 0.5726 - acc: 0.692 - ETA: 0s - loss: 0.5723 - acc: 0.693 - ETA: 0s - loss: 0.5721 - acc: 0.693 - ETA: 0s - loss: 0.5713 - acc: 0.693 - 14s 109ms/step - loss: 0.5711 - acc: 0.6941 - val_loss: 0.5336 - val_acc: 0.7236\n",
      "Epoch 10/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 10s - loss: 0.5187 - acc: 0.71 - ETA: 12s - loss: 0.5388 - acc: 0.73 - ETA: 13s - loss: 0.5185 - acc: 0.72 - ETA: 12s - loss: 0.5368 - acc: 0.71 - ETA: 12s - loss: 0.5343 - acc: 0.73 - ETA: 12s - loss: 0.5393 - acc: 0.72 - ETA: 11s - loss: 0.5504 - acc: 0.72 - ETA: 12s - loss: 0.5542 - acc: 0.71 - ETA: 12s - loss: 0.5718 - acc: 0.70 - ETA: 11s - loss: 0.5852 - acc: 0.70 - ETA: 11s - loss: 0.5815 - acc: 0.71 - ETA: 11s - loss: 0.5773 - acc: 0.71 - ETA: 11s - loss: 0.5799 - acc: 0.70 - ETA: 11s - loss: 0.5915 - acc: 0.69 - ETA: 11s - loss: 0.5845 - acc: 0.70 - ETA: 11s - loss: 0.5758 - acc: 0.70 - ETA: 11s - loss: 0.5693 - acc: 0.71 - ETA: 11s - loss: 0.5653 - acc: 0.71 - ETA: 10s - loss: 0.5718 - acc: 0.71 - ETA: 10s - loss: 0.5720 - acc: 0.71 - ETA: 10s - loss: 0.5704 - acc: 0.71 - ETA: 10s - loss: 0.5701 - acc: 0.71 - ETA: 10s - loss: 0.5671 - acc: 0.71 - ETA: 10s - loss: 0.5654 - acc: 0.71 - ETA: 10s - loss: 0.5624 - acc: 0.72 - ETA: 10s - loss: 0.5618 - acc: 0.71 - ETA: 10s - loss: 0.5607 - acc: 0.71 - ETA: 10s - loss: 0.5573 - acc: 0.71 - ETA: 9s - loss: 0.5589 - acc: 0.7123 - ETA: 9s - loss: 0.5567 - acc: 0.715 - ETA: 9s - loss: 0.5606 - acc: 0.711 - ETA: 9s - loss: 0.5620 - acc: 0.710 - ETA: 9s - loss: 0.5620 - acc: 0.710 - ETA: 9s - loss: 0.5571 - acc: 0.714 - ETA: 9s - loss: 0.5580 - acc: 0.714 - ETA: 9s - loss: 0.5567 - acc: 0.715 - ETA: 9s - loss: 0.5520 - acc: 0.718 - ETA: 9s - loss: 0.5509 - acc: 0.719 - ETA: 9s - loss: 0.5507 - acc: 0.721 - ETA: 8s - loss: 0.5494 - acc: 0.723 - ETA: 8s - loss: 0.5497 - acc: 0.721 - ETA: 8s - loss: 0.5481 - acc: 0.724 - ETA: 8s - loss: 0.5458 - acc: 0.724 - ETA: 8s - loss: 0.5482 - acc: 0.721 - ETA: 8s - loss: 0.5502 - acc: 0.718 - ETA: 8s - loss: 0.5534 - acc: 0.716 - ETA: 8s - loss: 0.5553 - acc: 0.713 - ETA: 7s - loss: 0.5544 - acc: 0.714 - ETA: 7s - loss: 0.5534 - acc: 0.715 - ETA: 7s - loss: 0.5552 - acc: 0.713 - ETA: 7s - loss: 0.5563 - acc: 0.714 - ETA: 7s - loss: 0.5537 - acc: 0.716 - ETA: 7s - loss: 0.5541 - acc: 0.715 - ETA: 7s - loss: 0.5549 - acc: 0.714 - ETA: 7s - loss: 0.5542 - acc: 0.713 - ETA: 7s - loss: 0.5524 - acc: 0.714 - ETA: 7s - loss: 0.5525 - acc: 0.715 - ETA: 6s - loss: 0.5522 - acc: 0.713 - ETA: 6s - loss: 0.5510 - acc: 0.714 - ETA: 6s - loss: 0.5488 - acc: 0.716 - ETA: 6s - loss: 0.5497 - acc: 0.716 - ETA: 6s - loss: 0.5503 - acc: 0.716 - ETA: 6s - loss: 0.5481 - acc: 0.718 - ETA: 6s - loss: 0.5491 - acc: 0.717 - ETA: 6s - loss: 0.5483 - acc: 0.717 - ETA: 6s - loss: 0.5483 - acc: 0.718 - ETA: 5s - loss: 0.5474 - acc: 0.717 - ETA: 5s - loss: 0.5482 - acc: 0.716 - ETA: 5s - loss: 0.5468 - acc: 0.718 - ETA: 5s - loss: 0.5487 - acc: 0.717 - ETA: 5s - loss: 0.5460 - acc: 0.719 - ETA: 5s - loss: 0.5443 - acc: 0.720 - ETA: 5s - loss: 0.5433 - acc: 0.721 - ETA: 5s - loss: 0.5424 - acc: 0.721 - ETA: 5s - loss: 0.5435 - acc: 0.721 - ETA: 5s - loss: 0.5431 - acc: 0.720 - ETA: 4s - loss: 0.5426 - acc: 0.720 - ETA: 4s - loss: 0.5412 - acc: 0.720 - ETA: 4s - loss: 0.5404 - acc: 0.721 - ETA: 4s - loss: 0.5409 - acc: 0.721 - ETA: 4s - loss: 0.5417 - acc: 0.721 - ETA: 4s - loss: 0.5403 - acc: 0.722 - ETA: 4s - loss: 0.5398 - acc: 0.722 - ETA: 4s - loss: 0.5390 - acc: 0.724 - ETA: 4s - loss: 0.5381 - acc: 0.725 - ETA: 4s - loss: 0.5398 - acc: 0.723 - ETA: 3s - loss: 0.5396 - acc: 0.722 - ETA: 3s - loss: 0.5401 - acc: 0.721 - ETA: 3s - loss: 0.5404 - acc: 0.720 - ETA: 3s - loss: 0.5408 - acc: 0.720 - ETA: 3s - loss: 0.5408 - acc: 0.720 - ETA: 3s - loss: 0.5403 - acc: 0.721 - ETA: 3s - loss: 0.5397 - acc: 0.721 - ETA: 3s - loss: 0.5402 - acc: 0.721 - ETA: 3s - loss: 0.5408 - acc: 0.720 - ETA: 3s - loss: 0.5421 - acc: 0.719 - ETA: 2s - loss: 0.5424 - acc: 0.719 - ETA: 2s - loss: 0.5424 - acc: 0.718 - ETA: 2s - loss: 0.5427 - acc: 0.718 - ETA: 2s - loss: 0.5437 - acc: 0.718 - ETA: 2s - loss: 0.5432 - acc: 0.718 - ETA: 2s - loss: 0.5431 - acc: 0.719 - ETA: 2s - loss: 0.5444 - acc: 0.718 - ETA: 2s - loss: 0.5453 - acc: 0.717 - ETA: 2s - loss: 0.5450 - acc: 0.718 - ETA: 2s - loss: 0.5449 - acc: 0.719 - ETA: 2s - loss: 0.5464 - acc: 0.717 - ETA: 1s - loss: 0.5467 - acc: 0.717 - ETA: 1s - loss: 0.5447 - acc: 0.719 - ETA: 1s - loss: 0.5444 - acc: 0.720 - ETA: 1s - loss: 0.5451 - acc: 0.719 - ETA: 1s - loss: 0.5442 - acc: 0.720 - ETA: 1s - loss: 0.5436 - acc: 0.720 - ETA: 1s - loss: 0.5432 - acc: 0.720 - ETA: 1s - loss: 0.5436 - acc: 0.720 - ETA: 1s - loss: 0.5422 - acc: 0.722 - ETA: 1s - loss: 0.5423 - acc: 0.722 - ETA: 0s - loss: 0.5426 - acc: 0.721 - ETA: 0s - loss: 0.5417 - acc: 0.721 - ETA: 0s - loss: 0.5408 - acc: 0.722 - ETA: 0s - loss: 0.5413 - acc: 0.721 - ETA: 0s - loss: 0.5425 - acc: 0.720 - ETA: 0s - loss: 0.5437 - acc: 0.719 - ETA: 0s - loss: 0.5426 - acc: 0.720 - ETA: 0s - loss: 0.5439 - acc: 0.719 - ETA: 0s - loss: 0.5432 - acc: 0.719 - ETA: 0s - loss: 0.5423 - acc: 0.720 - 14s 110ms/step - loss: 0.5438 - acc: 0.7192 - val_loss: 0.5280 - val_acc: 0.7280\n",
      "Epoch 11/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 10s - loss: 0.5269 - acc: 0.68 - ETA: 10s - loss: 0.4903 - acc: 0.73 - ETA: 11s - loss: 0.4774 - acc: 0.72 - ETA: 11s - loss: 0.4870 - acc: 0.73 - ETA: 11s - loss: 0.4820 - acc: 0.73 - ETA: 11s - loss: 0.4721 - acc: 0.75 - ETA: 11s - loss: 0.4655 - acc: 0.75 - ETA: 11s - loss: 0.4731 - acc: 0.75 - ETA: 11s - loss: 0.4880 - acc: 0.73 - ETA: 11s - loss: 0.4943 - acc: 0.73 - ETA: 11s - loss: 0.5064 - acc: 0.73 - ETA: 11s - loss: 0.5076 - acc: 0.73 - ETA: 11s - loss: 0.5046 - acc: 0.73 - ETA: 11s - loss: 0.5171 - acc: 0.72 - ETA: 11s - loss: 0.5103 - acc: 0.73 - ETA: 11s - loss: 0.5070 - acc: 0.73 - ETA: 10s - loss: 0.5112 - acc: 0.73 - ETA: 10s - loss: 0.5083 - acc: 0.73 - ETA: 10s - loss: 0.5113 - acc: 0.73 - ETA: 10s - loss: 0.5130 - acc: 0.73 - ETA: 10s - loss: 0.5117 - acc: 0.74 - ETA: 10s - loss: 0.5086 - acc: 0.74 - ETA: 10s - loss: 0.5079 - acc: 0.74 - ETA: 10s - loss: 0.5089 - acc: 0.74 - ETA: 10s - loss: 0.5111 - acc: 0.74 - ETA: 10s - loss: 0.5094 - acc: 0.74 - ETA: 10s - loss: 0.5067 - acc: 0.74 - ETA: 10s - loss: 0.5046 - acc: 0.74 - ETA: 10s - loss: 0.5037 - acc: 0.74 - ETA: 9s - loss: 0.5054 - acc: 0.7479 - ETA: 9s - loss: 0.5091 - acc: 0.745 - ETA: 9s - loss: 0.5090 - acc: 0.744 - ETA: 9s - loss: 0.5071 - acc: 0.743 - ETA: 9s - loss: 0.5070 - acc: 0.744 - ETA: 9s - loss: 0.5055 - acc: 0.747 - ETA: 9s - loss: 0.5058 - acc: 0.747 - ETA: 9s - loss: 0.5062 - acc: 0.744 - ETA: 9s - loss: 0.5058 - acc: 0.745 - ETA: 8s - loss: 0.5054 - acc: 0.746 - ETA: 8s - loss: 0.5080 - acc: 0.746 - ETA: 8s - loss: 0.5100 - acc: 0.743 - ETA: 8s - loss: 0.5108 - acc: 0.741 - ETA: 8s - loss: 0.5070 - acc: 0.744 - ETA: 8s - loss: 0.5088 - acc: 0.743 - ETA: 8s - loss: 0.5094 - acc: 0.743 - ETA: 8s - loss: 0.5090 - acc: 0.743 - ETA: 8s - loss: 0.5086 - acc: 0.743 - ETA: 8s - loss: 0.5063 - acc: 0.744 - ETA: 7s - loss: 0.5076 - acc: 0.743 - ETA: 7s - loss: 0.5072 - acc: 0.743 - ETA: 7s - loss: 0.5088 - acc: 0.743 - ETA: 7s - loss: 0.5111 - acc: 0.742 - ETA: 7s - loss: 0.5119 - acc: 0.740 - ETA: 7s - loss: 0.5128 - acc: 0.739 - ETA: 7s - loss: 0.5126 - acc: 0.738 - ETA: 7s - loss: 0.5111 - acc: 0.739 - ETA: 7s - loss: 0.5111 - acc: 0.741 - ETA: 7s - loss: 0.5109 - acc: 0.740 - ETA: 6s - loss: 0.5118 - acc: 0.741 - ETA: 6s - loss: 0.5111 - acc: 0.742 - ETA: 6s - loss: 0.5111 - acc: 0.742 - ETA: 6s - loss: 0.5113 - acc: 0.741 - ETA: 6s - loss: 0.5122 - acc: 0.739 - ETA: 6s - loss: 0.5112 - acc: 0.742 - ETA: 6s - loss: 0.5098 - acc: 0.742 - ETA: 6s - loss: 0.5102 - acc: 0.742 - ETA: 6s - loss: 0.5096 - acc: 0.742 - ETA: 6s - loss: 0.5097 - acc: 0.742 - ETA: 5s - loss: 0.5088 - acc: 0.741 - ETA: 5s - loss: 0.5100 - acc: 0.740 - ETA: 5s - loss: 0.5109 - acc: 0.739 - ETA: 5s - loss: 0.5104 - acc: 0.740 - ETA: 5s - loss: 0.5098 - acc: 0.740 - ETA: 5s - loss: 0.5104 - acc: 0.740 - ETA: 5s - loss: 0.5097 - acc: 0.740 - ETA: 5s - loss: 0.5086 - acc: 0.741 - ETA: 5s - loss: 0.5090 - acc: 0.741 - ETA: 4s - loss: 0.5099 - acc: 0.740 - ETA: 4s - loss: 0.5095 - acc: 0.741 - ETA: 4s - loss: 0.5086 - acc: 0.742 - ETA: 4s - loss: 0.5088 - acc: 0.741 - ETA: 4s - loss: 0.5091 - acc: 0.740 - ETA: 4s - loss: 0.5093 - acc: 0.740 - ETA: 4s - loss: 0.5100 - acc: 0.740 - ETA: 4s - loss: 0.5110 - acc: 0.739 - ETA: 4s - loss: 0.5115 - acc: 0.739 - ETA: 4s - loss: 0.5113 - acc: 0.739 - ETA: 3s - loss: 0.5111 - acc: 0.737 - ETA: 3s - loss: 0.5107 - acc: 0.739 - ETA: 3s - loss: 0.5111 - acc: 0.738 - ETA: 3s - loss: 0.5112 - acc: 0.738 - ETA: 3s - loss: 0.5115 - acc: 0.738 - ETA: 3s - loss: 0.5124 - acc: 0.737 - ETA: 3s - loss: 0.5140 - acc: 0.736 - ETA: 3s - loss: 0.5146 - acc: 0.735 - ETA: 3s - loss: 0.5152 - acc: 0.735 - ETA: 3s - loss: 0.5153 - acc: 0.735 - ETA: 2s - loss: 0.5153 - acc: 0.735 - ETA: 2s - loss: 0.5148 - acc: 0.736 - ETA: 2s - loss: 0.5143 - acc: 0.737 - ETA: 2s - loss: 0.5139 - acc: 0.737 - ETA: 2s - loss: 0.5153 - acc: 0.735 - ETA: 2s - loss: 0.5135 - acc: 0.736 - ETA: 2s - loss: 0.5122 - acc: 0.737 - ETA: 2s - loss: 0.5125 - acc: 0.736 - ETA: 2s - loss: 0.5131 - acc: 0.736 - ETA: 2s - loss: 0.5126 - acc: 0.736 - ETA: 1s - loss: 0.5120 - acc: 0.736 - ETA: 1s - loss: 0.5126 - acc: 0.736 - ETA: 1s - loss: 0.5122 - acc: 0.737 - ETA: 1s - loss: 0.5124 - acc: 0.737 - ETA: 1s - loss: 0.5129 - acc: 0.737 - ETA: 1s - loss: 0.5132 - acc: 0.737 - ETA: 1s - loss: 0.5133 - acc: 0.737 - ETA: 1s - loss: 0.5130 - acc: 0.738 - ETA: 1s - loss: 0.5136 - acc: 0.738 - ETA: 1s - loss: 0.5137 - acc: 0.736 - ETA: 0s - loss: 0.5146 - acc: 0.736 - ETA: 0s - loss: 0.5146 - acc: 0.735 - ETA: 0s - loss: 0.5153 - acc: 0.734 - ETA: 0s - loss: 0.5155 - acc: 0.734 - ETA: 0s - loss: 0.5155 - acc: 0.734 - ETA: 0s - loss: 0.5158 - acc: 0.734 - ETA: 0s - loss: 0.5157 - acc: 0.733 - ETA: 0s - loss: 0.5154 - acc: 0.734 - ETA: 0s - loss: 0.5153 - acc: 0.734 - ETA: 0s - loss: 0.5156 - acc: 0.734 - 15s 113ms/step - loss: 0.5158 - acc: 0.7346 - val_loss: 0.4960 - val_acc: 0.7520\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.3624 - acc: 0.81 - ETA: 11s - loss: 0.5475 - acc: 0.67 - ETA: 11s - loss: 0.5345 - acc: 0.70 - ETA: 12s - loss: 0.5503 - acc: 0.71 - ETA: 12s - loss: 0.5885 - acc: 0.70 - ETA: 12s - loss: 0.5653 - acc: 0.71 - ETA: 11s - loss: 0.5685 - acc: 0.70 - ETA: 11s - loss: 0.5721 - acc: 0.69 - ETA: 11s - loss: 0.5711 - acc: 0.70 - ETA: 11s - loss: 0.5658 - acc: 0.70 - ETA: 11s - loss: 0.5644 - acc: 0.70 - ETA: 11s - loss: 0.5582 - acc: 0.70 - ETA: 11s - loss: 0.5514 - acc: 0.70 - ETA: 11s - loss: 0.5605 - acc: 0.69 - ETA: 11s - loss: 0.5600 - acc: 0.69 - ETA: 11s - loss: 0.5578 - acc: 0.70 - ETA: 10s - loss: 0.5531 - acc: 0.70 - ETA: 10s - loss: 0.5461 - acc: 0.70 - ETA: 10s - loss: 0.5352 - acc: 0.71 - ETA: 10s - loss: 0.5367 - acc: 0.71 - ETA: 10s - loss: 0.5321 - acc: 0.72 - ETA: 10s - loss: 0.5316 - acc: 0.72 - ETA: 10s - loss: 0.5312 - acc: 0.72 - ETA: 10s - loss: 0.5376 - acc: 0.71 - ETA: 10s - loss: 0.5331 - acc: 0.71 - ETA: 9s - loss: 0.5341 - acc: 0.7200 - ETA: 9s - loss: 0.5289 - acc: 0.722 - ETA: 9s - loss: 0.5263 - acc: 0.722 - ETA: 9s - loss: 0.5231 - acc: 0.725 - ETA: 9s - loss: 0.5276 - acc: 0.721 - ETA: 9s - loss: 0.5253 - acc: 0.724 - ETA: 9s - loss: 0.5217 - acc: 0.729 - ETA: 9s - loss: 0.5191 - acc: 0.732 - ETA: 9s - loss: 0.5207 - acc: 0.730 - ETA: 9s - loss: 0.5210 - acc: 0.730 - ETA: 9s - loss: 0.5252 - acc: 0.725 - ETA: 8s - loss: 0.5277 - acc: 0.722 - ETA: 8s - loss: 0.5270 - acc: 0.722 - ETA: 8s - loss: 0.5278 - acc: 0.723 - ETA: 8s - loss: 0.5280 - acc: 0.721 - ETA: 8s - loss: 0.5300 - acc: 0.720 - ETA: 8s - loss: 0.5304 - acc: 0.719 - ETA: 8s - loss: 0.5319 - acc: 0.718 - ETA: 8s - loss: 0.5355 - acc: 0.715 - ETA: 8s - loss: 0.5347 - acc: 0.716 - ETA: 8s - loss: 0.5371 - acc: 0.714 - ETA: 8s - loss: 0.5400 - acc: 0.713 - ETA: 7s - loss: 0.5380 - acc: 0.714 - ETA: 7s - loss: 0.5368 - acc: 0.717 - ETA: 7s - loss: 0.5378 - acc: 0.716 - ETA: 7s - loss: 0.5358 - acc: 0.716 - ETA: 7s - loss: 0.5344 - acc: 0.719 - ETA: 7s - loss: 0.5344 - acc: 0.718 - ETA: 7s - loss: 0.5335 - acc: 0.719 - ETA: 7s - loss: 0.5310 - acc: 0.722 - ETA: 7s - loss: 0.5308 - acc: 0.723 - ETA: 7s - loss: 0.5314 - acc: 0.722 - ETA: 6s - loss: 0.5329 - acc: 0.722 - ETA: 6s - loss: 0.5299 - acc: 0.724 - ETA: 6s - loss: 0.5291 - acc: 0.723 - ETA: 6s - loss: 0.5280 - acc: 0.724 - ETA: 6s - loss: 0.5285 - acc: 0.724 - ETA: 6s - loss: 0.5282 - acc: 0.724 - ETA: 6s - loss: 0.5278 - acc: 0.724 - ETA: 6s - loss: 0.5258 - acc: 0.726 - ETA: 6s - loss: 0.5284 - acc: 0.724 - ETA: 6s - loss: 0.5280 - acc: 0.724 - ETA: 5s - loss: 0.5304 - acc: 0.722 - ETA: 5s - loss: 0.5290 - acc: 0.724 - ETA: 5s - loss: 0.5293 - acc: 0.724 - ETA: 5s - loss: 0.5286 - acc: 0.724 - ETA: 5s - loss: 0.5285 - acc: 0.725 - ETA: 5s - loss: 0.5274 - acc: 0.727 - ETA: 5s - loss: 0.5269 - acc: 0.725 - ETA: 5s - loss: 0.5255 - acc: 0.726 - ETA: 5s - loss: 0.5241 - acc: 0.727 - ETA: 5s - loss: 0.5237 - acc: 0.728 - ETA: 4s - loss: 0.5243 - acc: 0.728 - ETA: 4s - loss: 0.5240 - acc: 0.728 - ETA: 4s - loss: 0.5247 - acc: 0.727 - ETA: 4s - loss: 0.5258 - acc: 0.726 - ETA: 4s - loss: 0.5246 - acc: 0.728 - ETA: 4s - loss: 0.5237 - acc: 0.728 - ETA: 4s - loss: 0.5224 - acc: 0.728 - ETA: 4s - loss: 0.5239 - acc: 0.727 - ETA: 4s - loss: 0.5238 - acc: 0.727 - ETA: 4s - loss: 0.5238 - acc: 0.728 - ETA: 3s - loss: 0.5230 - acc: 0.729 - ETA: 3s - loss: 0.5224 - acc: 0.729 - ETA: 3s - loss: 0.5212 - acc: 0.730 - ETA: 3s - loss: 0.5200 - acc: 0.730 - ETA: 3s - loss: 0.5195 - acc: 0.730 - ETA: 3s - loss: 0.5196 - acc: 0.730 - ETA: 3s - loss: 0.5185 - acc: 0.732 - ETA: 3s - loss: 0.5181 - acc: 0.732 - ETA: 3s - loss: 0.5175 - acc: 0.733 - ETA: 3s - loss: 0.5177 - acc: 0.732 - ETA: 2s - loss: 0.5165 - acc: 0.734 - ETA: 2s - loss: 0.5160 - acc: 0.734 - ETA: 2s - loss: 0.5154 - acc: 0.734 - ETA: 2s - loss: 0.5147 - acc: 0.735 - ETA: 2s - loss: 0.5152 - acc: 0.734 - ETA: 2s - loss: 0.5148 - acc: 0.734 - ETA: 2s - loss: 0.5159 - acc: 0.733 - ETA: 2s - loss: 0.5170 - acc: 0.732 - ETA: 2s - loss: 0.5172 - acc: 0.732 - ETA: 2s - loss: 0.5164 - acc: 0.733 - ETA: 1s - loss: 0.5150 - acc: 0.734 - ETA: 1s - loss: 0.5164 - acc: 0.734 - ETA: 1s - loss: 0.5155 - acc: 0.734 - ETA: 1s - loss: 0.5166 - acc: 0.734 - ETA: 1s - loss: 0.5164 - acc: 0.735 - ETA: 1s - loss: 0.5169 - acc: 0.735 - ETA: 1s - loss: 0.5173 - acc: 0.735 - ETA: 1s - loss: 0.5179 - acc: 0.734 - ETA: 1s - loss: 0.5181 - acc: 0.733 - ETA: 1s - loss: 0.5189 - acc: 0.733 - ETA: 0s - loss: 0.5207 - acc: 0.732 - ETA: 0s - loss: 0.5213 - acc: 0.732 - ETA: 0s - loss: 0.5228 - acc: 0.732 - ETA: 0s - loss: 0.5221 - acc: 0.733 - ETA: 0s - loss: 0.5218 - acc: 0.734 - ETA: 0s - loss: 0.5220 - acc: 0.733 - ETA: 0s - loss: 0.5218 - acc: 0.734 - ETA: 0s - loss: 0.5203 - acc: 0.735 - ETA: 0s - loss: 0.5208 - acc: 0.734 - ETA: 0s - loss: 0.5196 - acc: 0.735 - 14s 112ms/step - loss: 0.5207 - acc: 0.7344 - val_loss: 0.5048 - val_acc: 0.7444\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.5159 - acc: 0.68 - ETA: 13s - loss: 0.4849 - acc: 0.75 - ETA: 14s - loss: 0.5094 - acc: 0.73 - ETA: 13s - loss: 0.5420 - acc: 0.69 - ETA: 13s - loss: 0.5554 - acc: 0.69 - ETA: 13s - loss: 0.5737 - acc: 0.66 - ETA: 13s - loss: 0.5760 - acc: 0.66 - ETA: 13s - loss: 0.5833 - acc: 0.64 - ETA: 13s - loss: 0.5712 - acc: 0.66 - ETA: 13s - loss: 0.5670 - acc: 0.66 - ETA: 12s - loss: 0.5681 - acc: 0.67 - ETA: 12s - loss: 0.5590 - acc: 0.68 - ETA: 12s - loss: 0.5491 - acc: 0.69 - ETA: 12s - loss: 0.5451 - acc: 0.70 - ETA: 12s - loss: 0.5407 - acc: 0.70 - ETA: 12s - loss: 0.5401 - acc: 0.70 - ETA: 11s - loss: 0.5367 - acc: 0.71 - ETA: 11s - loss: 0.5401 - acc: 0.70 - ETA: 11s - loss: 0.5394 - acc: 0.70 - ETA: 11s - loss: 0.5394 - acc: 0.70 - ETA: 11s - loss: 0.5369 - acc: 0.71 - ETA: 11s - loss: 0.5397 - acc: 0.71 - ETA: 11s - loss: 0.5378 - acc: 0.70 - ETA: 11s - loss: 0.5419 - acc: 0.70 - ETA: 11s - loss: 0.5449 - acc: 0.70 - ETA: 11s - loss: 0.5407 - acc: 0.70 - ETA: 11s - loss: 0.5338 - acc: 0.71 - ETA: 10s - loss: 0.5383 - acc: 0.70 - ETA: 10s - loss: 0.5403 - acc: 0.70 - ETA: 10s - loss: 0.5422 - acc: 0.70 - ETA: 10s - loss: 0.5374 - acc: 0.71 - ETA: 10s - loss: 0.5319 - acc: 0.71 - ETA: 10s - loss: 0.5323 - acc: 0.71 - ETA: 10s - loss: 0.5313 - acc: 0.71 - ETA: 10s - loss: 0.5335 - acc: 0.71 - ETA: 9s - loss: 0.5320 - acc: 0.7170 - ETA: 9s - loss: 0.5327 - acc: 0.716 - ETA: 9s - loss: 0.5344 - acc: 0.714 - ETA: 9s - loss: 0.5333 - acc: 0.716 - ETA: 9s - loss: 0.5314 - acc: 0.718 - ETA: 9s - loss: 0.5328 - acc: 0.718 - ETA: 9s - loss: 0.5312 - acc: 0.718 - ETA: 9s - loss: 0.5342 - acc: 0.717 - ETA: 9s - loss: 0.5345 - acc: 0.717 - ETA: 9s - loss: 0.5322 - acc: 0.720 - ETA: 9s - loss: 0.5329 - acc: 0.718 - ETA: 8s - loss: 0.5310 - acc: 0.720 - ETA: 8s - loss: 0.5326 - acc: 0.720 - ETA: 8s - loss: 0.5332 - acc: 0.719 - ETA: 8s - loss: 0.5317 - acc: 0.720 - ETA: 8s - loss: 0.5310 - acc: 0.721 - ETA: 8s - loss: 0.5307 - acc: 0.723 - ETA: 8s - loss: 0.5300 - acc: 0.722 - ETA: 8s - loss: 0.5295 - acc: 0.722 - ETA: 8s - loss: 0.5303 - acc: 0.723 - ETA: 7s - loss: 0.5296 - acc: 0.724 - ETA: 7s - loss: 0.5303 - acc: 0.724 - ETA: 7s - loss: 0.5301 - acc: 0.725 - ETA: 7s - loss: 0.5286 - acc: 0.726 - ETA: 7s - loss: 0.5277 - acc: 0.728 - ETA: 7s - loss: 0.5280 - acc: 0.729 - ETA: 7s - loss: 0.5297 - acc: 0.727 - ETA: 7s - loss: 0.5301 - acc: 0.726 - ETA: 6s - loss: 0.5305 - acc: 0.726 - ETA: 6s - loss: 0.5300 - acc: 0.726 - ETA: 6s - loss: 0.5295 - acc: 0.727 - ETA: 6s - loss: 0.5287 - acc: 0.728 - ETA: 6s - loss: 0.5279 - acc: 0.730 - ETA: 6s - loss: 0.5282 - acc: 0.730 - ETA: 6s - loss: 0.5274 - acc: 0.731 - ETA: 6s - loss: 0.5278 - acc: 0.730 - ETA: 6s - loss: 0.5257 - acc: 0.731 - ETA: 5s - loss: 0.5278 - acc: 0.729 - ETA: 5s - loss: 0.5291 - acc: 0.730 - ETA: 5s - loss: 0.5304 - acc: 0.729 - ETA: 5s - loss: 0.5296 - acc: 0.731 - ETA: 5s - loss: 0.5304 - acc: 0.730 - ETA: 5s - loss: 0.5296 - acc: 0.730 - ETA: 5s - loss: 0.5293 - acc: 0.731 - ETA: 5s - loss: 0.5285 - acc: 0.732 - ETA: 4s - loss: 0.5276 - acc: 0.732 - ETA: 4s - loss: 0.5276 - acc: 0.732 - ETA: 4s - loss: 0.5281 - acc: 0.733 - ETA: 4s - loss: 0.5271 - acc: 0.732 - ETA: 4s - loss: 0.5280 - acc: 0.731 - ETA: 4s - loss: 0.5296 - acc: 0.730 - ETA: 4s - loss: 0.5293 - acc: 0.731 - ETA: 4s - loss: 0.5290 - acc: 0.731 - ETA: 4s - loss: 0.5285 - acc: 0.731 - ETA: 3s - loss: 0.5274 - acc: 0.733 - ETA: 3s - loss: 0.5265 - acc: 0.733 - ETA: 3s - loss: 0.5273 - acc: 0.732 - ETA: 3s - loss: 0.5274 - acc: 0.732 - ETA: 3s - loss: 0.5258 - acc: 0.733 - ETA: 3s - loss: 0.5270 - acc: 0.731 - ETA: 3s - loss: 0.5258 - acc: 0.732 - ETA: 3s - loss: 0.5245 - acc: 0.732 - ETA: 3s - loss: 0.5241 - acc: 0.732 - ETA: 3s - loss: 0.5243 - acc: 0.732 - ETA: 2s - loss: 0.5242 - acc: 0.732 - ETA: 2s - loss: 0.5238 - acc: 0.733 - ETA: 2s - loss: 0.5239 - acc: 0.733 - ETA: 2s - loss: 0.5236 - acc: 0.734 - ETA: 2s - loss: 0.5222 - acc: 0.734 - ETA: 2s - loss: 0.5221 - acc: 0.734 - ETA: 2s - loss: 0.5215 - acc: 0.735 - ETA: 2s - loss: 0.5216 - acc: 0.734 - ETA: 2s - loss: 0.5211 - acc: 0.735 - ETA: 1s - loss: 0.5207 - acc: 0.736 - ETA: 1s - loss: 0.5206 - acc: 0.736 - ETA: 1s - loss: 0.5220 - acc: 0.735 - ETA: 1s - loss: 0.5216 - acc: 0.736 - ETA: 1s - loss: 0.5211 - acc: 0.736 - ETA: 1s - loss: 0.5226 - acc: 0.735 - ETA: 1s - loss: 0.5224 - acc: 0.735 - ETA: 1s - loss: 0.5218 - acc: 0.736 - ETA: 1s - loss: 0.5225 - acc: 0.735 - ETA: 1s - loss: 0.5229 - acc: 0.734 - ETA: 0s - loss: 0.5230 - acc: 0.734 - ETA: 0s - loss: 0.5223 - acc: 0.734 - ETA: 0s - loss: 0.5217 - acc: 0.735 - ETA: 0s - loss: 0.5216 - acc: 0.734 - ETA: 0s - loss: 0.5218 - acc: 0.734 - ETA: 0s - loss: 0.5232 - acc: 0.733 - ETA: 0s - loss: 0.5234 - acc: 0.733 - ETA: 0s - loss: 0.5230 - acc: 0.732 - ETA: 0s - loss: 0.5226 - acc: 0.733 - 15s 119ms/step - loss: 0.5233 - acc: 0.7327 - val_loss: 0.5271 - val_acc: 0.7253\n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.4994 - acc: 0.81 - ETA: 11s - loss: 0.5513 - acc: 0.73 - ETA: 11s - loss: 0.5801 - acc: 0.70 - ETA: 11s - loss: 0.6059 - acc: 0.67 - ETA: 11s - loss: 0.5655 - acc: 0.71 - ETA: 10s - loss: 0.5467 - acc: 0.73 - ETA: 10s - loss: 0.5469 - acc: 0.74 - ETA: 10s - loss: 0.5358 - acc: 0.75 - ETA: 10s - loss: 0.5296 - acc: 0.75 - ETA: 10s - loss: 0.5258 - acc: 0.75 - ETA: 10s - loss: 0.5225 - acc: 0.75 - ETA: 10s - loss: 0.5251 - acc: 0.74 - ETA: 10s - loss: 0.5238 - acc: 0.74 - ETA: 10s - loss: 0.5295 - acc: 0.74 - ETA: 11s - loss: 0.5292 - acc: 0.74 - ETA: 10s - loss: 0.5384 - acc: 0.73 - ETA: 10s - loss: 0.5288 - acc: 0.74 - ETA: 10s - loss: 0.5244 - acc: 0.75 - ETA: 10s - loss: 0.5237 - acc: 0.75 - ETA: 10s - loss: 0.5232 - acc: 0.75 - ETA: 10s - loss: 0.5243 - acc: 0.75 - ETA: 10s - loss: 0.5226 - acc: 0.75 - ETA: 10s - loss: 0.5250 - acc: 0.75 - ETA: 10s - loss: 0.5215 - acc: 0.75 - ETA: 9s - loss: 0.5214 - acc: 0.7488 - ETA: 9s - loss: 0.5180 - acc: 0.750 - ETA: 9s - loss: 0.5154 - acc: 0.751 - ETA: 9s - loss: 0.5148 - acc: 0.750 - ETA: 9s - loss: 0.5165 - acc: 0.747 - ETA: 9s - loss: 0.5165 - acc: 0.746 - ETA: 9s - loss: 0.5167 - acc: 0.748 - ETA: 9s - loss: 0.5142 - acc: 0.749 - ETA: 9s - loss: 0.5151 - acc: 0.747 - ETA: 8s - loss: 0.5186 - acc: 0.746 - ETA: 8s - loss: 0.5175 - acc: 0.748 - ETA: 8s - loss: 0.5188 - acc: 0.747 - ETA: 8s - loss: 0.5165 - acc: 0.748 - ETA: 8s - loss: 0.5193 - acc: 0.744 - ETA: 8s - loss: 0.5181 - acc: 0.742 - ETA: 8s - loss: 0.5191 - acc: 0.742 - ETA: 8s - loss: 0.5198 - acc: 0.740 - ETA: 8s - loss: 0.5183 - acc: 0.741 - ETA: 8s - loss: 0.5220 - acc: 0.738 - ETA: 7s - loss: 0.5214 - acc: 0.738 - ETA: 7s - loss: 0.5233 - acc: 0.737 - ETA: 7s - loss: 0.5225 - acc: 0.739 - ETA: 7s - loss: 0.5195 - acc: 0.740 - ETA: 7s - loss: 0.5215 - acc: 0.738 - ETA: 7s - loss: 0.5202 - acc: 0.739 - ETA: 7s - loss: 0.5221 - acc: 0.737 - ETA: 7s - loss: 0.5224 - acc: 0.737 - ETA: 7s - loss: 0.5224 - acc: 0.735 - ETA: 7s - loss: 0.5191 - acc: 0.737 - ETA: 7s - loss: 0.5183 - acc: 0.737 - ETA: 6s - loss: 0.5181 - acc: 0.738 - ETA: 6s - loss: 0.5163 - acc: 0.741 - ETA: 6s - loss: 0.5156 - acc: 0.739 - ETA: 6s - loss: 0.5150 - acc: 0.739 - ETA: 6s - loss: 0.5150 - acc: 0.739 - ETA: 6s - loss: 0.5165 - acc: 0.740 - ETA: 6s - loss: 0.5163 - acc: 0.740 - ETA: 6s - loss: 0.5166 - acc: 0.740 - ETA: 6s - loss: 0.5161 - acc: 0.741 - ETA: 6s - loss: 0.5180 - acc: 0.740 - ETA: 6s - loss: 0.5182 - acc: 0.738 - ETA: 5s - loss: 0.5181 - acc: 0.737 - ETA: 5s - loss: 0.5179 - acc: 0.739 - ETA: 5s - loss: 0.5168 - acc: 0.739 - ETA: 5s - loss: 0.5145 - acc: 0.742 - ETA: 5s - loss: 0.5119 - acc: 0.744 - ETA: 5s - loss: 0.5118 - acc: 0.745 - ETA: 5s - loss: 0.5122 - acc: 0.744 - ETA: 5s - loss: 0.5092 - acc: 0.745 - ETA: 5s - loss: 0.5093 - acc: 0.744 - ETA: 5s - loss: 0.5082 - acc: 0.744 - ETA: 5s - loss: 0.5081 - acc: 0.744 - ETA: 4s - loss: 0.5076 - acc: 0.745 - ETA: 4s - loss: 0.5074 - acc: 0.745 - ETA: 4s - loss: 0.5082 - acc: 0.744 - ETA: 4s - loss: 0.5070 - acc: 0.745 - ETA: 4s - loss: 0.5059 - acc: 0.746 - ETA: 4s - loss: 0.5053 - acc: 0.747 - ETA: 4s - loss: 0.5049 - acc: 0.747 - ETA: 4s - loss: 0.5071 - acc: 0.745 - ETA: 4s - loss: 0.5084 - acc: 0.744 - ETA: 4s - loss: 0.5083 - acc: 0.743 - ETA: 4s - loss: 0.5069 - acc: 0.744 - ETA: 3s - loss: 0.5062 - acc: 0.745 - ETA: 3s - loss: 0.5061 - acc: 0.745 - ETA: 3s - loss: 0.5062 - acc: 0.745 - ETA: 3s - loss: 0.5059 - acc: 0.745 - ETA: 3s - loss: 0.5081 - acc: 0.743 - ETA: 3s - loss: 0.5071 - acc: 0.743 - ETA: 3s - loss: 0.5068 - acc: 0.744 - ETA: 3s - loss: 0.5070 - acc: 0.744 - ETA: 3s - loss: 0.5084 - acc: 0.743 - ETA: 3s - loss: 0.5093 - acc: 0.742 - ETA: 2s - loss: 0.5092 - acc: 0.742 - ETA: 2s - loss: 0.5096 - acc: 0.741 - ETA: 2s - loss: 0.5090 - acc: 0.741 - ETA: 2s - loss: 0.5096 - acc: 0.741 - ETA: 2s - loss: 0.5099 - acc: 0.741 - ETA: 2s - loss: 0.5092 - acc: 0.741 - ETA: 2s - loss: 0.5100 - acc: 0.741 - ETA: 2s - loss: 0.5106 - acc: 0.741 - ETA: 2s - loss: 0.5107 - acc: 0.740 - ETA: 2s - loss: 0.5106 - acc: 0.740 - ETA: 1s - loss: 0.5101 - acc: 0.740 - ETA: 1s - loss: 0.5094 - acc: 0.741 - ETA: 1s - loss: 0.5110 - acc: 0.739 - ETA: 1s - loss: 0.5113 - acc: 0.739 - ETA: 1s - loss: 0.5109 - acc: 0.740 - ETA: 1s - loss: 0.5109 - acc: 0.740 - ETA: 1s - loss: 0.5098 - acc: 0.741 - ETA: 1s - loss: 0.5105 - acc: 0.740 - ETA: 1s - loss: 0.5105 - acc: 0.740 - ETA: 1s - loss: 0.5104 - acc: 0.740 - ETA: 0s - loss: 0.5102 - acc: 0.742 - ETA: 0s - loss: 0.5114 - acc: 0.741 - ETA: 0s - loss: 0.5100 - acc: 0.743 - ETA: 0s - loss: 0.5092 - acc: 0.744 - ETA: 0s - loss: 0.5081 - acc: 0.744 - ETA: 0s - loss: 0.5089 - acc: 0.744 - ETA: 0s - loss: 0.5088 - acc: 0.744 - ETA: 0s - loss: 0.5083 - acc: 0.744 - ETA: 0s - loss: 0.5069 - acc: 0.745 - ETA: 0s - loss: 0.5056 - acc: 0.747 - 14s 111ms/step - loss: 0.5056 - acc: 0.7473 - val_loss: 0.4782 - val_acc: 0.7710\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 11s - loss: 0.4871 - acc: 0.78 - ETA: 10s - loss: 0.4606 - acc: 0.81 - ETA: 10s - loss: 0.4488 - acc: 0.81 - ETA: 10s - loss: 0.4856 - acc: 0.78 - ETA: 10s - loss: 0.4808 - acc: 0.79 - ETA: 10s - loss: 0.4773 - acc: 0.78 - ETA: 10s - loss: 0.4693 - acc: 0.78 - ETA: 10s - loss: 0.4609 - acc: 0.78 - ETA: 10s - loss: 0.4688 - acc: 0.77 - ETA: 10s - loss: 0.4711 - acc: 0.77 - ETA: 10s - loss: 0.4629 - acc: 0.78 - ETA: 10s - loss: 0.4701 - acc: 0.77 - ETA: 10s - loss: 0.4758 - acc: 0.77 - ETA: 10s - loss: 0.4723 - acc: 0.77 - ETA: 10s - loss: 0.4768 - acc: 0.77 - ETA: 10s - loss: 0.4849 - acc: 0.76 - ETA: 10s - loss: 0.4901 - acc: 0.76 - ETA: 10s - loss: 0.4976 - acc: 0.76 - ETA: 10s - loss: 0.4970 - acc: 0.75 - ETA: 10s - loss: 0.5047 - acc: 0.75 - ETA: 10s - loss: 0.5076 - acc: 0.74 - ETA: 9s - loss: 0.5141 - acc: 0.7386 - ETA: 9s - loss: 0.5165 - acc: 0.740 - ETA: 9s - loss: 0.5130 - acc: 0.742 - ETA: 9s - loss: 0.5137 - acc: 0.741 - ETA: 9s - loss: 0.5125 - acc: 0.742 - ETA: 9s - loss: 0.5199 - acc: 0.737 - ETA: 9s - loss: 0.5142 - acc: 0.741 - ETA: 9s - loss: 0.5168 - acc: 0.740 - ETA: 9s - loss: 0.5201 - acc: 0.739 - ETA: 9s - loss: 0.5169 - acc: 0.741 - ETA: 8s - loss: 0.5196 - acc: 0.740 - ETA: 8s - loss: 0.5147 - acc: 0.744 - ETA: 8s - loss: 0.5137 - acc: 0.744 - ETA: 8s - loss: 0.5141 - acc: 0.744 - ETA: 8s - loss: 0.5150 - acc: 0.743 - ETA: 8s - loss: 0.5131 - acc: 0.746 - ETA: 8s - loss: 0.5141 - acc: 0.745 - ETA: 8s - loss: 0.5156 - acc: 0.744 - ETA: 8s - loss: 0.5173 - acc: 0.743 - ETA: 8s - loss: 0.5175 - acc: 0.743 - ETA: 7s - loss: 0.5172 - acc: 0.743 - ETA: 7s - loss: 0.5206 - acc: 0.741 - ETA: 7s - loss: 0.5191 - acc: 0.742 - ETA: 7s - loss: 0.5185 - acc: 0.743 - ETA: 7s - loss: 0.5167 - acc: 0.743 - ETA: 7s - loss: 0.5160 - acc: 0.746 - ETA: 7s - loss: 0.5155 - acc: 0.746 - ETA: 7s - loss: 0.5163 - acc: 0.745 - ETA: 7s - loss: 0.5168 - acc: 0.744 - ETA: 7s - loss: 0.5169 - acc: 0.744 - ETA: 6s - loss: 0.5139 - acc: 0.747 - ETA: 6s - loss: 0.5126 - acc: 0.747 - ETA: 6s - loss: 0.5112 - acc: 0.748 - ETA: 6s - loss: 0.5121 - acc: 0.747 - ETA: 6s - loss: 0.5112 - acc: 0.747 - ETA: 6s - loss: 0.5087 - acc: 0.750 - ETA: 6s - loss: 0.5057 - acc: 0.752 - ETA: 6s - loss: 0.5088 - acc: 0.752 - ETA: 6s - loss: 0.5074 - acc: 0.753 - ETA: 6s - loss: 0.5084 - acc: 0.752 - ETA: 6s - loss: 0.5077 - acc: 0.751 - ETA: 5s - loss: 0.5064 - acc: 0.752 - ETA: 5s - loss: 0.5080 - acc: 0.751 - ETA: 5s - loss: 0.5076 - acc: 0.751 - ETA: 5s - loss: 0.5085 - acc: 0.751 - ETA: 5s - loss: 0.5102 - acc: 0.750 - ETA: 5s - loss: 0.5085 - acc: 0.751 - ETA: 5s - loss: 0.5066 - acc: 0.752 - ETA: 5s - loss: 0.5081 - acc: 0.751 - ETA: 5s - loss: 0.5075 - acc: 0.751 - ETA: 5s - loss: 0.5089 - acc: 0.750 - ETA: 5s - loss: 0.5075 - acc: 0.751 - ETA: 5s - loss: 0.5071 - acc: 0.751 - ETA: 4s - loss: 0.5074 - acc: 0.752 - ETA: 4s - loss: 0.5070 - acc: 0.752 - ETA: 4s - loss: 0.5066 - acc: 0.753 - ETA: 4s - loss: 0.5067 - acc: 0.752 - ETA: 4s - loss: 0.5055 - acc: 0.754 - ETA: 4s - loss: 0.5066 - acc: 0.752 - ETA: 4s - loss: 0.5061 - acc: 0.753 - ETA: 4s - loss: 0.5065 - acc: 0.752 - ETA: 4s - loss: 0.5058 - acc: 0.752 - ETA: 4s - loss: 0.5058 - acc: 0.752 - ETA: 3s - loss: 0.5047 - acc: 0.754 - ETA: 3s - loss: 0.5034 - acc: 0.754 - ETA: 3s - loss: 0.5024 - acc: 0.755 - ETA: 3s - loss: 0.5023 - acc: 0.756 - ETA: 3s - loss: 0.5021 - acc: 0.756 - ETA: 3s - loss: 0.5023 - acc: 0.756 - ETA: 3s - loss: 0.5023 - acc: 0.756 - ETA: 3s - loss: 0.5035 - acc: 0.755 - ETA: 3s - loss: 0.5042 - acc: 0.754 - ETA: 3s - loss: 0.5040 - acc: 0.755 - ETA: 3s - loss: 0.5035 - acc: 0.754 - ETA: 2s - loss: 0.5042 - acc: 0.753 - ETA: 2s - loss: 0.5043 - acc: 0.753 - ETA: 2s - loss: 0.5030 - acc: 0.754 - ETA: 2s - loss: 0.5023 - acc: 0.754 - ETA: 2s - loss: 0.5027 - acc: 0.754 - ETA: 2s - loss: 0.5024 - acc: 0.754 - ETA: 2s - loss: 0.5022 - acc: 0.754 - ETA: 2s - loss: 0.5016 - acc: 0.755 - ETA: 2s - loss: 0.5016 - acc: 0.754 - ETA: 2s - loss: 0.5034 - acc: 0.753 - ETA: 2s - loss: 0.5026 - acc: 0.753 - ETA: 1s - loss: 0.5023 - acc: 0.753 - ETA: 1s - loss: 0.5045 - acc: 0.752 - ETA: 1s - loss: 0.5055 - acc: 0.751 - ETA: 1s - loss: 0.5068 - acc: 0.751 - ETA: 1s - loss: 0.5092 - acc: 0.750 - ETA: 1s - loss: 0.5081 - acc: 0.750 - ETA: 1s - loss: 0.5076 - acc: 0.750 - ETA: 1s - loss: 0.5071 - acc: 0.750 - ETA: 1s - loss: 0.5106 - acc: 0.748 - ETA: 1s - loss: 0.5095 - acc: 0.749 - ETA: 1s - loss: 0.5103 - acc: 0.748 - ETA: 0s - loss: 0.5105 - acc: 0.748 - ETA: 0s - loss: 0.5094 - acc: 0.749 - ETA: 0s - loss: 0.5103 - acc: 0.749 - ETA: 0s - loss: 0.5110 - acc: 0.748 - ETA: 0s - loss: 0.5102 - acc: 0.748 - ETA: 0s - loss: 0.5090 - acc: 0.748 - ETA: 0s - loss: 0.5089 - acc: 0.748 - ETA: 0s - loss: 0.5082 - acc: 0.748 - ETA: 0s - loss: 0.5089 - acc: 0.747 - ETA: 0s - loss: 0.5093 - acc: 0.748 - 14s 107ms/step - loss: 0.5092 - acc: 0.7485 - val_loss: 0.5267 - val_acc: 0.7322\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 13s - loss: 0.4689 - acc: 0.81 - ETA: 15s - loss: 0.4541 - acc: 0.78 - ETA: 15s - loss: 0.4422 - acc: 0.78 - ETA: 14s - loss: 0.4551 - acc: 0.78 - ETA: 14s - loss: 0.4650 - acc: 0.77 - ETA: 13s - loss: 0.4647 - acc: 0.77 - ETA: 12s - loss: 0.4632 - acc: 0.77 - ETA: 12s - loss: 0.4563 - acc: 0.77 - ETA: 12s - loss: 0.4612 - acc: 0.77 - ETA: 12s - loss: 0.4587 - acc: 0.77 - ETA: 11s - loss: 0.4602 - acc: 0.77 - ETA: 11s - loss: 0.4642 - acc: 0.77 - ETA: 11s - loss: 0.4659 - acc: 0.77 - ETA: 11s - loss: 0.4712 - acc: 0.77 - ETA: 11s - loss: 0.4749 - acc: 0.76 - ETA: 10s - loss: 0.4682 - acc: 0.76 - ETA: 10s - loss: 0.4700 - acc: 0.76 - ETA: 10s - loss: 0.4766 - acc: 0.75 - ETA: 10s - loss: 0.4722 - acc: 0.76 - ETA: 10s - loss: 0.4736 - acc: 0.76 - ETA: 10s - loss: 0.4773 - acc: 0.75 - ETA: 10s - loss: 0.4781 - acc: 0.75 - ETA: 10s - loss: 0.4792 - acc: 0.76 - ETA: 9s - loss: 0.4908 - acc: 0.7487 - ETA: 9s - loss: 0.4910 - acc: 0.751 - ETA: 9s - loss: 0.4889 - acc: 0.751 - ETA: 9s - loss: 0.4856 - acc: 0.754 - ETA: 9s - loss: 0.4901 - acc: 0.750 - ETA: 9s - loss: 0.4883 - acc: 0.750 - ETA: 9s - loss: 0.4896 - acc: 0.750 - ETA: 9s - loss: 0.4923 - acc: 0.746 - ETA: 9s - loss: 0.4927 - acc: 0.746 - ETA: 8s - loss: 0.4963 - acc: 0.746 - ETA: 8s - loss: 0.4956 - acc: 0.746 - ETA: 8s - loss: 0.4973 - acc: 0.746 - ETA: 8s - loss: 0.4959 - acc: 0.744 - ETA: 8s - loss: 0.4905 - acc: 0.748 - ETA: 8s - loss: 0.4907 - acc: 0.746 - ETA: 8s - loss: 0.4873 - acc: 0.749 - ETA: 8s - loss: 0.4841 - acc: 0.751 - ETA: 8s - loss: 0.4850 - acc: 0.750 - ETA: 8s - loss: 0.4877 - acc: 0.748 - ETA: 8s - loss: 0.4860 - acc: 0.750 - ETA: 7s - loss: 0.4850 - acc: 0.750 - ETA: 7s - loss: 0.4850 - acc: 0.749 - ETA: 7s - loss: 0.4856 - acc: 0.750 - ETA: 7s - loss: 0.4883 - acc: 0.749 - ETA: 7s - loss: 0.4875 - acc: 0.751 - ETA: 7s - loss: 0.4870 - acc: 0.751 - ETA: 7s - loss: 0.4866 - acc: 0.753 - ETA: 7s - loss: 0.4863 - acc: 0.753 - ETA: 7s - loss: 0.4881 - acc: 0.752 - ETA: 7s - loss: 0.4871 - acc: 0.752 - ETA: 7s - loss: 0.4848 - acc: 0.755 - ETA: 7s - loss: 0.4825 - acc: 0.756 - ETA: 6s - loss: 0.4789 - acc: 0.759 - ETA: 6s - loss: 0.4807 - acc: 0.757 - ETA: 6s - loss: 0.4784 - acc: 0.759 - ETA: 6s - loss: 0.4786 - acc: 0.758 - ETA: 6s - loss: 0.4798 - acc: 0.758 - ETA: 6s - loss: 0.4780 - acc: 0.760 - ETA: 6s - loss: 0.4794 - acc: 0.757 - ETA: 6s - loss: 0.4795 - acc: 0.758 - ETA: 6s - loss: 0.4803 - acc: 0.757 - ETA: 5s - loss: 0.4803 - acc: 0.758 - ETA: 5s - loss: 0.4789 - acc: 0.758 - ETA: 5s - loss: 0.4795 - acc: 0.757 - ETA: 5s - loss: 0.4795 - acc: 0.757 - ETA: 5s - loss: 0.4804 - acc: 0.755 - ETA: 5s - loss: 0.4803 - acc: 0.755 - ETA: 5s - loss: 0.4789 - acc: 0.757 - ETA: 5s - loss: 0.4801 - acc: 0.756 - ETA: 5s - loss: 0.4794 - acc: 0.757 - ETA: 5s - loss: 0.4820 - acc: 0.754 - ETA: 5s - loss: 0.4820 - acc: 0.754 - ETA: 4s - loss: 0.4804 - acc: 0.755 - ETA: 4s - loss: 0.4799 - acc: 0.755 - ETA: 4s - loss: 0.4787 - acc: 0.756 - ETA: 4s - loss: 0.4796 - acc: 0.754 - ETA: 4s - loss: 0.4803 - acc: 0.754 - ETA: 4s - loss: 0.4792 - acc: 0.755 - ETA: 4s - loss: 0.4779 - acc: 0.756 - ETA: 4s - loss: 0.4757 - acc: 0.759 - ETA: 4s - loss: 0.4742 - acc: 0.760 - ETA: 4s - loss: 0.4732 - acc: 0.760 - ETA: 3s - loss: 0.4732 - acc: 0.760 - ETA: 3s - loss: 0.4750 - acc: 0.759 - ETA: 3s - loss: 0.4759 - acc: 0.759 - ETA: 3s - loss: 0.4744 - acc: 0.760 - ETA: 3s - loss: 0.4742 - acc: 0.760 - ETA: 3s - loss: 0.4737 - acc: 0.761 - ETA: 3s - loss: 0.4739 - acc: 0.760 - ETA: 3s - loss: 0.4727 - acc: 0.762 - ETA: 3s - loss: 0.4725 - acc: 0.762 - ETA: 3s - loss: 0.4741 - acc: 0.761 - ETA: 3s - loss: 0.4741 - acc: 0.762 - ETA: 2s - loss: 0.4749 - acc: 0.761 - ETA: 2s - loss: 0.4747 - acc: 0.761 - ETA: 2s - loss: 0.4746 - acc: 0.762 - ETA: 2s - loss: 0.4744 - acc: 0.761 - ETA: 2s - loss: 0.4752 - acc: 0.761 - ETA: 2s - loss: 0.4748 - acc: 0.761 - ETA: 2s - loss: 0.4745 - acc: 0.762 - ETA: 2s - loss: 0.4756 - acc: 0.761 - ETA: 2s - loss: 0.4737 - acc: 0.762 - ETA: 2s - loss: 0.4736 - acc: 0.762 - ETA: 1s - loss: 0.4737 - acc: 0.762 - ETA: 1s - loss: 0.4731 - acc: 0.762 - ETA: 1s - loss: 0.4727 - acc: 0.762 - ETA: 1s - loss: 0.4748 - acc: 0.761 - ETA: 1s - loss: 0.4755 - acc: 0.762 - ETA: 1s - loss: 0.4751 - acc: 0.763 - ETA: 1s - loss: 0.4749 - acc: 0.763 - ETA: 1s - loss: 0.4736 - acc: 0.765 - ETA: 1s - loss: 0.4743 - acc: 0.765 - ETA: 1s - loss: 0.4730 - acc: 0.766 - ETA: 1s - loss: 0.4718 - acc: 0.767 - ETA: 0s - loss: 0.4715 - acc: 0.767 - ETA: 0s - loss: 0.4717 - acc: 0.767 - ETA: 0s - loss: 0.4725 - acc: 0.766 - ETA: 0s - loss: 0.4727 - acc: 0.767 - ETA: 0s - loss: 0.4741 - acc: 0.766 - ETA: 0s - loss: 0.4750 - acc: 0.766 - ETA: 0s - loss: 0.4755 - acc: 0.765 - ETA: 0s - loss: 0.4753 - acc: 0.765 - ETA: 0s - loss: 0.4746 - acc: 0.765 - ETA: 0s - loss: 0.4755 - acc: 0.765 - 14s 109ms/step - loss: 0.4747 - acc: 0.7659 - val_loss: 0.5039 - val_acc: 0.7495\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 13s - loss: 0.4580 - acc: 0.75 - ETA: 13s - loss: 0.4582 - acc: 0.76 - ETA: 13s - loss: 0.4718 - acc: 0.77 - ETA: 12s - loss: 0.4583 - acc: 0.78 - ETA: 12s - loss: 0.4320 - acc: 0.80 - ETA: 12s - loss: 0.4463 - acc: 0.79 - ETA: 12s - loss: 0.4334 - acc: 0.79 - ETA: 12s - loss: 0.4294 - acc: 0.80 - ETA: 12s - loss: 0.4368 - acc: 0.79 - ETA: 12s - loss: 0.4553 - acc: 0.78 - ETA: 11s - loss: 0.4569 - acc: 0.78 - ETA: 11s - loss: 0.4572 - acc: 0.78 - ETA: 11s - loss: 0.4659 - acc: 0.78 - ETA: 11s - loss: 0.4681 - acc: 0.78 - ETA: 11s - loss: 0.4682 - acc: 0.77 - ETA: 11s - loss: 0.4683 - acc: 0.78 - ETA: 11s - loss: 0.4669 - acc: 0.78 - ETA: 11s - loss: 0.4659 - acc: 0.78 - ETA: 11s - loss: 0.4653 - acc: 0.78 - ETA: 11s - loss: 0.4640 - acc: 0.78 - ETA: 11s - loss: 0.4641 - acc: 0.78 - ETA: 10s - loss: 0.4748 - acc: 0.77 - ETA: 10s - loss: 0.4760 - acc: 0.76 - ETA: 10s - loss: 0.4763 - acc: 0.76 - ETA: 10s - loss: 0.4736 - acc: 0.76 - ETA: 10s - loss: 0.4720 - acc: 0.77 - ETA: 10s - loss: 0.4648 - acc: 0.77 - ETA: 10s - loss: 0.4672 - acc: 0.77 - ETA: 9s - loss: 0.4678 - acc: 0.7759 - ETA: 9s - loss: 0.4637 - acc: 0.779 - ETA: 9s - loss: 0.4632 - acc: 0.782 - ETA: 9s - loss: 0.4634 - acc: 0.780 - ETA: 9s - loss: 0.4665 - acc: 0.773 - ETA: 9s - loss: 0.4697 - acc: 0.771 - ETA: 9s - loss: 0.4735 - acc: 0.769 - ETA: 9s - loss: 0.4725 - acc: 0.769 - ETA: 9s - loss: 0.4759 - acc: 0.766 - ETA: 9s - loss: 0.4737 - acc: 0.768 - ETA: 9s - loss: 0.4752 - acc: 0.770 - ETA: 8s - loss: 0.4746 - acc: 0.770 - ETA: 8s - loss: 0.4785 - acc: 0.766 - ETA: 8s - loss: 0.4768 - acc: 0.769 - ETA: 8s - loss: 0.4782 - acc: 0.768 - ETA: 8s - loss: 0.4777 - acc: 0.768 - ETA: 8s - loss: 0.4771 - acc: 0.768 - ETA: 8s - loss: 0.4735 - acc: 0.771 - ETA: 8s - loss: 0.4767 - acc: 0.768 - ETA: 8s - loss: 0.4783 - acc: 0.768 - ETA: 7s - loss: 0.4784 - acc: 0.767 - ETA: 7s - loss: 0.4781 - acc: 0.766 - ETA: 7s - loss: 0.4800 - acc: 0.765 - ETA: 7s - loss: 0.4832 - acc: 0.763 - ETA: 7s - loss: 0.4833 - acc: 0.763 - ETA: 7s - loss: 0.4809 - acc: 0.766 - ETA: 7s - loss: 0.4806 - acc: 0.766 - ETA: 7s - loss: 0.4813 - acc: 0.765 - ETA: 7s - loss: 0.4803 - acc: 0.765 - ETA: 7s - loss: 0.4853 - acc: 0.764 - ETA: 6s - loss: 0.4928 - acc: 0.761 - ETA: 6s - loss: 0.4955 - acc: 0.760 - ETA: 6s - loss: 0.4966 - acc: 0.759 - ETA: 6s - loss: 0.4959 - acc: 0.759 - ETA: 6s - loss: 0.4965 - acc: 0.758 - ETA: 6s - loss: 0.4954 - acc: 0.758 - ETA: 6s - loss: 0.5037 - acc: 0.753 - ETA: 6s - loss: 0.5083 - acc: 0.750 - ETA: 6s - loss: 0.5088 - acc: 0.749 - ETA: 5s - loss: 0.5072 - acc: 0.749 - ETA: 5s - loss: 0.5060 - acc: 0.750 - ETA: 5s - loss: 0.5048 - acc: 0.750 - ETA: 5s - loss: 0.5030 - acc: 0.751 - ETA: 5s - loss: 0.5032 - acc: 0.752 - ETA: 5s - loss: 0.5053 - acc: 0.752 - ETA: 5s - loss: 0.5044 - acc: 0.753 - ETA: 5s - loss: 0.5065 - acc: 0.752 - ETA: 5s - loss: 0.5068 - acc: 0.752 - ETA: 5s - loss: 0.5066 - acc: 0.752 - ETA: 5s - loss: 0.5060 - acc: 0.753 - ETA: 4s - loss: 0.5051 - acc: 0.754 - ETA: 4s - loss: 0.5063 - acc: 0.752 - ETA: 4s - loss: 0.5049 - acc: 0.752 - ETA: 4s - loss: 0.5053 - acc: 0.751 - ETA: 4s - loss: 0.5048 - acc: 0.752 - ETA: 4s - loss: 0.5034 - acc: 0.754 - ETA: 4s - loss: 0.5028 - acc: 0.754 - ETA: 4s - loss: 0.5025 - acc: 0.755 - ETA: 4s - loss: 0.5018 - acc: 0.755 - ETA: 4s - loss: 0.5000 - acc: 0.757 - ETA: 3s - loss: 0.4992 - acc: 0.757 - ETA: 3s - loss: 0.4993 - acc: 0.756 - ETA: 3s - loss: 0.5001 - acc: 0.755 - ETA: 3s - loss: 0.5009 - acc: 0.754 - ETA: 3s - loss: 0.5014 - acc: 0.754 - ETA: 3s - loss: 0.5021 - acc: 0.753 - ETA: 3s - loss: 0.5012 - acc: 0.753 - ETA: 3s - loss: 0.5028 - acc: 0.752 - ETA: 3s - loss: 0.5015 - acc: 0.752 - ETA: 3s - loss: 0.5008 - acc: 0.753 - ETA: 2s - loss: 0.5003 - acc: 0.752 - ETA: 2s - loss: 0.4996 - acc: 0.753 - ETA: 2s - loss: 0.4990 - acc: 0.753 - ETA: 2s - loss: 0.4983 - acc: 0.753 - ETA: 2s - loss: 0.4992 - acc: 0.753 - ETA: 2s - loss: 0.4996 - acc: 0.753 - ETA: 2s - loss: 0.5003 - acc: 0.752 - ETA: 2s - loss: 0.4997 - acc: 0.753 - ETA: 2s - loss: 0.5002 - acc: 0.753 - ETA: 2s - loss: 0.5005 - acc: 0.752 - ETA: 1s - loss: 0.5012 - acc: 0.752 - ETA: 1s - loss: 0.5015 - acc: 0.751 - ETA: 1s - loss: 0.5014 - acc: 0.751 - ETA: 1s - loss: 0.5004 - acc: 0.752 - ETA: 1s - loss: 0.5015 - acc: 0.751 - ETA: 1s - loss: 0.4998 - acc: 0.752 - ETA: 1s - loss: 0.5009 - acc: 0.751 - ETA: 1s - loss: 0.5018 - acc: 0.751 - ETA: 1s - loss: 0.5036 - acc: 0.750 - ETA: 1s - loss: 0.5045 - acc: 0.750 - ETA: 0s - loss: 0.5028 - acc: 0.751 - ETA: 0s - loss: 0.5025 - acc: 0.751 - ETA: 0s - loss: 0.5027 - acc: 0.751 - ETA: 0s - loss: 0.5027 - acc: 0.750 - ETA: 0s - loss: 0.5014 - acc: 0.752 - ETA: 0s - loss: 0.5011 - acc: 0.752 - ETA: 0s - loss: 0.5028 - acc: 0.750 - ETA: 0s - loss: 0.5032 - acc: 0.749 - ETA: 0s - loss: 0.5037 - acc: 0.749 - 15s 115ms/step - loss: 0.5041 - acc: 0.7483 - val_loss: 0.4639 - val_acc: 0.7708\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 12s - loss: 0.6978 - acc: 0.62 - ETA: 11s - loss: 0.6097 - acc: 0.68 - ETA: 11s - loss: 0.6216 - acc: 0.69 - ETA: 11s - loss: 0.5716 - acc: 0.72 - ETA: 11s - loss: 0.5973 - acc: 0.70 - ETA: 11s - loss: 0.5720 - acc: 0.72 - ETA: 11s - loss: 0.5581 - acc: 0.73 - ETA: 11s - loss: 0.5592 - acc: 0.72 - ETA: 10s - loss: 0.5697 - acc: 0.70 - ETA: 10s - loss: 0.5520 - acc: 0.72 - ETA: 10s - loss: 0.5551 - acc: 0.71 - ETA: 10s - loss: 0.5410 - acc: 0.72 - ETA: 10s - loss: 0.5309 - acc: 0.73 - ETA: 10s - loss: 0.5306 - acc: 0.73 - ETA: 10s - loss: 0.5184 - acc: 0.74 - ETA: 10s - loss: 0.5229 - acc: 0.74 - ETA: 10s - loss: 0.5167 - acc: 0.74 - ETA: 10s - loss: 0.5107 - acc: 0.74 - ETA: 10s - loss: 0.5099 - acc: 0.74 - ETA: 9s - loss: 0.5091 - acc: 0.7422 - ETA: 9s - loss: 0.5023 - acc: 0.747 - ETA: 9s - loss: 0.5045 - acc: 0.744 - ETA: 9s - loss: 0.5043 - acc: 0.744 - ETA: 9s - loss: 0.5070 - acc: 0.743 - ETA: 9s - loss: 0.5105 - acc: 0.738 - ETA: 9s - loss: 0.5169 - acc: 0.734 - ETA: 9s - loss: 0.5212 - acc: 0.731 - ETA: 9s - loss: 0.5209 - acc: 0.731 - ETA: 9s - loss: 0.5220 - acc: 0.731 - ETA: 9s - loss: 0.5175 - acc: 0.736 - ETA: 8s - loss: 0.5158 - acc: 0.737 - ETA: 8s - loss: 0.5135 - acc: 0.740 - ETA: 8s - loss: 0.5095 - acc: 0.743 - ETA: 8s - loss: 0.5123 - acc: 0.740 - ETA: 8s - loss: 0.5142 - acc: 0.737 - ETA: 8s - loss: 0.5135 - acc: 0.737 - ETA: 8s - loss: 0.5113 - acc: 0.739 - ETA: 8s - loss: 0.5078 - acc: 0.741 - ETA: 8s - loss: 0.5090 - acc: 0.739 - ETA: 8s - loss: 0.5052 - acc: 0.743 - ETA: 8s - loss: 0.5048 - acc: 0.746 - ETA: 7s - loss: 0.5036 - acc: 0.746 - ETA: 7s - loss: 0.5033 - acc: 0.747 - ETA: 7s - loss: 0.5055 - acc: 0.746 - ETA: 7s - loss: 0.5019 - acc: 0.750 - ETA: 7s - loss: 0.5013 - acc: 0.752 - ETA: 7s - loss: 0.4992 - acc: 0.753 - ETA: 7s - loss: 0.4997 - acc: 0.752 - ETA: 7s - loss: 0.4975 - acc: 0.755 - ETA: 7s - loss: 0.4976 - acc: 0.753 - ETA: 7s - loss: 0.4957 - acc: 0.756 - ETA: 7s - loss: 0.4957 - acc: 0.756 - ETA: 7s - loss: 0.4945 - acc: 0.757 - ETA: 6s - loss: 0.4930 - acc: 0.759 - ETA: 6s - loss: 0.4908 - acc: 0.760 - ETA: 6s - loss: 0.4929 - acc: 0.759 - ETA: 6s - loss: 0.4941 - acc: 0.758 - ETA: 6s - loss: 0.4961 - acc: 0.757 - ETA: 6s - loss: 0.4942 - acc: 0.757 - ETA: 6s - loss: 0.4960 - acc: 0.755 - ETA: 6s - loss: 0.4964 - acc: 0.756 - ETA: 6s - loss: 0.4963 - acc: 0.757 - ETA: 6s - loss: 0.4970 - acc: 0.756 - ETA: 6s - loss: 0.4953 - acc: 0.757 - ETA: 5s - loss: 0.4952 - acc: 0.757 - ETA: 5s - loss: 0.4972 - acc: 0.755 - ETA: 5s - loss: 0.4975 - acc: 0.755 - ETA: 5s - loss: 0.4994 - acc: 0.754 - ETA: 5s - loss: 0.5005 - acc: 0.752 - ETA: 5s - loss: 0.4984 - acc: 0.753 - ETA: 5s - loss: 0.4966 - acc: 0.754 - ETA: 5s - loss: 0.4966 - acc: 0.753 - ETA: 5s - loss: 0.4972 - acc: 0.753 - ETA: 5s - loss: 0.4976 - acc: 0.753 - ETA: 5s - loss: 0.4968 - acc: 0.753 - ETA: 4s - loss: 0.4968 - acc: 0.753 - ETA: 4s - loss: 0.4964 - acc: 0.754 - ETA: 4s - loss: 0.4965 - acc: 0.754 - ETA: 4s - loss: 0.4965 - acc: 0.754 - ETA: 4s - loss: 0.4984 - acc: 0.753 - ETA: 4s - loss: 0.4973 - acc: 0.754 - ETA: 4s - loss: 0.4966 - acc: 0.755 - ETA: 4s - loss: 0.4971 - acc: 0.754 - ETA: 4s - loss: 0.4990 - acc: 0.753 - ETA: 4s - loss: 0.4983 - acc: 0.752 - ETA: 4s - loss: 0.5001 - acc: 0.750 - ETA: 3s - loss: 0.4993 - acc: 0.751 - ETA: 3s - loss: 0.4986 - acc: 0.751 - ETA: 3s - loss: 0.4997 - acc: 0.750 - ETA: 3s - loss: 0.5008 - acc: 0.750 - ETA: 3s - loss: 0.5027 - acc: 0.750 - ETA: 3s - loss: 0.5019 - acc: 0.750 - ETA: 3s - loss: 0.5025 - acc: 0.750 - ETA: 3s - loss: 0.5027 - acc: 0.750 - ETA: 3s - loss: 0.5029 - acc: 0.750 - ETA: 3s - loss: 0.5023 - acc: 0.750 - ETA: 2s - loss: 0.5011 - acc: 0.750 - ETA: 2s - loss: 0.5007 - acc: 0.751 - ETA: 2s - loss: 0.5000 - acc: 0.751 - ETA: 2s - loss: 0.5004 - acc: 0.751 - ETA: 2s - loss: 0.4999 - acc: 0.751 - ETA: 2s - loss: 0.5002 - acc: 0.750 - ETA: 2s - loss: 0.5006 - acc: 0.750 - ETA: 2s - loss: 0.5015 - acc: 0.750 - ETA: 2s - loss: 0.5007 - acc: 0.751 - ETA: 2s - loss: 0.5017 - acc: 0.750 - ETA: 2s - loss: 0.5024 - acc: 0.750 - ETA: 1s - loss: 0.5012 - acc: 0.751 - ETA: 1s - loss: 0.5006 - acc: 0.752 - ETA: 1s - loss: 0.5013 - acc: 0.752 - ETA: 1s - loss: 0.5005 - acc: 0.752 - ETA: 1s - loss: 0.4998 - acc: 0.752 - ETA: 1s - loss: 0.4989 - acc: 0.752 - ETA: 1s - loss: 0.4982 - acc: 0.753 - ETA: 1s - loss: 0.4984 - acc: 0.753 - ETA: 1s - loss: 0.4984 - acc: 0.753 - ETA: 1s - loss: 0.4980 - acc: 0.753 - ETA: 0s - loss: 0.4987 - acc: 0.752 - ETA: 0s - loss: 0.4980 - acc: 0.752 - ETA: 0s - loss: 0.4982 - acc: 0.752 - ETA: 0s - loss: 0.4981 - acc: 0.752 - ETA: 0s - loss: 0.4991 - acc: 0.751 - ETA: 0s - loss: 0.5002 - acc: 0.751 - ETA: 0s - loss: 0.5006 - acc: 0.750 - ETA: 0s - loss: 0.5016 - acc: 0.750 - ETA: 0s - loss: 0.5017 - acc: 0.750 - ETA: 0s - loss: 0.5017 - acc: 0.749 - 15s 116ms/step - loss: 0.5020 - acc: 0.7498 - val_loss: 0.4628 - val_acc: 0.7673\n",
      "Epoch 19/300\n",
      " 77/128 [=================>............] - ETA: 11s - loss: 0.3888 - acc: 0.78 - ETA: 11s - loss: 0.4601 - acc: 0.73 - ETA: 11s - loss: 0.4619 - acc: 0.73 - ETA: 11s - loss: 0.4579 - acc: 0.75 - ETA: 12s - loss: 0.4567 - acc: 0.74 - ETA: 13s - loss: 0.4549 - acc: 0.75 - ETA: 13s - loss: 0.4744 - acc: 0.74 - ETA: 13s - loss: 0.4712 - acc: 0.75 - ETA: 13s - loss: 0.4697 - acc: 0.75 - ETA: 13s - loss: 0.4769 - acc: 0.75 - ETA: 13s - loss: 0.4732 - acc: 0.75 - ETA: 13s - loss: 0.4663 - acc: 0.76 - ETA: 13s - loss: 0.4640 - acc: 0.76 - ETA: 13s - loss: 0.4623 - acc: 0.76 - ETA: 13s - loss: 0.4584 - acc: 0.77 - ETA: 13s - loss: 0.4577 - acc: 0.77 - ETA: 13s - loss: 0.4607 - acc: 0.77 - ETA: 12s - loss: 0.4626 - acc: 0.77 - ETA: 12s - loss: 0.4654 - acc: 0.76 - ETA: 12s - loss: 0.4672 - acc: 0.76 - ETA: 12s - loss: 0.4736 - acc: 0.76 - ETA: 12s - loss: 0.4736 - acc: 0.76 - ETA: 11s - loss: 0.4770 - acc: 0.76 - ETA: 11s - loss: 0.4806 - acc: 0.76 - ETA: 11s - loss: 0.4807 - acc: 0.76 - ETA: 11s - loss: 0.4831 - acc: 0.76 - ETA: 11s - loss: 0.4842 - acc: 0.75 - ETA: 11s - loss: 0.4814 - acc: 0.76 - ETA: 11s - loss: 0.4795 - acc: 0.76 - ETA: 11s - loss: 0.4776 - acc: 0.76 - ETA: 11s - loss: 0.4787 - acc: 0.76 - ETA: 10s - loss: 0.4771 - acc: 0.76 - ETA: 10s - loss: 0.4744 - acc: 0.76 - ETA: 10s - loss: 0.4723 - acc: 0.76 - ETA: 10s - loss: 0.4677 - acc: 0.77 - ETA: 10s - loss: 0.4683 - acc: 0.77 - ETA: 10s - loss: 0.4691 - acc: 0.77 - ETA: 10s - loss: 0.4728 - acc: 0.76 - ETA: 10s - loss: 0.4689 - acc: 0.77 - ETA: 9s - loss: 0.4704 - acc: 0.7727 - ETA: 9s - loss: 0.4774 - acc: 0.767 - ETA: 9s - loss: 0.4784 - acc: 0.767 - ETA: 9s - loss: 0.4777 - acc: 0.766 - ETA: 9s - loss: 0.4784 - acc: 0.765 - ETA: 9s - loss: 0.4791 - acc: 0.763 - ETA: 9s - loss: 0.4831 - acc: 0.761 - ETA: 9s - loss: 0.4807 - acc: 0.764 - ETA: 9s - loss: 0.4841 - acc: 0.762 - ETA: 8s - loss: 0.4836 - acc: 0.763 - ETA: 8s - loss: 0.4831 - acc: 0.761 - ETA: 8s - loss: 0.4848 - acc: 0.761 - ETA: 8s - loss: 0.4843 - acc: 0.763 - ETA: 8s - loss: 0.4847 - acc: 0.761 - ETA: 8s - loss: 0.4853 - acc: 0.762 - ETA: 8s - loss: 0.4857 - acc: 0.761 - ETA: 8s - loss: 0.4854 - acc: 0.761 - ETA: 7s - loss: 0.4859 - acc: 0.761 - ETA: 7s - loss: 0.4878 - acc: 0.759 - ETA: 7s - loss: 0.4863 - acc: 0.759 - ETA: 7s - loss: 0.4859 - acc: 0.760 - ETA: 7s - loss: 0.4876 - acc: 0.759 - ETA: 7s - loss: 0.4876 - acc: 0.759 - ETA: 7s - loss: 0.4879 - acc: 0.759 - ETA: 7s - loss: 0.4872 - acc: 0.760 - ETA: 7s - loss: 0.4873 - acc: 0.760 - ETA: 6s - loss: 0.4874 - acc: 0.760 - ETA: 6s - loss: 0.4884 - acc: 0.759 - ETA: 6s - loss: 0.4878 - acc: 0.759 - ETA: 6s - loss: 0.4894 - acc: 0.758 - ETA: 6s - loss: 0.4912 - acc: 0.758 - ETA: 6s - loss: 0.4914 - acc: 0.758 - ETA: 6s - loss: 0.4896 - acc: 0.759 - ETA: 6s - loss: 0.4902 - acc: 0.758 - ETA: 5s - loss: 0.4906 - acc: 0.758 - ETA: 5s - loss: 0.4893 - acc: 0.759 - ETA: 5s - loss: 0.4888 - acc: 0.759 - ETA: 5s - loss: 0.4876 - acc: 0.7606"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9738a0c7769d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_sequence, \n",
    "    steps_per_epoch=128, \n",
    "    epochs=300, \n",
    "    verbose=1, \n",
    "    callbacks=None, \n",
    "    validation_data=val_sequence, \n",
    "    validation_steps=128, \n",
    "    class_weight=None, \n",
    "    max_queue_size=10, \n",
    "    workers=1, \n",
    "    use_multiprocessing=False, \n",
    "    shuffle=True, \n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, run_name):\n",
    "    cwd = os.getcwd()\n",
    "    modelPath = os.path.join(cwd, 'model')\n",
    "    if not os.path.isdir(modelPath):\n",
    "        os.mkdir(modelPath)\n",
    "    weigths_file = os.path.join(modelPath, run_name + '.h5')\n",
    "    print(weigths_file)\n",
    "    model.save(weigths_file)\n",
    "saveModel(model, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time elapsed: %.1fs' % (time.time() - t0))\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
