{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict-Image-Similar-FCNN-Binary\n",
    "For landmark-recognition-2019 algorithm validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Dog-Breed_4-Predict-Dog-Breed_3-Image-Similar-FCNN-Binary_20190501-194400_20190502-092437\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Dog-Breed'\n",
    "model_name = 'Dog-Breed_3-Image-Similar-FCNN-Binary_20190501-194400'\n",
    "step_name = '4-Predict-%s' % model_name\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle\\dog-breed-identification\\feature\\feature_wrapper_171023.h5\n",
      "D:\\Kaggle\\dog-breed-identification\\input\\train.csv\n",
      "D:\\Kaggle\\dog-breed-identification\\input\\test.csv\n",
      "D:\\Kaggle\\dog-breed-identification\\input\\sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "vgg16_feature_file = os.path.join(feature_folder, 'feature_wrapper_171023.h5')\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')\n",
    "print(vgg16_feature_file)\n",
    "print(train_csv_file)\n",
    "print(test_csv_file)\n",
    "print(sample_submission_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(vgg16_feature_file, 'r') as h:\n",
    "    x_train = np.array(h['train'])\n",
    "    y_train = np.array(h['train_label'])\n",
    "    x_val = np.array(h['val'])\n",
    "    y_val = np.array(h['val_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9199, 512)\n",
      "(9199,)\n",
      "(1023, 512)\n",
      "(1023,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle\\dog-breed-identification\\model\\Dog-Breed_3-Image-Similar-FCNN-Binary_20190501-194400.h5\n",
      "WARNING:tensorflow:From C:\\Users\\study\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\study\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model_file = os.path.join(model_folder, '%s.h5' % model_name)\n",
    "print(model_file)\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "library_input (InputLayer)      (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           main_input[0][0]                 \n",
      "                                                                 library_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         1049600     dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1025        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,149,825\n",
      "Trainable params: 3,149,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2372 --> 30 [0, 0, 54, 20, 0, 62, 0, 54, 85, 30]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "item_main_x = np.array([x_train[idx]]*x_train.shape[0])\n",
    "item_x_train = {\n",
    "    'main_input': item_main_x,\n",
    "    'library_input': x_train\n",
    "}\n",
    "y_proba = model.predict(item_x_train, batch_size=1024)\n",
    "print(y_train[idx], np.argmax(y_proba), '-->', y_train[np.argmax(y_proba)], [y_train[item[0]] for item in np.argsort(y_proba, axis=0)[-10:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 30 [0, 0, 54, 20, 0, 62, 0, 54, 85, 30]\n",
      "0 --> 0 [96, 30, 108, 109, 1, 0, 23, 0, 0, 0]\n",
      "0 --> 1 [97, 1, 1, 1, 106, 30, 1, 78, 1, 1]\n",
      "0 --> 6 [26, 0, 0, 0, 6, 6, 79, 119, 119, 6]\n",
      "0 --> 0 [85, 0, 0, 0, 96, 26, 0, 26, 96, 0]\n",
      "0 --> 0 [0, 0, 96, 0, 0, 26, 26, 0, 0, 0]\n",
      "0 --> 0 [64, 0, 0, 76, 0, 78, 109, 20, 3, 0]\n",
      "0 --> 59 [107, 68, 77, 68, 0, 48, 3, 3, 110, 59]\n",
      "0 --> 109 [23, 0, 6, 119, 96, 111, 26, 0, 26, 109]\n",
      "0 --> 0 [0, 20, 108, 85, 0, 0, 0, 0, 0, 0]\n",
      "********************************************************************************\n",
      "5 0.50\n",
      "9 0.90\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "amount = 10\n",
    "top1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    item_main_x = np.array([x_train[idx]]*x_train.shape[0])\n",
    "    item_x_train = {\n",
    "        'main_input': item_main_x,\n",
    "        'library_input': x_train\n",
    "    }\n",
    "    y_proba = model.predict(item_x_train, batch_size=1024)\n",
    "    item_y_train = y_train[idx]\n",
    "    top1_pred = y_train[np.argmax(y_proba)]\n",
    "    topn_pred_arr = [y_train[item[0]] for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    if item_y_train == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_train in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_train, '-->', top1_pred, topn_pred_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]] <class 'numpy.ndarray'>\n",
      "6\n",
      "[0 0 1 1 2 2] <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 2, 1], [0.3, 0.4, 0.5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weight_topn(y_proba, topn, y_data):\n",
    "    y_proba_argsorted = [(y_data[item[0]], y_proba[item[0]][0]) for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    class_score_dict = {}\n",
    "    for item_class, item_proba in y_proba_argsorted:\n",
    "        if item_class in class_score_dict:\n",
    "            class_score_dict[item_class] += item_proba\n",
    "        else:\n",
    "            class_score_dict[item_class] = item_proba\n",
    "    class_score_arr = list(class_score_dict.items())\n",
    "    class_score_arr = sorted(class_score_arr, key=lambda x: x[1])\n",
    "    topn_pred_arr = [item[0] for item in class_score_arr]\n",
    "    class_score_arr = [round(item[1], 2) for item in class_score_arr]\n",
    "    return topn_pred_arr, class_score_arr\n",
    "\n",
    "y_proba = np.array([[0.1], [0.2], [0.3], [0.2], [0.2], [0.2]])\n",
    "topn = 6\n",
    "y_data = np.array([0, 0, 1, 1, 2, 2])\n",
    "print(y_proba, type(y_proba))\n",
    "print(topn)\n",
    "print(y_data, type(y_data))\n",
    "get_weight_topn(y_proba, topn, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 30 \t 0 [20, 62, 85, 30, 54, 0] [0.98, 0.98, 0.99, 0.99, 1.96, 3.92]\n",
      "0 --> 0 \t 0 [96, 30, 108, 109, 1, 23, 0] [0.95, 0.95, 0.95, 0.95, 0.96, 0.96, 3.86]\n",
      "0 --> 1 \t 1 [97, 106, 30, 78, 1] [0.96, 0.97, 0.97, 0.97, 5.8]\n",
      "0 --> 6 \t 6 [26, 79, 119, 0, 6] [0.98, 0.98, 1.97, 2.94, 2.96]\n",
      "0 --> 0 \t 0 [85, 96, 26, 0] [0.99, 1.98, 1.98, 4.94]\n",
      "0 --> 0 \t 0 [96, 26, 0] [0.97, 1.95, 6.83]\n",
      "0 --> 0 \t 0 [64, 76, 78, 109, 20, 3, 0] [0.96, 0.96, 0.97, 0.97, 0.97, 0.97, 3.87]\n",
      "0 --> 59 \t 3 [107, 77, 0, 48, 110, 59, 68, 3] [0.88, 0.89, 0.9, 0.91, 0.93, 0.95, 1.78, 1.83]\n",
      "0 --> 109 \t 26 [23, 6, 119, 96, 111, 109, 0, 26] [0.96, 0.96, 0.96, 0.97, 0.97, 0.97, 1.93, 1.93]\n",
      "0 --> 0 \t 0 [20, 108, 85, 0] [0.98, 0.98, 0.98, 6.91]\n",
      "********************************************************************************\n",
      "5 0.50\n",
      "6 0.60\n",
      "9 0.90\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "amount = 10\n",
    "top1_count = 0\n",
    "topn_1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    item_main_x = np.array([x_train[idx]]*x_train.shape[0])\n",
    "    item_x_train = {\n",
    "        'main_input': item_main_x,\n",
    "        'library_input': x_train\n",
    "    }\n",
    "    y_proba = model.predict(item_x_train, batch_size=1024)\n",
    "    item_y_train = y_train[idx]\n",
    "    top1_pred = y_train[np.argmax(y_proba)]\n",
    "#     topn_pred_arr = [y_train[item[0]] for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    topn_pred_arr, class_score_arr = get_weight_topn(y_proba, topn, y_train)\n",
    "    topn_1_pred = topn_pred_arr[-1]\n",
    "    if item_y_train == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_train == topn_1_pred:\n",
    "        topn_1_count += 1\n",
    "    if item_y_train in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_train, '-->', top1_pred, '\\t', topn_1_pred, topn_pred_arr, class_score_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_1_count, '%.2f' % (topn_1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encupsolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (30, [0, 0, 54, 20, 0, 62, 0, 54, 85, 30], 0, [20, 62, 85, 30, 54, 0], [0.98, 0.98, 0.99, 0.99, 1.96, 3.92])\n",
      "0 (54, [54, 54, 62, 62, 87, 62, 54, 30, 54, 54], 54, [87, 30, 62, 54], [0.99, 0.99, 2.96, 4.95])\n"
     ]
    }
   ],
   "source": [
    "def get_single_pred(idx, main_x, libary_x, topn, batch_size=1024):\n",
    "    item_main_x = np.array([main_x[idx]]*libary_x.shape[0])\n",
    "    item_x = {\n",
    "        'main_input': item_main_x,\n",
    "        'library_input': libary_x\n",
    "    }\n",
    "    y_proba = model.predict(item_x, batch_size=batch_size)\n",
    "    top1_pred = y_train[np.argmax(y_proba)]\n",
    "    topn_pred_arr = [y_train[item[0]] for item in np.argsort(y_proba, axis=0)[-topn:]]\n",
    "    weighted_topn_pred_arr, class_score_arr = get_weight_topn(y_proba, topn, y_train)\n",
    "    weighted_top1_pred = weighted_topn_pred_arr[-1]\n",
    "    return top1_pred, topn_pred_arr, weighted_top1_pred, weighted_topn_pred_arr, class_score_arr\n",
    "\n",
    "idx = 0\n",
    "topn = 10\n",
    "# train\n",
    "print(y_train[idx], get_single_pred(idx, x_train, x_train, topn, batch_size=1024))\n",
    "# val\n",
    "print(y_val[idx], get_single_pred(idx, x_val, x_train, topn, batch_size=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 30 0 \t [20, 62, 85, 30, 54, 0] [0.98, 0.98, 0.99, 0.99, 1.96, 3.92]\n",
      "0 --> 0 0 \t [96, 30, 108, 109, 1, 23, 0] [0.95, 0.95, 0.95, 0.95, 0.96, 0.96, 3.86]\n",
      "0 --> 1 1 \t [97, 106, 30, 78, 1] [0.96, 0.97, 0.97, 0.97, 5.8]\n",
      "0 --> 6 6 \t [26, 79, 119, 0, 6] [0.98, 0.98, 1.97, 2.94, 2.96]\n",
      "0 --> 0 0 \t [85, 96, 26, 0] [0.99, 1.98, 1.98, 4.94]\n",
      "0 --> 0 0 \t [96, 26, 0] [0.97, 1.95, 6.83]\n",
      "0 --> 0 0 \t [64, 76, 78, 109, 20, 3, 0] [0.96, 0.96, 0.97, 0.97, 0.97, 0.97, 3.87]\n",
      "0 --> 59 3 \t [107, 77, 0, 48, 110, 59, 68, 3] [0.88, 0.89, 0.9, 0.91, 0.93, 0.95, 1.78, 1.83]\n",
      "0 --> 109 26 \t [23, 6, 119, 96, 111, 109, 0, 26] [0.96, 0.96, 0.96, 0.97, 0.97, 0.97, 1.93, 1.93]\n",
      "0 --> 0 0 \t [20, 108, 85, 0] [0.98, 0.98, 0.98, 6.91]\n",
      "********************************************************************************\n",
      "5 0.50\n",
      "6 0.60\n",
      "9 0.90\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "amount = 10\n",
    "top1_count = 0\n",
    "topn_1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    top1_pred, topn_pred_arr, weighted_top1_pred, weighted_topn_pred_arr, class_score_arr = get_single_pred(idx, x_train, x_train, topn, batch_size=1024)\n",
    "    \n",
    "    item_y_data = y_train[idx]\n",
    "    if item_y_data == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_data == weighted_top1_pred:\n",
    "        topn_1_count += 1\n",
    "    if item_y_data in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_data, '-->', top1_pred, weighted_top1_pred, '\\t', weighted_topn_pred_arr, class_score_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_1_count, '%.2f' % (topn_1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 54 54 \t [87, 30, 62, 54] [0.99, 0.99, 2.96, 4.95]\n",
      "0 --> 0 0 \t [26, 119, 96, 0] [0.99, 0.99, 1.98, 5.93]\n",
      "0 --> 70 0 \t [85, 20, 70, 109, 0] [0.97, 0.98, 1.96, 2.91, 2.92]\n",
      "0 --> 54 58 \t [78, 105, 54, 20, 58] [0.99, 0.99, 1.0, 2.97, 3.96]\n",
      "0 --> 70 87 \t [73, 85, 65, 70, 0, 30, 87] [0.98, 0.98, 0.99, 0.99, 1.97, 1.97, 1.97]\n",
      "0 --> 0 0 \t [85, 0] [0.97, 8.74]\n",
      "0 --> 0 0 \t [96, 26, 109, 0] [0.98, 0.98, 0.98, 6.87]\n",
      "0 --> 0 0 \t [26, 0] [0.98, 8.83]\n",
      "0 --> 85 73 \t [83, 110, 85, 70, 73] [0.97, 0.98, 0.98, 1.96, 4.89]\n",
      "0 --> 48 48 \t [107, 3, 102, 20, 0, 48] [0.93, 0.93, 0.94, 0.94, 2.81, 2.84]\n",
      "********************************************************************************\n",
      "4 0.40\n",
      "5 0.50\n",
      "7 0.70\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "amount = 10\n",
    "top1_count = 0\n",
    "topn_1_count = 0\n",
    "topn_count = 0\n",
    "for idx in range(amount):\n",
    "    top1_pred, topn_pred_arr, weighted_top1_pred, weighted_topn_pred_arr, class_score_arr = get_single_pred(idx, x_val, x_train, topn, batch_size=1024)\n",
    "    \n",
    "    item_y_data = y_val[idx]\n",
    "    if item_y_data == top1_pred:\n",
    "        top1_count += 1\n",
    "    if item_y_data == weighted_top1_pred:\n",
    "        topn_1_count += 1\n",
    "    if item_y_data in topn_pred_arr:\n",
    "        topn_count += 1\n",
    "    print(item_y_data, '-->', top1_pred, weighted_top1_pred, '\\t', weighted_topn_pred_arr, class_score_arr)\n",
    "\n",
    "print('*' * 80)\n",
    "print(top1_count, '%.2f' % (top1_count/amount))\n",
    "print(topn_1_count, '%.2f' % (topn_1_count/amount))\n",
    "print(topn_count, '%.2f' % (topn_count/amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog-Breed_4-Predict-Dog-Breed_3-Image-Similar-FCNN-Binary_20190501-194400_20190502-092437_7000\n"
     ]
    }
   ],
   "source": [
    "acc10000 = int(topn_count/amount*10000)\n",
    "# acc10000 = 10000 # for test\n",
    "# print(acc10000)\n",
    "if acc10000 == 10000:\n",
    "    run_name_acc = '%s_%05d' % (run_name, acc10000)\n",
    "else:\n",
    "    run_name_acc = '%s_%04d' % (run_name, acc10000)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 62.4s\n",
      "Dog-Breed_4-Predict-Dog-Breed_3-Image-Similar-FCNN-Binary_20190501-194400_20190502-092437_7000\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed: %.1fs' % (time.time() - t0))\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
