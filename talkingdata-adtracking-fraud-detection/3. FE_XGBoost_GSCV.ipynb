{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. FE_XGBoost_GSCV\n",
    "Kaggle score:\n",
    "\n",
    "pip install jupyter notebook tqdm pillow h5py seaborn scikit-learn scikit-image xgboost\n",
    "\n",
    "Abstract:\n",
    "- date 7, 8, 9少feature的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: TalkingdataAFD2018_FE_XGBoost_GSCV_20180506_180544\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'TalkingdataAFD2018'\n",
    "step_name = 'FE_XGBoost_GSCV'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = '%s_%s_%s' % (project_name, step_name, time_str)\n",
    "print('run_name: %s' % run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date:  100\n",
      "is_debug: False\n",
      "TalkingdataAFD2018_FE_XGBoost_20180506_180300_date100\n"
     ]
    }
   ],
   "source": [
    "feature_run_name = 'TalkingdataAFD2018_FeatureExtraction_20180501_185800'\n",
    "date = 100\n",
    "print('date: ', date)\n",
    "\n",
    "\n",
    "is_debug = False\n",
    "print('is_debug: %s' % is_debug)\n",
    "\n",
    "# epoch = 3\n",
    "# batch_size = 2000 * 10000\n",
    "# skip_data_len = (epoch - 1) * batch_size\n",
    "# data_len = batch_size\n",
    "# print('Echo: %s, Data rows: [%s, %s]' % (epoch, skip_data_len, skip_data_len + data_len))\n",
    "\n",
    "# epoch = 2\n",
    "# batch_size = 4000 * 10000\n",
    "# skip_data_len = 59633310 - batch_size\n",
    "# data_len = batch_size\n",
    "# print('batch_size: %s' % batch_size)\n",
    "# print('epoch: %s, data rows: [%s, %s]' % (epoch, skip_data_len, skip_data_len + data_len))\n",
    "\n",
    "# run_name = '%s_date%s%s' % (run_name, date, epoch)\n",
    "run_name = '%s_date%s' % (run_name, date)\n",
    "\n",
    "print(run_name)\n",
    "\n",
    "if is_debug:\n",
    "    test_n_rows = 1 * 10000\n",
    "else:\n",
    "    test_n_rows = None\n",
    "#     test_n_rows = 18790469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_rows = {\n",
    "    0: {\n",
    "        'n_skiprows': 1,\n",
    "        'n_rows': 1 * 1000\n",
    "    },\n",
    "    1: {\n",
    "        'n_skiprows': 1 * 1000,\n",
    "        'n_rows': 2 * 1000\n",
    "    },\n",
    "    6: {\n",
    "        'n_skiprows': 1,\n",
    "        'n_rows': 2 * 1000 # 9308568\n",
    "    },\n",
    "    7: {\n",
    "        'n_skiprows': 1 + 9308568,\n",
    "        'n_rows': 2 * 1000 # 59633310\n",
    "    },\n",
    "    8: {\n",
    "        'n_skiprows': 1 + 9308568 + 59633310,\n",
    "        'n_rows': 2 * 1000 # 62945075\n",
    "    },\n",
    "    9: {\n",
    "        'n_skiprows': 1 + 9308568 + 59633310 + 62945075,\n",
    "        'n_rows': 2 * 1000 # 53016937\n",
    "    }\n",
    "}\n",
    "# n_skiprows = day_rows[date]['n_skiprows']\n",
    "# n_rows = day_rows[date]['n_rows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount: 30\n",
      "random_num: 1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import zipfile\n",
    "import h5py\n",
    "import pickle\n",
    "import math\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_num = np.random.randint(10000)\n",
    "cpu_amount = cpu_count()\n",
    "\n",
    "print('cpu_amount: %s' % (cpu_amount - 2))\n",
    "print('random_num: %s' % random_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input\n",
      "output_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/output\n",
      "model_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/model\n",
      "feature_folder: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature\n",
      "log_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/log\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/train.csv\n",
      "train_sample_csv_file: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/train_sample.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/test.csv\n",
      "sample_submission_csv_file: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "train_sample_csv_file = os.path.join(input_folder, 'train_sample.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission.csv')\n",
    "\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('train_sample_csv_file: \\t\\t%s' % train_sample_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "print('sample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_csv.shape: \t (18790469, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0              0\n",
       "1         1              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv: 286.72 Mb\n"
     ]
    }
   ],
   "source": [
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "print('sample_submission_csv.shape: \\t', sample_submission_csv.shape)\n",
    "display(sample_submission_csv.head(2))\n",
    "\n",
    "print('train_csv: %.2f Mb' % (sys.getsizeof(sample_submission_csv)/1024./1024.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(x_data, y_data, file_name):\n",
    "    print(y_data[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: %s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('x_data', data=x_data)\n",
    "        h.create_dataset('y_data', data=y_data)\n",
    "    print('File saved:   %s' % file_name)\n",
    "\n",
    "def load_feature(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        x_data = np.array(h['x_data'])\n",
    "        y_data = np.array(h['y_data'])\n",
    "    print('File loaded:  %s' % file_name)\n",
    "    print(y_data[:5])\n",
    "    \n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "def save_test_feature(x_test, click_ids, file_name):\n",
    "    print(click_ids[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: %s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('x_test', data=x_test)\n",
    "        h.create_dataset('click_ids', data=click_ids)\n",
    "    print('File saved:   %s' % file_name)\n",
    "\n",
    "def load_test_feature(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        x_test = np.array(h['x_test'])\n",
    "        click_ids = np.array(h['click_ids'])\n",
    "    print('File loaded:  %s' % file_name)\n",
    "    print(click_ids[:5])\n",
    "    \n",
    "    return x_test, click_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature_map(feature_map, file_name):\n",
    "    print(feature_map[:5])\n",
    "    feature_map_encode = []\n",
    "    for item in feature_map:\n",
    "        feature_name_encode = item[1].encode('UTF-8')\n",
    "        feature_map_encode.append((item[0], feature_name_encode))\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('feature_map', data=feature_map_encode)\n",
    "    print('File saved: \\t%s' % file_name)\n",
    "\n",
    "def load_feature_map(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        feature_map_encode = np.array(h['feature_map'])\n",
    "    print('File loaded: \\t%s' % file_name)\n",
    "    feature_map = []\n",
    "    for item in feature_map_encode:\n",
    "        feature_name = item[1].decode('UTF-8')\n",
    "        feature_map.append((int(item[0]), feature_name))\n",
    "    print(feature_map[:5])\n",
    "    \n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10) \t0.38 Mb\n",
      "5000 \t\t0.04 Mb\n"
     ]
    }
   ],
   "source": [
    "def describe(data):\n",
    "    if isinstance(data, list):\n",
    "        print(len(data), '\\t\\t%.2f Mb' % (sys.getsizeof(data)/1024./1024.))\n",
    "    else:\n",
    "        print(data.shape, '\\t%.2f Mb' % (sys.getsizeof(data)/1024./1024.))\n",
    "\n",
    "test_np = np.ones((5000, 10))\n",
    "describe(test_np)\n",
    "describe(list(range(5000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded:  /data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_20180501_185800_date7.p\n",
      "[0 0 0 0 0]\n",
      "File loaded:  /data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_20180501_185800_date8.p\n",
      "[0 0 0 0 0]\n",
      "File loaded:  /data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_20180501_185800_date9.p\n",
      "[0 0 0 0 0]\n",
      "File loaded:  /data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_20180501_185800_date6.p\n",
      "[0 0 0 0 0]\n",
      "********************************************************************************\n",
      "(175595322, 34) \t45549.32 Mb\n",
      "(175595322,) \t167.46 Mb\n",
      "(9308568, 34) \t2414.64 Mb\n",
      "(9308568,) \t8.88 Mb\n",
      "CPU times: user 16.2 s, sys: 40.4 s, total: 56.6 s\n",
      "Wall time: 56.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "feature_files = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "if date == 100:\n",
    "    for key in [7, 8, 9]:\n",
    "        y_proba_file = os.path.join(feature_folder, 'feature_%s_date%s.p' % (feature_run_name, key))\n",
    "        feature_files.append(y_proba_file)\n",
    "        x_train_date, y_train_date = load_feature(y_proba_file)\n",
    "        x_train.append(x_train_date)\n",
    "        y_train.append(y_train_date)\n",
    "    x_train = np.concatenate(x_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "else:\n",
    "    y_proba_file = os.path.join(feature_folder, 'feature_%s_date%s.p' % (feature_run_name, date))\n",
    "    feature_files.append(y_proba_file)\n",
    "    x_train, y_train = load_feature(y_proba_file)\n",
    "\n",
    "# Use date 6 as validation dataset\n",
    "y_proba_file = os.path.join(feature_folder, 'feature_%s_date%s.p' % (feature_run_name, 6))\n",
    "feature_files.append(y_proba_file)\n",
    "x_val, y_val = load_feature(y_proba_file)\n",
    "\n",
    "\n",
    "print('*' * 80)\n",
    "describe(x_train)\n",
    "describe(y_train)\n",
    "describe(x_val)\n",
    "describe(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175595322, 34) \t45549.32 Mb\n",
      "(175595322,) \t167.46 Mb\n",
      "(9308568, 34) \t2414.64 Mb\n",
      "(9308568,) \t8.88 Mb\n",
      "CPU times: user 36.6 s, sys: 10.5 s, total: 47.1 s\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_data[skip_data_len: data_len], y_data[skip_data_len: data_len], test_size=0.1, random_state=random_num, shuffle=True)\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=random_num, shuffle=False)\n",
    "\n",
    "# x_train = x_train[skip_data_len: skip_data_len + data_len]\n",
    "# y_train = y_train[skip_data_len: skip_data_len + data_len]\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=random_num)\n",
    "describe(x_train)\n",
    "describe(y_train)\n",
    "describe(x_val)\n",
    "describe(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    max_depth=20, \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=5000, \n",
    "    silent=False, \n",
    "    objective='gpu:binary:logistic', \n",
    "    booster='gbtree', \n",
    "#     n_jobs=1, \n",
    "    nthread=None, \n",
    "    gamma=0, \n",
    "    min_child_weight=1, \n",
    "    max_delta_step=0, \n",
    "    subsample=0.5, \n",
    "    colsample_bytree=0.7, \n",
    "    colsample_bylevel=0.7, \n",
    "    reg_alpha=0, \n",
    "    reg_lambda=1, \n",
    "    scale_pos_weight=97, \n",
    "    base_score=0.5, \n",
    "    random_state=0, \n",
    "    seed=None, \n",
    "    missing=None,\n",
    "    # booster params\n",
    "    num_boost_round=50,\n",
    "    early_stopping_rounds=30,\n",
    "    tree_method='gpu_hist',\n",
    "    predictor='gpu_predictor',\n",
    "    eval_metric=['auc'],\n",
    "\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'reg_alpha':[0.3], \n",
    "    'reg_lambda':[0.8],\n",
    "    'scale_pos_weight': [1, 98, 200]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameters, verbose=2, cv=3)\n",
    "grid_search.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 80)\n",
    "y_train_proba = grid_search.predict_proba(x_train)\n",
    "print(y_train_proba.shape)\n",
    "print(y_train_proba[:10])\n",
    "y_train_pred = (y_train_proba[:, 1]>=0.5).astype(int)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "roc_train = roc_auc_score(y_train, y_train_proba[:, 1])\n",
    "print('acc_train: %.4f \\t roc_train: %.4f' % (acc_train, roc_train))\n",
    "\n",
    "# y_train_pred = grid_search.predict(x_train)\n",
    "# acc_train = accuracy_score(y_train, y_train_pred)\n",
    "# roc_train = roc_auc_score(y_train, y_train_proba[:, 1])\n",
    "# print('acc_train: %.4f \\t roc_train: %.4f' % (acc_train, roc_train))\n",
    "\n",
    "y_val_proba = grid_search.predict_proba(x_val)\n",
    "print(y_val_proba.shape)\n",
    "print(y_val_proba[:10])\n",
    "y_val_pred = (y_val_proba[:, 0]>=0.5).astype(int)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "roc_val = roc_auc_score(y_val, y_val_proba[:, 1])\n",
    "print('acc_val:   %.4f \\t roc_val:   %.4f' % (acc_val, roc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = best_estimator_.get_boostor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,int(x_train.shape[1]/2)))\n",
    "plot_importance(xgboost_model, height=0.5, ax=ax, max_num_features=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_file_name = os.path.join(feature_folder, 'feature_map_TalkingdataAFD2018_FeatureExtraction_test_20180501_143516.p')\n",
    "\n",
    "feature_map = load_feature_map(feature_map_file_name)\n",
    "print(len(feature_map))\n",
    "print(feature_map[:5])\n",
    "\n",
    "feature_dict = {}\n",
    "for item in feature_map:\n",
    "    feature_dict[item[0]] = item[1]\n",
    "print(list(feature_dict.keys())[:5])\n",
    "print(list(feature_dict.values())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(grid_search.best_estimator_.get_booster()))\n",
    "importance_score = xgboost_model.get_fscore()\n",
    "sorted_score = []\n",
    "for key in importance_score:\n",
    "    indx = int(key[1:])\n",
    "    sorted_score.append((importance_score[key], key, indx, feature_dict[indx]))\n",
    "dtype = [('importance_score', int), ('key', 'S50'), ('indx', int), ('name', 'S50')]\n",
    "importance_table = np.array(sorted_score, dtype=dtype)\n",
    "display(importance_table[:2])\n",
    "importance_table = np.sort(importance_table, axis=0, order=['importance_score'])\n",
    "importance_table = importance_table[::-1]\n",
    "display(importance_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del x_train\n",
    "# del y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_acc = run_name + '_' + str(int(roc_val*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_proba_file = os.path.join(feature_folder, 'feature_%s_test.p' % feature_run_name)\n",
    "feature_files.append(y_proba_file)\n",
    "x_test, click_ids = load_test_feature(y_proba_file)\n",
    "\n",
    "describe(x_test)\n",
    "describe(click_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = grid_search.predict_proba(x_test)\n",
    "\n",
    "print(y_test_proba.shape)\n",
    "print(y_test_proba[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_proba(y_val_proba, y_val, y_test_proba, click_ids, file_name):\n",
    "    print(click_ids[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: %s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "#         h.create_dataset('y_train_proba', data=y_train_proba)\n",
    "#         h.create_dataset('y_train', data=y_train)\n",
    "        h.create_dataset('y_val_proba', data=y_val_proba)\n",
    "        h.create_dataset('y_val', data=y_val)\n",
    "        h.create_dataset('y_test_proba', data=y_test_proba)\n",
    "        h.create_dataset('click_ids', data=click_ids)\n",
    "    print('File saved:   %s' % file_name)\n",
    "\n",
    "def load_proba(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "#         y_train_proba = np.array(h['y_train_proba'])\n",
    "#         y_train = np.array(h['y_train'])\n",
    "        y_val_proba = np.array(h['y_val_proba'])\n",
    "        y_val = np.array(h['y_val'])\n",
    "        y_test_proba = np.array(h['y_test_proba'])\n",
    "        click_ids = np.array(h['click_ids'])\n",
    "    print('File loaded:  %s' % file_name)\n",
    "    print(click_ids[:5])\n",
    "    \n",
    "    return y_val_proba, y_val, y_test_proba, click_ids\n",
    "\n",
    "\n",
    "y_proba_file = os.path.join(model_folder, 'proba_%s.p' % run_name_acc)\n",
    "print(y_proba_file)\n",
    "save_proba(\n",
    "#     y_train_proba, \n",
    "#     y_train, \n",
    "    y_val_proba, \n",
    "    y_val, \n",
    "    y_test_proba, \n",
    "    np.array(sample_submission_csv['click_id']), \n",
    "    y_proba_file\n",
    ")\n",
    "y_val_proba_true, y_val, y_test_proba_true, click_ids = load_proba(y_proba_file)\n",
    "\n",
    "# print(y_train_proba_true.shape)\n",
    "# print(y_train.shape)\n",
    "print(y_val_proba_true.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test_proba_true.shape)\n",
    "print(len(click_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "submission_csv_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "print(submission_csv_file)\n",
    "submission_csv = pd.DataFrame({ 'click_id': click_ids , 'is_attributed': y_test_proba_true })\n",
    "submission_csv.to_csv(submission_csv_file, index = False)\n",
    "display(submission_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "\n",
    "print('random_num: ', random_num)\n",
    "print('date: ', date)\n",
    "print(run_name_acc)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
