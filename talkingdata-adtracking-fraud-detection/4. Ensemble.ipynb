{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble\n",
    "\n",
    "Kaggle score: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: TalkingdataAFD2018_Ensemble_20180507_223338\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'TalkingdataAFD2018'\n",
    "step_name = 'Ensemble'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = '%s_%s_%s' % (project_name, step_name, time_str)\n",
    "print('run_name: %s' % run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_num:  5998\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "statistics_type = 'val_roc_mean'\n",
    "\n",
    "random_num = random.randint(1, 10000)\n",
    "print('random_num: ', random_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import zipfile\n",
    "import h5py\n",
    "import pickle\n",
    "import math\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "cpu_amount = cpu_count()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_folder: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature\n",
      "input_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input\n",
      "log_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/log\n",
      "model_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/model\n",
      "output_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/output\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/train.csv\n",
      "train_sample_csv_file: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/train_sample.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/test.csv\n",
      "sample_submission_csv_file: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "train_sample_csv_file = os.path.join(input_folder, 'train_sample.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission.csv')\n",
    "\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('train_sample_csv_file: \\t\\t%s' % train_sample_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "print('sample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predict probability files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: proba_TalkingdataAFD2018_FE_XGBoost_20180506_233145_date100_9772.p\n",
      "File exists: proba_TalkingdataAFD2018_FE_XGBoost_20180507_065745_date100_9768.p\n",
      "File exists: proba_TalkingdataAFD2018_FE_XGBoost_20180507_090216_date100_9774.p\n",
      "File exists: proba_TalkingdataAFD2018_FE_XGBoost_20180506_204229_date100_9722.p\n",
      "File exists: proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180501_110046_date7_9680.p\n"
     ]
    }
   ],
   "source": [
    "ori_proba_files = [\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180429_063128_9748.p', 'kaggle_score': 0.17812},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180429_101701_date71_9527.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180429_111325_date71_9584.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180429_114421_date71_9493.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180430_074910_date71_9560.p'},\n",
    "    \n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180430_105818_date71_9633.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180430_092846_date71_9621.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180430_084725_date71_9604.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180430_114955_date71_9643.p'},\n",
    "#     { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBoost_20180506_204229_date100_9722.p'},\n",
    "    { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBoost_20180506_233145_date100_9772.p'},\n",
    "    { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBoost_20180507_065745_date100_9768.p'},\n",
    "    \n",
    "    { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBoost_20180507_090216_date100_9774.p'},\n",
    "    { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBoost_20180506_204229_date100_9722.p'},\n",
    "    { 'file_name': 'proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180501_110046_date7_9680.p'},\n",
    "    \n",
    "]\n",
    "\n",
    "for file in ori_proba_files:\n",
    "    if os.path.exists(os.path.join(model_folder, file['file_name'])):\n",
    "        print('File exists: %s' % file['file_name'])\n",
    "    else:\n",
    "        print('***File do not exists: %s' % file['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/model/proba_TalkingdataAFD2018_FE_XGBoost_20180506_233145_date100_9772.p\n",
      "[0 1 2 3 4]\n",
      "1\n",
      "(9308568,)\n",
      "(9308568,)\n",
      "(18790469,)\n",
      "18790469\n",
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/model/proba_TalkingdataAFD2018_FE_XGBoost_20180507_065745_date100_9768.p\n",
      "[0 1 2 3 4]\n",
      "1\n",
      "(9308568,)\n",
      "(9308568,)\n",
      "(18790469,)\n",
      "18790469\n",
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/model/proba_TalkingdataAFD2018_FE_XGBoost_20180507_090216_date100_9774.p\n",
      "[0 1 2 3 4]\n",
      "1\n",
      "(9308568,)\n",
      "(9308568,)\n",
      "(18790469,)\n",
      "18790469\n",
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/model/proba_TalkingdataAFD2018_FE_XGBoost_20180506_204229_date100_9722.p\n",
      "[0 1 2 3 4]\n",
      "1\n",
      "(9308568,)\n",
      "(9308568,)\n",
      "(18790469,)\n",
      "18790469\n",
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/model/proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180501_110046_date7_9680.p\n",
      "[0 1 2 3 4]\n",
      "2\n",
      "(9308568,)\n",
      "(9308568,)\n",
      "(18790469,)\n",
      "18790469\n",
      "proba_TalkingdataAFD2018_FE_XGBoost_20180506_233145_date100_9772.p 0.9848 0.9773\n",
      "proba_TalkingdataAFD2018_FE_XGBoost_20180507_065745_date100_9768.p 0.9879 0.9769\n",
      "proba_TalkingdataAFD2018_FE_XGBoost_20180507_090216_date100_9774.p 0.9866 0.9774\n",
      "proba_TalkingdataAFD2018_FE_XGBoost_20180506_204229_date100_9722.p 0.9674 0.9723\n",
      "proba_TalkingdataAFD2018_FE_XGBClassifier_GSCV_20180501_110046_date7_9680.p 0.9646 0.9681\n",
      "CPU times: user 20 s, sys: 2.32 s, total: 22.3 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def save_proba(y_val_proba, y_val, y_test_proba, click_ids, file_name):\n",
    "    print(click_ids[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "#         h.create_dataset('y_train_proba', data=y_train_proba)\n",
    "#         h.create_dataset('y_train', data=y_train)\n",
    "        h.create_dataset('y_val_proba', data=y_val_proba)\n",
    "        h.create_dataset('y_val', data=y_val)\n",
    "        h.create_dataset('y_test_proba', data=y_test_proba)\n",
    "        h.create_dataset('click_ids', data=click_ids)\n",
    "    print('File saved: \\t%s' % file_name)\n",
    "\n",
    "def load_proba(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "#         y_train_proba = np.array(h['y_train_proba'])\n",
    "#         y_train = np.array(h['y_train'])\n",
    "        y_val_proba = np.array(h['y_val_proba'])\n",
    "        y_val = np.array(h['y_val'])\n",
    "        y_test_proba = np.array(h['y_test_proba'])\n",
    "        click_ids = np.array(h['click_ids'])\n",
    "    print('File loaded: \\t%s' % file_name)\n",
    "    print(click_ids[:5])\n",
    "    \n",
    "    return y_val_proba, y_val, y_test_proba, click_ids\n",
    "\n",
    "\n",
    "def get_acc(y_pred, y_proba):\n",
    "    y_hat = (y_proba>=0.5).astype(int)\n",
    "    return accuracy_score(y_pred, y_hat)\n",
    "\n",
    "def get_roc(y_pred, y_proba):\n",
    "    return roc_auc_score(y_pred, y_proba)\n",
    "\n",
    "\n",
    "y_train_probas = []\n",
    "y_trains = []\n",
    "y_val_probas = []\n",
    "y_vas = []\n",
    "y_test_probas = []\n",
    "for file in ori_proba_files:\n",
    "    y_proba_file = os.path.join(model_folder, file['file_name'])\n",
    "    y_val_proba, y_val, y_test_proba, click_ids = load_proba(y_proba_file)\n",
    "#     print(y_train_proba.shape)\n",
    "#     print(y_train.shape)\n",
    "#     y_train_probas.append(y_train_proba)\n",
    "    print(len(y_val_proba.shape))\n",
    "    if len(y_val_proba.shape) == 2:\n",
    "        y_val_proba = y_val_proba[:, 1]\n",
    "        y_test_proba = y_test_proba[:, 1]\n",
    "    print(y_val_proba.shape)\n",
    "    print(y_val.shape)\n",
    "    print(y_test_proba.shape)\n",
    "    print(len(click_ids))\n",
    "    y_val_probas.append(y_val_proba)\n",
    "    y_test_probas.append(y_test_proba)\n",
    "#     file['train_acc'] = get_acc(y_train, y_train_proba)\n",
    "    file['acc_val'] = get_acc(y_val, y_val_proba)\n",
    "    \n",
    "#     file['train_roc'] = get_roc(y_train, y_train_proba)\n",
    "    file['roc_val'] = get_roc(y_val, y_val_proba)\n",
    "\n",
    "for f in ori_proba_files:\n",
    "    print(f['file_name'], '%.4f' % f['acc_val'], '%.4f' % f['roc_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic statistical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****probas_mean.shape: \t (9308568,)\n",
      "*****probas_mean.shape: \t (18790469,)\n",
      "CPU times: user 3.64 s, sys: 356 ms, total: 4 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_mean(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_mean = np.mean(probas_newaxis, axis=-1)\n",
    "    print('probas_mean.shape: \\t', probas_mean.shape)\n",
    "    return probas_mean\n",
    "\n",
    "# ensemble_res['train_roc_mean'] = get_roc(y_train ,get_mean(y_train_probas))\n",
    "ensemble_res['val_roc_mean'] = get_roc(y_val ,get_mean(y_val_probas))\n",
    "y_test_proba_mean = get_mean(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****probas_min.shape: \t (9308568,)\n",
      "*****probas_min.shape: \t (18790469,)\n",
      "CPU times: user 3.98 s, sys: 356 ms, total: 4.34 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_min(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_min = np.min(probas_newaxis, axis=-1)\n",
    "    print('probas_min.shape: \\t', probas_min.shape)\n",
    "    return probas_min\n",
    "\n",
    "# ensemble_res['train_roc_min'] = get_roc(y_train ,get_min(y_train_probas))\n",
    "ensemble_res['val_roc_min'] = get_roc(y_val ,get_min(y_val_probas))\n",
    "y_test_proba_min = get_min(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****probas_max.shape: \t (9308568,)\n",
      "*****probas_max.shape: \t (18790469,)\n",
      "CPU times: user 4.08 s, sys: 312 ms, total: 4.39 s\n",
      "Wall time: 4.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_max(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_max = np.max(probas_newaxis, axis=-1)\n",
    "    print('probas_max.shape: \\t', probas_max.shape)\n",
    "    return probas_max\n",
    "\n",
    "# ensemble_res['train_roc_max'] = get_roc(y_train ,get_max(y_train_probas))\n",
    "ensemble_res['val_roc_max'] = get_roc(y_val ,get_max(y_val_probas))\n",
    "y_test_proba_max = get_max(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****probas_median.shape: \t (9308568,)\n",
      "*****probas_median.shape: \t (18790469,)\n",
      "CPU times: user 5.58 s, sys: 556 ms, total: 6.14 s\n",
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_median(probas):\n",
    "    probas_newaxises = []\n",
    "    for p in probas:\n",
    "        print('*', end='')\n",
    "        probas_newaxises.append(p[:, np.newaxis])\n",
    "    probas_newaxis = np.concatenate(probas_newaxises, axis=-1)\n",
    "    probas_median = np.median(probas_newaxis, axis=-1)\n",
    "    print('probas_median.shape: \\t', probas_median.shape)\n",
    "    return probas_median\n",
    "\n",
    "# ensemble_res['train_roc_median'] = get_roc(y_train ,get_median(y_train_probas))\n",
    "ensemble_res['val_roc_median'] = get_roc(y_val ,get_median(y_val_probas))\n",
    "y_test_proba_median = get_median(y_test_probas)\n",
    "\n",
    "# print(ensemble_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_roc_mean    \t0.9756\n",
      "val_roc_min     \t0.9773\n",
      "val_roc_max     \t0.9718\n",
      "val_roc_median  \t0.9773\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(ensemble_res.keys()):\n",
    "#     if i % 2 == 0:\n",
    "#         print('%-15s \\t%.4f' % (key, ensemble_res[key]), end='\\t')\n",
    "#     else:\n",
    "#         print('%-15s \\t%.4f' % (key, ensemble_res[key]))\n",
    "    print('%-15s \\t%.4f' % (key, ensemble_res[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****probas_mean.shape: \t (9308568,)\n",
      "*****probas_min.shape: \t (9308568,)\n",
      "*****probas_max.shape: \t (9308568,)\n",
      "*****probas_median.shape: \t (9308568,)\n",
      "(37234272,)\n",
      "*****probas_mean.shape: \t (18790469,)\n",
      "*****probas_min.shape: \t (18790469,)\n",
      "*****probas_max.shape: \t (18790469,)\n",
      "*****probas_median.shape: \t (18790469,)\n",
      "(75161876,)\n"
     ]
    }
   ],
   "source": [
    "# Exclude y_train, becourse x_train batch is not align\n",
    "# y_train_probas_sta = np.concatenate([\n",
    "#     get_mean(y_train_probas), \n",
    "#     get_min(y_train_probas), \n",
    "#     get_max(y_train_probas), \n",
    "#     get_median(y_train_probas)\n",
    "# ], axis=-1)\n",
    "# print(y_train_probas_sta.shape)\n",
    "\n",
    "y_val_probas_sta = np.concatenate([\n",
    "    get_mean(y_val_probas), \n",
    "    get_min(y_val_probas), \n",
    "    get_max(y_val_probas), \n",
    "    get_median(y_val_probas)\n",
    "], axis=-1)\n",
    "print(y_val_probas_sta.shape)\n",
    "\n",
    "y_test_probas_sta = np.concatenate([\n",
    "    get_mean(y_test_probas), \n",
    "    get_min(y_test_probas), \n",
    "    get_max(y_test_probas), \n",
    "    get_median(y_test_probas)\n",
    "], axis=-1)\n",
    "print(y_test_probas_sta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_probas_sta = y_train_probas_sta.copy()\n",
    "# y_train = y_train.copy()\n",
    "# y_val_probas_sta = y_val_probas_sta.copy()\n",
    "# y_val = y_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# clf = xgb.XGBClassifier(\n",
    "#     max_depth=5, \n",
    "#     learning_rate=0.1, \n",
    "#     n_estimators=1000, \n",
    "#     silent=False, \n",
    "#     objective='gpu:multi:softmax', \n",
    "#     booster='gbtree', \n",
    "#     n_jobs=2, \n",
    "#     nthread=None, \n",
    "#     gamma=0, \n",
    "#     min_child_weight=1, \n",
    "#     max_delta_step=0, \n",
    "#     subsample=0.7, \n",
    "#     colsample_bytree=0.3, \n",
    "#     colsample_bylevel=0.3, \n",
    "#     reg_alpha=1, \n",
    "#     reg_lambda=5, \n",
    "#     scale_pos_weight=97, \n",
    "#     base_score=0.5, \n",
    "#     random_state=random_num, \n",
    "#     seed=None, \n",
    "#     missing=None,\n",
    "#     # booster params\n",
    "#     num_boost_round=50,\n",
    "# #     early_stopping_rounds=10,\n",
    "#     tree_method='gpu_hist',\n",
    "# #     predictor='gpu_predictor',\n",
    "#     eval_metric=['merror', 'mlogloss']\n",
    "# )\n",
    "\n",
    "# parameters = {\n",
    "#     'max_depth': [3, 4],\n",
    "# #     'learning_rate': [0.1],\n",
    "#     'reg_alpha': [2, 5],\n",
    "#     'reg_lambda': [7, 15],\n",
    "# #     'scale_pos_weight': [1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(clf, parameters, verbose=2, cv=4, scoring='accuracy', return_train_score=True)\n",
    "# grid_search.fit(y_train_probas_sta, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = grid_search.predict(y_train_probas_sta)\n",
    "# acc_train = accuracy_score(y_train, y_train_pred)\n",
    "# print('acc_train: %.4f' % acc_train)\n",
    "\n",
    "# y_val_pred = grid_search.predict(y_val_probas_sta)\n",
    "# acc_val = accuracy_score(y_val, y_val_pred)\n",
    "# print('acc_val:   %.4f' % acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid_search.cv_results_)\n",
    "# print(grid_search.grid_scores_ )\n",
    "# print(grid_search.best_estimator_)\n",
    "# print(grid_search.best_score_)\n",
    "# print(grid_search.best_params_)\n",
    "# print(grid_search.scorer_)\n",
    "# print('*' * 60)\n",
    "# print(type(grid_search.best_estimator_))\n",
    "# print(dir(grid_search.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred = grid_search.predict(y_test_probas_sta)\n",
    "# print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18790469,)\n"
     ]
    }
   ],
   "source": [
    "if statistics_type == 'val_roc_mean':\n",
    "    y_test_proba_final = y_test_proba_mean\n",
    "elif statistics_type == 'val_roc_min':\n",
    "    y_test_proba_final = y_test_proba_min\n",
    "elif statistics_type == 'val_roc_max':\n",
    "    y_test_proba_final = y_test_proba_max\n",
    "else: \n",
    "    # statistics_type == 'val_roc_median'\n",
    "    y_test_proba_final = y_test_proba_median\n",
    "print(y_test_proba_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TalkingdataAFD2018_Ensemble_20180507_223338_9755\n"
     ]
    }
   ],
   "source": [
    "run_name_acc = run_name + '_' + str(int(ensemble_res[statistics_type]*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/kaggle/talkingdata-adtracking-fraud-detection/output/pred_TalkingdataAFD2018_Ensemble_20180507_223338_9755.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.243868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0       0.243868\n",
       "1         1       0.003056\n",
       "2         2       0.001123\n",
       "3         3       0.005200\n",
       "4         4       0.009790"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "submission_csv_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "print(submission_csv_file)\n",
    "submission_csv = pd.DataFrame({ 'click_id': click_ids , 'is_attributed': y_test_proba_final })\n",
    "submission_csv.to_csv(submission_csv_file, index = False)\n",
    "display(submission_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 295.70 s\n",
      "random_num:  5998\n",
      "TalkingdataAFD2018_Ensemble_20180507_223338_9755\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "\n",
    "print('random_num: ', random_num)\n",
    "print(run_name_acc)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
