{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XGBClassifier_GPU\n",
    "**Start from the most basic features, and try to improve step by step.**\n",
    "Reference:\n",
    "- XGBoost Parameters, http://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters\n",
    "- Python API Reference, http://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "- https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: TalkingdataAFD2018_XGBClassifier_GPU_20180426_205343\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'TalkingdataAFD2018'\n",
    "step_name = 'XGBClassifier_GPU'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = '%s_%s_%s' % (project_name, step_name, time_str)\n",
    "print('run_name: %s' % run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 6\n",
    "print('date: ', date)\n",
    "\n",
    "test_n_rows = None\n",
    "# test_n_rows = 18790469\n",
    "# test_n_rows = 10*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_rows = {\n",
    "    0: {\n",
    "        'n_skiprows': 1,\n",
    "        'n_rows': 10 * 10000\n",
    "    },\n",
    "    6: {\n",
    "        'n_skiprows': 1,\n",
    "        'n_rows': 9308568\n",
    "    },\n",
    "    7: {\n",
    "        'n_skiprows': 1 + 9308568,\n",
    "        'n_rows': 59633310\n",
    "    },\n",
    "    8: {\n",
    "        'n_skiprows': 1 + 9308568 + 59633310,\n",
    "        'n_rows': 62945075\n",
    "    },\n",
    "    9: {\n",
    "        'n_skiprows': 1 + 9308568 + 59633310 + 62945075,\n",
    "        'n_rows': 53016937\n",
    "    }\n",
    "}\n",
    "n_skiprows = day_rows[date]['n_skiprows']\n",
    "n_rows = day_rows[date]['n_rows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import zipfile\n",
    "import h5py\n",
    "import pickle\n",
    "import math\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_num = np.random.randint(10000)\n",
    "print('random_num: %s' % random_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "train_sample_csv_file = os.path.join(input_folder, 'train_sample.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission.csv')\n",
    "\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('train_sample_csv_file: \\t\\t%s' % train_sample_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "print('sample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_columns  = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']\n",
    "dtypes = {\n",
    "    'ip'            : 'uint32',\n",
    "    'app'           : 'uint16',\n",
    "    'device'        : 'uint16',\n",
    "    'os'            : 'uint16',\n",
    "    'channel'       : 'uint16',\n",
    "    'is_attributed' : 'uint8',\n",
    "    'click_id'      : 'uint32'\n",
    "}\n",
    "\n",
    "train_csv = pd.read_csv(\n",
    "    train_csv_file, \n",
    "    skiprows=range(1, n_skiprows), \n",
    "    nrows=n_rows, \n",
    "    usecols=train_columns,\n",
    "    dtype=dtypes,\n",
    "    parse_dates=['click_time']\n",
    ")\n",
    "test_csv = pd.read_csv(\n",
    "    test_csv_file, \n",
    "    nrows=test_n_rows, \n",
    "    usecols=test_columns,\n",
    "    dtype=dtypes,\n",
    "    parse_dates=['click_time']\n",
    ")\n",
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "\n",
    "print('train_csv.shape: \\t\\t', train_csv.shape)\n",
    "print('test_csv.shape: \\t\\t', test_csv.shape)\n",
    "print('sample_submission_csv.shape: \\t', sample_submission_csv.shape)\n",
    "print('train_csv.dtypes: \\n', train_csv.dtypes)\n",
    "\n",
    "display(train_csv.head(2))\n",
    "display(test_csv.head(2))\n",
    "display(sample_submission_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = train_csv['is_attributed']\n",
    "train_csv.drop(['is_attributed'], axis=1, inplace=True)\n",
    "display(y_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['day'] = train_csv['click_time'].dt.day.astype('uint8')\n",
    "train_csv['hour'] = train_csv['click_time'].dt.hour.astype('uint8')\n",
    "train_csv['minute'] = train_csv['click_time'].dt.minute.astype('uint8')\n",
    "train_csv['second'] = train_csv['click_time'].dt.second.astype('uint8')\n",
    "print('train_csv.shape: \\t', train_csv.shape)\n",
    "display(train_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['day'] = test_csv['click_time'].dt.day.astype('uint8')\n",
    "test_csv['hour'] = test_csv['click_time'].dt.hour.astype('uint8')\n",
    "test_csv['minute'] = test_csv['click_time'].dt.minute.astype('uint8')\n",
    "test_csv['second'] = test_csv['click_time'].dt.second.astype('uint8')\n",
    "print('test_csv.shape: \\t', test_csv.shape)\n",
    "display(test_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[3,6,6],[4,5,1]])\n",
    "print(arr)\n",
    "np.ravel_multi_index(arr, (7,6))\n",
    "print(arr)\n",
    "print(np.ravel_multi_index(arr, (7,6), order='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_counts(df, cols, tag=\"_count\"):\n",
    "    arr_slice = df[cols].values\n",
    "    unq, unqtags, counts = np.unique(\n",
    "        np.ravel_multi_index(arr_slice.T, arr_slice.max(0) + 1), \n",
    "        return_inverse=True, \n",
    "        return_counts=True\n",
    "    )\n",
    "    df[\"_\".join(cols) + tag] = counts[unqtags]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_uniques(df, cols, tag=\"_unique\"):\n",
    "    gp = df[cols] \\\n",
    "        .groupby(by=cols[0:len(cols) - 1])[cols[len(cols) - 1]] \\\n",
    "        .nunique() \\\n",
    "        .reset_index() \\\n",
    "        .rename(index=str, columns={cols[len(cols) - 1]: \"_\".join(cols)+tag})\n",
    "    df = df.merge(gp, on=cols[0:len(cols) - 1], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = df_add_counts(train_csv, ['ip', 'day', 'hour'])\n",
    "train_csv = df_add_counts(train_csv, ['ip', 'app'])\n",
    "train_csv = df_add_counts(train_csv, ['ip', 'app', 'os'])\n",
    "train_csv = df_add_counts(train_csv, ['ip', 'device'])\n",
    "train_csv = df_add_counts(train_csv, ['app', 'channel'])\n",
    "train_csv = df_add_uniques(train_csv, ['ip', 'channel'])\n",
    "train_csv = df_add_uniques(train_csv, ['ip', 'app', 'device', 'os', 'channel'])\n",
    "train_csv = df_add_uniques(train_csv, ['ip', 'os', 'device'])\n",
    "train_csv = df_add_uniques(train_csv, ['ip', 'os', 'device', 'app'])\n",
    "\n",
    "display(train_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = df_add_counts(test_csv, ['ip', 'day', 'hour'])\n",
    "test_csv = df_add_counts(test_csv, ['ip', 'app'])\n",
    "test_csv = df_add_counts(test_csv, ['ip', 'app', 'os'])\n",
    "test_csv = df_add_counts(test_csv, ['ip', 'device'])\n",
    "test_csv = df_add_counts(test_csv, ['app', 'channel'])\n",
    "test_csv = df_add_uniques(test_csv, ['ip', 'channel'])\n",
    "test_csv = df_add_uniques(test_csv, ['ip', 'app', 'device', 'os', 'channel'])\n",
    "test_csv = df_add_uniques(test_csv, ['ip', 'os', 'device'])\n",
    "test_csv = df_add_uniques(test_csv, ['ip', 'os', 'device', 'app'])\n",
    "\n",
    "display(test_csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_useless_features = ['click_time']\n",
    "train_csv.drop(train_useless_features, axis=1, inplace=True)\n",
    "\n",
    "test_useless_features = ['click_time', 'click_id']\n",
    "test_csv.drop(test_useless_features, axis=1, inplace=True)\n",
    "\n",
    "display(train_csv.head())\n",
    "display(test_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_csv, y_data, test_size=0.01, random_state=2017)\n",
    "x_test = test_csv\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print('Time cost: %.2f s' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    max_depth=100, \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=1000, \n",
    "    silent=False, \n",
    "    objective='gpu:binary:logistic', \n",
    "    booster='gbtree', \n",
    "    n_jobs=1, \n",
    "    nthread=None, \n",
    "    gamma=0, \n",
    "    min_child_weight=1, \n",
    "    max_delta_step=0, \n",
    "    subsample=0.7, \n",
    "    colsample_bytree=0.7, \n",
    "#     colsample_bylevel=0.7, \n",
    "    reg_alpha=0.01, \n",
    "    reg_lambda=0.99, \n",
    "    scale_pos_weight=97, \n",
    "    base_score=0.5, \n",
    "    random_state=random_num, \n",
    "    seed=None, \n",
    "    missing=None,\n",
    "    # booster params\n",
    "    num_boost_round=50,\n",
    "#     early_stopping_rounds=10,\n",
    "    tree_method='gpu_hist',\n",
    "    predictor='gpu_predictor',\n",
    "#     eval_metric=['auc', 'logloss']\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "#     sample_weight=None, \n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)], \n",
    "    eval_metric=['auc', 'logloss', 'error'], \n",
    "    early_stopping_rounds=20, \n",
    "#     verbose=False, \n",
    "#     xgb_model=None\n",
    ")\n",
    "\n",
    "\n",
    "print('*' * 80)\n",
    "y_train_proba = clf.predict(x_train)\n",
    "y_train_pred = (y_train_proba>=0.5).astype(int)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "roc_train = roc_auc_score(y_train, y_train_proba)\n",
    "print('acc_train: %.4f \\t roc_train: %.4f' % (acc_train, roc_train))\n",
    "\n",
    "y_val_proba = clf.predict(x_val)\n",
    "y_val_pred = (y_val_proba>=0.5).astype(int)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "roc_val = roc_auc_score(y_val, y_val_proba)\n",
    "print('acc_val:   %.4f \\t roc_val:   %.4f' % (acc_val, roc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = clf.evals_result()\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "\n",
    "n_round = len(evals_result['validation_0']['auc'])\n",
    "x = list(range(1, n_round + 1))\n",
    "for metric_key in evals_result['validation_0'].keys():\n",
    "    plt.xlabel('echo')\n",
    "    plt.ylabel(metric_key)\n",
    "    for i, val_key in enumerate(evals_result.keys()):\n",
    "        plt.plot(x, evals_result[val_key][metric_key], colors[i])\n",
    "    plt.legend(labels = list(evals_result.keys()), loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_acc = run_name + '_' + str(int(roc_val*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = clf.predict(x_test)\n",
    "print(y_test_proba.shape)\n",
    "print(y_test_proba[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_proba(y_train_proba, y_train, y_val_proba, y_val, y_test_proba, click_ids, file_name):\n",
    "    print(click_ids[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('y_train_proba', data=y_train_proba)\n",
    "        h.create_dataset('y_train', data=y_train)\n",
    "        h.create_dataset('y_val_proba', data=y_val_proba)\n",
    "        h.create_dataset('y_val', data=y_val)\n",
    "        h.create_dataset('y_test_proba', data=y_test_proba)\n",
    "        h.create_dataset('click_ids', data=click_ids)\n",
    "    print('File saved: \\t%s' % file_name)\n",
    "\n",
    "def load_proba(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        y_train_proba = np.array(h['y_train_proba'])\n",
    "        y_train = np.array(h['y_train'])\n",
    "        y_val_proba = np.array(h['y_val_proba'])\n",
    "        y_val = np.array(h['y_val'])\n",
    "        y_test_proba = np.array(h['y_test_proba'])\n",
    "        click_ids = np.array(h['click_ids'])\n",
    "    print('File loaded: \\t%s' % file_name)\n",
    "    print(click_ids[:5])\n",
    "    \n",
    "    return y_train_proba, y_train, y_val_proba, y_val, y_test_proba, click_ids\n",
    "\n",
    "\n",
    "y_proba_file = os.path.join(model_folder, 'proba_%s.p' % run_name_acc)\n",
    "save_proba(y_train_proba, y_train, y_val_proba, y_val, y_test_proba, np.array(sample_submission_csv['click_id']), y_proba_file)\n",
    "y_train_proba, y_train, y_val_proba, y_val, y_test_proba, click_ids = load_proba(y_proba_file)\n",
    "\n",
    "print(y_train_proba.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val_proba.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test_proba.shape)\n",
    "print(len(click_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "submission_csv_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "print(submission_csv_file)\n",
    "submission_csv = pd.DataFrame({ 'click_id': click_ids , 'is_attributed': y_test_proba })\n",
    "submission_csv.to_csv(submission_csv_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "\n",
    "print('random_num: ', random_num)\n",
    "print('date: ', date)\n",
    "print(run_name_acc)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
