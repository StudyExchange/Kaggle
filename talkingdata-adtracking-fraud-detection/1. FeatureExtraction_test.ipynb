{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. FeatureExtraction_test\n",
    "\n",
    "Reference:\n",
    "- https://www.kaggle.com/asraful70/talkingdata-new-features-in-lightgbm-lb-0-9784\n",
    "- https://www.kaggle.com/danieleewww/talkingdata-added-new-features-in-lightg-50cf9b/code\n",
    "- https://www.kaggle.com/anttip/talkingdata-wordbatch-fm-ftrl-lb-0-9769\n",
    "- https://www.kaggle.com/pranav84/talkingdata-eda-to-model-evaluation-lb-0-9683\n",
    "- https://www.kaggle.com/aharless/kaggle-runnable-version-of-baris-kanber-s-lightgbm\n",
    "- https://www.kaggle.com/pranav84/lgb-entire-dataset-in-2-hrs-lb-0-9718\n",
    "- https://www.kaggle.com/panjianning/talkingdata-simple-lightgbm-0-9772"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: TalkingdataAFD2018_FeatureExtraction_test_20180501_143516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'TalkingdataAFD2018'\n",
    "step_name = 'FeatureExtraction_test'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = '%s_%s_%s' % (project_name, step_name, time_str)\n",
    "print('run_name: %s' % run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_debug: False\n"
     ]
    }
   ],
   "source": [
    "# date = 0\n",
    "# print('date: ', date)\n",
    "\n",
    "is_debug = False\n",
    "print('is_debug: %s' % is_debug)\n",
    "\n",
    "\n",
    "if is_debug:\n",
    "    test_n_rows = 1 * 10000\n",
    "else:\n",
    "    test_n_rows = None\n",
    "#     test_n_rows = 18790469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_rows = {\n",
    "    0: {\n",
    "        'n_skiprows': 1,\n",
    "        'n_rows': 1 * 10000\n",
    "    },\n",
    "    1: {\n",
    "        'n_skiprows': 1 * 10000,\n",
    "        'n_rows': 2 * 10000\n",
    "    },\n",
    "    6: {\n",
    "        'n_skiprows': 1,\n",
    "        'n_rows': 9308568\n",
    "    },\n",
    "    7: {\n",
    "        'n_skiprows': 1 + 9308568,\n",
    "        'n_rows': 59633310\n",
    "    },\n",
    "    8: {\n",
    "        'n_skiprows': 1 + 9308568 + 59633310,\n",
    "        'n_rows': 62945075\n",
    "    },\n",
    "    9: {\n",
    "        'n_skiprows': 1 + 9308568 + 59633310 + 62945075,\n",
    "        'n_rows': 53016937\n",
    "    }\n",
    "}\n",
    "# n_skiprows = day_rows[date]['n_skiprows']\n",
    "# n_rows = day_rows[date]['n_rows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_num: 7148\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import zipfile\n",
    "import h5py\n",
    "import pickle\n",
    "import math\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_num = np.random.randint(10000)\n",
    "print('random_num: %s' % random_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input\n",
      "output_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/output\n",
      "model_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/model\n",
      "feature_folder: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature\n",
      "log_folder: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/log\n",
      "\n",
      "train_csv_file: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/train.csv\n",
      "train_sample_csv_file: \t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/train_sample.csv\n",
      "test_csv_file: \t\t\t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/test.csv\n",
      "sample_submission_csv_file: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/input/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "print('input_folder: \\t\\t\\t%s' % input_folder)\n",
    "print('output_folder: \\t\\t\\t%s' % output_folder)\n",
    "print('model_folder: \\t\\t\\t%s' % model_folder)\n",
    "print('feature_folder: \\t\\t%s' % feature_folder)\n",
    "print('log_folder: \\t\\t\\t%s' % log_folder)\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "train_sample_csv_file = os.path.join(input_folder, 'train_sample.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission.csv')\n",
    "\n",
    "print('\\ntrain_csv_file: \\t\\t%s' % train_csv_file)\n",
    "print('train_sample_csv_file: \\t\\t%s' % train_sample_csv_file)\n",
    "print('test_csv_file: \\t\\t\\t%s' % test_csv_file)\n",
    "print('sample_submission_csv_file: \\t%s' % sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_columns  = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']\n",
    "dtypes = {\n",
    "    'ip'            : 'uint32',\n",
    "    'app'           : 'uint16',\n",
    "    'device'        : 'uint16',\n",
    "    'os'            : 'uint16',\n",
    "    'channel'       : 'uint16',\n",
    "    'is_attributed' : 'uint8',\n",
    "    'click_id'      : 'uint32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_csv.shape: \t (18790469, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0              0\n",
       "1         1              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv: 286.72 Mb\n"
     ]
    }
   ],
   "source": [
    "sample_submission_csv = pd.read_csv(sample_submission_csv_file)\n",
    "print('sample_submission_csv.shape: \\t', sample_submission_csv.shape)\n",
    "display(sample_submission_csv.head(2))\n",
    "\n",
    "print('train_csv: %.2f Mb' % (sys.getsizeof(sample_submission_csv)/1024./1024.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_click_time(df):\n",
    "    df['day'] = df['click_time'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['click_time'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['click_time'].dt.minute.astype('uint8')\n",
    "    df['second'] = df['click_time'].dt.second.astype('uint8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prev_click(df, group_cols, agg_type='float32'):\n",
    "    agg_suffix = 'prevClick'\n",
    "    new_feature = new_feature = '{}_{}'.format('_'.join(group_cols), agg_suffix)\n",
    "    all_features = group_cols + ['click_time']\n",
    "    df[new_feature] = (df.click_time - df[all_features].groupby(group_cols).click_time.shift(+1) ).dt.seconds.astype(agg_type)\n",
    "    return df\n",
    "    \n",
    "def do_next_click(df, group_cols, agg_type='float32'):\n",
    "    agg_suffix = 'nextClick'\n",
    "    new_feature = new_feature = '{}_{}'.format('_'.join(group_cols), agg_suffix)\n",
    "    all_features = group_cols + ['click_time']\n",
    "    df[new_feature] = (df[all_features].groupby(group_cols).click_time.shift(-1) - df.click_time).dt.seconds.astype(agg_type)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below a function is written to extract count feature by aggregating different cols\n",
    "def do_count( df, group_cols, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name='{}_count'.format('_'.join(group_cols))\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "#     predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "    \n",
    "##  Below a function is written to extract unique count feature from different cols\n",
    "def do_countuniq( df, group_cols, counted, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_countuniq'.format(('_'.join(group_cols)),(counted))  \n",
    "    if show_agg:\n",
    "        print( \"Counting unqiue \", counted, \" by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "#     predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "### Below a function is written to extract cumulative count feature  from different cols    \n",
    "def do_cumcount( df, group_cols, counted,agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_cumcount'.format(('_'.join(group_cols)),(counted)) \n",
    "    if show_agg:\n",
    "        print( \"Cumulative count by \", group_cols , '... and saved in', agg_name  )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "#     predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "### Below a function is written to extract mean feature  from different cols\n",
    "def do_mean( df, group_cols, counted, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_mean'.format(('_'.join(group_cols)),(counted))  \n",
    "    if show_agg:\n",
    "        print( \"Calculating mean of \", counted, \" by \", group_cols , '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].mean().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "#     predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "def do_var( df, group_cols, counted, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_var'.format(('_'.join(group_cols)),(counted)) \n",
    "    if show_agg:\n",
    "        print( \"Calculating variance of \", counted, \" by \", group_cols , '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].var().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "#     predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(x_data, y_data, file_name):\n",
    "    print(y_data[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('x_data', data=x_data)\n",
    "        h.create_dataset('y_data', data=y_data)\n",
    "    print('File saved: \\t%s' % file_name)\n",
    "\n",
    "def load_feature(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        x_data = np.array(h['x_data'])\n",
    "        y_data = np.array(h['y_data'])\n",
    "    print('File loaded: \\t%s' % file_name)\n",
    "    print(y_data[:5])\n",
    "    \n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "def save_test_feature(x_test, click_ids, file_name):\n",
    "    print(click_ids[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('x_test', data=x_test)\n",
    "        h.create_dataset('click_ids', data=click_ids)\n",
    "    print('File saved: \\t%s' % file_name)\n",
    "\n",
    "def load_test_feature(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        x_test = np.array(h['x_test'])\n",
    "        click_ids = np.array(h['click_ids'])\n",
    "    print('File loaded: \\t%s' % file_name)\n",
    "    print(click_ids[:5])\n",
    "    \n",
    "    return x_test, click_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature_map(feature_map, file_name):\n",
    "    print(feature_map[:5])\n",
    "    feature_map_encode = []\n",
    "    for item in feature_map:\n",
    "        feature_name_encode = item[1].encode('UTF-8')\n",
    "        feature_map_encode.append((item[0], feature_name_encode))\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: \\t%s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('feature_map', data=feature_map_encode)\n",
    "    print('File saved: \\t%s' % file_name)\n",
    "\n",
    "def load_feature_map(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        feature_map_encode = np.array(h['feature_map'])\n",
    "    print('File loaded: \\t%s' % file_name)\n",
    "    feature_map = []\n",
    "    for item in feature_map_encode:\n",
    "        feature_name = item[1].decode('UTF-8')\n",
    "        feature_map.append((int(item[0]), feature_name))\n",
    "    print(feature_map[:5])\n",
    "    \n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_feature(train_csv):\n",
    "    train_csv = do_click_time(train_csv)\n",
    "    \n",
    "    for cols in do_prev_click_cols:\n",
    "        print('>> ', cols)\n",
    "        train_csv = do_prev_click( train_csv, cols ); gc.collect()\n",
    "    \n",
    "    for cols in do_next_click_cols:\n",
    "        print('>> ', cols)\n",
    "        train_csv = do_next_click( train_csv, cols ); gc.collect()\n",
    "    \n",
    "    for cols in do_count_cols:\n",
    "        print('>> ', cols)\n",
    "        train_csv = do_count( train_csv, cols ); gc.collect()\n",
    "        \n",
    "    for cols in do_countuniq_cols:\n",
    "        print('>> ', cols[:-1], cols[-1])\n",
    "        train_csv = do_countuniq( train_csv, cols[:-1], cols[-1] ); gc.collect()\n",
    "        \n",
    "    for cols in do_cumcount_cols:\n",
    "        print('>> ', cols[:-1], cols[-1])\n",
    "        train_csv = do_cumcount( train_csv, cols[:-1], cols[-1] ); gc.collect()\n",
    "        \n",
    "    for cols in do_mean_cols:\n",
    "        print('>> ', cols[:-1], cols[-1])\n",
    "        train_csv = do_mean( train_csv, cols[:-1], cols[-1] ); gc.collect()\n",
    "        \n",
    "    for cols in do_var_cols:\n",
    "        print('>> ', cols[:-1], cols[-1])\n",
    "        train_csv = do_var( train_csv, cols[:-1], cols[-1] ); gc.collect()\n",
    "    \n",
    "    train_csv.drop(['click_time'], axis=1, inplace=True)\n",
    "    print(train_csv.shape)\n",
    "\n",
    "    display(train_csv.head())\n",
    "\n",
    "    print(train_csv.columns)\n",
    "    print('data_size: %.2f Mb' % (sys.getsizeof(train_csv)/1024./1024.))\n",
    "    return train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = [\n",
    "    # 5 choice 2\n",
    "    ['ip', 'app'],\n",
    "    ['ip', 'device'],\n",
    "    ['ip', 'os'],\n",
    "    ['ip', 'channel'],\n",
    "    ['app', 'device'],\n",
    "    ['app', 'os'],\n",
    "    ['app', 'channel'],\n",
    "    ['device', 'os'],\n",
    "    ['device', 'channel'],\n",
    "    ['os', 'channel'],\n",
    "    # 5 choice 3\n",
    "    ['device', 'os', 'channel'],\n",
    "    ['app', 'os', 'channel'],\n",
    "    ['app', 'device', 'channel'],\n",
    "    ['app', 'device', 'os'],\n",
    "    ['ip', 'os', 'channel'],\n",
    "    ['ip', 'device', 'channel'],\n",
    "    ['ip', 'device', 'os'],\n",
    "    ['ip', 'app', 'channel'],\n",
    "    ['ip', 'app', 'os'],\n",
    "    ['ip', 'app', 'device'],\n",
    "]\n",
    "\n",
    "template_hour = [\n",
    "    # 5 choice 2\n",
    "    ['ip', 'app', 'hour'],\n",
    "    ['ip', 'device', 'hour'],\n",
    "    ['ip', 'os', 'hour'],\n",
    "    ['ip', 'channel', 'hour'],\n",
    "    ['app', 'device', 'hour'],\n",
    "    ['app', 'os', 'hour'],\n",
    "    ['app', 'channel', 'hour'],\n",
    "    ['device', 'os', 'hour'],\n",
    "    ['device', 'channel', 'hour'],\n",
    "    ['os', 'channel', 'hour'],\n",
    "    # 5 choice 3\n",
    "    ['device', 'os', 'channel', 'hour'],\n",
    "    ['app', 'os', 'channel', 'hour'],\n",
    "    ['app', 'device', 'channel', 'hour'],\n",
    "    ['app', 'device', 'os', 'hour'],\n",
    "    ['ip', 'os', 'channel', 'hour'],\n",
    "    ['ip', 'device', 'channel', 'hour'],\n",
    "    ['ip', 'device', 'os', 'hour'],\n",
    "    ['ip', 'app', 'channel', 'hour'],\n",
    "    ['ip', 'app', 'os', 'hour'],\n",
    "    ['ip', 'app', 'device', 'hour'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ip'] device\n",
      "['app'] channel\n",
      "['device', 'os', 'channel'] hour\n",
      "['ip', 'device'] hour\n",
      "['app', 'device'] os\n",
      "['app', 'os', 'channel'] hour\n",
      "['app'] os\n",
      "['app'] hour\n",
      "['ip', 'day'] hour\n",
      "['ip'] app\n",
      "['ip', 'app'] os\n"
     ]
    }
   ],
   "source": [
    "do_prev_click_cols = [\n",
    "    ['ip', 'device'],\n",
    "    ['ip', 'app', 'device'],\n",
    "    ['ip', 'app'],\n",
    "    ['ip', 'app', 'device', 'os'],\n",
    "    ['ip', 'app', 'device', 'os', 'channel'],\n",
    "    ['ip', 'app', 'os', 'channel'],\n",
    "    ['ip', 'device', 'os', 'channel'],\n",
    "    \n",
    "    \n",
    "    \n",
    "    ['ip', 'os'],\n",
    "    ['ip', 'device', 'channel'],\n",
    "    ['ip', 'channel'], # ref\n",
    "]\n",
    "\n",
    "do_next_click_cols = [\n",
    "    ['ip', 'device'],\n",
    "    ['ip', 'app', 'device'],\n",
    "    ['ip', 'app'],\n",
    "    ['ip', 'app', 'device', 'os'], # ref\n",
    "    ['ip', 'os'],\n",
    "    ['ip', 'device', 'os'], # ref\n",
    "    ['ip', 'device', 'os', 'channel'],\n",
    "    ['ip', 'os', 'channel'],\n",
    "    ['ip', 'app', 'os', 'channel'],\n",
    "    \n",
    "    ['ip', 'app', 'os'],\n",
    "    ['ip', 'device', 'channel'],\n",
    "    \n",
    "    ['ip', 'app', 'device', 'os', 'channel'], # ref\n",
    "    ['device', 'channel'], # ref\n",
    "    ['app', 'device', 'channel'], # ref\n",
    "    ['device', 'hour'], # ref\n",
    "    \n",
    "#     ['ip', 'device'],\n",
    "#     ['ip', 'app', 'device', 'channel'],\n",
    "#     ['ip', 'os'],\n",
    "#     ['ip', 'app', 'channel'],\n",
    "#     ['ip' ,'channel'],\n",
    "]\n",
    "\n",
    "do_count_cols = [\n",
    "    ['ip', 'device'],\n",
    "    ['app', 'channel'],\n",
    "    ['device', 'os', 'channel', 'hour'],\n",
    "    ['ip', 'device', 'hour'],\n",
    "    ['app', 'device', 'os'],\n",
    "    ['app', 'os', 'channel', 'hour'],\n",
    "    ['app', 'os'],\n",
    "    \n",
    "    \n",
    "    ['app', 'hour'],\n",
    "    ['ip', 'day', 'hour'], # ref\n",
    "    ['ip', 'app'], # ref\n",
    "    ['ip', 'app', 'os'], # ref\n",
    "]\n",
    "do_countuniq_cols = [\n",
    "    ['ip', 'app'], # ref\n",
    "    ['ip', 'device', 'channel'],\n",
    "    ['ip', 'device', 'os'], # ref\n",
    "    \n",
    "    \n",
    "    ['ip', 'channel'], # ref\n",
    "    ['ip', 'device', 'os', 'hour'],\n",
    "    \n",
    "    ['ip', 'day', 'hour'], # ref\n",
    "    ['ip', 'app', 'os'], # ref\n",
    "    ['ip', 'device'],\n",
    "    ['app', 'channel'],\n",
    "]\n",
    "do_cumcount_cols = [\n",
    "    ['app', 'os', 'hour'],\n",
    "    ['app', 'device', 'channel'],\n",
    "    ['app', 'device'],\n",
    "    ['app', 'device', 'os'],\n",
    "    ['device', 'os'],\n",
    "    \n",
    "    \n",
    "    ['app', 'channel', 'hour'],\n",
    "    ['os', 'channel'],\n",
    "    ['device', 'channel', 'hour'],\n",
    "    ['device', 'os', 'channel'],\n",
    "    ['os', 'channel', 'hour'],\n",
    "    ['device', 'os', 'hour'],\n",
    "    ['app', 'device', 'channel', 'hour'],\n",
    "    ['app', 'os', 'channel'],\n",
    "    \n",
    "    ['ip', 'os'], # ref\n",
    "    ['ip', 'device', 'os'], # ref\n",
    "]\n",
    "do_mean_cols = [\n",
    "    ['ip', 'app'],\n",
    "    ['ip', 'app', 'channel'],\n",
    "    ['ip', 'os', 'channel'],\n",
    "    ['ip', 'device', 'os'],\n",
    "    ['ip', 'os'],\n",
    "    ['ip', 'device', 'hour'],\n",
    "    ['ip', 'channel'],\n",
    "    ['ip', 'app', 'os'],\n",
    "    ['ip', 'device', 'channel'],\n",
    "    ['os', 'channel', 'hour'],\n",
    "    ['app', 'os', 'channel'],\n",
    "    ['device', 'channel', 'hour'],\n",
    "    ['ip', 'app', 'channel', 'hour'],\n",
    "    ['ip', 'app', 'hour'],\n",
    "    ['ip', 'os', 'hour'],\n",
    "    ['ip', 'device', 'os', 'hour'],\n",
    "    ['ip', 'os', 'channel', 'hour'],\n",
    "    ['app', 'channel', 'hour'],\n",
    "    ['app', 'device', 'os', 'hour'],\n",
    "    \n",
    "\n",
    "    \n",
    "#     ['ip', 'os', 'channel'],\n",
    "#     ['ip', 'app', 'os'],\n",
    "#     ['ip', 'device', 'channel']\n",
    "]\n",
    "do_var_cols = [\n",
    "    ['ip', 'os', 'channel'],\n",
    "    ['ip', 'app'],\n",
    "    ['ip', 'app', 'channel'],\n",
    "    ['ip', 'device', 'hour'],\n",
    "    ['ip', 'device', 'channel'],\n",
    "    ['ip', 'app', 'os'],\n",
    "    ['ip', 'device', 'os'],\n",
    "    ['ip', 'channel'],\n",
    "    ['ip', 'os'],\n",
    "    ['app', 'os', 'channel', 'hour'],\n",
    "    ['ip', 'device', 'os', 'hour'],\n",
    "    ['device', 'os', 'channel', 'hour'],\n",
    "    ['os', 'channel'],\n",
    "    ['app', 'channel', 'hour'],\n",
    "    ['ip', 'device', 'channel', 'hour'],\n",
    "    ['ip', 'app', 'device'],\n",
    "    ['app', 'os', 'hour'],\n",
    "    \n",
    "    ['ip', 'app', 'hour'],\n",
    "    ['ip', 'app', 'device', 'hour'],\n",
    "#     ['ip', 'os', 'hour'],\n",
    "    ['app', 'os', 'channel'],\n",
    "#     ['ip', 'channel']\n",
    "]\n",
    "\n",
    "for cols in do_count_cols:\n",
    "    print(cols[:-1], cols[-1])\n",
    "\n",
    "feature_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 708 ms, total: 18.6 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_csv = pd.read_csv(\n",
    "    test_csv_file, \n",
    "    nrows=test_n_rows, \n",
    "    usecols=test_columns,\n",
    "    dtype=dtypes,\n",
    "    parse_dates=['click_time']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape: \t\t (18790469, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5744</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>119901</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id      ip  app  device  os  channel          click_time\n",
       "0         0    5744    9       1   3      107 2017-11-10 04:00:00\n",
       "1         1  119901    9       1   3      466 2017-11-10 04:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv:  430.08 Mb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: click_id, dtype: uint32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5744</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119901</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72287</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78477</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123080</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time\n",
       "0    5744    9       1   3      107 2017-11-10 04:00:00\n",
       "1  119901    9       1   3      466 2017-11-10 04:00:00\n",
       "2   72287   21       1  19      128 2017-11-10 04:00:00\n",
       "3   78477   15       1  13      111 2017-11-10 04:00:00\n",
       "4  123080   12       1  13      328 2017-11-10 04:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  ['ip', 'device']\n",
      ">>  ['ip', 'app', 'device']\n",
      ">>  ['ip', 'app']\n",
      ">>  ['ip', 'app', 'device', 'os']\n",
      ">>  ['ip', 'app', 'device', 'os', 'channel']\n",
      ">>  ['ip', 'app', 'os', 'channel']\n",
      ">>  ['ip', 'device', 'os', 'channel']\n",
      ">>  ['ip', 'os']\n",
      ">>  ['ip', 'device', 'channel']\n",
      ">>  ['ip', 'channel']\n",
      ">>  ['ip', 'device']\n",
      ">>  ['ip', 'app', 'device']\n",
      ">>  ['ip', 'app']\n",
      ">>  ['ip', 'app', 'device', 'os']\n",
      ">>  ['ip', 'os']\n",
      ">>  ['ip', 'device', 'os']\n",
      ">>  ['ip', 'device', 'os', 'channel']\n",
      ">>  ['ip', 'os', 'channel']\n",
      ">>  ['ip', 'app', 'os', 'channel']\n",
      ">>  ['ip', 'app', 'os']\n",
      ">>  ['ip', 'device', 'channel']\n",
      ">>  ['ip', 'app', 'device', 'os', 'channel']\n",
      ">>  ['device', 'channel']\n",
      ">>  ['app', 'device', 'channel']\n",
      ">>  ['device', 'hour']\n",
      ">>  ['ip', 'device']\n",
      "Aggregating by  ['ip', 'device'] ... and saved in ip_device_count\n",
      ">>  ['app', 'channel']\n",
      "Aggregating by  ['app', 'channel'] ... and saved in app_channel_count\n",
      ">>  ['device', 'os', 'channel', 'hour']\n",
      "Aggregating by  ['device', 'os', 'channel', 'hour'] ... and saved in device_os_channel_hour_count\n",
      ">>  ['ip', 'device', 'hour']\n",
      "Aggregating by  ['ip', 'device', 'hour'] ... and saved in ip_device_hour_count\n",
      ">>  ['app', 'device', 'os']\n",
      "Aggregating by  ['app', 'device', 'os'] ... and saved in app_device_os_count\n",
      ">>  ['app', 'os', 'channel', 'hour']\n",
      "Aggregating by  ['app', 'os', 'channel', 'hour'] ... and saved in app_os_channel_hour_count\n",
      ">>  ['app', 'os']\n",
      "Aggregating by  ['app', 'os'] ... and saved in app_os_count\n",
      ">>  ['app', 'hour']\n",
      "Aggregating by  ['app', 'hour'] ... and saved in app_hour_count\n",
      ">>  ['ip', 'day', 'hour']\n",
      "Aggregating by  ['ip', 'day', 'hour'] ... and saved in ip_day_hour_count\n",
      ">>  ['ip', 'app']\n",
      "Aggregating by  ['ip', 'app'] ... and saved in ip_app_count\n",
      ">>  ['ip', 'app', 'os']\n",
      "Aggregating by  ['ip', 'app', 'os'] ... and saved in ip_app_os_count\n",
      ">>  ['ip'] app\n",
      "Counting unqiue  app  by  ['ip'] ... and saved in ip_by_app_countuniq\n",
      ">>  ['ip', 'device'] channel\n",
      "Counting unqiue  channel  by  ['ip', 'device'] ... and saved in ip_device_by_channel_countuniq\n",
      ">>  ['ip', 'device'] os\n",
      "Counting unqiue  os  by  ['ip', 'device'] ... and saved in ip_device_by_os_countuniq\n",
      ">>  ['ip'] channel\n",
      "Counting unqiue  channel  by  ['ip'] ... and saved in ip_by_channel_countuniq\n",
      ">>  ['ip', 'device', 'os'] hour\n",
      "Counting unqiue  hour  by  ['ip', 'device', 'os'] ... and saved in ip_device_os_by_hour_countuniq\n",
      ">>  ['ip', 'day'] hour\n",
      "Counting unqiue  hour  by  ['ip', 'day'] ... and saved in ip_day_by_hour_countuniq\n",
      ">>  ['ip', 'app'] os\n",
      "Counting unqiue  os  by  ['ip', 'app'] ... and saved in ip_app_by_os_countuniq\n",
      ">>  ['ip'] device\n",
      "Counting unqiue  device  by  ['ip'] ... and saved in ip_by_device_countuniq\n",
      ">>  ['app'] channel\n",
      "Counting unqiue  channel  by  ['app'] ... and saved in app_by_channel_countuniq\n",
      ">>  ['app', 'os'] hour\n",
      "Cumulative count by  ['app', 'os'] ... and saved in app_os_by_hour_cumcount\n",
      ">>  ['app', 'device'] channel\n",
      "Cumulative count by  ['app', 'device'] ... and saved in app_device_by_channel_cumcount\n",
      ">>  ['app'] device\n",
      "Cumulative count by  ['app'] ... and saved in app_by_device_cumcount\n",
      ">>  ['app', 'device'] os\n",
      "Cumulative count by  ['app', 'device'] ... and saved in app_device_by_os_cumcount\n",
      ">>  ['device'] os\n",
      "Cumulative count by  ['device'] ... and saved in device_by_os_cumcount\n",
      ">>  ['app', 'channel'] hour\n",
      "Cumulative count by  ['app', 'channel'] ... and saved in app_channel_by_hour_cumcount\n",
      ">>  ['os'] channel\n",
      "Cumulative count by  ['os'] ... and saved in os_by_channel_cumcount\n",
      ">>  ['device', 'channel'] hour\n",
      "Cumulative count by  ['device', 'channel'] ... and saved in device_channel_by_hour_cumcount\n",
      ">>  ['device', 'os'] channel\n",
      "Cumulative count by  ['device', 'os'] ... and saved in device_os_by_channel_cumcount\n",
      ">>  ['os', 'channel'] hour\n",
      "Cumulative count by  ['os', 'channel'] ... and saved in os_channel_by_hour_cumcount\n",
      ">>  ['device', 'os'] hour\n",
      "Cumulative count by  ['device', 'os'] ... and saved in device_os_by_hour_cumcount\n",
      ">>  ['app', 'device', 'channel'] hour\n",
      "Cumulative count by  ['app', 'device', 'channel'] ... and saved in app_device_channel_by_hour_cumcount\n",
      ">>  ['app', 'os'] channel\n",
      "Cumulative count by  ['app', 'os'] ... and saved in app_os_by_channel_cumcount\n",
      ">>  ['ip'] os\n",
      "Cumulative count by  ['ip'] ... and saved in ip_by_os_cumcount\n",
      ">>  ['ip', 'device'] os\n",
      "Cumulative count by  ['ip', 'device'] ... and saved in ip_device_by_os_cumcount\n",
      ">>  ['ip'] app\n",
      "Calculating mean of  app  by  ['ip'] ... and saved in ip_by_app_mean\n",
      ">>  ['ip', 'app'] channel\n",
      "Calculating mean of  channel  by  ['ip', 'app'] ... and saved in ip_app_by_channel_mean\n",
      ">>  ['ip', 'os'] channel\n",
      "Calculating mean of  channel  by  ['ip', 'os'] ... and saved in ip_os_by_channel_mean\n",
      ">>  ['ip', 'device'] os\n",
      "Calculating mean of  os  by  ['ip', 'device'] ... and saved in ip_device_by_os_mean\n",
      ">>  ['ip'] os\n",
      "Calculating mean of  os  by  ['ip'] ... and saved in ip_by_os_mean\n",
      ">>  ['ip', 'device'] hour\n",
      "Calculating mean of  hour  by  ['ip', 'device'] ... and saved in ip_device_by_hour_mean\n",
      ">>  ['ip'] channel\n",
      "Calculating mean of  channel  by  ['ip'] ... and saved in ip_by_channel_mean\n",
      ">>  ['ip', 'app'] os\n",
      "Calculating mean of  os  by  ['ip', 'app'] ... and saved in ip_app_by_os_mean\n",
      ">>  ['ip', 'device'] channel\n",
      "Calculating mean of  channel  by  ['ip', 'device'] ... and saved in ip_device_by_channel_mean\n",
      ">>  ['os', 'channel'] hour\n",
      "Calculating mean of  hour  by  ['os', 'channel'] ... and saved in os_channel_by_hour_mean\n",
      ">>  ['app', 'os'] channel\n",
      "Calculating mean of  channel  by  ['app', 'os'] ... and saved in app_os_by_channel_mean\n",
      ">>  ['device', 'channel'] hour\n",
      "Calculating mean of  hour  by  ['device', 'channel'] ... and saved in device_channel_by_hour_mean\n",
      ">>  ['ip', 'app', 'channel'] hour\n",
      "Calculating mean of  hour  by  ['ip', 'app', 'channel'] ... and saved in ip_app_channel_by_hour_mean\n",
      ">>  ['ip', 'app'] hour\n",
      "Calculating mean of  hour  by  ['ip', 'app'] ... and saved in ip_app_by_hour_mean\n",
      ">>  ['ip', 'os'] hour\n",
      "Calculating mean of  hour  by  ['ip', 'os'] ... and saved in ip_os_by_hour_mean\n",
      ">>  ['ip', 'device', 'os'] hour\n",
      "Calculating mean of  hour  by  ['ip', 'device', 'os'] ... and saved in ip_device_os_by_hour_mean\n",
      ">>  ['ip', 'os', 'channel'] hour\n",
      "Calculating mean of  hour  by  ['ip', 'os', 'channel'] ... and saved in ip_os_channel_by_hour_mean\n",
      ">>  ['app', 'channel'] hour\n",
      "Calculating mean of  hour  by  ['app', 'channel'] ... and saved in app_channel_by_hour_mean\n",
      ">>  ['app', 'device', 'os'] hour\n",
      "Calculating mean of  hour  by  ['app', 'device', 'os'] ... and saved in app_device_os_by_hour_mean\n",
      ">>  ['ip', 'os'] channel\n",
      "Calculating variance of  channel  by  ['ip', 'os'] ... and saved in ip_os_by_channel_var\n",
      ">>  ['ip'] app\n",
      "Calculating variance of  app  by  ['ip'] ... and saved in ip_by_app_var\n",
      ">>  ['ip', 'app'] channel\n",
      "Calculating variance of  channel  by  ['ip', 'app'] ... and saved in ip_app_by_channel_var\n",
      ">>  ['ip', 'device'] hour\n",
      "Calculating variance of  hour  by  ['ip', 'device'] ... and saved in ip_device_by_hour_var\n",
      ">>  ['ip', 'device'] channel\n",
      "Calculating variance of  channel  by  ['ip', 'device'] ... and saved in ip_device_by_channel_var\n",
      ">>  ['ip', 'app'] os\n",
      "Calculating variance of  os  by  ['ip', 'app'] ... and saved in ip_app_by_os_var\n",
      ">>  ['ip', 'device'] os\n",
      "Calculating variance of  os  by  ['ip', 'device'] ... and saved in ip_device_by_os_var\n",
      ">>  ['ip'] channel\n",
      "Calculating variance of  channel  by  ['ip'] ... and saved in ip_by_channel_var\n",
      ">>  ['ip'] os\n",
      "Calculating variance of  os  by  ['ip'] ... and saved in ip_by_os_var\n",
      ">>  ['app', 'os', 'channel'] hour\n",
      "Calculating variance of  hour  by  ['app', 'os', 'channel'] ... and saved in app_os_channel_by_hour_var\n",
      ">>  ['ip', 'device', 'os'] hour\n",
      "Calculating variance of  hour  by  ['ip', 'device', 'os'] ... and saved in ip_device_os_by_hour_var\n",
      ">>  ['device', 'os', 'channel'] hour\n",
      "Calculating variance of  hour  by  ['device', 'os', 'channel'] ... and saved in device_os_channel_by_hour_var\n",
      ">>  ['os'] channel\n",
      "Calculating variance of  channel  by  ['os'] ... and saved in os_by_channel_var\n",
      ">>  ['app', 'channel'] hour\n",
      "Calculating variance of  hour  by  ['app', 'channel'] ... and saved in app_channel_by_hour_var\n",
      ">>  ['ip', 'device', 'channel'] hour\n",
      "Calculating variance of  hour  by  ['ip', 'device', 'channel'] ... and saved in ip_device_channel_by_hour_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  ['ip', 'app'] device\n",
      "Calculating variance of  device  by  ['ip', 'app'] ... and saved in ip_app_by_device_var\n",
      ">>  ['app', 'os'] hour\n",
      "Calculating variance of  hour  by  ['app', 'os'] ... and saved in app_os_by_hour_var\n",
      ">>  ['ip', 'app'] hour\n",
      "Calculating variance of  hour  by  ['ip', 'app'] ... and saved in ip_app_by_hour_var\n",
      ">>  ['ip', 'app', 'device'] hour\n",
      "Calculating variance of  hour  by  ['ip', 'app', 'device'] ... and saved in ip_app_device_by_hour_var\n",
      ">>  ['app', 'os'] channel\n",
      "Calculating variance of  channel  by  ['app', 'os'] ... and saved in app_os_by_channel_var\n",
      "(18790469, 108)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>ip_device_prevClick</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_device_os_by_hour_var</th>\n",
       "      <th>device_os_channel_by_hour_var</th>\n",
       "      <th>os_by_channel_var</th>\n",
       "      <th>app_channel_by_hour_var</th>\n",
       "      <th>ip_device_channel_by_hour_var</th>\n",
       "      <th>ip_app_by_device_var</th>\n",
       "      <th>app_os_by_hour_var</th>\n",
       "      <th>ip_app_by_hour_var</th>\n",
       "      <th>ip_app_device_by_hour_var</th>\n",
       "      <th>app_os_by_channel_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5744</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.514261</td>\n",
       "      <td>19569.292969</td>\n",
       "      <td>12.290454</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.302400</td>\n",
       "      <td>13.675926</td>\n",
       "      <td>13.675926</td>\n",
       "      <td>19538.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119901</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.367663</td>\n",
       "      <td>14.563915</td>\n",
       "      <td>19569.292969</td>\n",
       "      <td>14.336766</td>\n",
       "      <td>13.130157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.302400</td>\n",
       "      <td>13.528979</td>\n",
       "      <td>13.528979</td>\n",
       "      <td>19538.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72287</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.292033</td>\n",
       "      <td>12.521263</td>\n",
       "      <td>18658.412109</td>\n",
       "      <td>12.901376</td>\n",
       "      <td>10.612795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.649865</td>\n",
       "      <td>7.260285</td>\n",
       "      <td>7.260285</td>\n",
       "      <td>2402.308594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78477</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.280590</td>\n",
       "      <td>14.687875</td>\n",
       "      <td>18327.267578</td>\n",
       "      <td>14.795582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.517140</td>\n",
       "      <td>14.722997</td>\n",
       "      <td>14.722997</td>\n",
       "      <td>17858.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123080</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19.064627</td>\n",
       "      <td>14.444427</td>\n",
       "      <td>18327.267578</td>\n",
       "      <td>14.409562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.677645</td>\n",
       "      <td>10.824275</td>\n",
       "      <td>10.824275</td>\n",
       "      <td>9035.611328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel  day  hour  minute  second  \\\n",
       "0    5744    9       1   3      107   10     4       0       0   \n",
       "1  119901    9       1   3      466   10     4       0       0   \n",
       "2   72287   21       1  19      128   10     4       0       0   \n",
       "3   78477   15       1  13      111   10     4       0       0   \n",
       "4  123080   12       1  13      328   10     4       0       0   \n",
       "\n",
       "   ip_device_prevClick          ...            ip_device_os_by_hour_var  \\\n",
       "0                  NaN          ...                            0.000000   \n",
       "1                  NaN          ...                           11.367663   \n",
       "2                  NaN          ...                           14.292033   \n",
       "3                  NaN          ...                           14.280590   \n",
       "4                  NaN          ...                           19.064627   \n",
       "\n",
       "   device_os_channel_by_hour_var  os_by_channel_var  app_channel_by_hour_var  \\\n",
       "0                      12.514261       19569.292969                12.290454   \n",
       "1                      14.563915       19569.292969                14.336766   \n",
       "2                      12.521263       18658.412109                12.901376   \n",
       "3                      14.687875       18327.267578                14.795582   \n",
       "4                      14.444427       18327.267578                14.409562   \n",
       "\n",
       "   ip_device_channel_by_hour_var  ip_app_by_device_var  app_os_by_hour_var  \\\n",
       "0                       0.333333                   0.0           14.302400   \n",
       "1                      13.130157                   0.0           14.302400   \n",
       "2                      10.612795                   0.0            9.649865   \n",
       "3                       0.000000                   0.0           14.517140   \n",
       "4                       0.000000                   0.0           13.677645   \n",
       "\n",
       "   ip_app_by_hour_var  ip_app_device_by_hour_var  app_os_by_channel_var  \n",
       "0           13.675926                  13.675926           19538.246094  \n",
       "1           13.528979                  13.528979           19538.246094  \n",
       "2            7.260285                   7.260285            2402.308594  \n",
       "3           14.722997                  14.722997           17858.015625  \n",
       "4           10.824275                  10.824275            9035.611328  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ip', 'app', 'device', 'os', 'channel', 'day', 'hour', 'minute',\n",
      "       'second', 'ip_device_prevClick',\n",
      "       ...\n",
      "       'ip_device_os_by_hour_var', 'device_os_channel_by_hour_var',\n",
      "       'os_by_channel_var', 'app_channel_by_hour_var',\n",
      "       'ip_device_channel_by_hour_var', 'ip_app_by_device_var',\n",
      "       'app_os_by_hour_var', 'ip_app_by_hour_var', 'ip_app_device_by_hour_var',\n",
      "       'app_os_by_channel_var'],\n",
      "      dtype='object', length=108)\n",
      "data_size: 7526.39 Mb\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: click_id, dtype: uint32\n",
      "File saved: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_test_20180501_143516_test.p\n",
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_test_20180501_143516_test.p\n",
      "[0 1 2 3 4]\n",
      "(18790469, 108)\n",
      "18790469\n",
      "[\n",
      "  (0,\t\"ip\")\n",
      "  (1,\t\"app\")\n",
      "  (2,\t\"device\")\n",
      "  (3,\t\"os\")\n",
      "  (4,\t\"channel\")\n",
      "  (5,\t\"day\")\n",
      "  (6,\t\"hour\")\n",
      "  (7,\t\"minute\")\n",
      "  (8,\t\"second\")\n",
      "  (9,\t\"ip_device_prevClick\")\n",
      "  (10,\t\"ip_app_device_prevClick\")\n",
      "  (11,\t\"ip_app_prevClick\")\n",
      "  (12,\t\"ip_app_device_os_prevClick\")\n",
      "  (13,\t\"ip_app_device_os_channel_prevClick\")\n",
      "  (14,\t\"ip_app_os_channel_prevClick\")\n",
      "  (15,\t\"ip_device_os_channel_prevClick\")\n",
      "  (16,\t\"ip_os_prevClick\")\n",
      "  (17,\t\"ip_device_channel_prevClick\")\n",
      "  (18,\t\"ip_channel_prevClick\")\n",
      "  (19,\t\"ip_device_nextClick\")\n",
      "  (20,\t\"ip_app_device_nextClick\")\n",
      "  (21,\t\"ip_app_nextClick\")\n",
      "  (22,\t\"ip_app_device_os_nextClick\")\n",
      "  (23,\t\"ip_os_nextClick\")\n",
      "  (24,\t\"ip_device_os_nextClick\")\n",
      "  (25,\t\"ip_device_os_channel_nextClick\")\n",
      "  (26,\t\"ip_os_channel_nextClick\")\n",
      "  (27,\t\"ip_app_os_channel_nextClick\")\n",
      "  (28,\t\"ip_app_os_nextClick\")\n",
      "  (29,\t\"ip_device_channel_nextClick\")\n",
      "  (30,\t\"ip_app_device_os_channel_nextClick\")\n",
      "  (31,\t\"device_channel_nextClick\")\n",
      "  (32,\t\"app_device_channel_nextClick\")\n",
      "  (33,\t\"device_hour_nextClick\")\n",
      "  (34,\t\"ip_device_count\")\n",
      "  (35,\t\"app_channel_count\")\n",
      "  (36,\t\"device_os_channel_hour_count\")\n",
      "  (37,\t\"ip_device_hour_count\")\n",
      "  (38,\t\"app_device_os_count\")\n",
      "  (39,\t\"app_os_channel_hour_count\")\n",
      "  (40,\t\"app_os_count\")\n",
      "  (41,\t\"app_hour_count\")\n",
      "  (42,\t\"ip_day_hour_count\")\n",
      "  (43,\t\"ip_app_count\")\n",
      "  (44,\t\"ip_app_os_count\")\n",
      "  (45,\t\"ip_by_app_countuniq\")\n",
      "  (46,\t\"ip_device_by_channel_countuniq\")\n",
      "  (47,\t\"ip_device_by_os_countuniq\")\n",
      "  (48,\t\"ip_by_channel_countuniq\")\n",
      "  (49,\t\"ip_device_os_by_hour_countuniq\")\n",
      "  (50,\t\"ip_day_by_hour_countuniq\")\n",
      "  (51,\t\"ip_app_by_os_countuniq\")\n",
      "  (52,\t\"ip_by_device_countuniq\")\n",
      "  (53,\t\"app_by_channel_countuniq\")\n",
      "  (54,\t\"app_os_by_hour_cumcount\")\n",
      "  (55,\t\"app_device_by_channel_cumcount\")\n",
      "  (56,\t\"app_by_device_cumcount\")\n",
      "  (57,\t\"app_device_by_os_cumcount\")\n",
      "  (58,\t\"device_by_os_cumcount\")\n",
      "  (59,\t\"app_channel_by_hour_cumcount\")\n",
      "  (60,\t\"os_by_channel_cumcount\")\n",
      "  (61,\t\"device_channel_by_hour_cumcount\")\n",
      "  (62,\t\"device_os_by_channel_cumcount\")\n",
      "  (63,\t\"os_channel_by_hour_cumcount\")\n",
      "  (64,\t\"device_os_by_hour_cumcount\")\n",
      "  (65,\t\"app_device_channel_by_hour_cumcount\")\n",
      "  (66,\t\"app_os_by_channel_cumcount\")\n",
      "  (67,\t\"ip_by_os_cumcount\")\n",
      "  (68,\t\"ip_device_by_os_cumcount\")\n",
      "  (69,\t\"ip_by_app_mean\")\n",
      "  (70,\t\"ip_app_by_channel_mean\")\n",
      "  (71,\t\"ip_os_by_channel_mean\")\n",
      "  (72,\t\"ip_device_by_os_mean\")\n",
      "  (73,\t\"ip_by_os_mean\")\n",
      "  (74,\t\"ip_device_by_hour_mean\")\n",
      "  (75,\t\"ip_by_channel_mean\")\n",
      "  (76,\t\"ip_app_by_os_mean\")\n",
      "  (77,\t\"ip_device_by_channel_mean\")\n",
      "  (78,\t\"os_channel_by_hour_mean\")\n",
      "  (79,\t\"app_os_by_channel_mean\")\n",
      "  (80,\t\"device_channel_by_hour_mean\")\n",
      "  (81,\t\"ip_app_channel_by_hour_mean\")\n",
      "  (82,\t\"ip_app_by_hour_mean\")\n",
      "  (83,\t\"ip_os_by_hour_mean\")\n",
      "  (84,\t\"ip_device_os_by_hour_mean\")\n",
      "  (85,\t\"ip_os_channel_by_hour_mean\")\n",
      "  (86,\t\"app_channel_by_hour_mean\")\n",
      "  (87,\t\"app_device_os_by_hour_mean\")\n",
      "  (88,\t\"ip_os_by_channel_var\")\n",
      "  (89,\t\"ip_by_app_var\")\n",
      "  (90,\t\"ip_app_by_channel_var\")\n",
      "  (91,\t\"ip_device_by_hour_var\")\n",
      "  (92,\t\"ip_device_by_channel_var\")\n",
      "  (93,\t\"ip_app_by_os_var\")\n",
      "  (94,\t\"ip_device_by_os_var\")\n",
      "  (95,\t\"ip_by_channel_var\")\n",
      "  (96,\t\"ip_by_os_var\")\n",
      "  (97,\t\"app_os_channel_by_hour_var\")\n",
      "  (98,\t\"ip_device_os_by_hour_var\")\n",
      "  (99,\t\"device_os_channel_by_hour_var\")\n",
      "  (100,\t\"os_by_channel_var\")\n",
      "  (101,\t\"app_channel_by_hour_var\")\n",
      "  (102,\t\"ip_device_channel_by_hour_var\")\n",
      "  (103,\t\"ip_app_by_device_var\")\n",
      "  (104,\t\"app_os_by_hour_var\")\n",
      "  (105,\t\"ip_app_by_hour_var\")\n",
      "  (106,\t\"ip_app_device_by_hour_var\")\n",
      "  (107,\t\"app_os_by_channel_var\")\n",
      "]\n",
      "[(0, 'ip'), (1, 'app'), (2, 'device'), (3, 'os'), (4, 'channel')]\n",
      "File saved: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_map_TalkingdataAFD2018_FeatureExtraction_test_20180501_143516.p\n",
      "File loaded: \t/data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_map_TalkingdataAFD2018_FeatureExtraction_test_20180501_143516.p\n",
      "[(0, 'ip'), (1, 'app'), (2, 'device'), (3, 'os'), (4, 'channel')]\n",
      "108\n",
      "[(0, 'ip'), (1, 'app'), (2, 'device'), (3, 'os'), (4, 'channel')]\n",
      "CPU times: user 1h 9min 13s, sys: 9min 38s, total: 1h 18min 52s\n",
      "Wall time: 1h 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('test_csv.shape: \\t\\t', test_csv.shape)\n",
    "display(test_csv.head(2))\n",
    "print('test_csv:  %.2f Mb' % (sys.getsizeof(test_csv)/1024./1024.))\n",
    "# print('*' * 80)\n",
    "\n",
    "click_ids = test_csv['click_id']\n",
    "test_csv.drop(['click_id'], axis=1, inplace=True)\n",
    "display(click_ids.head())\n",
    "\n",
    "display(test_csv.head())\n",
    "# print('*' * 80)\n",
    "\n",
    "test_csv = do_feature(test_csv)\n",
    "    \n",
    "y_proba_file = os.path.join(feature_folder, 'feature_%s_test.p' % run_name)\n",
    "feature_files.append(y_proba_file)\n",
    "save_test_feature(\n",
    "    test_csv, \n",
    "    click_ids, \n",
    "    y_proba_file\n",
    ")\n",
    "x_test, click_ids = load_test_feature(y_proba_file)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(len(click_ids))\n",
    "\n",
    "feature_map = []\n",
    "print('[')\n",
    "for i, col in enumerate(test_csv.columns):\n",
    "    feature_map.append((i, col))\n",
    "    print('  (%s,\\t\"%s\")' % (i, col))\n",
    "print(']')\n",
    "feature_map_file_name = y_proba_file = os.path.join(feature_folder, 'feature_map_%s.p' % run_name)\n",
    "save_feature_map(feature_map, feature_map_file_name)\n",
    "feature_map1 = load_feature_map(feature_map_file_name)\n",
    "print(len(feature_map1))\n",
    "print(feature_map1[:5])\n",
    "\n",
    "# del test_csv\n",
    "# del x_test\n",
    "# del click_ids\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in day_rows.keys():\n",
    "#     key_str = str(key)\n",
    "#     print('date key: %s' % key_str)\n",
    "#     if is_debug and key > 1:\n",
    "#         print('is_debug=%s, skip date: %s' % (is_debug, key_str))\n",
    "#         continue\n",
    "#     if not is_debug and key <= 1:\n",
    "#         print('is_debug=%s, skip date: %s' % (is_debug, key_str))\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# for key in day_rows.keys():\n",
    "#     print('*' * 80)\n",
    "\n",
    "#     key_str = str(key)\n",
    "#     print('date key: %s' % key_str)\n",
    "#     if is_debug and key > 1:\n",
    "#         print('is_debug=%s, skip date: %s' % (is_debug, key_str))\n",
    "#         continue\n",
    "#     if not is_debug and key <= 1:\n",
    "#         print('is_debug=%s, skip date: %s' % (is_debug, key_str))\n",
    "#         continue\n",
    "    \n",
    "#     n_skiprows = day_rows[key]['n_skiprows']\n",
    "#     n_rows = day_rows[key]['n_rows']\n",
    "    \n",
    "#     train_csv = pd.read_csv(\n",
    "#         train_csv_file, \n",
    "#         skiprows=range(1, n_skiprows), \n",
    "#         nrows=n_rows, \n",
    "#         usecols=train_columns,\n",
    "#         dtype=dtypes,\n",
    "#         parse_dates=['click_time']\n",
    "#     )\n",
    "    \n",
    "#     print('train_csv.shape: \\t\\t', train_csv.shape)\n",
    "#     display(train_csv.head(2))\n",
    "#     print('train_csv: %.2f Mb' % (sys.getsizeof(train_csv)/1024./1024.))\n",
    "# #     print('*' * 80)\n",
    "    \n",
    "#     y_data = train_csv['is_attributed']\n",
    "#     train_csv.drop(['is_attributed'], axis=1, inplace=True)\n",
    "#     display(y_data.head())\n",
    "\n",
    "#     display(train_csv.head())\n",
    "# #     print('*' * 80)\n",
    "\n",
    "#     train_csv = do_feature(train_csv)\n",
    "    \n",
    "#     y_proba_file = os.path.join(feature_folder, 'feature_%s_date%s.p' % (run_name, key_str))\n",
    "#     feature_files.append(y_proba_file)\n",
    "#     save_feature(\n",
    "#         train_csv, \n",
    "#         y_data, \n",
    "#         y_proba_file\n",
    "#     )\n",
    "#     x_data, y_data = load_feature(y_proba_file)\n",
    "\n",
    "#     print(x_data.shape)\n",
    "#     print(y_data.shape)\n",
    "#     print('[')\n",
    "#     for i, col in enumerate(train_csv.columns):\n",
    "#         print('  (%s,\\t\"%s\")' % (i, col))\n",
    "#     print('')\n",
    "# #     del train_csv\n",
    "#     del x_data\n",
    "#     del y_data\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/kaggle/talkingdata-adtracking-fraud-detection/feature/feature_TalkingdataAFD2018_FeatureExtraction_test_20180501_143516_test.p\n"
     ]
    }
   ],
   "source": [
    "# print(x_data.shape)\n",
    "# print(y_data.shape)\n",
    "# print(x_test.shape)\n",
    "# print(click_ids.shape)\n",
    "for name in feature_files:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 4938.03 s\n",
      "TalkingdataAFD2018_FeatureExtraction_test_20180501_143516\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "print(run_name)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
