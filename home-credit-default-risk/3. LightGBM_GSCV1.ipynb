{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM_GSCV1\n",
    "\n",
    "\n",
    "Referenceï¼š\n",
    "- https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: HomeCreditDefaultRisk_LightGBM_GSCV1_20180603_204528\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'HomeCreditDefaultRisk'\n",
    "step_name = 'LightGBM_GSCV1'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount: 3\n",
      "random_num: 6612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import tqdm\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "# import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "random_num = np.random.randint(10000)\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "\n",
    "print('cpu_amount: %s' % (cpu_amount - 1))\n",
    "print('random_num: %s' % random_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost\n",
    "# from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\application_test.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\application_train.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\bureau.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\bureau_balance.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\credit_card_balance.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\installments_payments.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\POS_CASH_balance.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\previous_application.csv\n",
      "D:\\bitbucket\\kaggle\\home-credit-default-risk\\input\\sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "application_test_csv_file = os.path.join(input_folder, 'application_test.csv')\n",
    "application_train_csv_file = os.path.join(input_folder, 'application_train.csv')\n",
    "bureau_csv_file = os.path.join(input_folder, 'bureau.csv')\n",
    "bureau_balance_csv_file = os.path.join(input_folder, 'bureau_balance.csv')\n",
    "credit_card_balance_csv_file = os.path.join(input_folder, 'credit_card_balance.csv')\n",
    "installments_payments_csv_file = os.path.join(input_folder, 'installments_payments.csv')\n",
    "POS_CASH_balance_csv_file = os.path.join(input_folder, 'POS_CASH_balance.csv')\n",
    "previous_application_csv_file = os.path.join(input_folder, 'previous_application.csv')\n",
    "sample_submission_csv_file = os.path.join(input_folder, 'sample_submission.csv')\n",
    "\n",
    "print(application_test_csv_file)\n",
    "print(application_train_csv_file)\n",
    "print(bureau_csv_file)\n",
    "print(bureau_balance_csv_file)\n",
    "print(credit_card_balance_csv_file)\n",
    "print(installments_payments_csv_file)\n",
    "print(POS_CASH_balance_csv_file)\n",
    "print(previous_application_csv_file)\n",
    "print(sample_submission_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_input():\n",
    "    buro_bal = pd.read_csv(bureau_balance_csv_file)\n",
    "    print('Buro bal shape : ', buro_bal.shape)\n",
    "    \n",
    "    print('transform to dummies')\n",
    "    buro_bal = pd.concat([buro_bal, pd.get_dummies(buro_bal.STATUS, prefix='buro_bal_status')], axis=1).drop('STATUS', axis=1)\n",
    "    \n",
    "    print('Counting buros')\n",
    "    buro_counts = buro_bal[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n",
    "    buro_bal['buro_count'] = buro_bal['SK_ID_BUREAU'].map(buro_counts['MONTHS_BALANCE'])\n",
    "    \n",
    "    print('averaging buro bal')\n",
    "    avg_buro_bal = buro_bal.groupby('SK_ID_BUREAU').mean()\n",
    "    \n",
    "    avg_buro_bal.columns = ['avg_buro_' + f_ for f_ in avg_buro_bal.columns]\n",
    "    del buro_bal\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Read Bureau')\n",
    "    buro = pd.read_csv(bureau_csv_file)\n",
    "    \n",
    "    print('Go to dummies')\n",
    "    buro_credit_active_dum = pd.get_dummies(buro.CREDIT_ACTIVE, prefix='ca_')\n",
    "    buro_credit_currency_dum = pd.get_dummies(buro.CREDIT_CURRENCY, prefix='cu_')\n",
    "    buro_credit_type_dum = pd.get_dummies(buro.CREDIT_TYPE, prefix='ty_')\n",
    "    \n",
    "    buro_full = pd.concat([buro, buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum], axis=1)\n",
    "    # buro_full.columns = ['buro_' + f_ for f_ in buro_full.columns]\n",
    "    \n",
    "    del buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Merge with buro avg')\n",
    "    buro_full = buro_full.merge(right=avg_buro_bal.reset_index(), how='left', on='SK_ID_BUREAU', suffixes=('', '_bur_bal'))\n",
    "    \n",
    "    print('Counting buro per SK_ID_CURR')\n",
    "    nb_bureau_per_curr = buro_full[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "    buro_full['SK_ID_BUREAU'] = buro_full['SK_ID_CURR'].map(nb_bureau_per_curr['SK_ID_BUREAU'])\n",
    "    \n",
    "    print('Averaging bureau')\n",
    "    avg_buro = buro_full.groupby('SK_ID_CURR').mean()\n",
    "    print(avg_buro.head())\n",
    "    \n",
    "    del buro, buro_full\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Read prev')\n",
    "    prev = pd.read_csv(previous_application_csv_file)\n",
    "    \n",
    "    prev_cat_features = [\n",
    "        f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n",
    "    ]\n",
    "    \n",
    "    print('Go to dummies')\n",
    "    prev_dum = pd.DataFrame()\n",
    "    for f_ in prev_cat_features:\n",
    "        prev_dum = pd.concat([prev_dum, pd.get_dummies(prev[f_], prefix=f_).astype(np.uint8)], axis=1)\n",
    "    \n",
    "    prev = pd.concat([prev, prev_dum], axis=1)\n",
    "    \n",
    "    del prev_dum\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Counting number of Prevs')\n",
    "    nb_prev_per_curr = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    prev['SK_ID_PREV'] = prev['SK_ID_CURR'].map(nb_prev_per_curr['SK_ID_PREV'])\n",
    "    \n",
    "    print('Averaging prev')\n",
    "    avg_prev = prev.groupby('SK_ID_CURR').mean()\n",
    "    print(avg_prev.head())\n",
    "    del prev\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Reading POS_CASH')\n",
    "    pos = pd.read_csv(POS_CASH_balance_csv_file)\n",
    "    \n",
    "    print('Go to dummies')\n",
    "    pos = pd.concat([pos, pd.get_dummies(pos['NAME_CONTRACT_STATUS'])], axis=1)\n",
    "    \n",
    "    print('Compute nb of prevs per curr')\n",
    "    nb_prevs = pos[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    pos['SK_ID_PREV'] = pos['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    \n",
    "    print('Go to averages')\n",
    "    avg_pos = pos.groupby('SK_ID_CURR').mean()\n",
    "    \n",
    "    del pos, nb_prevs\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Reading CC balance')\n",
    "    cc_bal = pd.read_csv(credit_card_balance_csv_file)\n",
    "    \n",
    "    print('Go to dummies')\n",
    "    cc_bal = pd.concat([cc_bal, pd.get_dummies(cc_bal['NAME_CONTRACT_STATUS'], prefix='cc_bal_status_')], axis=1)\n",
    "    \n",
    "    nb_prevs = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    cc_bal['SK_ID_PREV'] = cc_bal['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    \n",
    "    print('Compute average')\n",
    "    avg_cc_bal = cc_bal.groupby('SK_ID_CURR').mean()\n",
    "    avg_cc_bal.columns = ['cc_bal_' + f_ for f_ in avg_cc_bal.columns]\n",
    "    \n",
    "    del cc_bal, nb_prevs\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Reading Installments')\n",
    "    inst = pd.read_csv(installments_payments_csv_file)\n",
    "    nb_prevs = inst[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    inst['SK_ID_PREV'] = inst['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    \n",
    "    avg_inst = inst.groupby('SK_ID_CURR').mean()\n",
    "    avg_inst.columns = ['inst_' + f_ for f_ in avg_inst.columns]\n",
    "    \n",
    "    print('Read data and test')\n",
    "    data = pd.read_csv(application_train_csv_file)\n",
    "    test = pd.read_csv(application_test_csv_file)\n",
    "    print('Shapes : ', data.shape, test.shape)\n",
    "    \n",
    "    id_test = test['SK_ID_CURR']\n",
    "    \n",
    "    y = data['TARGET']\n",
    "    del data['TARGET']\n",
    "    \n",
    "    categorical_feats = [\n",
    "        f for f in data.columns if data[f].dtype == 'object'\n",
    "    ]\n",
    "    categorical_feats\n",
    "    for f_ in categorical_feats:\n",
    "        data[f_], indexer = pd.factorize(data[f_])\n",
    "        test[f_] = indexer.get_indexer(test[f_])\n",
    "        \n",
    "    data = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    del avg_buro, avg_prev\n",
    "    gc.collect()\n",
    "\n",
    "    return data, test, y, id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buro bal shape :  (27299925, 3)\n",
      "transform to dummies\n",
      "Counting buros\n",
      "averaging buro bal\n",
      "Read Bureau\n",
      "Go to dummies\n",
      "Merge with buro avg\n",
      "Counting buro per SK_ID_CURR\n",
      "Averaging bureau\n",
      "            SK_ID_BUREAU  DAYS_CREDIT  CREDIT_DAY_OVERDUE  \\\n",
      "SK_ID_CURR                                                  \n",
      "100001               7.0  -735.000000                 0.0   \n",
      "100002               8.0  -874.000000                 0.0   \n",
      "100003               4.0 -1400.750000                 0.0   \n",
      "100004               2.0  -867.000000                 0.0   \n",
      "100005               3.0  -190.666667                 0.0   \n",
      "\n",
      "            DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  AMT_CREDIT_MAX_OVERDUE  \\\n",
      "SK_ID_CURR                                                                   \n",
      "100001                82.428571        -825.500000                     NaN   \n",
      "100002              -349.000000        -697.500000                1681.029   \n",
      "100003              -544.500000       -1097.333333                   0.000   \n",
      "100004              -488.500000        -532.500000                   0.000   \n",
      "100005               439.333333        -123.000000                   0.000   \n",
      "\n",
      "            CNT_CREDIT_PROLONG  AMT_CREDIT_SUM  AMT_CREDIT_SUM_DEBT  \\\n",
      "SK_ID_CURR                                                            \n",
      "100001                     0.0   207623.571429         85240.928571   \n",
      "100002                     0.0   108131.945625         49156.200000   \n",
      "100003                     0.0   254350.125000             0.000000   \n",
      "100004                     0.0    94518.900000             0.000000   \n",
      "100005                     0.0   219042.000000        189469.500000   \n",
      "\n",
      "            AMT_CREDIT_SUM_LIMIT         ...           \\\n",
      "SK_ID_CURR                               ...            \n",
      "100001                   0.00000         ...            \n",
      "100002                7997.14125         ...            \n",
      "100003              202500.00000         ...            \n",
      "100004                   0.00000         ...            \n",
      "100005                   0.00000         ...            \n",
      "\n",
      "            avg_buro_MONTHS_BALANCE  avg_buro_buro_bal_status_0  \\\n",
      "SK_ID_CURR                                                        \n",
      "100001                   -11.785714                    0.336651   \n",
      "100002                   -21.875000                    0.406960   \n",
      "100003                          NaN                         NaN   \n",
      "100004                          NaN                         NaN   \n",
      "100005                    -3.000000                    0.735043   \n",
      "\n",
      "            avg_buro_buro_bal_status_1  avg_buro_buro_bal_status_2  \\\n",
      "SK_ID_CURR                                                           \n",
      "100001                        0.007519                         0.0   \n",
      "100002                        0.255682                         0.0   \n",
      "100003                             NaN                         NaN   \n",
      "100004                             NaN                         NaN   \n",
      "100005                        0.000000                         0.0   \n",
      "\n",
      "            avg_buro_buro_bal_status_3  avg_buro_buro_bal_status_4  \\\n",
      "SK_ID_CURR                                                           \n",
      "100001                             0.0                         0.0   \n",
      "100002                             0.0                         0.0   \n",
      "100003                             NaN                         NaN   \n",
      "100004                             NaN                         NaN   \n",
      "100005                             0.0                         0.0   \n",
      "\n",
      "            avg_buro_buro_bal_status_5  avg_buro_buro_bal_status_C  \\\n",
      "SK_ID_CURR                                                           \n",
      "100001                             0.0                    0.441240   \n",
      "100002                             0.0                    0.175426   \n",
      "100003                             NaN                         NaN   \n",
      "100004                             NaN                         NaN   \n",
      "100005                             0.0                    0.128205   \n",
      "\n",
      "            avg_buro_buro_bal_status_X  avg_buro_buro_count  \n",
      "SK_ID_CURR                                                   \n",
      "100001                        0.214590            24.571429  \n",
      "100002                        0.161932            13.750000  \n",
      "100003                             NaN                  NaN  \n",
      "100004                             NaN                  NaN  \n",
      "100005                        0.136752             7.000000  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "Read prev\n",
      "Go to dummies\n",
      "Counting number of Prevs\n",
      "Averaging prev\n",
      "            SK_ID_PREV  AMT_ANNUITY  AMT_APPLICATION  AMT_CREDIT  \\\n",
      "SK_ID_CURR                                                         \n",
      "100001             1.0     3951.000         24835.50    23787.00   \n",
      "100002             1.0     9251.775        179055.00   179055.00   \n",
      "100003             3.0    56553.990        435436.50   484191.00   \n",
      "100004             1.0     5357.250         24282.00    20106.00   \n",
      "100005             2.0     4813.200         22308.75    20076.75   \n",
      "\n",
      "            AMT_DOWN_PAYMENT  AMT_GOODS_PRICE  HOUR_APPR_PROCESS_START  \\\n",
      "SK_ID_CURR                                                               \n",
      "100001                2520.0          24835.5                13.000000   \n",
      "100002                   0.0         179055.0                 9.000000   \n",
      "100003                3442.5         435436.5                14.666667   \n",
      "100004                4860.0          24282.0                 5.000000   \n",
      "100005                4464.0          44617.5                10.500000   \n",
      "\n",
      "            NFLAG_LAST_APPL_IN_DAY  RATE_DOWN_PAYMENT  RATE_INTEREST_PRIMARY  \\\n",
      "SK_ID_CURR                                                                     \n",
      "100001                         1.0           0.104326                    NaN   \n",
      "100002                         1.0           0.000000                    NaN   \n",
      "100003                         1.0           0.050030                    NaN   \n",
      "100004                         1.0           0.212008                    NaN   \n",
      "100005                         1.0           0.108964                    NaN   \n",
      "\n",
      "                                 ...                         \\\n",
      "SK_ID_CURR                       ...                          \n",
      "100001                           ...                          \n",
      "100002                           ...                          \n",
      "100003                           ...                          \n",
      "100004                           ...                          \n",
      "100005                           ...                          \n",
      "\n",
      "            PRODUCT_COMBINATION_Cash X-Sell: low  \\\n",
      "SK_ID_CURR                                         \n",
      "100001                                  0.000000   \n",
      "100002                                  0.000000   \n",
      "100003                                  0.333333   \n",
      "100004                                  0.000000   \n",
      "100005                                  0.000000   \n",
      "\n",
      "            PRODUCT_COMBINATION_Cash X-Sell: middle  \\\n",
      "SK_ID_CURR                                            \n",
      "100001                                          0.0   \n",
      "100002                                          0.0   \n",
      "100003                                          0.0   \n",
      "100004                                          0.0   \n",
      "100005                                          0.0   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS household with interest  \\\n",
      "SK_ID_CURR                                                    \n",
      "100001                                             0.000000   \n",
      "100002                                             0.000000   \n",
      "100003                                             0.333333   \n",
      "100004                                             0.000000   \n",
      "100005                                             0.000000   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS household without interest  \\\n",
      "SK_ID_CURR                                                       \n",
      "100001                                                    0.0    \n",
      "100002                                                    0.0    \n",
      "100003                                                    0.0    \n",
      "100004                                                    0.0    \n",
      "100005                                                    0.0    \n",
      "\n",
      "            PRODUCT_COMBINATION_POS industry with interest  \\\n",
      "SK_ID_CURR                                                   \n",
      "100001                                            0.000000   \n",
      "100002                                            0.000000   \n",
      "100003                                            0.333333   \n",
      "100004                                            0.000000   \n",
      "100005                                            0.000000   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS industry without interest  \\\n",
      "SK_ID_CURR                                                      \n",
      "100001                                                    0.0   \n",
      "100002                                                    0.0   \n",
      "100003                                                    0.0   \n",
      "100004                                                    0.0   \n",
      "100005                                                    0.0   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS mobile with interest  \\\n",
      "SK_ID_CURR                                                 \n",
      "100001                                               1.0   \n",
      "100002                                               0.0   \n",
      "100003                                               0.0   \n",
      "100004                                               0.0   \n",
      "100005                                               0.5   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS mobile without interest  \\\n",
      "SK_ID_CURR                                                    \n",
      "100001                                                  0.0   \n",
      "100002                                                  0.0   \n",
      "100003                                                  0.0   \n",
      "100004                                                  1.0   \n",
      "100005                                                  0.0   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS other with interest  \\\n",
      "SK_ID_CURR                                                \n",
      "100001                                              0.0   \n",
      "100002                                              1.0   \n",
      "100003                                              0.0   \n",
      "100004                                              0.0   \n",
      "100005                                              0.0   \n",
      "\n",
      "            PRODUCT_COMBINATION_POS others without interest  \n",
      "SK_ID_CURR                                                   \n",
      "100001                                                  0.0  \n",
      "100002                                                  0.0  \n",
      "100003                                                  0.0  \n",
      "100004                                                  0.0  \n",
      "100005                                                  0.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 rows x 163 columns]\n",
      "Reading POS_CASH\n",
      "Go to dummies\n",
      "Compute nb of prevs per curr\n",
      "Go to averages\n",
      "Reading CC balance\n",
      "Go to dummies\n",
      "Compute average\n",
      "Reading Installments\n",
      "Read data and test\n",
      "Shapes :  (307511, 122) (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "x_data, x_test, y_data, id_test = build_model_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_data = train_csv['SK_ID_CURR']\n",
    "# id_test = test_csv['SK_ID_CURR']\n",
    "\n",
    "# useless_features = []\n",
    "# x_data = train_csv.drop(columns=['SK_ID_CURR'] + useless_features)\n",
    "# x_test = test_csv.drop(columns=['SK_ID_CURR'] + useless_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_csv.loc[2][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(x_data[['EXT_SOURCE_1']], bins=100, normed=True)\n",
    "# plt.xlabel(('x'))\n",
    "# plt.ylabel('EXT_SOURCE_1')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_columns = ['EXT_SOURCE_1']\n",
    "\n",
    "# for data_set in [x_data, x_test]:\n",
    "#     data_set = data_set[log_columns].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(x_data[['EXT_SOURCE_1']], bins=100, normed=True)\n",
    "# plt.xlabel(('x'))\n",
    "# plt.ylabel('EXT_SOURCE_1')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292135, 380)\n",
      "(292135,)\n",
      "(15376, 380)\n",
      "(15376,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.05, random_state=random_num, shuffle=False)\n",
    "\n",
    "# x_train, y_train = shuffle(x_train, y_train, random_state=random_num)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] colsample_bytree=0.2, max_depth=6 ...............................\n",
      "[CV] ................ colsample_bytree=0.2, max_depth=6, total=11.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 13.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] colsample_bytree=0.2, max_depth=6 ...............................\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# lgb_train = lgb.Dataset(x_train, label=y_train)\n",
    "# lgb_val = lgb.Dataset(x_val, label=y_val, reference=lgb_train)\n",
    "\n",
    "# LightGBM parameters\n",
    "param_grid = {\n",
    "#     'task': 'train',\n",
    "#     'num_boost_round': [200],\n",
    "#     'early_stopping_rounds': [10],\n",
    "#     'boosting_type': ['gbdt'], # (default=\"gbdt\")\n",
    "#     'num_leaves': [300], # (default=31)\n",
    "    'max_depth': [6,7,8], # (default=-1)\n",
    "#     'learning_rate': [0.1], # (default=0.1)\n",
    "#     'n_estimators': [1000, 500], # (default=10)\n",
    "#     'max_bin': [1000, 255], # (default=255)\n",
    "#     'subsample_for_bin': [100*10000], # (default=50000)\n",
    "#     'objective': ['binary'], # (default=None)\n",
    "#     'min_split_gain': [0.], # (default=0.)\n",
    "#     'min_child_weight': [1e-3], # (default=1e-3)\n",
    "#     'min_child_samples': [10], # (default=20)\n",
    "#     'subsample': [0.7], # (default=1.)\n",
    "#     'subsample_freq': [1], # (default=1)\n",
    "    'colsample_bytree': [0.2, 0.8], # (default=1.)\n",
    "#     'reg_alpha': [0.], # (default=0.)\n",
    "#     'reg_lambda': [0.], # (default=0.)\n",
    "#     'random_state': [random_num], # (default=None)\n",
    "#     'n_jobs': [-1], # (default=-1)\n",
    "#     'silent': [False], # (default=True)\n",
    "#     'metric': ['auc', 'binary_logloss'],\n",
    "}\n",
    "# print('params: ', params)\n",
    "# train\n",
    "clf = lgb.LGBMClassifier(\n",
    "#     'num_boost_round'=200,\n",
    "#     'early_stopping_rounds'=10,\n",
    "    boosting_type='gbdt', # (default=\"gbdt\")\n",
    "    num_leaves=300, # (default=31)\n",
    "    max_depth=-1, # (default=-1)\n",
    "    learning_rate=0.03, # (default=0.1)\n",
    "    n_estimators=4000, # (default=10)\n",
    "#     'max_bin'=255, # (default=255)\n",
    "    subsample_for_bin=500, # (default=50000)\n",
    "    objective='binary', # (default=None)\n",
    "    class_weight=None,\n",
    "    min_split_gain=0.01, # (default=0.)\n",
    "    min_child_weight=2, # (default=1e-3)\n",
    "    min_child_samples=10, # (default=20)\n",
    "    subsample=0.9, # (default=1.)\n",
    "#     'subsample_freq'=1, # (default=1)\n",
    "    colsample_bytree=0.2, # (default=1.)\n",
    "    reg_alpha=0.1, # (default=0.)\n",
    "    reg_lambda=0.1, # (default=0.)\n",
    "    random_state=random_num, # (default=None)\n",
    "    n_jobs=-1, # (default=-1)\n",
    "    silent=False, # (default=True)\n",
    "#     'metric'=['auc', 'binary_logloss'],\n",
    ")\n",
    "# gbm = lgb.train(\n",
    "#     params,\n",
    "#     train_set=lgb_train,\n",
    "#     valid_sets=lgb_val\n",
    "# )\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, verbose=2, cv=3, n_jobs=1, scoring='roc_auc')\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('*' * 80)\n",
    "y_train_proba = grid_search.predict_proba(x_train)\n",
    "print(y_train.shape)\n",
    "print(y_train_proba.shape)\n",
    "print(y_train_proba[:10])\n",
    "y_train_pred = (y_train_proba[:, 1]>=0.5).astype(int)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "roc_train = roc_auc_score(y_train, y_train_proba[:, 1])\n",
    "print('acc_train: %.4f \\t roc_train: %.4f' % (acc_train, roc_train))\n",
    "\n",
    "# y_train_pred = grid_search.predict(x_train)\n",
    "# acc_train = accuracy_score(y_train, y_train_pred)\n",
    "# roc_train = roc_auc_score(y_train, y_train_proba[:, 1])\n",
    "# print('acc_train: %.4f \\t roc_train: %.4f' % (acc_train, roc_train))\n",
    "\n",
    "y_val_proba = grid_search.predict_proba(x_val)\n",
    "print(y_val.shape)\n",
    "print(y_val_proba.shape)\n",
    "print(y_val_proba[:10])\n",
    "y_val_pred = (y_val_proba[:, 1]>=0.5).astype(int)\n",
    "print(y_val.shape)\n",
    "print(y_val_pred.shape)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "roc_val = roc_auc_score(y_val, y_val_proba[:, 1])\n",
    "print('acc_val:   %.4f \\t roc_val:   %.4f' % (acc_val, roc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.cv_results_)\n",
    "print('*' * 60)\n",
    "print(grid_search.grid_scores_ )\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.scorer_)\n",
    "print('*' * 60)\n",
    "print(type(grid_search.best_estimator_))\n",
    "print(dir(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "display(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_times = grid_search.best_estimator_.booster_.feature_importance()\n",
    "fe_name = grid_search.best_estimator_.booster_.feature_name()\n",
    "print(fe_times)\n",
    "print(fe_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_score = pd.DataFrame(data={'feature': fe_name, 'importance': fe_times})\n",
    "display(importance_score.head())\n",
    "\n",
    "plt.figure(figsize=(18,60))\n",
    "# sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=importance_score.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_score=importance_score.sort_values(by='importance', ascending=False)\n",
    "display(importance_score['feature'][:20])\n",
    "for item in importance_score.values:\n",
    "    print('%s\\t%s' % (item[1], item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_acc = run_name + '_' + str(int(roc_val*10000)).zfill(4)\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = grid_search.predict_proba(x_test)\n",
    "\n",
    "print(y_test_proba.shape)\n",
    "print(y_test_proba[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_proba(y_val_proba, y_val, y_test_proba, id_test, file_name):\n",
    "    print(id_test[:5])\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print('File removed: %s' % file_name)\n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset('y_val_proba', data=y_val_proba)\n",
    "        h.create_dataset('y_val', data=y_val)\n",
    "        h.create_dataset('y_test_proba', data=y_test_proba)\n",
    "        h.create_dataset('id_test', data=id_test)\n",
    "    print('File saved:   %s' % file_name)\n",
    "\n",
    "def load_proba(file_name):\n",
    "    with h5py.File(file_name, 'r') as h:\n",
    "        y_val_proba = np.array(h['y_val_proba'])\n",
    "        y_val = np.array(h['y_val'])\n",
    "        y_test_proba = np.array(h['y_test_proba'])\n",
    "        id_test = np.array(h['id_test'])\n",
    "    print('File loaded:  %s' % file_name)\n",
    "    print(id_test[:5])\n",
    "    \n",
    "    return y_val_proba, y_val, y_test_proba, id_test\n",
    "\n",
    "\n",
    "y_proba_file = os.path.join(model_folder, 'proba_%s.p' % run_name_acc)\n",
    "save_proba(\n",
    "    y_val_proba[:, 1], \n",
    "    y_val, \n",
    "    y_test_proba[:, 1], \n",
    "    id_test,\n",
    "    y_proba_file\n",
    ")\n",
    "y_val_proba_true, y_val, y_test_proba_true, id_test = load_proba(y_proba_file)\n",
    "\n",
    "print(y_val_proba_true.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test_proba_true.shape)\n",
    "print(len(id_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "submission_csv_file = os.path.join(output_folder, 'pred_%s.csv' % run_name_acc)\n",
    "print(submission_csv_file)\n",
    "submission_csv = pd.DataFrame({ 'SK_ID_CURR': id_test , 'TARGET': y_test_proba_true })\n",
    "submission_csv.to_csv(submission_csv_file, index = False)\n",
    "display(submission_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))\n",
    "\n",
    "print('random_num: ', random_num)\n",
    "print(run_name_acc)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
