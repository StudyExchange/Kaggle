{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo_faiss_ORB_GPU\n",
    "\n",
    "Reference:\n",
    "- [const FLANN_INDEX_HIERARCHICAL](https://docs.opencv.org/3.4/dc/d8c/namespacecvflann.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google_LandMark_Rec_Demo_faiss_ORB_GPU_20180528_101259\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Google_LandMark_Rec'\n",
    "step_name = 'Demo_faiss_ORB_GPU'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925\n"
     ]
    }
   ],
   "source": [
    "feature_run_name = 'Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925'\n",
    "# feature_run_name = 'Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411'\n",
    "print(feature_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (1225029, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (117703, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000088da12d664db</td>\n",
       "      <td>https://lh3.googleusercontent.com/-k45wfamuhT8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001623c6d808702</td>\n",
       "      <td>https://lh3.googleusercontent.com/-OQ0ywv8KVIA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  000088da12d664db  https://lh3.googleusercontent.com/-k45wfamuhT8...\n",
       "1  0001623c6d808702  https://lh3.googleusercontent.com/-OQ0ywv8KVIA..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_landmark_id) = \t14951\n",
      "len(id_2_landmark_id_dict) = \t1225029\n",
      "id: cacf8152e2d2ae60, \tlandmark_id:4676\n",
      "id: 0a58358a2afd3e4e, \tlandmark_id:6651\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['id']\n",
    "train_landmark_id = train_csv['landmark_id']\n",
    "print('len(train_landmark_id) = \\t%s' % len(list(set(train_landmark_id))))\n",
    "\n",
    "id_2_landmark_id_dict = dict(zip(train_id, train_landmark_id))\n",
    "print('len(id_2_landmark_id_dict) = \\t%d' % len(id_2_landmark_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b0.pickle  19991\n",
      "CPU times: user 2.18 s, sys: 440 ms, total: 2.62 s\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def dump_pickle_feature_batch(run_name, dataset_name, batch_num, image_features):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    if not os.path.exists(run_name_folder):\n",
    "        os.mkdir(run_name_folder)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    print('Dump: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    pickle.dump(image_features, open(image_features_file, \"wb\"), True)\n",
    "\n",
    "def load_pickle_feature_batch(run_name, dataset_name, batch_num):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features\n",
    "\n",
    "# dump_pickle_feature_batch(run_name, image_features)\n",
    "image_features = load_pickle_feature_batch(feature_run_name, 'train', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "len_image_features= 19991\n",
      "image_id: 69b846bd58c3f09a, \tlandmark_id:6051,\t feature_shape:  (500, 32)\n",
      "image_id: 19a1de4f08cd0305, \tlandmark_id:9179,\t feature_shape:  (500, 32)\n",
      "image_id: 4ee821754ef5fd83, \tlandmark_id:11301,\t feature_shape:  (500, 32)\n"
     ]
    }
   ],
   "source": [
    "print('*'*80)\n",
    "print('len_image_features=', len(image_features.keys()))\n",
    "for i, image_id in enumerate(list(image_features.keys())[:3]):\n",
    "    print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), image_features[image_id].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file_batch(image_features_file):\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_feature_all(feature_run_name, dataset_name):\n",
    "    file_names = os.listdir(os.path.join(feature_folder, feature_run_name))\n",
    "#     file_names = list(filter(lambda x: dataset_name in x, file_names))[:3]\n",
    "    file_names = list(filter(lambda x: dataset_name in x, file_names))\n",
    "    \n",
    "    all_image_fatures = {}\n",
    "    for file_name in file_names:\n",
    "        image_features_file = os.path.join(feature_folder, feature_run_name, file_name)\n",
    "        image_features = load_pickle_file_batch(image_features_file)\n",
    "        all_image_fatures.update(image_features)\n",
    "    return all_image_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_feature_all_parallel(feature_run_name, dataset_name):\n",
    "    file_names = os.listdir(os.path.join(feature_folder, feature_run_name))\n",
    "#     file_names = list(filter(lambda x: dataset_name in x, file_names))[:3]\n",
    "    file_names = list(filter(lambda x: dataset_name in x, file_names))\n",
    "    file_names.sort()\n",
    "    file_names = file_names[:5]\n",
    "    all_image_fatures = {}\n",
    "#     for file_name in file_names:\n",
    "#         image_features_file = os.path.join(feature_folder, feature_run_name, file_name)\n",
    "#         image_features = load_pickle_file_batch(image_features_file)\n",
    "#         all_image_fatures.update(image_features)\n",
    "#     return all_image_fatures\n",
    "\n",
    "    image_features_files = [os.path.join(feature_folder, feature_run_name, file_name) for file_name in file_names]\n",
    "    pool = multiprocessing.Pool(processes=cpu_amount)\n",
    "    for image_features in tqdm(pool.imap(load_pickle_file_batch, image_features_files), total=len(image_features_files)):\n",
    "        all_image_fatures.update(image_features)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    return all_image_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b11.pickle  19988\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b10.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b1.pickle  19990\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b0.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b12.pickle  19993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 2.01 s, total: 3.44 s\n",
      "Wall time: 9.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_image_fatures_train = load_pickle_feature_all_parallel(feature_run_name, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "len_image_features= 99953\n",
      "image_id: 69b846bd58c3f09a, \tlandmark_id:6051,\t feature_shape:  (500, 32)\n",
      "image_id: 19a1de4f08cd0305, \tlandmark_id:9179,\t feature_shape:  (500, 32)\n",
      "image_id: 4ee821754ef5fd83, \tlandmark_id:11301,\t feature_shape:  (500, 32)\n"
     ]
    }
   ],
   "source": [
    "print('*'*80)\n",
    "print('len_image_features=', len(all_image_fatures_train.keys()))\n",
    "for i, image_id in enumerate(list(all_image_fatures_train.keys())[:3]):\n",
    "    print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), all_image_fatures_train[image_id].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(key_train)= 49976\n",
      "len(key_val)= 49977\n"
     ]
    }
   ],
   "source": [
    "key_train, key_val = train_test_split(list(all_image_fatures_train.keys()), test_size=0.5, random_state=2017)\n",
    "print('len(key_train)=', len(key_train))\n",
    "print('len(key_val)=', len(key_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## faiss Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import faiss\n",
    "# dim = 32\n",
    "# indx = faiss.IndexFlatL2(dim)\n",
    "# print(indx.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# labels = []\n",
    "# count = 0\n",
    "# for image_id in tqdm(key_train, total=len(key_train)):\n",
    "#     feature = all_image_fatures_train[image_id].astype('float32')\n",
    "#     landmark_id = id_2_landmark_id_dict[image_id]\n",
    "# #     print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, landmark_id), feature.shape)\n",
    "# #     print(feature[:100].shape)\n",
    "#     indx.add(feature[:100])\n",
    "#     labels.append(np.ones((feature.shape[0], 1)) * landmark_id)\n",
    "#     del all_image_fatures_train[image_id]\n",
    "\n",
    "#     count += 1\n",
    "#     if count % 20000 == 0:\n",
    "# #         print(count)\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.concatenate(labels, axis=0)\n",
    "# print(labels.shape)\n",
    "# print(indx.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# k = 10\n",
    "# feats = all_image_fatures_train[key_val[0]].astype('float32')\n",
    "# D, I = indx.search(feats[:100], k)\n",
    "# print(D.shape)\n",
    "# print(I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minlength = 50000\n",
    "\n",
    "# y = np.array(list(map(lambda n: n if n <= minlength else 0, D.reshape(-1)))).astype('int32')\n",
    "# y = np.bincount(y)\n",
    "# print(y)\n",
    "# print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "dim = 32\n",
    "\n",
    "res = faiss.StandardGpuResources()  # use a single GPU\n",
    "# build a flat (CPU) index\n",
    "index_flat = faiss.IndexFlatL2(dim)\n",
    "# make it into a gpu index\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_index_flat.add(xb)         # add vectors to the index\n",
    "# print(gpu_index_flat.ntotal)\n",
    "\n",
    "# k = 4                          # we want to see 4 nearest neighbors\n",
    "# D, I = gpu_index_flat.search(xq, k)  # actual search\n",
    "# print(I[:5])                   # neighbors of the 5 first queries\n",
    "# print(I[-5:])                  # neighbors of the 5 last queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49976/49976 [30:22<00:00, 27.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 27s, sys: 25min 1s, total: 30min 28s\n",
      "Wall time: 30min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = []\n",
    "count = 0\n",
    "for image_id in tqdm(key_train, total=len(key_train)):\n",
    "    feature = all_image_fatures_train[image_id].astype('float32')\n",
    "    landmark_id = id_2_landmark_id_dict[image_id]\n",
    "#     print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, landmark_id), feature.shape)\n",
    "#     print(feature[:100].shape)\n",
    "    gpu_index_flat.add(feature[:100])\n",
    "    labels.append(np.ones((feature.shape[0], 1)) * landmark_id)\n",
    "    del all_image_fatures_train[image_id]\n",
    "\n",
    "    count += 1\n",
    "    if count % 20000 == 0:\n",
    "#         print(count)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24636101, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "labels = np.concatenate(labels, axis=0)\n",
    "print(labels.shape)\n",
    "print(indx.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100, 10)\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 540 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 10\n",
    "feats = all_image_fatures_train[key_val[0]].astype('float32')\n",
    "D, I = indx.search(feats[:100], k)\n",
    "print(D.shape)\n",
    "print(I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
