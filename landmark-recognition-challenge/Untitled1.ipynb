{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "x_data.shape: \t (506, 13)\n",
      "y_data.shape: \t (506,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "random_num = np.random.randint(10000)\n",
    "\n",
    "random_num = np.random.randint(10000)\n",
    "\n",
    "boston = load_boston()\n",
    "features = boston.feature_names\n",
    "x_data = boston.data\n",
    "y_data = boston.target\n",
    "print('features:', features)\n",
    "print('x_data.shape: \\t', x_data.shape)\n",
    "print('y_data.shape: \\t', y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full train\t 13.0713925453\n",
      "model 1 \t 23.8455878457\n",
      "model 2 \t 17.6584998215\n",
      "model 1+2\t 21.150640958\n",
      "model 1+update2\t 20.9334575737\n"
     ]
    }
   ],
   "source": [
    "x_data = pd.DataFrame(x_data, columns=features)\n",
    "y_data = pd.Series(y_data, index=x_data.index)\n",
    "\n",
    "train_idx, val_idx = train_test_split(list(range(len(x_data))), test_size=0.5, random_state=random_num, shuffle=True)\n",
    "train1_idx, train2_idx = train_test_split(train_idx, test_size=0.5, random_state=random_num, shuffle=True)\n",
    "\n",
    "x_train = x_data.loc[train_idx]\n",
    "x_train_1 = x_data.loc[train1_idx]\n",
    "x_train_2 = x_data.loc[train2_idx]\n",
    "x_val = x_data.loc[val_idx]\n",
    "\n",
    "y_train = y_data.loc[train_idx]\n",
    "y_train_1 = y_data.loc[train1_idx]\n",
    "y_train_2 = y_data.loc[train2_idx]\n",
    "y_val = y_data.loc[val_idx]\n",
    "\n",
    "xg_train_0 = xgb.DMatrix(x_train, label=y_train)\n",
    "xg_train_1 = xgb.DMatrix(x_train_1, label=y_train_1)\n",
    "xg_train_2 = xgb.DMatrix(x_train_2, label=y_train_2)\n",
    "xg_val = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "params = {'objective': 'reg:linear', 'verbose': False}\n",
    "model_0 = xgb.train(params, xg_train_0, 30)\n",
    "model_1 = xgb.train(params, xg_train_1, 30)\n",
    "model_1.save_model('model_1.model')\n",
    "model_2_v1 = xgb.train(params, xg_train_2, 30)\n",
    "model_2_v2 = xgb.train(params, xg_train_2, 30, xgb_model=model_1)\n",
    "\n",
    "params.update({'process_type': 'update',\n",
    "               'updater'     : 'refresh',\n",
    "               'refresh_leaf': True})\n",
    "model_2_v2_update = xgb.train(params, xg_train_2, 30, xgb_model=model_1)\n",
    "\n",
    "print('full train\\t',mse(model_0.predict(xg_val), y_val)) # benchmark\n",
    "print('model 1 \\t',mse(model_1.predict(xg_val), y_val))  \n",
    "print('model 2 \\t',mse(model_2_v1.predict(xg_val), y_val))  # \"before\"\n",
    "print('model 1+2\\t',mse(model_2_v2.predict(xg_val), y_val))  # \"after\"\n",
    "print('model 1+update2\\t',mse(model_2_v2_update.predict(xg_val), y_val))  # \"after\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
