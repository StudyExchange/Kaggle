{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess-TruncatedImages\n",
    "在使用keras预训练的model提取特征的时候，有的图片报错：StopIteration: image file is truncated (85 bytes not processed)，会打断程序。所以，这里把truncated图片删除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import tqdm\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搜索并删除truncated图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_truncated_images(target_folder):\n",
    "    print(target_folder)\n",
    "    percent_count = 1000\n",
    "    t0 = time.time()\n",
    "    sub_folders = os.listdir(target_folder)\n",
    "    sub_folders.sort()\n",
    "    for c in sub_folders:\n",
    "        print(c, end='  ')\n",
    "        class_folder = os.path.join(target_folder, c)\n",
    "        count = 0\n",
    "        for image_name in os.listdir(class_folder):\n",
    "            image_file = os.path.join(class_folder, image_name)\n",
    "            try:\n",
    "                img = Image.open(image_file)\n",
    "                img = img.resize((229, 229))\n",
    "            except Exception as ex:\n",
    "                print('%s: %s' % (image_file, ex))\n",
    "                os.remove(image_file)\n",
    "            count += 1\n",
    "            if count % percent_count == 0:\n",
    "                print(int(count/percent_count), end='  ')\n",
    "    t1 = time.time()\n",
    "    print('Spend time: {0} s'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_truncated_images(train_folder)\n",
    "# search_truncated_images(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(image_files)=1193694\n",
      "len(image_files)=24362\n",
      "len(image_files)=115619\n"
     ]
    }
   ],
   "source": [
    "def get_all_images(target_folder):\n",
    "    sub_folder_names = os.listdir(target_folder)\n",
    "    sub_folder_names.sort()\n",
    "    sub_folders = []\n",
    "    for name in sub_folder_names:\n",
    "        sub_folders.append(os.path.join(target_folder, name))\n",
    "    sub_folders.sort()\n",
    "    \n",
    "    image_files = []\n",
    "    for folder in sub_folders:\n",
    "        for image_name in os.listdir(folder):\n",
    "            image_files.append(os.path.join(folder, image_name))\n",
    "    print('len(image_files)=%d' % len(image_files))\n",
    "    return image_files\n",
    "\n",
    "train_image_files = get_all_images(train_folder)\n",
    "val_image_files = get_all_images(val_folder)\n",
    "test_image_files = get_all_images(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(image_file):\n",
    "    result = None\n",
    "    try:\n",
    "#         result = image_file\n",
    "        img = Image.open(image_file)\n",
    "        img = img.resize((229, 229))\n",
    "    except Exception as ex:\n",
    "        result = '%s: %s' % (image_file, ex)\n",
    "        os.remove(image_file)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_truncated_images_parallel(target_images):\n",
    "    t0 = time.time()\n",
    "    print(target_images[:3])\n",
    "    print('total=%d' % len(target_images))\n",
    "    cores_count = multiprocessing.cpu_count()\n",
    "    print('cores_count=%d' % cores_count)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=cores_count)\n",
    "#     pool.map(check_image, target_images)\n",
    "    for i in tqdm.tqdm(pool.imap_unordered(check_image, target_images), total=len(target_images)):\n",
    "        if i is not None:\n",
    "            print(i)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    t1 = time.time()\n",
    "    print('spend time: %.2f s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data1/kaggle/landmark-recognition-challenge/input/data_train/00000/473e80b9005fcb77.jpg', '/data1/kaggle/landmark-recognition-challenge/input/data_train/00000/464ccf9c677c1c8c.jpg', '/data1/kaggle/landmark-recognition-challenge/input/data_train/00000/22e28089dac709f0.jpg']\n",
      "total=1193694\n",
      "cores_count=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 225990/1193694 [1:14:51<5:20:31, 50.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/kaggle/landmark-recognition-challenge/input/data_train/02975/989cece8afd99098.jpg: cannot identify image file '/data1/kaggle/landmark-recognition-challenge/input/data_train/02975/989cece8afd99098.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 866071/1193694 [4:46:28<1:48:22, 50.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/kaggle/landmark-recognition-challenge/input/data_train/10045/15f0ac5892156ac3.jpg: image file is truncated (40 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1058705/1193694 [5:49:52<44:36, 50.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/kaggle/landmark-recognition-challenge/input/data_train/12718/fd86977aeb91d108.jpg: cannot identify image file '/data1/kaggle/landmark-recognition-challenge/input/data_train/12718/fd86977aeb91d108.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193694/1193694 [6:33:58<00:00, 50.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spend time: 23638.66 s\n",
      "['/data1/kaggle/landmark-recognition-challenge/input/data_val/00000/4e8ab93c1620e8a3.jpg', '/data1/kaggle/landmark-recognition-challenge/input/data_val/00000/90187c0b6f3fa112.jpg', '/data1/kaggle/landmark-recognition-challenge/input/data_val/00000/e8f5d139190cf632.jpg']\n",
      "total=24362\n",
      "cores_count=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24362/24362 [08:05<00:00, 50.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spend time: 485.49 s\n",
      "['/data1/kaggle/landmark-recognition-challenge/input/data_test/test/3d8d7d0946abc715.jpg', '/data1/kaggle/landmark-recognition-challenge/input/data_test/test/48f52f2d6ac1ce30.jpg', '/data1/kaggle/landmark-recognition-challenge/input/data_test/test/97ab0a1fc0daa989.jpg']\n",
      "total=115619\n",
      "cores_count=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115619/115619 [37:32<00:00, 51.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spend time: 2252.79 s\n"
     ]
    }
   ],
   "source": [
    "search_truncated_images_parallel(train_image_files)\n",
    "search_truncated_images_parallel(val_image_files)\n",
    "search_truncated_images_parallel(test_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
