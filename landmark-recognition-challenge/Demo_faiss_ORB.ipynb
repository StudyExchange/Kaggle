{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo_faiss_ORB\n",
    "\n",
    "Reference:\n",
    "- [const FLANN_INDEX_HIERARCHICAL](https://docs.opencv.org/3.4/dc/d8c/namespacecvflann.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google_LandMark_Rec_Demo_faiss_ORB_20180528_135813\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Google_LandMark_Rec'\n",
    "step_name = 'Demo_faiss_ORB'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925\n"
     ]
    }
   ],
   "source": [
    "feature_run_name = 'Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925'\n",
    "# feature_run_name = 'Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411'\n",
    "print(feature_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (1225029, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (117703, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000088da12d664db</td>\n",
       "      <td>https://lh3.googleusercontent.com/-k45wfamuhT8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001623c6d808702</td>\n",
       "      <td>https://lh3.googleusercontent.com/-OQ0ywv8KVIA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  000088da12d664db  https://lh3.googleusercontent.com/-k45wfamuhT8...\n",
       "1  0001623c6d808702  https://lh3.googleusercontent.com/-OQ0ywv8KVIA..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_landmark_id) = \t14951\n",
      "len(id_2_landmark_id_dict) = \t1225029\n",
      "id: cacf8152e2d2ae60, \tlandmark_id:4676\n",
      "id: 0a58358a2afd3e4e, \tlandmark_id:6651\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['id']\n",
    "train_landmark_id = train_csv['landmark_id']\n",
    "print('len(train_landmark_id) = \\t%s' % len(list(set(train_landmark_id))))\n",
    "\n",
    "id_2_landmark_id_dict = dict(zip(train_id, train_landmark_id))\n",
    "print('len(id_2_landmark_id_dict) = \\t%d' % len(id_2_landmark_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b0.pickle  19991\n",
      "CPU times: user 2.11 s, sys: 424 ms, total: 2.53 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def dump_pickle_feature_batch(run_name, dataset_name, batch_num, image_features):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    if not os.path.exists(run_name_folder):\n",
    "        os.mkdir(run_name_folder)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    print('Dump: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    pickle.dump(image_features, open(image_features_file, \"wb\"), True)\n",
    "\n",
    "def load_pickle_feature_batch(run_name, dataset_name, batch_num):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features\n",
    "\n",
    "# dump_pickle_feature_batch(run_name, image_features)\n",
    "image_features = load_pickle_feature_batch(feature_run_name, 'train', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "len_image_features= 19991\n",
      "image_id: 69b846bd58c3f09a, \tlandmark_id:6051,\t feature_shape:  (500, 32)\n",
      "image_id: 19a1de4f08cd0305, \tlandmark_id:9179,\t feature_shape:  (500, 32)\n",
      "image_id: 4ee821754ef5fd83, \tlandmark_id:11301,\t feature_shape:  (500, 32)\n"
     ]
    }
   ],
   "source": [
    "print('*'*80)\n",
    "print('len_image_features=', len(image_features.keys()))\n",
    "for i, image_id in enumerate(list(image_features.keys())[:3]):\n",
    "    print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), image_features[image_id].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file_batch(image_features_file):\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_feature_all(feature_run_name, dataset_name):\n",
    "    file_names = os.listdir(os.path.join(feature_folder, feature_run_name))\n",
    "#     file_names = list(filter(lambda x: dataset_name in x, file_names))[:3]\n",
    "    file_names = list(filter(lambda x: dataset_name in x, file_names))\n",
    "    \n",
    "    all_image_fatures = {}\n",
    "    for file_name in file_names:\n",
    "        image_features_file = os.path.join(feature_folder, feature_run_name, file_name)\n",
    "        image_features = load_pickle_file_batch(image_features_file)\n",
    "        all_image_fatures.update(image_features)\n",
    "    return all_image_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_feature_all_parallel(feature_run_name, dataset_name):\n",
    "    file_names = os.listdir(os.path.join(feature_folder, feature_run_name))\n",
    "#     file_names = list(filter(lambda x: dataset_name in x, file_names))[:3]\n",
    "    file_names = list(filter(lambda x: dataset_name in x, file_names))\n",
    "    file_names.sort()\n",
    "    file_names = file_names\n",
    "    all_image_fatures = {}\n",
    "#     for file_name in file_names:\n",
    "#         image_features_file = os.path.join(feature_folder, feature_run_name, file_name)\n",
    "#         image_features = load_pickle_file_batch(image_features_file)\n",
    "#         all_image_fatures.update(image_features)\n",
    "#     return all_image_fatures\n",
    "\n",
    "    image_features_files = [os.path.join(feature_folder, feature_run_name, file_name) for file_name in file_names]\n",
    "    pool = multiprocessing.Pool(processes=cpu_amount)\n",
    "    for image_features in tqdm(pool.imap(load_pickle_file_batch, image_features_files), total=len(image_features_files)):\n",
    "        all_image_fatures.update(image_features)\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    return all_image_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b11.pickle  19988\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b13.pickle  19993\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b10.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b0.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b1.pickle  19990\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b14.pickle  19994\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b16.pickle  19997\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b12.pickle  19993\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b15.pickle  19990\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b17.pickle  19989\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b21.pickle  19992\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b22.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b18.pickle  19992\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b20.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b19.pickle  19990\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b2.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b23.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b24.pickle  19993\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b25.pickle  19993\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b26.pickle  19992\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b27.pickle  19995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/61 [00:10<10:35, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b28.pickle  19990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 8/61 [00:11<01:14,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b29.pickle  19990\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b3.pickle  19995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 10/61 [00:12<01:05,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b30.pickle  19989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 11/61 [00:14<01:04,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b31.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b32.pickle  19992\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b33.pickle  19994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 12/61 [00:15<01:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b34.pickle  19987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 13/61 [00:16<01:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b35.pickle  19994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 17/61 [00:17<00:44,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b36.pickle  19994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 18/61 [00:17<00:42,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b37.pickle  19992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 19/61 [00:18<00:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b38.pickle  19990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 20/61 [00:19<00:39,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b39.pickle  19989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 21/61 [00:19<00:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b4.pickle  19993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 22/61 [00:20<00:36,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b40.pickle  19988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 23/61 [00:21<00:35,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b41.pickle  19992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 24/61 [00:22<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b42.pickle  19990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 25/61 [00:22<00:32,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b43.pickle  19989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 26/61 [00:23<00:31,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b44.pickle  19989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 27/61 [00:24<00:30,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b45.pickle  19992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 28/61 [00:24<00:29,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b46.pickle  19991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 29/61 [00:25<00:28,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b47.pickle  19995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 30/61 [00:26<00:27,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b48.pickle  19991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 31/61 [00:26<00:26,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b49.pickle  19988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 32/61 [00:27<00:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b5.pickle  19997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 33/61 [00:28<00:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b50.pickle  19989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 34/61 [00:29<00:23,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b51.pickle  19985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 35/61 [00:30<00:22,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b52.pickle  19989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 36/61 [00:30<00:21,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b53.pickle  19995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 38/61 [00:32<00:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b54.pickle  19997\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b55.pickle  19998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 39/61 [00:32<00:18,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b56.pickle  19996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 40/61 [00:33<00:17,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b57.pickle  19995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 41/61 [00:34<00:16,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b58.pickle  19990\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b59.pickle  19994\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b6.pickle  19996\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b60.pickle  17676\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b7.pickle  19998\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b8.pickle  19991\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925_train_b9.pickle  19995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:47<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 21.7 s, total: 35.9 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_image_fatures_train = load_pickle_feature_all_parallel(feature_run_name, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "len_image_features= 1217193\n",
      "image_id: 69b846bd58c3f09a, \tlandmark_id:6051,\t feature_shape:  (500, 32)\n",
      "image_id: 19a1de4f08cd0305, \tlandmark_id:9179,\t feature_shape:  (500, 32)\n",
      "image_id: 4ee821754ef5fd83, \tlandmark_id:11301,\t feature_shape:  (500, 32)\n"
     ]
    }
   ],
   "source": [
    "print('*'*80)\n",
    "print('len_image_features=', len(all_image_fatures_train.keys()))\n",
    "for i, image_id in enumerate(list(all_image_fatures_train.keys())[:3]):\n",
    "    print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), all_image_fatures_train[image_id].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(key_train)= 60859\n",
      "len(key_val)= 1156334\n"
     ]
    }
   ],
   "source": [
    "key_train, key_val = train_test_split(list(all_image_fatures_train.keys()), test_size=0.95, random_state=2017)\n",
    "print('len(key_train)=', len(key_train))\n",
    "print('len(key_val)=', len(key_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## faiss Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "dim = 32\n",
    "faiss_indx = faiss.IndexFlatL2(dim)\n",
    "print(faiss_indx.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60859/60859 [00:04<00:00, 14551.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 1.54 s, total: 4.21 s\n",
      "Wall time: 4.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = []\n",
    "count = 0\n",
    "for image_id in tqdm(key_train, total=len(key_train)):\n",
    "    feature = all_image_fatures_train[image_id].astype('float32')\n",
    "    landmark_id = id_2_landmark_id_dict[image_id]\n",
    "#     print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, landmark_id), feature.shape)\n",
    "#     print(feature[:100].shape)\n",
    "    faiss_indx.add(feature)\n",
    "    labels.append(np.ones(feature.shape[0]) * landmark_id)\n",
    "#     del all_image_fatures_train[image_id]\n",
    "\n",
    "    count += 1\n",
    "    if count % 100000 == 0:\n",
    "#         print(count)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30014128,)\n",
      "30014128\n"
     ]
    }
   ],
   "source": [
    "labels = np.concatenate(labels, axis=0)\n",
    "print(labels.shape)\n",
    "print(faiss_indx.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9633 6051 5554] [24 21  8] 1cb7cab636743701 4118 -\n",
      "[9633 6051 9779] [26 19  6] c6e30b6ebf7e5813 1039 -\n",
      "[6051 9633 6599] [17 15 13] e0a41aecee2946a8 1685 -\n",
      "[9633 6051 2228] [20 16 10] bd65da3fad734987 2228 +\n",
      "[6051 9633 6599] [17 16 12] b9da46d93e488704 6577 -\n",
      "[9633 6051 6599] [20 18 10] 5aebac37cd82703b 8988 -\n",
      "[6051 9633 6599] [24 22  9] 855a7dddb6c262e5 13060 -\n",
      "[6051 9633 6599] [22 17 12] bdd71ccf855fc035 243 -\n",
      "[9633 6051 2061] [59 21  8] 0dda3e0def9b87fb 9633 +\n",
      "[6599 6051 9633] [15 15 14] 1e83b143d7c64d37 4936 -\n",
      "[6051 9633 6599] [27 22 14] 16631bb3f7046c06 3420 -\n",
      "[6051 9633 5554] [32 13 11] 312d9b3ed4e833e7 6696 -\n",
      "[9633 6051 6599] [23 16 13] 26d381d08c369f70 11812 -\n",
      "[6051 9633 6599] [23 18 12] cf05e576dcca6da7 503 -\n",
      "[9633 6051 6599] [17 15  8] 232dd63d3dc267d1 6072 -\n",
      "[6051 9633 9779] [19 17 15] 8564836c9efca669 6051 +\n",
      "[6051 9633 6599] [20 16 12] 08b6077ecc4890fc 3495 -\n",
      "[6051 9633 2061] [21 15  9] d06f85088c8ccebf 165 -\n",
      "[9633 6051 9779] [31 21  9] 780afb0d334562c7 9039 -\n",
      "[6051 9633 3426] [32 17 14] a4c2717a1f605f85 3426 +\n",
      "[9633 6051 2061] [96 17  7] da99685bfe6ccce4 9633 +\n",
      "[9633 6051 2061] [20 17  9] 38d877ca9175a54e 1906 -\n",
      "[9633 6051 6599] [18 18  8] 211bd9ca8077a469 9072 -\n",
      "[6051 1553 9633] [18 16 15] 5c1fdf5f6dd013f2 1553 +\n",
      "[6051 9633 6599] [24 18 11] 62e9c5dcbb905936 5869 -\n",
      "[6051 6599 5554] [17 13 13] 3efebc8671cd0d72 13574 -\n",
      "[6051 9633 6599] [23 18  9] 8832e1105dd85cf3 6511 -\n",
      "[9633 6051 6599] [23 18 15] f33363406c7a0ce8 428 -\n",
      "[6051 9633 6599] [22 19  7] 87c1ae7b61e320d3 1602 -\n",
      "[6051 9633 6599] [23 20  8] 98b42f4df1f6e647 8532 -\n",
      "[ 9779 14785  9618] [2 1 1] 062b4f0efaf7882b 1472 -\n",
      "[9633 6051 7218] [24 14 11] 77615f96278d3d25 7218 +\n",
      "[6051 9633 6599] [21 19 11] d1bf2ffae3e96ba0 10557 -\n",
      "[6051 9633 6599] [20 16 10] bf20c684235110f9 9499 -\n",
      "[6051 9633 9779] [20 15  9] 0d71f077a83255e3 326 -\n",
      "[9633 9779 2061] [13  5  3] 5764ce75391998c9 2061 +\n",
      "[9633 6051 6599] [22 16 15] 69ebbe957b0a4fc0 5955 -\n",
      "[9633 6051 6599] [24 23 11] 47f2d6b92902803c 11183 -\n",
      "[6051 9633 6599] [26 24  8] c5dd3721d5b01f95 8715 -\n",
      "[6051 9633 6599] [27 17 13] e5178ac938d21108 4340 -\n",
      "[ 9633 14012  1874] [2 1 1] 98d34f3988993d87 4954 -\n",
      "[9633 6051 6599] [29 28 11] c89e24c4f7fbb89a 9416 -\n",
      "[6051 9633 6599] [36 14 11] 919f318a03de99ae 6051 +\n",
      "[ 8429  9633 10033] [24 23 15] 6f82b6214d314ed1 11814 -\n",
      "[6051 9633 5554] [26 15 10] 068ae315b11e87b6 1472 -\n",
      "[9633 6051 6599] [30 18 17] 7b4191f1b8cedd69 6599 +\n",
      "[6051 9633 2061] [33 14  9] b7075233642a8061 9446 -\n",
      "[6051 9633 6599] [35 21 15] 3de39e45b6b47bef 9633 +\n",
      "[6051 9633 6599] [21 18 12] 33a3c87e1febb221 5203 -\n",
      "[6051 9633 2061] [19 16  8] 654f9fe71eca24c1 10537 -\n",
      "[6051 9633 6599] [20 18  8] e2ca4c221b711569 7951 -\n",
      "[9633 6051 6599] [24 15 10] 445d0c22b0b96b31 1410 -\n",
      "[6051 9633 6599] [26 26  9] 22adc49da4d68a7c 12937 -\n",
      "[9779 9633 6051] [120  17  11] afdbcb4fcc6169a1 9779 +\n",
      "[6051 9633 2061] [29 21  9] be26cc72a828ec1b 4987 -\n",
      "[6051 9633 2061] [21 17 10] c6daa2a2b2d15c72 6511 -\n",
      "[9633 6051 9779] [25 23  7] 70d9bb7a81ebad99 5113 -\n",
      "[9633 6051 2802] [25 24 12] 13bf31ba01cc00da 2802 +\n",
      "[6051 6599 9633] [21 15 14] 7464a28191bca316 4645 -\n",
      "[9633 6051 1553] [18 18  7] 5e1d847cf4758d5b 9399 -\n",
      "[9633 6051 2061] [20 17 11] 716fdbd97085e0ae 2099 -\n",
      "[9633 6051 6599] [25 25 10] 5138c4baec44b3ba 4830 -\n",
      "[6051 9633 6599] [24 22  9] b31fb8c431a3c825 10357 -\n",
      "[9633 6599 6051] [18 10 10] 6269c0f24657c09f 6971 -\n",
      "[6051 9633 6599] [18 18 12] 58babbcd87d4c0aa 13526 -\n",
      "[6051 9633 2061] [21 20 12] 2407c7df771f3580 9633 +\n",
      "[6051 9633 2743] [21 19  7] 32ea0780c0ea1227 11605 -\n",
      "[5554 6051 9633] [34 21 19] ebd7d95c6b4e9394 5554 +\n",
      "[9633 6051 9779] [49 22 14] 4579165490c10c1e 9633 +\n",
      "[9633 6051 9779] [23 13 11] 743ce7b447233056 6720 -\n",
      "[6051 6599 9633] [26 15 11] 1bcaf23aad269b44 8633 -\n",
      "[6051 9633 1553] [16 10  7] c6157fe5342a9b53 3685 -\n",
      "[ 6051  9633 13526] [27 17 10] 83d3705f3e732831 5376 -\n",
      "[9633 6051 6599] [26 21 12] 2c64e26ed07b313d 2341 -\n",
      "[6051 9633 6599] [22 16  9] bff0edb011b50b3a 14785 -\n",
      "[9633 6051 9779] [20 20  7] 07d9269190eb283b 9481 -\n",
      "[6051 9779 9633] [7 5 4] 87a8ba67a358d86f 6112 -\n",
      "[6051 6599 9633] [25 18 16] 893a29861609ef3a 13176 -\n",
      "[9779 6051 4936] [6 6 4] 8ec0e9b388b968f1 1310 -\n",
      "[9633 6051 4352] [60 16  6] d80364db4f8a212e 9633 +\n",
      "[9633 6051 6599] [20 18 10] 8e5c51169edb7263 6125 -\n",
      "[6051 9633 6599] [18 15 11] 1be1d07a95640830 11536 -\n",
      "[6051 9633 4352] [18 14  8] cda6d51d9659874d 9633 +\n",
      "[6051 9633 6599] [22 15 10] 3a4a4eae4c544478 14170 -\n",
      "[6051 9633 5376] [27 21  8] 36dc4b04865570d4 10107 -\n",
      "[9633 6051 6599] [20 19 10] fa17a5387c4f24f6 4853 -\n",
      "[6051 9633 6599] [38 17 16] 4c67439ea62491d2 6051 +\n",
      "[6051 9633 9779] [17 13 10] 9c9395f04c851380 7866 -\n",
      "[6051 9633 6599] [18 15 12] bbc981e54bb3f1af 12181 -\n",
      "[6051 9633 6599] [20 11  8] aa58a45b93c555d1 7837 -\n",
      "[ 9633  6051 13526] [32 17 16] f470fccb51dde189 13526 +\n",
      "[9633 6051 9779] [23 19  7] f0f1a4561f64e6aa 6455 -\n",
      "[6051 9633 6599] [28 16 16] 693e2ea3fc222653 12519 -\n",
      "[6051 9633 9779] [23 17 14] 731320d36aa9d080 4476 -\n",
      "[6051 9633 6599] [21 17 12] 2ea99c794a30c4ab 12837 -\n",
      "[9633 6051 6599] [22 19 11] bae4bdd36bdba454 7613 -\n",
      "[6051 9633 6599] [27 21  9] 50ca162ef298041c 1203 -\n",
      "[6051 9633 2061] [29 18  9] 88594f2f87b60dca 823 -\n",
      "[9633 6051 9779] [24 20 10] 9014df78bffb688c 133 -\n",
      "[9633 6051 6599] [17 15 11] 0888ad64d326e7ac 12172 -\n",
      "CPU times: user 3h 6min 58s, sys: 4min 42s, total: 3h 11min 41s\n",
      "Wall time: 12min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 1\n",
    "min_des = 5\n",
    "rows = 100\n",
    "count = 0\n",
    "for key in key_val[:rows]:\n",
    "    feats = all_image_fatures_train[key].astype('float32')\n",
    "    D, I = faiss_indx.search(feats, k)\n",
    "#     print(D.shape)\n",
    "#     print(I.shape)\n",
    "    indx = I.reshape(-1)\n",
    "#     des = np.array(list(map(lambda n: print(n, end=' ') if n <= minlength else n, des)))\n",
    "#     print(des.shape, des)\n",
    "#     indx = I.reshape(-1)\n",
    "    lable = [labels[i] for i in indx]\n",
    "    count_indx = np.bincount(lable)\n",
    "    label = np.argsort(count_indx)\n",
    "    label = label[::-1][:3]\n",
    "    print(label, count_indx[label], end=' ')\n",
    "#     count_des = np.array(list(map(lambda n: n if n <= minlength else 0, des)))\n",
    "#     print(count_des.shape, count_des)\n",
    "#     y = np.bincount(y)\n",
    "#     print(y)\n",
    "    print(key, id_2_landmark_id_dict[key], end=' ')\n",
    "    if id_2_landmark_id_dict[key] in label:\n",
    "        print('+')\n",
    "        count += 1\n",
    "    else:\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.20\n"
     ]
    }
   ],
   "source": [
    "acc = count*1.0 / rows\n",
    "print('acc=%.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
