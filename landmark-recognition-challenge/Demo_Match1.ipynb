{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo_Match1\n",
    "\n",
    "Reference:\n",
    "- [const FLANN_INDEX_HIERARCHICAL](https://docs.opencv.org/3.4/dc/d8c/namespacecvflann.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google_LandMark_Rec_Demo_Match1_20180520_152940\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Google_LandMark_Rec'\n",
    "step_name = 'Demo_Match1'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411\n"
     ]
    }
   ],
   "source": [
    "# feature_run_name = 'Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180519_141925'\n",
    "feature_run_name = 'Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411'\n",
    "print(feature_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (1225029, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (117703, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000088da12d664db</td>\n",
       "      <td>https://lh3.googleusercontent.com/-k45wfamuhT8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001623c6d808702</td>\n",
       "      <td>https://lh3.googleusercontent.com/-OQ0ywv8KVIA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  000088da12d664db  https://lh3.googleusercontent.com/-k45wfamuhT8...\n",
       "1  0001623c6d808702  https://lh3.googleusercontent.com/-OQ0ywv8KVIA..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_landmark_id) = \t14951\n",
      "len(id_2_landmark_id_dict) = \t1225029\n",
      "id: cacf8152e2d2ae60, \tlandmark_id:4676\n",
      "id: 0a58358a2afd3e4e, \tlandmark_id:6651\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['id']\n",
    "train_landmark_id = train_csv['landmark_id']\n",
    "print('len(train_landmark_id) = \\t%s' % len(list(set(train_landmark_id))))\n",
    "\n",
    "id_2_landmark_id_dict = dict(zip(train_id, train_landmark_id))\n",
    "print('len(id_2_landmark_id_dict) = \\t%d' % len(id_2_landmark_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411_train_b0.pickle  19991\n",
      "CPU times: user 636 ms, sys: 128 ms, total: 764 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def dump_pickle_feature_batch(run_name, dataset_name, batch_num, image_features):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    if not os.path.exists(run_name_folder):\n",
    "        os.mkdir(run_name_folder)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    print('Dump: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    pickle.dump(image_features, open(image_features_file, \"wb\"), True)\n",
    "\n",
    "def load_pickle_feature_batch(run_name, dataset_name, batch_num):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features\n",
    "\n",
    "# dump_pickle_feature_batch(run_name, image_features)\n",
    "image_features = load_pickle_feature_batch(feature_run_name, 'train', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "len_image_features= 19991\n",
      "image_id: 69b846bd58c3f09a, \tlandmark_id:6051,\t feature_shape:  (100, 32)\n",
      "image_id: 19a1de4f08cd0305, \tlandmark_id:9179,\t feature_shape:  (100, 32)\n",
      "image_id: 4ee821754ef5fd83, \tlandmark_id:11301,\t feature_shape:  (100, 32)\n"
     ]
    }
   ],
   "source": [
    "print('*'*80)\n",
    "print('len_image_features=', len(image_features.keys()))\n",
    "for i, image_id in enumerate(list(image_features.keys())[:3]):\n",
    "    print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), image_features[image_id].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_feature_batch(image_features_file):\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_feature_all(feature_run_name, dataset_name):\n",
    "    file_names = os.listdir(os.path.join(feature_folder, feature_run_name))\n",
    "    file_names = list(filter(lambda x: dataset_name in x, file_names))[:3]\n",
    "    all_image_fatures = {}\n",
    "    for file_name in file_names:\n",
    "        image_features_file = os.path.join(feature_folder, feature_run_name, file_name)\n",
    "        image_features = load_pickle_feature_batch(image_features_file)\n",
    "        all_image_fatures.update(image_features)\n",
    "    return all_image_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411_train_b6.pickle  19996\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411_train_b24.pickle  19993\n",
      "Load:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411/feature_Google_LandMark_Rec_FeatureExtraction_ORB_Parallel_20180520_125411_train_b29.pickle  19990\n"
     ]
    }
   ],
   "source": [
    "all_image_fatures_train = load_pickle_feature_all(feature_run_name, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "len_image_features= 59979\n",
      "image_id: 233c663432549b33, \tlandmark_id:7048,\t feature_shape:  (100, 32)\n",
      "image_id: 2e31b117f4748914, \tlandmark_id:3249,\t feature_shape:  (100, 32)\n",
      "image_id: 299f52148392856a, \tlandmark_id:4702,\t feature_shape:  (100, 32)\n"
     ]
    }
   ],
   "source": [
    "print('*'*80)\n",
    "print('len_image_features=', len(all_image_fatures_train.keys()))\n",
    "for i, image_id in enumerate(list(all_image_fatures_train.keys())[:3]):\n",
    "    print('image_id: %s, \\tlandmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), all_image_fatures_train[image_id].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrbMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1 \n",
      "{6051: 1, 14950: 0, 4993: 0}\n",
      "CPU times: user 656 ms, sys: 2.56 s, total: 3.21 s\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Basic params\n",
    "\n",
    "def match(\n",
    "    feature,\n",
    "    org_features,\n",
    "    id_2_landmark_id_dict=id_2_landmark_id_dict,\n",
    "    is_crossCheck = False, \n",
    "    n_matches=50, \n",
    "    min_distance=50, \n",
    "    min_good_match=30,\n",
    "    n_class = 14951,\n",
    "    top=3,\n",
    "):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=is_crossCheck)\n",
    "    matched_image_classes = np.zeros(n_class, dtype=np.int16)\n",
    "\n",
    "    image_ids = list(org_features.keys())\n",
    "#     rows = len(image_ids)\n",
    "    rows = 1000\n",
    "    print(rows)\n",
    "    for i, image_id in enumerate(image_ids[:rows]):\n",
    "        test_feature = org_features[image_id]\n",
    "        if test_feature is None:\n",
    "            print('None ', image_id, end=' ')\n",
    "            continue\n",
    "        try:\n",
    "            matches = bf.match(feature, org_features[image_id])\n",
    "        except Exception as ex:\n",
    "            print(image_id, end=' ')\n",
    "#             print(ex)\n",
    "            continue\n",
    "        matches = list(filter(lambda x: x.distance < min_distance, matches))\n",
    "        if len(matches) > min_good_match:\n",
    "            class_idx = id_2_landmark_id_dict[image_id]\n",
    "            matched_image_classes[class_idx] = matched_image_classes[class_idx] + 1\n",
    "#             print('image_id=', image_id, end=' ')\n",
    "#             print('len(matches)=', len(matches), end=' ')\n",
    "#             print('+%s' % class_idx)\n",
    "#         else:\n",
    "#             print('-', end='')\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('%s' % int((i+1)/1000), end=' ')\n",
    "\n",
    "    print('')\n",
    "    sorted_matches_idx = np.argsort(matched_image_classes)\n",
    "    sorted_matches_idx = sorted_matches_idx[::-1]\n",
    "    best_matches_idx = sorted_matches_idx[0: top]\n",
    "    best_matches = {}\n",
    "    for i in best_matches_idx:\n",
    "        best_matches[i] = matched_image_classes[i]\n",
    "    return best_matches\n",
    "\n",
    "indx = 0\n",
    "finding_key = list(image_features.keys())[indx]\n",
    "best_matches = match(image_features[finding_key], image_features)\n",
    "print(best_matches)\n",
    "\n",
    "# for i in range(1, 3):\n",
    "#     finding_key = list(image_features.keys())[i]\n",
    "#     best_matches = match(image_features[finding_key], image_features)\n",
    "#     print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1 \n",
      "{6051: 1, 14950: 0, 4993: 0}\n",
      "1000\n",
      "1 \n",
      "{9179: 1, 14950: 0, 4978: 0}\n",
      "1000\n",
      "1 \n",
      "{11301: 1, 4979: 0, 4991: 0}\n",
      "CPU times: user 2.86 s, sys: 16.3 s, total: 19.2 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## matches = list(filter(lambda x: x[0].distance < min_distance, matches))\n",
    "\n",
    "def match_knn(\n",
    "    feature,\n",
    "    org_features,\n",
    "    id_2_landmark_id_dict=id_2_landmark_id_dict,\n",
    "    is_crossCheck = False, \n",
    "    n_matches=100, \n",
    "    min_distance=50, \n",
    "    min_good_match=30,\n",
    "    n_class = 14951,\n",
    "    top=3,\n",
    "):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    \n",
    "    \n",
    "    matched_image_classes = np.zeros(n_class, dtype=np.int16)\n",
    "\n",
    "    image_ids = list(org_features.keys())\n",
    "#     rows = len(image_ids)\n",
    "    rows = 1000\n",
    "    print(rows)\n",
    "    for i, image_id in enumerate(image_ids[:rows]):\n",
    "        test_feature = org_features[image_id]\n",
    "        if test_feature is None:\n",
    "            print('None ', image_id, end=' ')\n",
    "            continue\n",
    "        try:\n",
    "            matches = bf.knnMatch(feature, org_features[image_id], k=2)\n",
    "#             matches = bf.match(feature, org_features[image_id])\n",
    "        except Exception as ex:\n",
    "            print(image_id, end=' ')\n",
    "            print(ex)\n",
    "            continue\n",
    "#         print('len(matches)=%s' % len(matches))\n",
    "#         print('len(matches[0])=%s' % len(matches[0]))\n",
    "#         print('matches[0][0].distance=%s' % matches[0][0].distance, end=' ')\n",
    "#         print('matches[0][1].distance=%s' % matches[0][1].distance)\n",
    "        matches = list(filter(lambda x: x[0].distance < min_distance, matches))\n",
    "#         matches = list(filter(lambda x: x[0].distance < min_distance and x[0].distance < 0.6*x[1].distance, matches))\n",
    "#         print('len(matches)=%s' % len(matches))\n",
    "#         matches = list(filter(lambda x: x.distance < min_distance, matches))\n",
    "        if len(matches) > min_good_match:\n",
    "            class_idx = id_2_landmark_id_dict[image_id]\n",
    "            matched_image_classes[class_idx] = matched_image_classes[class_idx] + 1\n",
    "#             print('image_id=', image_id, end=' ')\n",
    "#             print('len(matches)=', len(matches), end=' ')\n",
    "#             print('+%s' % class_idx)\n",
    "#         else:\n",
    "#             print('-', end='')\n",
    "            \n",
    "#         print('*'*10)\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('%s' % int((i+1)/1000), end=' ')\n",
    "\n",
    "    print('')\n",
    "    sorted_matches_idx = np.argsort(matched_image_classes)\n",
    "    sorted_matches_idx = sorted_matches_idx[::-1]\n",
    "    best_matches_idx = sorted_matches_idx[0: top]\n",
    "    best_matches = {}\n",
    "    for i in best_matches_idx:\n",
    "        best_matches[i] = matched_image_classes[i]\n",
    "    return best_matches\n",
    "\n",
    "indx = 0\n",
    "finding_key = list(image_features.keys())[indx]\n",
    "best_matches = match_knn(image_features[finding_key], image_features)\n",
    "print(best_matches)\n",
    "\n",
    "for i in range(1, 3):\n",
    "    finding_key = list(image_features.keys())[i]\n",
    "    best_matches = match_knn(image_features[finding_key], image_features)\n",
    "    print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1 \n",
      "{6051: 1, 14950: 0, 4993: 0}\n",
      "1000\n",
      "1 \n",
      "{9179: 1, 14950: 0, 4978: 0}\n",
      "1000\n",
      "1 \n",
      "{11301: 1, 4979: 0, 4991: 0}\n",
      "CPU times: user 2.58 s, sys: 12.6 s, total: 15.2 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## matches = list(filter(lambda x: x[0].distance < min_distance and x[0].distance < 0.8*x[1].distance, matches))\n",
    "\n",
    "def match_knn(\n",
    "    feature,\n",
    "    org_features,\n",
    "    id_2_landmark_id_dict=id_2_landmark_id_dict,\n",
    "    is_crossCheck = False, \n",
    "    n_matches=100, \n",
    "    min_distance=50, \n",
    "    min_good_match=30,\n",
    "    n_class = 14951,\n",
    "    top=3,\n",
    "):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    \n",
    "    \n",
    "    matched_image_classes = np.zeros(n_class, dtype=np.int16)\n",
    "\n",
    "    image_ids = list(org_features.keys())\n",
    "#     rows = len(image_ids)\n",
    "    rows = 1000\n",
    "    print(rows)\n",
    "    for i, image_id in enumerate(image_ids[:rows]):\n",
    "        test_feature = org_features[image_id]\n",
    "        if test_feature is None:\n",
    "            print('None ', image_id, end=' ')\n",
    "            continue\n",
    "        try:\n",
    "            matches = bf.knnMatch(feature, org_features[image_id], k=2)\n",
    "#             matches = bf.match(feature, org_features[image_id])\n",
    "        except Exception as ex:\n",
    "            print(image_id, end=' ')\n",
    "            print(ex)\n",
    "            continue\n",
    "#         print('len(matches)=%s' % len(matches))\n",
    "#         print('len(matches[0])=%s' % len(matches[0]))\n",
    "#         print('matches[0][0].distance=%s' % matches[0][0].distance, end=' ')\n",
    "#         print('matches[0][1].distance=%s' % matches[0][1].distance)\n",
    "        matches = list(filter(lambda x: x[0].distance < min_distance and x[0].distance < 0.8*x[1].distance, matches))\n",
    "#         matches = list(filter(lambda x: x[0].distance < min_distance and x[0].distance < 0.6*x[1].distance, matches))\n",
    "#         print('len(matches)=%s' % len(matches))\n",
    "#         matches = list(filter(lambda x: x.distance < min_distance, matches))\n",
    "        if len(matches) > min_good_match:\n",
    "            class_idx = id_2_landmark_id_dict[image_id]\n",
    "            matched_image_classes[class_idx] = matched_image_classes[class_idx] + 1\n",
    "#             print('image_id=', image_id, end=' ')\n",
    "#             print('len(matches)=', len(matches), end=' ')\n",
    "#             print('+%s' % class_idx)\n",
    "#         else:\n",
    "#             print('-', end='')\n",
    "            \n",
    "#         print('*'*10)\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('%s' % int((i+1)/1000), end=' ')\n",
    "\n",
    "    print('')\n",
    "    sorted_matches_idx = np.argsort(matched_image_classes)\n",
    "    sorted_matches_idx = sorted_matches_idx[::-1]\n",
    "    best_matches_idx = sorted_matches_idx[0: top]\n",
    "    best_matches = {}\n",
    "    for i in best_matches_idx:\n",
    "        best_matches[i] = matched_image_classes[i]\n",
    "    return best_matches\n",
    "\n",
    "indx = 0\n",
    "finding_key = list(image_features.keys())[indx]\n",
    "best_matches = match_knn(image_features[finding_key], image_features)\n",
    "print(best_matches)\n",
    "\n",
    "for i in range(1, 3):\n",
    "    finding_key = list(image_features.keys())[i]\n",
    "    best_matches = match_knn(image_features[finding_key], image_features)\n",
    "    print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "1000\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) /io/opencv/modules/flann/src/miniflann.cpp:315: error: (-210) type=0\n in function buildIndex_\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.1) /io/opencv/modules/flann/src/miniflann.cpp:315: error: (-210) type=0\n in function buildIndex_\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_matches = 50\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "FLANN_INDEX_HIERARCHICAL = 5\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=10)\n",
    "search_params = dict(checks=n_matches)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "rows = 1000\n",
    "trained_features = []\n",
    "for i, image_id in enumerate(list(image_features.keys())[:rows]):\n",
    "    test_feature = image_features[image_id]\n",
    "    if test_feature is None:\n",
    "        print('None ', image_id, end=' ')\n",
    "        continue\n",
    "    try:\n",
    "        trained_features.append(image_features[image_id])\n",
    "    except Exception as ex:\n",
    "        print(image_id, end=' ')\n",
    "        print(ex)\n",
    "        continue\n",
    "print('***')\n",
    "flann.add(trained_features)\n",
    "print(len(flann.getTrainDescriptors()))\n",
    "flann.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# ## matches = flann.knnMatch(feature, org_features[image_id], k=2)\n",
    "\n",
    "# def match_knn(\n",
    "#     feature,\n",
    "#     org_features,\n",
    "#     id_2_landmark_id_dict=id_2_landmark_id_dict,\n",
    "#     is_crossCheck = False, \n",
    "#     n_matches=100, \n",
    "#     min_distance=50, \n",
    "#     min_good_match=30,\n",
    "#     n_class = 14951,\n",
    "#     top=3,\n",
    "# ):\n",
    "#     FLANN_INDEX_KDTREE = 0\n",
    "#     FLANN_INDEX_HIERARCHICAL = 5\n",
    "#     FLANN_INDEX_LSH = 6\n",
    "#     index_params = dict(algorithm=FLANN_INDEX_LSH, trees=5)\n",
    "#     search_params = dict(checks=n_matches)\n",
    "#     flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    \n",
    "#     matched_image_classes = np.zeros(n_class, dtype=np.int16)\n",
    "\n",
    "#     image_ids = list(org_features.keys())\n",
    "# #     rows = len(image_ids)\n",
    "#     rows = 1000\n",
    "#     print(rows)\n",
    "#     for i, image_id in enumerate(image_ids[:rows]):\n",
    "#         test_feature = org_features[image_id]\n",
    "#         if test_feature is None:\n",
    "#             print('None ', image_id, end=' ')\n",
    "#             continue\n",
    "#         try:\n",
    "#             matches = flann.knnMatch(feature, org_features[image_id], k=2)\n",
    "# #             matches = bf.match(feature, org_features[image_id])\n",
    "#         except Exception as ex:\n",
    "#             print(image_id, end=' ')\n",
    "#             print(ex)\n",
    "#             continue\n",
    "# #         print('len(matches)=%s' % len(matches))\n",
    "# #         print('len(matches[0])=%s' % len(matches[0]))\n",
    "# #         print('matches[0][0].distance=%s' % matches[0][0].distance, end=' ')\n",
    "# #         print('matches[0][1].distance=%s' % matches[0][1].distance)\n",
    "#         matches = list(filter(lambda x: len(x) > 0 and x[0].distance < min_distance, matches))\n",
    "# #         matches = list(filter(lambda x: x[0].distance < min_distance and x[0].distance < 0.6*x[1].distance, matches))\n",
    "# #         print('len(matches)=%s' % len(matches))\n",
    "# #         matches = list(filter(lambda x: x.distance < min_distance, matches))\n",
    "#         if len(matches) > min_good_match:\n",
    "#             class_idx = id_2_landmark_id_dict[image_id]\n",
    "#             matched_image_classes[class_idx] = matched_image_classes[class_idx] + 1\n",
    "# #             print('image_id=', image_id, end=' ')\n",
    "# #             print('len(matches)=', len(matches), end=' ')\n",
    "# #             print('+%s' % class_idx)\n",
    "# #         else:\n",
    "# #             print('-', end='')\n",
    "            \n",
    "# #         print('*'*10)\n",
    "#         if (i+1) % 1000 == 0:\n",
    "#             print('%s' % int((i+1)/1000), end=' ')\n",
    "\n",
    "#     print('')\n",
    "#     sorted_matches_idx = np.argsort(matched_image_classes)\n",
    "#     sorted_matches_idx = sorted_matches_idx[::-1]\n",
    "#     best_matches_idx = sorted_matches_idx[0: top]\n",
    "#     best_matches = {}\n",
    "#     for i in best_matches_idx:\n",
    "#         best_matches[i] = matched_image_classes[i]\n",
    "#     return best_matches\n",
    "\n",
    "# indx = 0\n",
    "# finding_key = list(image_features.keys())[indx]\n",
    "# best_matches = match_knn(image_features[finding_key], image_features)\n",
    "# print(best_matches)\n",
    "\n",
    "# for i in range(1, 3):\n",
    "#     finding_key = list(image_features.keys())[i]\n",
    "#     best_matches = match_knn(image_features[finding_key], image_features)\n",
    "#     print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19991\n"
     ]
    }
   ],
   "source": [
    "print(len(list(image_features.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# n_matches = 100\n",
    "\n",
    "# FLANN_INDEX_KDTREE = 0\n",
    "# FLANN_INDEX_HIERARCHICAL = 5\n",
    "# FLANN_INDEX_LSH = 6\n",
    "# index_params = dict(algorithm=FLANN_INDEX_LSH, trees=10)\n",
    "# search_params = dict(checks=n_matches)\n",
    "# flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# rows = 1000\n",
    "# for i, image_id in enumerate(list(image_features.keys())[:rows]):\n",
    "#     test_feature = image_features[image_id]\n",
    "#     if test_feature is None:\n",
    "#         print('None ', image_id, end=' ')\n",
    "#         continue\n",
    "#     try:\n",
    "#         matches = flann.add(image_features[image_id])\n",
    "#     except Exception as ex:\n",
    "#         print(image_id, end=' ')\n",
    "#         print(ex)\n",
    "#         continue\n",
    "# print(len(flann.getTrainDescriptors()))\n",
    "# flann.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# ## matches = flann.knnMatch(feature, org_features[image_id], k=2)\n",
    "\n",
    "# def match_knn(\n",
    "#     feature,\n",
    "#     org_features,\n",
    "#     id_2_landmark_id_dict=id_2_landmark_id_dict,\n",
    "#     is_crossCheck = False, \n",
    "#     n_matches=100, \n",
    "#     min_distance=50, \n",
    "#     min_good_match=30,\n",
    "#     n_class = 14951,\n",
    "#     top=3,\n",
    "# ):\n",
    "#     FLANN_INDEX_LSH = 6\n",
    "#     index_params= dict(\n",
    "#         algorithm = FLANN_INDEX_LSH,\n",
    "#         table_number = 6,\n",
    "#         key_size = 12,\n",
    "#         multi_probe_level = 1\n",
    "#     )\n",
    "#     search_params = dict(n_matches=n_matches)\n",
    "#     flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    \n",
    "#     matched_image_classes = np.zeros(n_class, dtype=np.int16)\n",
    "\n",
    "#     image_ids = list(org_features.keys())\n",
    "# #     rows = len(image_ids)\n",
    "#     rows = 1000\n",
    "#     print(rows)\n",
    "#     for i, image_id in enumerate(image_ids[:rows]):\n",
    "#         test_feature = org_features[image_id]\n",
    "#         if test_feature is None:\n",
    "#             print('None ', image_id, end=' ')\n",
    "#             continue\n",
    "#         try:\n",
    "#             matches = flann.add(org_features[image_id])\n",
    "# #             matches = bf.match(feature, org_features[image_id])\n",
    "#         except Exception as ex:\n",
    "#             print(image_id, end=' ')\n",
    "#             print(ex)\n",
    "#             continue\n",
    "#     print(len(flann.getTrainDescriptors()))\n",
    "#     flann.train()\n",
    "    \n",
    "#     for i, image_id in enumerate(image_ids[:rows]):\n",
    "#         test_feature = org_features[image_id]\n",
    "#         if test_feature is None:\n",
    "#             print('None ', image_id, end=' ')\n",
    "#             continue\n",
    "#         try:\n",
    "#             matches = flann.add(org_features[image_id])\n",
    "# #             matches = bf.match(feature, org_features[image_id])\n",
    "#         except Exception as ex:\n",
    "#             print(image_id, end=' ')\n",
    "#             print(ex)\n",
    "#             continue\n",
    "#     matches = flann.knnMatch(feature, k=2)\n",
    "#     print('len(matches)=%s' % len(matches))\n",
    "#     print('len(matches[0])=%s' % len(matches[0]))\n",
    "\n",
    "# indx = 0\n",
    "# finding_key = list(image_features.keys())[indx]\n",
    "# best_matches = match_knn(image_features[finding_key], image_features)\n",
    "# # print(best_matches)\n",
    "\n",
    "# # for i in range(1, 3):\n",
    "# #     finding_key = list(image_features.keys())[i]\n",
    "# #     best_matches = match_knn(image_features[finding_key], image_features)\n",
    "# #     print(best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train val dataset\n",
    "# match --> proba_list\n",
    "# predcit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(image_id_train)=56980\n",
      "len(image_id_val)=2999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_id_train, image_id_val = train_test_split(list(all_image_fatures_train.keys()), test_size=0.05, random_state=2018)\n",
    "print('len(image_id_train)=%s' % len(image_id_train))\n",
    "print('len(image_id_val)=%s' % len(image_id_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "# function_partial = partial(\n",
    "#     match_knn,\n",
    "#     org_features=all_image_fatures_train,\n",
    "#     n_matches=100, \n",
    "#     min_distance=30,\n",
    "#     min_good_match=30,\n",
    "# )\n",
    "\n",
    "# image_features_val = [all_image_fatures_train[img_id] for img_id in image_id_val]\n",
    "# pool = multiprocessing.Pool(processes=cpu_amount)\n",
    "# for res in tqdm(pool.imap(function_partial, image_features_val), total=len(2)):\n",
    "#     print(res)\n",
    "# pool.close()\n",
    "# pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
