{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  FeatureExtraction_SIFT_Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180527_100055\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'Google_LandMark_Rec'\n",
    "step_name = 'FeatureExtraction_SIFT_Parallel'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount:  36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import tqdm\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "print('cpu_amount: ', cpu_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "\n",
    "org_train_folder = os.path.join(input_folder, 'org_train')\n",
    "org_test_folder = os.path.join(input_folder, 'org_test')\n",
    "train_folder = os.path.join(input_folder, 'data_train')\n",
    "val_folder = os.path.join(input_folder, 'data_val')\n",
    "test_folder = os.path.join(input_folder, 'data_test')\n",
    "test_sub_folder = os.path.join(test_folder, 'test')\n",
    "\n",
    "train_csv_file = os.path.join(input_folder, 'train.csv')\n",
    "test_csv_file = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_folder = os.path.join(input_folder, 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv.shape is (1225029, 3).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_csv.shape is (117703, 2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000088da12d664db</td>\n",
       "      <td>https://lh3.googleusercontent.com/-k45wfamuhT8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001623c6d808702</td>\n",
       "      <td>https://lh3.googleusercontent.com/-OQ0ywv8KVIA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  000088da12d664db  https://lh3.googleusercontent.com/-k45wfamuhT8...\n",
       "1  0001623c6d808702  https://lh3.googleusercontent.com/-OQ0ywv8KVIA..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_file)\n",
    "print('train_csv.shape is {0}.'.format(train_csv.shape))\n",
    "display(train_csv.head(2))\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_file)\n",
    "print('test_csv.shape is {0}.'.format(test_csv.shape))\n",
    "display(test_csv.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_landmark_id) = \t14951\n",
      "len(id_2_landmark_id_dict) = \t1225029\n",
      "id: cacf8152e2d2ae60, \tlandmark_id:4676\n",
      "id: 0a58358a2afd3e4e, \tlandmark_id:6651\n"
     ]
    }
   ],
   "source": [
    "train_id = train_csv['id']\n",
    "train_landmark_id = train_csv['landmark_id']\n",
    "print('len(train_landmark_id) = \\t%s' % len(list(set(train_landmark_id))))\n",
    "\n",
    "id_2_landmark_id_dict = dict(zip(train_id, train_landmark_id))\n",
    "print('len(id_2_landmark_id_dict) = \\t%d' % len(id_2_landmark_id_dict))\n",
    "\n",
    "index = 0\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))\n",
    "index = 1\n",
    "print('id: %s, \\tlandmark_id:%s' % (train_id[index], id_2_landmark_id_dict[train_id[index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "/data1/kaggle/landmark-recognition-challenge/input/org_train/69b846bd58c3f09a.jpg\n"
     ]
    }
   ],
   "source": [
    "def image_detect_and_compute(image_file, clf):\n",
    "    \"\"\"Detect and compute interest points and their descriptors.\"\"\"\n",
    "    img = cv2.imread(image_file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    des = None\n",
    "    try:\n",
    "        kp, des = clf.detectAndCompute(img, None)\n",
    "    except Exception as ex:\n",
    "        print(image_file, ex)\n",
    "    return des\n",
    "\n",
    "n_features = 100\n",
    "# clf = cv2.ORB_create(n_features)\n",
    "clf = cv2.xfeatures2d.SIFT_create(n_features)\n",
    "\n",
    "org_train_images = os.listdir(org_train_folder)[:10]\n",
    "print(len(org_train_images))\n",
    "image_file = os.path.join(org_train_folder, org_train_images[0])\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 22.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def dump_pickle_feature_batch(run_name, dataset_name, batch_num, image_features):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    if not os.path.exists(run_name_folder):\n",
    "        os.mkdir(run_name_folder)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    print('Dump: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    pickle.dump(image_features, open(image_features_file, \"wb\"), True)\n",
    "\n",
    "def load_pickle_feature_batch(run_name, dataset_name, batch_num):\n",
    "    run_name_folder = os.path.join(feature_folder, run_name)\n",
    "    image_features_file = os.path.join(run_name_folder, 'feature_%s_%s_b%s.pickle' % (run_name, dataset_name, batch_num))\n",
    "    image_features = pickle.load(open(image_features_file, \"rb\"))\n",
    "    print('Load: ', image_features_file, end='  ')\n",
    "    print(len(image_features.keys()))\n",
    "    return image_features\n",
    "\n",
    "# dump_pickle_feature(run_name, image_features)\n",
    "# image_features = load_pickle_feature(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_batch(batch_num, folder, run_name, dataset_name, batch_size):\n",
    "    print('batch=%s %s %s %s %s' % (batch_num, folder, run_name, dataset_name, batch_size))\n",
    "    image_names = os.listdir(folder)\n",
    "    img_names_batch = image_names[batch_num*batch_size: (batch_num+1)*batch_size]\n",
    "    print(len(img_names_batch), end=' --> ')\n",
    "    \n",
    "    clf = cv2.xfeatures2d.SIFT_create(n_features)\n",
    "    \n",
    "    image_features = {}\n",
    "    for j, image_name in enumerate(img_names_batch):\n",
    "        image_id = image_name[:-4]\n",
    "        image_file = os.path.join(folder, image_name)\n",
    "        des = image_detect_and_compute(image_file, clf)\n",
    "        if des is not None:\n",
    "            image_features[image_id] = des\n",
    "    print(len(image_features.keys()), end='  ')\n",
    "    dump_pickle_feature_batch(run_name, dataset_name, batch_num, image_features)\n",
    "    print('')\n",
    "    del clf\n",
    "    del image_features\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def feature_extraction(folder, run_name, dataset_name, batch_size=500, cpu_amount=cpu_amount):\n",
    "    image_names = os.listdir(folder)\n",
    "    amount = len(image_names)\n",
    "#     amount = 1000\n",
    "    batch_count = math.ceil(amount / batch_size)\n",
    "    print('amount: %s, batch_count: %s' % (amount, batch_count))\n",
    "    batch_nums = list(range(batch_count))\n",
    "    print(batch_nums)\n",
    "#     batches = []\n",
    "#     for i in range(batch_count):\n",
    "#         img_names_batch = image_names[i*batch_size: (i+1)*batch_size]\n",
    "#         batches.append(img_names_batch)\n",
    "#     print(len(batches))\n",
    "#     print(len(batches[0]))\n",
    "    \n",
    "    function_partial = partial(\n",
    "        feature_extraction_batch,\n",
    "        folder=folder,\n",
    "        dataset_name=dataset_name,\n",
    "        run_name=run_name,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    pool = multiprocessing.Pool(processes=cpu_amount)\n",
    "    for i in tqdm(pool.imap_unordered(function_partial, batch_nums), total=len(batch_nums)):\n",
    "        pass\n",
    "    pool.close()\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount: 1217684, batch_count: 122\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]\n",
      "batch=0 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch=17 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=5 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=15 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=8 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=14 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=16 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=4 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=19 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=3 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=20 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=6 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=22 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=21 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=9 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=24 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=23 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=7 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=1 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=2 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=18 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=25 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=26 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=29 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=28 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=27 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=30 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=32 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=31 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=34 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=35 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=33 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=13 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=11 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=10 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=12 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=36 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=37 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=38 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=39 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=40 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=41 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=42 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=43 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=44 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=45 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=46 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=47 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=48 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=49 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=50 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=51 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=52 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=53 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=54 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=55 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch=56 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=57 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=58 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=59 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=60 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=61 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=62 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=63 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=64 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=65 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "10000 --> /data1/kaggle/landmark-recognition-challenge/input/org_train/7cfad5156347592b.jpg OpenCV(3.4.1) /io/opencv/modules/core/src/matrix.cpp:362: error: (-215) u != 0 in function create\n",
      "\n",
      "batch=66 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=67 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=68 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=69 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "10000 --> /data1/kaggle/landmark-recognition-challenge/input/org_train/a861a231162c86d6.jpg OpenCV(3.4.1) /io/opencv/modules/core/src/matrix.cpp:362: error: (-215) u != 0 in function create\n",
      "\n",
      "batch=70 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=71 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=72 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=73 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=74 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=75 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=76 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=77 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=78 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=79 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=80 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=81 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=82 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "10000 --> /data1/kaggle/landmark-recognition-challenge/input/org_train/dc1093e4867ed4c5.jpg OpenCV(3.4.1) /io/opencv/modules/core/src/matrix.cpp:362: error: (-215) u != 0 in function create\n",
      "\n",
      "batch=83 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=84 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=85 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=86 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=87 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=88 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=89 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=90 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=91 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=92 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=93 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=94 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=95 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=96 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=97 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=98 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=99 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=100 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=101 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=102 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=103 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=104 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=105 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=106 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch=107 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=108 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=109 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=110 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=111 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=112 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "10000 --> /data1/kaggle/landmark-recognition-challenge/input/org_train/f106488d9205e994.jpg OpenCV(3.4.1) /io/opencv/modules/core/src/matrix.cpp:362: error: (-215) u != 0 in function create\n",
      "\n",
      "batch=113 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=114 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=115 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=116 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=117 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=118 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=119 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "batch=120 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "10000 --> /data1/kaggle/landmark-recognition-challenge/input/org_train/7bb7d04fcfb8245a.jpg OpenCV(3.4.1) /io/opencv/modules/core/src/matrix.cpp:362: error: (-215) u != 0 in function create\n",
      "\n",
      "batch=121 /data1/kaggle/landmark-recognition-challenge/input/org_train Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917 train 10000\n",
      "10000 --> /data1/kaggle/landmark-recognition-challenge/input/org_train/7d827416a02295a6.jpg OpenCV(3.4.1) /io/opencv/modules/core/src/matrix.cpp:362: error: (-215) u != 0 in function create\n",
      "\n",
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b66.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/122 [3:09:46<382:41:59, 11386.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b58.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/122 [3:10:13<190:13:28, 5706.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b77.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/122 [3:15:07<128:59:45, 3902.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b40.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 4/122 [3:15:17<96:00:51, 2929.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b39.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 5/122 [3:16:47<76:44:56, 2361.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b87.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 6/122 [3:17:28<63:37:58, 1974.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b47.pickle  9999\n",
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b92.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 7/122 [3:18:44<54:24:58, 1703.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 8/122 [3:18:47<47:12:42, 1490.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b106.pickle  9998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 9/122 [3:19:56<41:50:21, 1332.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 9999  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b53.pickle  9999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 10/122 [3:20:41<37:27:45, 1204.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b63.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 11/122 [3:21:17<33:51:14, 1097.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b116.pickle  9998\n",
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b117.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 12/122 [3:21:24<30:46:12, 1007.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 13/122 [3:21:26<28:09:03, 929.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b115.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 14/122 [3:21:46<25:56:36, 864.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 9999  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b109.pickle  9999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 15/122 [3:25:44<24:27:37, 822.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b120.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 16/122 [3:26:29<22:47:58, 774.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b113.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 17/122 [3:26:35<21:16:02, 729.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 --> 10000  Dump:  /data1/kaggle/landmark-recognition-challenge/feature/Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917/feature_Google_LandMark_Rec_FeatureExtraction_SIFT_Parallel_20180523_023917_train_b110.pickle  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 18/122 [3:27:12<19:57:11, 690.69s/it]"
     ]
    }
   ],
   "source": [
    "feature_extraction(org_train_folder, run_name, 'train', batch_size)\n",
    "# feature_extraction(org_train_folder, run_name, 'train', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = load_pickle_feature_batch(run_name, 'train', 1)\n",
    "\n",
    "print('*'*80)\n",
    "print('len_image_features=', len(image_features.keys()))\n",
    "for i, image_id in enumerate(list(image_features.keys())[:3]):\n",
    "    print('image_id: %s,\\t landmark_id:%s,\\t feature_shape: ' % (image_id, id_2_landmark_id_dict[image_id]), image_features[image_id].shape, end=' ')\n",
    "    print(image_features[image_id][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction(org_test_folder, run_name, 'test', batch_size)\n",
    "# feature_extraction(org_test_folder, run_name, 'test', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = load_pickle_feature_batch(run_name, 'test', 1)\n",
    "\n",
    "print('*'*80)\n",
    "print('len_image_features=', len(image_features.keys()))\n",
    "for i, image_id in enumerate(list(image_features.keys())[:3]):\n",
    "    print('image_id: %s,\\t feature_shape: %s' % (image_id, image_features[image_id].shape), end=' ')\n",
    "    print(image_features[image_id][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time cost: %.2f s' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
