{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost_20181015-224246\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_name = 'XGBoost'\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "run_name = '%s_%s' % (project_name, time_str)\n",
    "print(run_name)\n",
    "\n",
    "time0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "test_rows = 2\n",
    "\n",
    "print(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_amount: 3\n",
      "random_num: 7778\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import multiprocessing\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, jaccard_similarity_score\n",
    "\n",
    "cpu_amount = multiprocessing.cpu_count()\n",
    "random_num = np.random.randint(0, 9999)\n",
    "random_num_str = '%04d' % random_num\n",
    "\n",
    "print('cpu_amount: %s' % (cpu_amount - 1))\n",
    "print('random_num: %s' % random_num_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle\\ga-customer-revenue-prediction\\feature\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\input\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\output\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\model\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\log\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\input\\train.csv\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\input\\test.csv\n",
      "D:\\Kaggle\\ga-customer-revenue-prediction\\input\\sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "feature_folder = os.path.join(cwd, 'feature')\n",
    "input_folder = os.path.join(cwd, 'input')\n",
    "output_folder = os.path.join(cwd, 'output')\n",
    "model_folder = os.path.join(cwd, 'model')\n",
    "log_folder = os.path.join(cwd, 'log')\n",
    "\n",
    "print(feature_folder)\n",
    "print(input_folder)\n",
    "print(output_folder)\n",
    "print(model_folder)\n",
    "print(log_folder)\n",
    "\n",
    "train_csv = os.path.join(input_folder, 'train.csv')\n",
    "test_csv = os.path.join(input_folder, 'test.csv')\n",
    "sample_submission_csv = os.path.join(input_folder, 'sample_submission.csv')\n",
    "print(train_csv)\n",
    "print(test_csv)\n",
    "print(sample_submission_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>socialEngagementType</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>1472830385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>1472880147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping      date        fullVisitorId  \\\n",
       "0  Organic Search  20160902  1131660440785968503   \n",
       "1  Organic Search  20160902   377306020877927890   \n",
       "\n",
       "                        sessionId  socialEngagementType     visitId  \\\n",
       "0  1131660440785968503_1472830385  Not Socially Engaged  1472830385   \n",
       "1   377306020877927890_1472880147  Not Socially Engaged  1472880147   \n",
       "\n",
       "   visitNumber  visitStartTime  \n",
       "0            1      1472830385  \n",
       "1            1      1472880147  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n",
    "\n",
    "def load_df(csv_path, nrows=None, JSON_COLUMNS=['device', 'geoNetwork', 'totals', 'trafficSource']):\n",
    "    data_df = pd.read_csv(csv_path, nrows=nrows)\n",
    "    for idx, row in data_df.iterrows():\n",
    "        for col in JSON_COLUMNS:\n",
    "            if isinstance(data_df.at[idx, col], str):\n",
    "                json_str = data_df.at[idx, col]\n",
    "            if isinstance(data_df.at[idx, col], list):\n",
    "                json_str = data_df.at[idx, col][0]\n",
    "                print(len(data_df.at[idx, col]))\n",
    "            json_obj = json.loads(json_str)\n",
    "#             for key in json_obj:\n",
    "#                 sub_col = '%s.%s' % (col, key)\n",
    "#                 data_df.at[idx, sub_col] = json_obj[key]\n",
    "#                 if sub_col == 'trafficSource.adwordsClickInfo':\n",
    "#                     sub_json_str = data_df.at[idx, sub_col]\n",
    "#                     sub_json_obj = json.loads(json_str)\n",
    "#                     for sub_key in sub_json_obj:\n",
    "#                         sub_sub_col = '%s.%s' % (sub_col, sub_key)\n",
    "#                         data_df.at[idx, sub_sub_col] = json_obj[sub_key]\n",
    "    data_df.drop(columns=['device', 'geoNetwork', 'totals', 'trafficSource'], inplace=True)\n",
    "    return data_df\n",
    "\n",
    "train_df = load_df(train_csv, test_rows)\n",
    "display(train_df.shape, train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_json_format(raw_msg): \n",
    "    \"\"\"\n",
    "    用于判断一个字符串是否符合Json格式\n",
    "    \"\"\" \n",
    "    if isinstance(raw_msg, str): # 首先判断变量是否为字符串 \n",
    "        try: \n",
    "            json.loads(raw_msg, encoding='utf-8') \n",
    "        except ValueError: \n",
    "            return False \n",
    "        return True \n",
    "    else: \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 device.deviceCategory\n",
      "1 device.screenResolution\n",
      "1 device.screenColors\n",
      "1 device.language\n",
      "1 device.flashVersion\n",
      "1 device.mobileDeviceMarketingName\n",
      "1 device.mobileDeviceInfo\n",
      "1 device.mobileInputSelector\n",
      "1 device.mobileDeviceModel\n",
      "1 device.mobileDeviceBranding\n",
      "1 device.isMobile\n",
      "1 device.operatingSystemVersion\n",
      "1 device.operatingSystem\n",
      "1 device.browserSize\n",
      "1 device.browserVersion\n",
      "1 device.browser\n",
      "1 geoNetwork.networkLocation\n",
      "1 geoNetwork.longitude\n",
      "1 geoNetwork.latitude\n",
      "1 geoNetwork.networkDomain\n",
      "1 geoNetwork.cityId\n",
      "1 geoNetwork.city\n",
      "1 geoNetwork.metro\n",
      "1 geoNetwork.region\n",
      "1 geoNetwork.country\n",
      "1 geoNetwork.subContinent\n",
      "1 geoNetwork.continent\n",
      "1 2 2 "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-8a075ddf31e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-8a075ddf31e4>\u001b[0m in \u001b[0;36mload_df\u001b[1;34m(csv_path, nrows, JSON_COLUMNS)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#                 print(key)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                     \u001b[0mkey_prefix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n",
    "\n",
    "def load_df(csv_path, nrows=None, JSON_COLUMNS=['device', 'geoNetwork', 'totals', 'trafficSource']):\n",
    "    df = pd.read_csv(csv_path, nrows=nrows)\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in JSON_COLUMNS:\n",
    "#             print(df.at[idx, col])\n",
    "            json_str = df.at[idx, col]\n",
    "            json_obj = json.loads(json_str)\n",
    "            # Flatten json object to flattened key-value list\n",
    "            key_prefix = [col]\n",
    "            key_stack = [[json_obj, key, key_prefix] for key in json_obj]\n",
    "            while(len(key_stack) > 0):\n",
    "                item = key_stack.pop()\n",
    "                obj = item[0]\n",
    "                key = item[1]\n",
    "                key_prefix = item[2]\n",
    "                print(len(key_prefix), end=' ')\n",
    "#                 print(key)\n",
    "                if isinstance(obj[key], dict):\n",
    "                    key_prefix.append(key)\n",
    "                    print(len(key_prefix), end=' ')\n",
    "                    sub_obj = obj[key]\n",
    "                    key_stack = key_stack + [[sub_obj, sub_key, key_prefix] for sub_key in sub_obj]\n",
    "                elif check_json_format(obj[key]):\n",
    "                    key_prefix.append(key)\n",
    "                    print(len(key_prefix), end=' ')\n",
    "                    sub_obj = json.loads(obj[key])\n",
    "                    if isinstance(sub_obj, dict):\n",
    "                        key_stack = key_stack + [[sub_obj, sub_key, key_prefix] for sub_key in sub_obj]\n",
    "                    elif isinstance(sub_obj, list):\n",
    "                        for i in len(sub_obj):\n",
    "                            key_stack = key_stack + [[sub_obj, sub_key, key_prefix] for sub_key in sub_obj]\n",
    "                else:\n",
    "                    if len(key_prefix) > 0:\n",
    "                        key_str = '.'.join(key_prefix) + '.' + key\n",
    "                    else:\n",
    "                        key_str = key\n",
    "                    if key_str not in df.columns:\n",
    "                        df[key_str] = ''\n",
    "                    print(key_str)\n",
    "                    df.at[idx, key_str] = obj\n",
    "\n",
    "    df.drop(columns=['device', 'geoNetwork', 'totals', 'trafficSource'], inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = load_df(train_csv, test_rows)\n",
    "display(train_df.shape, train_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prevew data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv, nrows=test_rows)\n",
    "test_df = pd.read_csv(test_csv, nrows=test_rows)\n",
    "sample_submission_df = pd.read_csv(sample_submission_csv, nrows=test_rows)\n",
    "\n",
    "display(train_df.columns)\n",
    "display(train_df.shape, train_df.head(2))\n",
    "display(test_df.shape, test_df.head(2))\n",
    "display(sample_submission_df.shape, sample_submission_df.head(2))\n",
    "\n",
    "## Load and preview data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    for col in JSON_COLUMNS:\n",
    "        if isinstance(train_df.at[idx, col], str):\n",
    "            json_str = train_df.at[idx, col]\n",
    "        else:\n",
    "            json_str = train_df.at[idx, col][0]\n",
    "        json_obj = json.loads(json_str)\n",
    "        for key in json_obj:\n",
    "            sub_col = '%s.%s' % (col, key)\n",
    "            print(sub_col)\n",
    "            train_df.at[idx, sub_col] = json_obj[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_name)\n",
    "print('Time elapsed: %.2f s' % (time.time() - time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
