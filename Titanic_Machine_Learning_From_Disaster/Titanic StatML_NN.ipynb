{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic StatML_NN\n",
    "\n",
    "## 概要：\n",
    "- 运行时间比较长的训练，还是应该弄个TensorBoard，方便监控结果，免得每次都需要用鼠标手动托页面查看最新的运行结果。\n",
    "- 模型为全链接神经网络和统计学习方法。\n",
    "\n",
    "## Result:\n",
    "\n",
    "\n",
    "Reference: \n",
    "1. https://www.kaggle.com/c/titanic#tutorials\n",
    "2. https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n",
    "3. https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import original data as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'STON/O2. 3101282'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('./input/train.csv')\n",
    "data_test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "display(data_train.head(2))\n",
    "display(data_test.head(2))\n",
    "data_train.loc[2, 'Ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show columns of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_train_original_col = data_train.columns\n",
    "data_test_original_col = data_test.columns\n",
    "print(data_train_original_col)\n",
    "print(data_test_original_col)\n",
    "# data_train0 = data_train.drop(data_train_original_col, axis = 1)\n",
    "# data_test0  = data_test.drop(data_test_original_col, axis = 1)\n",
    "# display(data_train0.head(2))\n",
    "# display(data_test0.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = [data_train, data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not have null value!\n",
      "Do not have null value!\n"
     ]
    }
   ],
   "source": [
    "# Pclass\n",
    "for dataset in full_data:\n",
    "    temp = dataset[dataset['Pclass'].isnull()]\n",
    "    if len(temp) == 0:\n",
    "        print('Do not have null value!')\n",
    "    else:\n",
    "        temp.head(2)\n",
    "        \n",
    "for dataset in full_data:\n",
    "    dataset['a_Pclass'] = dataset['Pclass']\n",
    "#     display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name\n",
    "for dataset in full_data:\n",
    "    dataset['a_Name_Length'] = dataset['Name'].apply(len)\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "for dataset in full_data:\n",
    "    dataset['a_Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "for dataset in full_data:\n",
    "    dataset['a_Age'] = dataset['Age'].fillna(-1)\n",
    "    dataset['a_Have_Age'] = dataset['Age'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "#     display(dataset[dataset['Age'].isnull()].head(2))\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['a_FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['a_IsAlone'] = dataset['a_FamilySize'].apply(lambda x: 1 if x<=1 else 0)\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ticket(Very one have a ticket)\n",
    "for dataset in full_data:\n",
    "    dataset['a_Have_Ticket'] = dataset['Ticket'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "#     display(dataset[dataset['Ticket'].isnull()].head(2))\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fare\n",
    "for dataset in full_data:\n",
    "    dataset['a_Fare'] = dataset['Fare'].fillna(-1)\n",
    "    dataset['a_Have_Fare'] = dataset['Fare'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "#     display(dataset[dataset['Fare'].isnull()].head(2))\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cabin\n",
    "for dataset in full_data:\n",
    "    dataset['a_Have_Cabin'] = dataset['Cabin'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "#     display(dataset[dataset['Cabin'].isnull()].head(2))\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embarked\n",
    "for dataset in full_data:\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('N')\n",
    "    dataset['a_Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2, None: 3} ).astype(int)\n",
    "    dataset['a_Have_Embarked'] = dataset['Embarked'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "#     display(dataset[dataset['Embarked'].isnull()].head(2))\n",
    "#     display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name words segmentation and one-hote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name words segmentation\n",
    "import re\n",
    "name_words = []\n",
    "\n",
    "# Inorder to allign columns of data_train and data_test, only data_train to fetch word\n",
    "for name in data_train['Name']:\n",
    "#     print(name)\n",
    "    words = re.findall(r\"[\\w']+\", name)\n",
    "#     print(len(words))\n",
    "#     print(words)\n",
    "    for w in words:\n",
    "        if w not in name_words:\n",
    "            name_words.append(w)\n",
    "# print(len(name_words))\n",
    "name_words.sort()\n",
    "# print(name_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add columns\n",
    "for dataset in full_data:\n",
    "    for w in name_words:\n",
    "        col_name = 'a_Name_' + w\n",
    "        dataset[col_name] = 0\n",
    "    dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name words one-hote\n",
    "for dataset in full_data:\n",
    "    for i, row in dataset.iterrows():\n",
    "    #     print(row['Name'])\n",
    "        words = re.findall(r\"[\\w']+\", row['Name'])\n",
    "        for w in words:\n",
    "            if w in name_words:\n",
    "                col_name = 'a_Name_' + w\n",
    "                dataset.loc[i, col_name] = 1\n",
    "#     display(dataset[dataset['a_Name_Braund'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin segmentation and one-hote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T']\n"
     ]
    }
   ],
   "source": [
    "# Get cabin segmentation words\n",
    "import re\n",
    "cabin_words = []\n",
    "\n",
    "# Inorder to allign columns of data_train and data_test, only data_train to fetch number\n",
    "for c in data_train['Cabin']:\n",
    "#     print(c)\n",
    "    if c is not np.nan:\n",
    "        word = re.findall(r\"[a-zA-Z]\", c)\n",
    "#         print(words[0])\n",
    "        cabin_words.append(word[0])\n",
    "print(len(cabin_words))\n",
    "cabin_words.sort()\n",
    "print(np.unique(cabin_words))\n",
    "cabin_words_unique = list(np.unique(cabin_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cabin_word(cabin):\n",
    "    if cabin is not np.nan:\n",
    "        word = re.findall(r\"[a-zA-Z]\", cabin)\n",
    "        if word:\n",
    "            return cabin_words_unique.index(word[0])\n",
    "    return -1\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['a_Cabin_Word'] = dataset['Cabin'].apply(get_cabin_word)\n",
    "    # dataset['a_Cabin_Word'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cabin_number(cabin):\n",
    "    if cabin is not np.nan:\n",
    "        word = re.findall(r\"[0-9]+\", cabin)\n",
    "        if word:\n",
    "            return int(word[0])\n",
    "    return -1\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['a_Cabin_Number'] = dataset['Cabin'].apply(get_cabin_number)\n",
    "    # dataset['a_Cabin_Number'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "# Reference: \n",
    "#    1. https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n",
    "#    2. https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook\n",
    "# full_data = [data_train, data_test]\n",
    "# for dataset in full_data:\n",
    "#     dataset['a_Name_length'] = dataset['Name'].apply(len)\n",
    "#     #dataset['Sex'] = (dataset['Sex']=='male').astype(int)\n",
    "#     dataset['a_Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "#     dataset['a_Age'] = dataset['Age'].fillna(0)\n",
    "#     dataset['a_Age_IsNull'] = dataset['Age'].isnull()\n",
    "#     dataset['a_FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "#     dataset['a_IsAlone'] = dataset['a_FamilySize'].apply(lambda x: 1 if x<=1 else 0)\n",
    "#     dataset['a_Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "#     #dataset['Has_Cabin'] = dataset['Cabin'].apply(lambda x: 1 if type(x) == str else 0) # same as below\n",
    "#     dataset['a_Has_Cabin'] = dataset['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "#     dataset['a_Has_Embarked'] = dataset['Embarked'].isnull()\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('N')\n",
    "#     dataset['a_Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2, 'N': 3} ).astype(int)\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    \n",
    "# display(data_train.head(2))\n",
    "# display(data_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_de</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  a_IsAlone  \\\n",
       "0         3             23      1   22.0           1             2          0   \n",
       "1         1             51      0   38.0           1             2          0   \n",
       "\n",
       "   a_Have_Ticket   a_Fare  a_Have_Fare       ...        a_Name_de  a_Name_del  \\\n",
       "0              1   7.2500            1       ...                0           0   \n",
       "1              1  71.2833            1       ...                0           0   \n",
       "\n",
       "   a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  a_Name_y  \\\n",
       "0           0            0          0           0           0         0   \n",
       "1           0            0          0           0           0         0   \n",
       "\n",
       "   a_Cabin_Word  a_Cabin_Number  \n",
       "0            -1              -1  \n",
       "1             2              85  \n",
       "\n",
       "[2 rows x 1544 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_de</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  a_IsAlone  \\\n",
       "0         3             16      1   34.5           1             1          1   \n",
       "1         3             32      0   47.0           1             2          0   \n",
       "\n",
       "   a_Have_Ticket  a_Fare  a_Have_Fare       ...        a_Name_de  a_Name_del  \\\n",
       "0              1  7.8292            1       ...                0           0   \n",
       "1              1  7.0000            1       ...                0           0   \n",
       "\n",
       "   a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  a_Name_y  \\\n",
       "0           0            0          0           0           0         0   \n",
       "1           0            0          0           0           0         0   \n",
       "\n",
       "   a_Cabin_Word  a_Cabin_Number  \n",
       "0            -1              -1  \n",
       "1            -1              -1  \n",
       "\n",
       "[2 rows x 1544 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_de</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  a_IsAlone  \\\n",
       "0         3             23      1   22.0           1             2          0   \n",
       "1         1             51      0   38.0           1             2          0   \n",
       "\n",
       "   a_Have_Ticket   a_Fare  a_Have_Fare       ...        a_Name_de  a_Name_del  \\\n",
       "0              1   7.2500            1       ...                0           0   \n",
       "1              1  71.2833            1       ...                0           0   \n",
       "\n",
       "   a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  a_Name_y  \\\n",
       "0           0            0          0           0           0         0   \n",
       "1           0            0          0           0           0         0   \n",
       "\n",
       "   a_Cabin_Word  a_Cabin_Number  \n",
       "0            -1              -1  \n",
       "1             2              85  \n",
       "\n",
       "[2 rows x 1544 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "survived = data_train['Survived']\n",
    "data_train0 = data_train.drop(data_train_original_col, axis = 1)\n",
    "data_test0  = data_test.drop(data_test_original_col, axis = 1)\n",
    "display(data_train0.head(2))\n",
    "display(data_test0.head(2))\n",
    "\n",
    "features = data_train0\n",
    "display(features.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and confirm all columns is proccessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in features.columns:\n",
    "    if not col.startswith('a_'):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle and split the train_data into train, crossvalidation and testing subsets\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, survived, test_size=0.1, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 1544)\n",
      "(90, 1544)\n",
      "(801,)\n",
      "(90,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_de</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>262.375</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.850</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  \\\n",
       "742         1             37      0   21.0           1             5   \n",
       "206         3             26      1   32.0           1             2   \n",
       "\n",
       "     a_IsAlone  a_Have_Ticket   a_Fare  a_Have_Fare       ...        \\\n",
       "742          0              1  262.375            1       ...         \n",
       "206          0              1   15.850            1       ...         \n",
       "\n",
       "     a_Name_de  a_Name_del  a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  \\\n",
       "742          0           0           0            0          0           0   \n",
       "206          0           0           0            0          0           0   \n",
       "\n",
       "     a_Name_van  a_Name_y  a_Cabin_Word  a_Cabin_Number  \n",
       "742           0         0             1              57  \n",
       "206           0         0            -1              -1  \n",
       "\n",
       "[2 rows x 1544 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "742    1\n",
       "206    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show distribute of abave data sets\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "display(x_train.head(2))\n",
    "display(y_train.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def my_GridSearchCV(model, parameters):\n",
    "    if parameters:\n",
    "        clf = GridSearchCV(model, parameters)\n",
    "    else:\n",
    "        clf = model\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def ny_train(models):\n",
    "    clfs = {}\n",
    "    for key, value in models.items():\n",
    "        print('start ' + key)\n",
    "        clf = my_GridSearchCV(value['model'], value['param'])\n",
    "        clfs[key] = clf\n",
    "    return clfs\n",
    "\n",
    "def my_predict(clfs, x_val=x_val, y_val=y_val):\n",
    "    for key, value in clfs.items():\n",
    "        print(key, end=':  ')\n",
    "        y_pred = value.predict(x_val)\n",
    "        print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start GaussianNB\n",
      "start AdaBoostClassifier\n",
      "start RandomForestClassifier\n",
      "GaussianNB:  0.433333333333\n",
      "AdaBoostClassifier:  0.833333333333\n",
      "RandomForestClassifier:  0.866666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {}\n",
    "models = {\n",
    "#     'SVC': {\n",
    "#         'model': SVC(),\n",
    "#         'param': {'kernel':('linear', 'rbf'), 'C':[1, 5, 10]}\n",
    "#     },\n",
    "    'GaussianNB':{\n",
    "        'model': GaussianNB(),\n",
    "        'param': {}\n",
    "    },\n",
    "    'AdaBoostClassifier':{\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'param': {}\n",
    "    },\n",
    "    'RandomForestClassifier':{\n",
    "        'model': RandomForestClassifier(),\n",
    "        'param': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "clfs = ny_train(models)\n",
    "my_predict(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/300\n",
      "801/801 [==============================] - 2s - loss: 0.7377 - acc: 0.5556 - val_loss: 0.5959 - val_acc: 0.7000\n",
      "Epoch 2/300\n",
      "801/801 [==============================] - 0s - loss: 0.7198 - acc: 0.5630 - val_loss: 0.5893 - val_acc: 0.7222\n",
      "Epoch 3/300\n",
      "801/801 [==============================] - 0s - loss: 0.6926 - acc: 0.5855 - val_loss: 0.5716 - val_acc: 0.7333\n",
      "Epoch 4/300\n",
      "801/801 [==============================] - 0s - loss: 0.6818 - acc: 0.5930 - val_loss: 0.5808 - val_acc: 0.7444\n",
      "Epoch 5/300\n",
      "801/801 [==============================] - 0s - loss: 0.6685 - acc: 0.6267 - val_loss: 0.5487 - val_acc: 0.7556\n",
      "Epoch 6/300\n",
      "801/801 [==============================] - 0s - loss: 0.6605 - acc: 0.6305 - val_loss: 0.5434 - val_acc: 0.7556\n",
      "Epoch 7/300\n",
      "801/801 [==============================] - 0s - loss: 0.6504 - acc: 0.6517 - val_loss: 0.5559 - val_acc: 0.7889\n",
      "Epoch 8/300\n",
      "801/801 [==============================] - 0s - loss: 0.6450 - acc: 0.6429 - val_loss: 0.5269 - val_acc: 0.7444\n",
      "Epoch 9/300\n",
      "801/801 [==============================] - 0s - loss: 0.6258 - acc: 0.6529 - val_loss: 0.5329 - val_acc: 0.7889\n",
      "Epoch 10/300\n",
      "801/801 [==============================] - 0s - loss: 0.6408 - acc: 0.6529 - val_loss: 0.5203 - val_acc: 0.7778\n",
      "Epoch 11/300\n",
      "801/801 [==============================] - 0s - loss: 0.6286 - acc: 0.6767 - val_loss: 0.5460 - val_acc: 0.7889\n",
      "Epoch 12/300\n",
      "801/801 [==============================] - 0s - loss: 0.6424 - acc: 0.6517 - val_loss: 0.5109 - val_acc: 0.7667\n",
      "Epoch 13/300\n",
      "801/801 [==============================] - 0s - loss: 0.6310 - acc: 0.6554 - val_loss: 0.5141 - val_acc: 0.7778\n",
      "Epoch 14/300\n",
      "801/801 [==============================] - 0s - loss: 0.6193 - acc: 0.6717 - val_loss: 0.5099 - val_acc: 0.7889\n",
      "Epoch 15/300\n",
      "801/801 [==============================] - 0s - loss: 0.6130 - acc: 0.6704 - val_loss: 0.5145 - val_acc: 0.7778\n",
      "Epoch 16/300\n",
      "801/801 [==============================] - 0s - loss: 0.6019 - acc: 0.6742 - val_loss: 0.5160 - val_acc: 0.7889\n",
      "Epoch 17/300\n",
      "801/801 [==============================] - 0s - loss: 0.6202 - acc: 0.6629 - val_loss: 0.4998 - val_acc: 0.7889\n",
      "Epoch 18/300\n",
      "801/801 [==============================] - 0s - loss: 0.5963 - acc: 0.6929 - val_loss: 0.4954 - val_acc: 0.7889\n",
      "Epoch 19/300\n",
      "801/801 [==============================] - 0s - loss: 0.6088 - acc: 0.6692 - val_loss: 0.4993 - val_acc: 0.7889\n",
      "Epoch 20/300\n",
      "801/801 [==============================] - 0s - loss: 0.5981 - acc: 0.7041 - val_loss: 0.4885 - val_acc: 0.7889\n",
      "Epoch 21/300\n",
      "801/801 [==============================] - 0s - loss: 0.5861 - acc: 0.6904 - val_loss: 0.4886 - val_acc: 0.7778\n",
      "Epoch 22/300\n",
      "801/801 [==============================] - 0s - loss: 0.5950 - acc: 0.6891 - val_loss: 0.4904 - val_acc: 0.8000\n",
      "Epoch 23/300\n",
      "801/801 [==============================] - 0s - loss: 0.5837 - acc: 0.6841 - val_loss: 0.4793 - val_acc: 0.7778\n",
      "Epoch 24/300\n",
      "801/801 [==============================] - 0s - loss: 0.5855 - acc: 0.6854 - val_loss: 0.4849 - val_acc: 0.8222\n",
      "Epoch 25/300\n",
      "801/801 [==============================] - 0s - loss: 0.5819 - acc: 0.6979 - val_loss: 0.4782 - val_acc: 0.8111\n",
      "Epoch 26/300\n",
      "801/801 [==============================] - 0s - loss: 0.5764 - acc: 0.6904 - val_loss: 0.4734 - val_acc: 0.8111\n",
      "Epoch 27/300\n",
      "801/801 [==============================] - 0s - loss: 0.5798 - acc: 0.7116 - val_loss: 0.4752 - val_acc: 0.8111\n",
      "Epoch 28/300\n",
      "801/801 [==============================] - 0s - loss: 0.5664 - acc: 0.7054 - val_loss: 0.4659 - val_acc: 0.8222\n",
      "Epoch 29/300\n",
      "801/801 [==============================] - 0s - loss: 0.5704 - acc: 0.6954 - val_loss: 0.4739 - val_acc: 0.8333\n",
      "Epoch 30/300\n",
      "801/801 [==============================] - 0s - loss: 0.5629 - acc: 0.7004 - val_loss: 0.4567 - val_acc: 0.8333\n",
      "Epoch 31/300\n",
      "801/801 [==============================] - 0s - loss: 0.5606 - acc: 0.7291 - val_loss: 0.4541 - val_acc: 0.8333\n",
      "Epoch 32/300\n",
      "801/801 [==============================] - 0s - loss: 0.5552 - acc: 0.7253 - val_loss: 0.4539 - val_acc: 0.8333\n",
      "Epoch 33/300\n",
      "801/801 [==============================] - 0s - loss: 0.5515 - acc: 0.7191 - val_loss: 0.4626 - val_acc: 0.8333\n",
      "Epoch 34/300\n",
      "801/801 [==============================] - 0s - loss: 0.5561 - acc: 0.7216 - val_loss: 0.4556 - val_acc: 0.8222\n",
      "Epoch 35/300\n",
      "801/801 [==============================] - 0s - loss: 0.5342 - acc: 0.7328 - val_loss: 0.4522 - val_acc: 0.8222\n",
      "Epoch 36/300\n",
      "801/801 [==============================] - 0s - loss: 0.5427 - acc: 0.7253 - val_loss: 0.4460 - val_acc: 0.8111\n",
      "Epoch 37/300\n",
      "801/801 [==============================] - 0s - loss: 0.5434 - acc: 0.7141 - val_loss: 0.4397 - val_acc: 0.8111\n",
      "Epoch 38/300\n",
      "801/801 [==============================] - 0s - loss: 0.5192 - acc: 0.7541 - val_loss: 0.4355 - val_acc: 0.8111\n",
      "Epoch 39/300\n",
      "801/801 [==============================] - 0s - loss: 0.5219 - acc: 0.7478 - val_loss: 0.4412 - val_acc: 0.8222\n",
      "Epoch 40/300\n",
      "801/801 [==============================] - 0s - loss: 0.5267 - acc: 0.7378 - val_loss: 0.4293 - val_acc: 0.8222\n",
      "Epoch 41/300\n",
      "801/801 [==============================] - 0s - loss: 0.5021 - acc: 0.7353 - val_loss: 0.4311 - val_acc: 0.8222\n",
      "Epoch 42/300\n",
      "801/801 [==============================] - 0s - loss: 0.5118 - acc: 0.7491 - val_loss: 0.4288 - val_acc: 0.8111\n",
      "Epoch 43/300\n",
      "801/801 [==============================] - 0s - loss: 0.5122 - acc: 0.7628 - val_loss: 0.4211 - val_acc: 0.8222\n",
      "Epoch 44/300\n",
      "801/801 [==============================] - 0s - loss: 0.4995 - acc: 0.7665 - val_loss: 0.4228 - val_acc: 0.8444\n",
      "Epoch 45/300\n",
      "801/801 [==============================] - 0s - loss: 0.4959 - acc: 0.7653 - val_loss: 0.4184 - val_acc: 0.8444\n",
      "Epoch 46/300\n",
      "801/801 [==============================] - 0s - loss: 0.4937 - acc: 0.7603 - val_loss: 0.4236 - val_acc: 0.8111\n",
      "Epoch 47/300\n",
      "801/801 [==============================] - 0s - loss: 0.4910 - acc: 0.7640 - val_loss: 0.4076 - val_acc: 0.8556\n",
      "Epoch 48/300\n",
      "801/801 [==============================] - 0s - loss: 0.5124 - acc: 0.7640 - val_loss: 0.4155 - val_acc: 0.8111\n",
      "Epoch 49/300\n",
      "801/801 [==============================] - 0s - loss: 0.4733 - acc: 0.7815 - val_loss: 0.4037 - val_acc: 0.8556\n",
      "Epoch 50/300\n",
      "801/801 [==============================] - 0s - loss: 0.4778 - acc: 0.7765 - val_loss: 0.4089 - val_acc: 0.8111\n",
      "Epoch 51/300\n",
      "801/801 [==============================] - 0s - loss: 0.4939 - acc: 0.7640 - val_loss: 0.4017 - val_acc: 0.8556\n",
      "Epoch 52/300\n",
      "801/801 [==============================] - 0s - loss: 0.4717 - acc: 0.7953 - val_loss: 0.4135 - val_acc: 0.8333\n",
      "Epoch 53/300\n",
      "801/801 [==============================] - 0s - loss: 0.4756 - acc: 0.7828 - val_loss: 0.4097 - val_acc: 0.8222\n",
      "Epoch 54/300\n",
      "801/801 [==============================] - 0s - loss: 0.4536 - acc: 0.7778 - val_loss: 0.4001 - val_acc: 0.8444\n",
      "Epoch 55/300\n",
      "801/801 [==============================] - 0s - loss: 0.4622 - acc: 0.7678 - val_loss: 0.4012 - val_acc: 0.8111\n",
      "Epoch 56/300\n",
      "801/801 [==============================] - 0s - loss: 0.4436 - acc: 0.7990 - val_loss: 0.3981 - val_acc: 0.8333\n",
      "Epoch 57/300\n",
      "801/801 [==============================] - 0s - loss: 0.4450 - acc: 0.7815 - val_loss: 0.4034 - val_acc: 0.8222\n",
      "Epoch 58/300\n",
      "801/801 [==============================] - 0s - loss: 0.4646 - acc: 0.7878 - val_loss: 0.3958 - val_acc: 0.8333\n",
      "Epoch 59/300\n",
      "801/801 [==============================] - 0s - loss: 0.4479 - acc: 0.8015 - val_loss: 0.3962 - val_acc: 0.8333\n",
      "Epoch 60/300\n",
      "801/801 [==============================] - 0s - loss: 0.4403 - acc: 0.7978 - val_loss: 0.3976 - val_acc: 0.8222\n",
      "Epoch 61/300\n",
      "801/801 [==============================] - 0s - loss: 0.4356 - acc: 0.8027 - val_loss: 0.4023 - val_acc: 0.8111\n",
      "Epoch 62/300\n",
      "801/801 [==============================] - 0s - loss: 0.4349 - acc: 0.8115 - val_loss: 0.3964 - val_acc: 0.8111\n",
      "Epoch 63/300\n",
      "801/801 [==============================] - 0s - loss: 0.4348 - acc: 0.7990 - val_loss: 0.3893 - val_acc: 0.8333\n",
      "Epoch 64/300\n",
      "801/801 [==============================] - 0s - loss: 0.4354 - acc: 0.8015 - val_loss: 0.3907 - val_acc: 0.8333\n",
      "Epoch 65/300\n",
      "801/801 [==============================] - 0s - loss: 0.4353 - acc: 0.7940 - val_loss: 0.3843 - val_acc: 0.8333\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s - loss: 0.4112 - acc: 0.8052 - val_loss: 0.3843 - val_acc: 0.8444\n",
      "Epoch 67/300\n",
      "801/801 [==============================] - 0s - loss: 0.4086 - acc: 0.8077 - val_loss: 0.3978 - val_acc: 0.8000\n",
      "Epoch 68/300\n",
      "801/801 [==============================] - 0s - loss: 0.4075 - acc: 0.8227 - val_loss: 0.3877 - val_acc: 0.8444\n",
      "Epoch 69/300\n",
      "801/801 [==============================] - 0s - loss: 0.4053 - acc: 0.8277 - val_loss: 0.3881 - val_acc: 0.8222\n",
      "Epoch 70/300\n",
      "801/801 [==============================] - 0s - loss: 0.3990 - acc: 0.8252 - val_loss: 0.3882 - val_acc: 0.8444\n",
      "Epoch 71/300\n",
      "801/801 [==============================] - 0s - loss: 0.3977 - acc: 0.8165 - val_loss: 0.3856 - val_acc: 0.8222\n",
      "Epoch 72/300\n",
      "801/801 [==============================] - 0s - loss: 0.3849 - acc: 0.8414 - val_loss: 0.3937 - val_acc: 0.8222\n",
      "Epoch 73/300\n",
      "801/801 [==============================] - 0s - loss: 0.4132 - acc: 0.8127 - val_loss: 0.3880 - val_acc: 0.8444\n",
      "Epoch 74/300\n",
      "801/801 [==============================] - 0s - loss: 0.3958 - acc: 0.8252 - val_loss: 0.3893 - val_acc: 0.8333\n",
      "Epoch 75/300\n",
      "801/801 [==============================] - 0s - loss: 0.3842 - acc: 0.8365 - val_loss: 0.3906 - val_acc: 0.8333\n",
      "Epoch 76/300\n",
      "801/801 [==============================] - 0s - loss: 0.3758 - acc: 0.8402 - val_loss: 0.3861 - val_acc: 0.8444\n",
      "Epoch 77/300\n",
      "801/801 [==============================] - 0s - loss: 0.3762 - acc: 0.8390 - val_loss: 0.3895 - val_acc: 0.8222\n",
      "Epoch 78/300\n",
      "801/801 [==============================] - 0s - loss: 0.3751 - acc: 0.8352 - val_loss: 0.3876 - val_acc: 0.8111\n",
      "Epoch 79/300\n",
      "801/801 [==============================] - 0s - loss: 0.3730 - acc: 0.8489 - val_loss: 0.3960 - val_acc: 0.8556\n",
      "Epoch 80/300\n",
      "801/801 [==============================] - 0s - loss: 0.3812 - acc: 0.8327 - val_loss: 0.3889 - val_acc: 0.8333\n",
      "Epoch 81/300\n",
      "801/801 [==============================] - 0s - loss: 0.3583 - acc: 0.8377 - val_loss: 0.3905 - val_acc: 0.8444\n",
      "Epoch 82/300\n",
      "801/801 [==============================] - 0s - loss: 0.3756 - acc: 0.8302 - val_loss: 0.3917 - val_acc: 0.8444\n",
      "Epoch 83/300\n",
      "801/801 [==============================] - 0s - loss: 0.3698 - acc: 0.8477 - val_loss: 0.3923 - val_acc: 0.8444\n",
      "Epoch 84/300\n",
      "801/801 [==============================] - 0s - loss: 0.3576 - acc: 0.8502 - val_loss: 0.3920 - val_acc: 0.8444\n",
      "Epoch 85/300\n",
      "801/801 [==============================] - 0s - loss: 0.3569 - acc: 0.8489 - val_loss: 0.3910 - val_acc: 0.8222\n",
      "Epoch 86/300\n",
      "801/801 [==============================] - 0s - loss: 0.3352 - acc: 0.8602 - val_loss: 0.3938 - val_acc: 0.8333\n",
      "Epoch 87/300\n",
      "801/801 [==============================] - 0s - loss: 0.3609 - acc: 0.8402 - val_loss: 0.3915 - val_acc: 0.8333\n",
      "Epoch 88/300\n",
      "801/801 [==============================] - 0s - loss: 0.3386 - acc: 0.8564 - val_loss: 0.4019 - val_acc: 0.8556\n",
      "Epoch 89/300\n",
      "801/801 [==============================] - 0s - loss: 0.3369 - acc: 0.8527 - val_loss: 0.3941 - val_acc: 0.8333\n",
      "Epoch 90/300\n",
      "801/801 [==============================] - 0s - loss: 0.3478 - acc: 0.8414 - val_loss: 0.3943 - val_acc: 0.8333\n",
      "Epoch 91/300\n",
      "801/801 [==============================] - 0s - loss: 0.3312 - acc: 0.8577 - val_loss: 0.3944 - val_acc: 0.8333\n",
      "Epoch 92/300\n",
      "801/801 [==============================] - 0s - loss: 0.3266 - acc: 0.8602 - val_loss: 0.3978 - val_acc: 0.8556\n",
      "Epoch 93/300\n",
      "801/801 [==============================] - 0s - loss: 0.3439 - acc: 0.8564 - val_loss: 0.3964 - val_acc: 0.8222\n",
      "Epoch 94/300\n",
      "801/801 [==============================] - 0s - loss: 0.3410 - acc: 0.8489 - val_loss: 0.3969 - val_acc: 0.8444\n",
      "Epoch 95/300\n",
      "801/801 [==============================] - 0s - loss: 0.3292 - acc: 0.8714 - val_loss: 0.3987 - val_acc: 0.8556\n",
      "Epoch 96/300\n",
      "801/801 [==============================] - 0s - loss: 0.3293 - acc: 0.8589 - val_loss: 0.4054 - val_acc: 0.8667\n",
      "Epoch 97/300\n",
      "801/801 [==============================] - 0s - loss: 0.3197 - acc: 0.8664 - val_loss: 0.4006 - val_acc: 0.8333\n",
      "Epoch 98/300\n",
      "801/801 [==============================] - 0s - loss: 0.3161 - acc: 0.8677 - val_loss: 0.4135 - val_acc: 0.8556\n",
      "Epoch 99/300\n",
      "801/801 [==============================] - 0s - loss: 0.3026 - acc: 0.8702 - val_loss: 0.4022 - val_acc: 0.8111\n",
      "Epoch 100/300\n",
      "801/801 [==============================] - 0s - loss: 0.3152 - acc: 0.8764 - val_loss: 0.4021 - val_acc: 0.8444\n",
      "Epoch 101/300\n",
      "801/801 [==============================] - 0s - loss: 0.3085 - acc: 0.8702 - val_loss: 0.4037 - val_acc: 0.8667\n",
      "Epoch 102/300\n",
      "801/801 [==============================] - 0s - loss: 0.2978 - acc: 0.8777 - val_loss: 0.4120 - val_acc: 0.8444\n",
      "Epoch 103/300\n",
      "801/801 [==============================] - 0s - loss: 0.3088 - acc: 0.8577 - val_loss: 0.4082 - val_acc: 0.8333\n",
      "Epoch 104/300\n",
      "801/801 [==============================] - 0s - loss: 0.2858 - acc: 0.8889 - val_loss: 0.4114 - val_acc: 0.8444\n",
      "Epoch 105/300\n",
      "801/801 [==============================] - 0s - loss: 0.3042 - acc: 0.8702 - val_loss: 0.4115 - val_acc: 0.8333\n",
      "Epoch 106/300\n",
      "801/801 [==============================] - 0s - loss: 0.3041 - acc: 0.8739 - val_loss: 0.4106 - val_acc: 0.8556\n",
      "Epoch 107/300\n",
      "801/801 [==============================] - 0s - loss: 0.2948 - acc: 0.8764 - val_loss: 0.4105 - val_acc: 0.8556\n",
      "Epoch 108/300\n",
      "801/801 [==============================] - 0s - loss: 0.2817 - acc: 0.8939 - val_loss: 0.4120 - val_acc: 0.8444\n",
      "Epoch 109/300\n",
      "801/801 [==============================] - 0s - loss: 0.2868 - acc: 0.8901 - val_loss: 0.4152 - val_acc: 0.8444\n",
      "Epoch 110/300\n",
      "801/801 [==============================] - 0s - loss: 0.2612 - acc: 0.8964 - val_loss: 0.4172 - val_acc: 0.8556\n",
      "Epoch 111/300\n",
      "801/801 [==============================] - 0s - loss: 0.2794 - acc: 0.8951 - val_loss: 0.4207 - val_acc: 0.8556\n",
      "Epoch 112/300\n",
      "801/801 [==============================] - 0s - loss: 0.2855 - acc: 0.8864 - val_loss: 0.4166 - val_acc: 0.8444\n",
      "Epoch 113/300\n",
      "801/801 [==============================] - 0s - loss: 0.2667 - acc: 0.8989 - val_loss: 0.4185 - val_acc: 0.8333\n",
      "Epoch 114/300\n",
      "801/801 [==============================] - 0s - loss: 0.2595 - acc: 0.8964 - val_loss: 0.4208 - val_acc: 0.8333\n",
      "Epoch 115/300\n",
      "801/801 [==============================] - 0s - loss: 0.2620 - acc: 0.8914 - val_loss: 0.4193 - val_acc: 0.8444\n",
      "Epoch 116/300\n",
      "801/801 [==============================] - 0s - loss: 0.2710 - acc: 0.8914 - val_loss: 0.4203 - val_acc: 0.8444\n",
      "Epoch 117/300\n",
      "801/801 [==============================] - 0s - loss: 0.2592 - acc: 0.8926 - val_loss: 0.4246 - val_acc: 0.8556\n",
      "Epoch 118/300\n",
      "801/801 [==============================] - 0s - loss: 0.2564 - acc: 0.9001 - val_loss: 0.4251 - val_acc: 0.8333\n",
      "Epoch 119/300\n",
      "801/801 [==============================] - 0s - loss: 0.2485 - acc: 0.9076 - val_loss: 0.4296 - val_acc: 0.8556\n",
      "Epoch 120/300\n",
      "801/801 [==============================] - 0s - loss: 0.2560 - acc: 0.8989 - val_loss: 0.4323 - val_acc: 0.8444\n",
      "Epoch 121/300\n",
      "801/801 [==============================] - 0s - loss: 0.2415 - acc: 0.9064 - val_loss: 0.4326 - val_acc: 0.8444\n",
      "Epoch 122/300\n",
      "801/801 [==============================] - 0s - loss: 0.2643 - acc: 0.8964 - val_loss: 0.4306 - val_acc: 0.8444\n",
      "Epoch 123/300\n",
      "801/801 [==============================] - 0s - loss: 0.2412 - acc: 0.9014 - val_loss: 0.4337 - val_acc: 0.8444\n",
      "Epoch 124/300\n",
      "801/801 [==============================] - 0s - loss: 0.2589 - acc: 0.8914 - val_loss: 0.4347 - val_acc: 0.8556\n",
      "Epoch 125/300\n",
      "801/801 [==============================] - 0s - loss: 0.2246 - acc: 0.9101 - val_loss: 0.4386 - val_acc: 0.8444\n",
      "Epoch 126/300\n",
      "801/801 [==============================] - 0s - loss: 0.2309 - acc: 0.9101 - val_loss: 0.4438 - val_acc: 0.8333\n",
      "Epoch 127/300\n",
      "801/801 [==============================] - 0s - loss: 0.2210 - acc: 0.9139 - val_loss: 0.4422 - val_acc: 0.8444\n",
      "Epoch 128/300\n",
      "801/801 [==============================] - 0s - loss: 0.2490 - acc: 0.9064 - val_loss: 0.4626 - val_acc: 0.8556\n",
      "Epoch 129/300\n",
      "801/801 [==============================] - 0s - loss: 0.2490 - acc: 0.9039 - val_loss: 0.4417 - val_acc: 0.8444\n",
      "Epoch 130/300\n",
      "801/801 [==============================] - 0s - loss: 0.1949 - acc: 0.9201 - val_loss: 0.4444 - val_acc: 0.8333\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s - loss: 0.2309 - acc: 0.9114 - val_loss: 0.4555 - val_acc: 0.8667\n",
      "Epoch 132/300\n",
      "801/801 [==============================] - 0s - loss: 0.2435 - acc: 0.9064 - val_loss: 0.4455 - val_acc: 0.8556\n",
      "Epoch 133/300\n",
      "801/801 [==============================] - 0s - loss: 0.2150 - acc: 0.9251 - val_loss: 0.4467 - val_acc: 0.8333\n",
      "Epoch 134/300\n",
      "801/801 [==============================] - 0s - loss: 0.2316 - acc: 0.9089 - val_loss: 0.4541 - val_acc: 0.8444\n",
      "Epoch 135/300\n",
      "801/801 [==============================] - 0s - loss: 0.2315 - acc: 0.9089 - val_loss: 0.4439 - val_acc: 0.8444\n",
      "Epoch 136/300\n",
      "801/801 [==============================] - 0s - loss: 0.2293 - acc: 0.9014 - val_loss: 0.4428 - val_acc: 0.8444\n",
      "Epoch 137/300\n",
      "801/801 [==============================] - 0s - loss: 0.2188 - acc: 0.9101 - val_loss: 0.4449 - val_acc: 0.8556\n",
      "Epoch 138/300\n",
      "801/801 [==============================] - 0s - loss: 0.2223 - acc: 0.9151 - val_loss: 0.4440 - val_acc: 0.8333\n",
      "Epoch 139/300\n",
      "801/801 [==============================] - 0s - loss: 0.2103 - acc: 0.9176 - val_loss: 0.4561 - val_acc: 0.8444\n",
      "Epoch 140/300\n",
      "801/801 [==============================] - 0s - loss: 0.2368 - acc: 0.9076 - val_loss: 0.4477 - val_acc: 0.8444\n",
      "Epoch 141/300\n",
      "801/801 [==============================] - 0s - loss: 0.2139 - acc: 0.9114 - val_loss: 0.4696 - val_acc: 0.8444\n",
      "Epoch 142/300\n",
      "801/801 [==============================] - 0s - loss: 0.2160 - acc: 0.9201 - val_loss: 0.4547 - val_acc: 0.8556\n",
      "Epoch 143/300\n",
      "801/801 [==============================] - 0s - loss: 0.2045 - acc: 0.9263 - val_loss: 0.4590 - val_acc: 0.8556\n",
      "Epoch 144/300\n",
      "801/801 [==============================] - 0s - loss: 0.2151 - acc: 0.9139 - val_loss: 0.4624 - val_acc: 0.8556\n",
      "Epoch 145/300\n",
      "801/801 [==============================] - 0s - loss: 0.1858 - acc: 0.9313 - val_loss: 0.4726 - val_acc: 0.8556\n",
      "Epoch 146/300\n",
      "801/801 [==============================] - 0s - loss: 0.2121 - acc: 0.9139 - val_loss: 0.4576 - val_acc: 0.8444\n",
      "Epoch 147/300\n",
      "801/801 [==============================] - 0s - loss: 0.1883 - acc: 0.9301 - val_loss: 0.4549 - val_acc: 0.8444\n",
      "Epoch 148/300\n",
      "801/801 [==============================] - 0s - loss: 0.1854 - acc: 0.9338 - val_loss: 0.4620 - val_acc: 0.8556\n",
      "Epoch 149/300\n",
      "801/801 [==============================] - 0s - loss: 0.2055 - acc: 0.9164 - val_loss: 0.4678 - val_acc: 0.8556\n",
      "Epoch 150/300\n",
      "801/801 [==============================] - 0s - loss: 0.2110 - acc: 0.9126 - val_loss: 0.4700 - val_acc: 0.8444\n",
      "Epoch 151/300\n",
      "801/801 [==============================] - 0s - loss: 0.2173 - acc: 0.9176 - val_loss: 0.4766 - val_acc: 0.8556\n",
      "Epoch 152/300\n",
      "801/801 [==============================] - 0s - loss: 0.1819 - acc: 0.9251 - val_loss: 0.4615 - val_acc: 0.8444\n",
      "Epoch 153/300\n",
      "801/801 [==============================] - 0s - loss: 0.1774 - acc: 0.9238 - val_loss: 0.4694 - val_acc: 0.8556\n",
      "Epoch 154/300\n",
      "801/801 [==============================] - 0s - loss: 0.1799 - acc: 0.9251 - val_loss: 0.4729 - val_acc: 0.8556\n",
      "Epoch 155/300\n",
      "801/801 [==============================] - 0s - loss: 0.1770 - acc: 0.9351 - val_loss: 0.4725 - val_acc: 0.8556\n",
      "Epoch 156/300\n",
      "801/801 [==============================] - 0s - loss: 0.1574 - acc: 0.9388 - val_loss: 0.4731 - val_acc: 0.8556\n",
      "Epoch 157/300\n",
      "801/801 [==============================] - 0s - loss: 0.1621 - acc: 0.9288 - val_loss: 0.4789 - val_acc: 0.8333\n",
      "Epoch 158/300\n",
      "801/801 [==============================] - 0s - loss: 0.1457 - acc: 0.9451 - val_loss: 0.4915 - val_acc: 0.8556\n",
      "Epoch 159/300\n",
      "801/801 [==============================] - 0s - loss: 0.1593 - acc: 0.9438 - val_loss: 0.4889 - val_acc: 0.8556\n",
      "Epoch 160/300\n",
      "801/801 [==============================] - 0s - loss: 0.1551 - acc: 0.9363 - val_loss: 0.4893 - val_acc: 0.8556\n",
      "Epoch 161/300\n",
      "801/801 [==============================] - 0s - loss: 0.1618 - acc: 0.9451 - val_loss: 0.4923 - val_acc: 0.8556\n",
      "Epoch 162/300\n",
      "801/801 [==============================] - 0s - loss: 0.1594 - acc: 0.9376 - val_loss: 0.4969 - val_acc: 0.8333\n",
      "Epoch 163/300\n",
      "801/801 [==============================] - 0s - loss: 0.1455 - acc: 0.9513 - val_loss: 0.5024 - val_acc: 0.8556\n",
      "Epoch 164/300\n",
      "801/801 [==============================] - 0s - loss: 0.1282 - acc: 0.9513 - val_loss: 0.5032 - val_acc: 0.8333\n",
      "Epoch 165/300\n",
      "801/801 [==============================] - 0s - loss: 0.1630 - acc: 0.9326 - val_loss: 0.5074 - val_acc: 0.8556\n",
      "Epoch 166/300\n",
      "801/801 [==============================] - 0s - loss: 0.1796 - acc: 0.9251 - val_loss: 0.5156 - val_acc: 0.8556\n",
      "Epoch 167/300\n",
      "801/801 [==============================] - 0s - loss: 0.1456 - acc: 0.9463 - val_loss: 0.5124 - val_acc: 0.8556\n",
      "Epoch 168/300\n",
      "801/801 [==============================] - 0s - loss: 0.1502 - acc: 0.9426 - val_loss: 0.5085 - val_acc: 0.8444\n",
      "Epoch 169/300\n",
      "801/801 [==============================] - 0s - loss: 0.1375 - acc: 0.9488 - val_loss: 0.5130 - val_acc: 0.8444\n",
      "Epoch 170/300\n",
      "801/801 [==============================] - 0s - loss: 0.1439 - acc: 0.9526 - val_loss: 0.5146 - val_acc: 0.8444\n",
      "Epoch 171/300\n",
      "801/801 [==============================] - 0s - loss: 0.1343 - acc: 0.9538 - val_loss: 0.5194 - val_acc: 0.8556\n",
      "Epoch 172/300\n",
      "801/801 [==============================] - 0s - loss: 0.1344 - acc: 0.9463 - val_loss: 0.5189 - val_acc: 0.8444\n",
      "Epoch 173/300\n",
      "801/801 [==============================] - 0s - loss: 0.1505 - acc: 0.9476 - val_loss: 0.5319 - val_acc: 0.8556\n",
      "Epoch 174/300\n",
      "801/801 [==============================] - 0s - loss: 0.1554 - acc: 0.9401 - val_loss: 0.5150 - val_acc: 0.8333\n",
      "Epoch 175/300\n",
      "801/801 [==============================] - 0s - loss: 0.1475 - acc: 0.9401 - val_loss: 0.5224 - val_acc: 0.8444\n",
      "Epoch 176/300\n",
      "801/801 [==============================] - 0s - loss: 0.1568 - acc: 0.9413 - val_loss: 0.5350 - val_acc: 0.8556\n",
      "Epoch 177/300\n",
      "801/801 [==============================] - 0s - loss: 0.1527 - acc: 0.9401 - val_loss: 0.5330 - val_acc: 0.8556\n",
      "Epoch 178/300\n",
      "801/801 [==============================] - 0s - loss: 0.1292 - acc: 0.9501 - val_loss: 0.5231 - val_acc: 0.8333\n",
      "Epoch 179/300\n",
      "801/801 [==============================] - 0s - loss: 0.1239 - acc: 0.9488 - val_loss: 0.5278 - val_acc: 0.8444\n",
      "Epoch 180/300\n",
      "801/801 [==============================] - 0s - loss: 0.1385 - acc: 0.9526 - val_loss: 0.5298 - val_acc: 0.8444\n",
      "Epoch 181/300\n",
      "801/801 [==============================] - 0s - loss: 0.1357 - acc: 0.9513 - val_loss: 0.5309 - val_acc: 0.8556\n",
      "Epoch 182/300\n",
      "801/801 [==============================] - 0s - loss: 0.1112 - acc: 0.9625 - val_loss: 0.5289 - val_acc: 0.8556\n",
      "Epoch 183/300\n",
      "801/801 [==============================] - 0s - loss: 0.1232 - acc: 0.9538 - val_loss: 0.5280 - val_acc: 0.8333\n",
      "Epoch 184/300\n",
      "801/801 [==============================] - 0s - loss: 0.1185 - acc: 0.9588 - val_loss: 0.5761 - val_acc: 0.8444\n",
      "Epoch 185/300\n",
      "801/801 [==============================] - 0s - loss: 0.1891 - acc: 0.9301 - val_loss: 0.5321 - val_acc: 0.8444\n",
      "Epoch 186/300\n",
      "801/801 [==============================] - 0s - loss: 0.1120 - acc: 0.9600 - val_loss: 0.5454 - val_acc: 0.8444\n",
      "Epoch 187/300\n",
      "801/801 [==============================] - 0s - loss: 0.1192 - acc: 0.9538 - val_loss: 0.5436 - val_acc: 0.8444\n",
      "Epoch 188/300\n",
      "801/801 [==============================] - 0s - loss: 0.1231 - acc: 0.9488 - val_loss: 0.5332 - val_acc: 0.8556\n",
      "Epoch 189/300\n",
      "801/801 [==============================] - 0s - loss: 0.1162 - acc: 0.9625 - val_loss: 0.5428 - val_acc: 0.8556\n",
      "Epoch 190/300\n",
      "801/801 [==============================] - 0s - loss: 0.1202 - acc: 0.9563 - val_loss: 0.5404 - val_acc: 0.8556\n",
      "Epoch 191/300\n",
      "801/801 [==============================] - 0s - loss: 0.1063 - acc: 0.9613 - val_loss: 0.5514 - val_acc: 0.8444\n",
      "Epoch 192/300\n",
      "801/801 [==============================] - 0s - loss: 0.1236 - acc: 0.9588 - val_loss: 0.5571 - val_acc: 0.8556\n",
      "Epoch 193/300\n",
      "801/801 [==============================] - 0s - loss: 0.1332 - acc: 0.9438 - val_loss: 0.5459 - val_acc: 0.8444\n",
      "Epoch 194/300\n",
      "801/801 [==============================] - 0s - loss: 0.1105 - acc: 0.9638 - val_loss: 0.5420 - val_acc: 0.8333\n",
      "Epoch 195/300\n",
      "801/801 [==============================] - 0s - loss: 0.1056 - acc: 0.9600 - val_loss: 0.5497 - val_acc: 0.8556\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s - loss: 0.1254 - acc: 0.9588 - val_loss: 0.5522 - val_acc: 0.8556\n",
      "Epoch 197/300\n",
      "801/801 [==============================] - 0s - loss: 0.1168 - acc: 0.9576 - val_loss: 0.5452 - val_acc: 0.8444\n",
      "Epoch 198/300\n",
      "801/801 [==============================] - 0s - loss: 0.1014 - acc: 0.9613 - val_loss: 0.5513 - val_acc: 0.8556\n",
      "Epoch 199/300\n",
      "801/801 [==============================] - 0s - loss: 0.1089 - acc: 0.9588 - val_loss: 0.5532 - val_acc: 0.8444\n",
      "Epoch 200/300\n",
      "801/801 [==============================] - 0s - loss: 0.1148 - acc: 0.9538 - val_loss: 0.5546 - val_acc: 0.8444\n",
      "Epoch 201/300\n",
      "801/801 [==============================] - 0s - loss: 0.1150 - acc: 0.9576 - val_loss: 0.5548 - val_acc: 0.8444\n",
      "Epoch 202/300\n",
      "801/801 [==============================] - 0s - loss: 0.0850 - acc: 0.9688 - val_loss: 0.5632 - val_acc: 0.8556\n",
      "Epoch 203/300\n",
      "801/801 [==============================] - 0s - loss: 0.1009 - acc: 0.9551 - val_loss: 0.5631 - val_acc: 0.8333\n",
      "Epoch 204/300\n",
      "801/801 [==============================] - 0s - loss: 0.1028 - acc: 0.9638 - val_loss: 0.5611 - val_acc: 0.8333\n",
      "Epoch 205/300\n",
      "801/801 [==============================] - 0s - loss: 0.1205 - acc: 0.9588 - val_loss: 0.5745 - val_acc: 0.8444\n",
      "Epoch 206/300\n",
      "801/801 [==============================] - 0s - loss: 0.1036 - acc: 0.9613 - val_loss: 0.5811 - val_acc: 0.8444\n",
      "Epoch 207/300\n",
      "801/801 [==============================] - 0s - loss: 0.1114 - acc: 0.9625 - val_loss: 0.5649 - val_acc: 0.8333\n",
      "Epoch 208/300\n",
      "801/801 [==============================] - 0s - loss: 0.1036 - acc: 0.9625 - val_loss: 0.5746 - val_acc: 0.8556\n",
      "Epoch 209/300\n",
      "801/801 [==============================] - 0s - loss: 0.1004 - acc: 0.9625 - val_loss: 0.5723 - val_acc: 0.8556\n",
      "Epoch 210/300\n",
      "801/801 [==============================] - 0s - loss: 0.1108 - acc: 0.9625 - val_loss: 0.5837 - val_acc: 0.8444\n",
      "Epoch 211/300\n",
      "801/801 [==============================] - 0s - loss: 0.1128 - acc: 0.9613 - val_loss: 0.5781 - val_acc: 0.8444\n",
      "Epoch 212/300\n",
      "801/801 [==============================] - 0s - loss: 0.1092 - acc: 0.9613 - val_loss: 0.5786 - val_acc: 0.8556\n",
      "Epoch 213/300\n",
      "801/801 [==============================] - 0s - loss: 0.1068 - acc: 0.9538 - val_loss: 0.5712 - val_acc: 0.8556\n",
      "Epoch 214/300\n",
      "801/801 [==============================] - 0s - loss: 0.1202 - acc: 0.9576 - val_loss: 0.5683 - val_acc: 0.8556\n",
      "Epoch 215/300\n",
      "801/801 [==============================] - 0s - loss: 0.1066 - acc: 0.9625 - val_loss: 0.5724 - val_acc: 0.8556\n",
      "Epoch 216/300\n",
      "801/801 [==============================] - 0s - loss: 0.0900 - acc: 0.9650 - val_loss: 0.5718 - val_acc: 0.8556\n",
      "Epoch 217/300\n",
      "801/801 [==============================] - 0s - loss: 0.1062 - acc: 0.9600 - val_loss: 0.5739 - val_acc: 0.8444\n",
      "Epoch 218/300\n",
      "801/801 [==============================] - 0s - loss: 0.0934 - acc: 0.9688 - val_loss: 0.5786 - val_acc: 0.8444\n",
      "Epoch 219/300\n",
      "801/801 [==============================] - 0s - loss: 0.0951 - acc: 0.9663 - val_loss: 0.5775 - val_acc: 0.8556\n",
      "Epoch 220/300\n",
      "801/801 [==============================] - 0s - loss: 0.0793 - acc: 0.9763 - val_loss: 0.5894 - val_acc: 0.8444\n",
      "Epoch 221/300\n",
      "801/801 [==============================] - 0s - loss: 0.0874 - acc: 0.9650 - val_loss: 0.5824 - val_acc: 0.8444\n",
      "Epoch 222/300\n",
      "801/801 [==============================] - 0s - loss: 0.0838 - acc: 0.9700 - val_loss: 0.5905 - val_acc: 0.8444\n",
      "Epoch 223/300\n",
      "801/801 [==============================] - 0s - loss: 0.0969 - acc: 0.9638 - val_loss: 0.6073 - val_acc: 0.8556\n",
      "Epoch 224/300\n",
      "801/801 [==============================] - 0s - loss: 0.1048 - acc: 0.9613 - val_loss: 0.5810 - val_acc: 0.8556\n",
      "Epoch 225/300\n",
      "801/801 [==============================] - 0s - loss: 0.1092 - acc: 0.9600 - val_loss: 0.5816 - val_acc: 0.8556\n",
      "Epoch 226/300\n",
      "801/801 [==============================] - 0s - loss: 0.0933 - acc: 0.9650 - val_loss: 0.6066 - val_acc: 0.8333\n",
      "Epoch 227/300\n",
      "801/801 [==============================] - 0s - loss: 0.1014 - acc: 0.9563 - val_loss: 0.5897 - val_acc: 0.8444\n",
      "Epoch 228/300\n",
      "801/801 [==============================] - 0s - loss: 0.1001 - acc: 0.9613 - val_loss: 0.6104 - val_acc: 0.8444\n",
      "Epoch 229/300\n",
      "801/801 [==============================] - 0s - loss: 0.0854 - acc: 0.9688 - val_loss: 0.5977 - val_acc: 0.8444\n",
      "Epoch 230/300\n",
      "801/801 [==============================] - 0s - loss: 0.0876 - acc: 0.9713 - val_loss: 0.6044 - val_acc: 0.8444\n",
      "Epoch 231/300\n",
      "801/801 [==============================] - 0s - loss: 0.0805 - acc: 0.9663 - val_loss: 0.6028 - val_acc: 0.8444\n",
      "Epoch 232/300\n",
      "801/801 [==============================] - 0s - loss: 0.1149 - acc: 0.9638 - val_loss: 0.6023 - val_acc: 0.8444\n",
      "Epoch 233/300\n",
      "801/801 [==============================] - 0s - loss: 0.0903 - acc: 0.9638 - val_loss: 0.6260 - val_acc: 0.8556\n",
      "Epoch 234/300\n",
      "801/801 [==============================] - 0s - loss: 0.0996 - acc: 0.9588 - val_loss: 0.6003 - val_acc: 0.8556\n",
      "Epoch 235/300\n",
      "801/801 [==============================] - 0s - loss: 0.0758 - acc: 0.9750 - val_loss: 0.6057 - val_acc: 0.8556\n",
      "Epoch 236/300\n",
      "801/801 [==============================] - 0s - loss: 0.1017 - acc: 0.9675 - val_loss: 0.6121 - val_acc: 0.8444\n",
      "Epoch 237/300\n",
      "801/801 [==============================] - 0s - loss: 0.0826 - acc: 0.9725 - val_loss: 0.5948 - val_acc: 0.8333\n",
      "Epoch 238/300\n",
      "801/801 [==============================] - 0s - loss: 0.0745 - acc: 0.9763 - val_loss: 0.6159 - val_acc: 0.8444\n",
      "Epoch 239/300\n",
      "801/801 [==============================] - 0s - loss: 0.0823 - acc: 0.9700 - val_loss: 0.6263 - val_acc: 0.8444\n",
      "Epoch 240/300\n",
      "801/801 [==============================] - 0s - loss: 0.0763 - acc: 0.9763 - val_loss: 0.6054 - val_acc: 0.8333\n",
      "Epoch 241/300\n",
      "801/801 [==============================] - 0s - loss: 0.0708 - acc: 0.9800 - val_loss: 0.6120 - val_acc: 0.8444\n",
      "Epoch 242/300\n",
      "801/801 [==============================] - 0s - loss: 0.0575 - acc: 0.9788 - val_loss: 0.6271 - val_acc: 0.8333\n",
      "Epoch 243/300\n",
      "801/801 [==============================] - 0s - loss: 0.0686 - acc: 0.9750 - val_loss: 0.6221 - val_acc: 0.8444\n",
      "Epoch 244/300\n",
      "801/801 [==============================] - 0s - loss: 0.0745 - acc: 0.9700 - val_loss: 0.6226 - val_acc: 0.8444\n",
      "Epoch 245/300\n",
      "801/801 [==============================] - 0s - loss: 0.0693 - acc: 0.9775 - val_loss: 0.6271 - val_acc: 0.8444\n",
      "Epoch 246/300\n",
      "801/801 [==============================] - 0s - loss: 0.0758 - acc: 0.9763 - val_loss: 0.6302 - val_acc: 0.8444\n",
      "Epoch 247/300\n",
      "801/801 [==============================] - 0s - loss: 0.0817 - acc: 0.9613 - val_loss: 0.6366 - val_acc: 0.8333\n",
      "Epoch 248/300\n",
      "801/801 [==============================] - 0s - loss: 0.0718 - acc: 0.9713 - val_loss: 0.6315 - val_acc: 0.8444\n",
      "Epoch 249/300\n",
      "801/801 [==============================] - 0s - loss: 0.0746 - acc: 0.9713 - val_loss: 0.6354 - val_acc: 0.8444\n",
      "Epoch 250/300\n",
      "801/801 [==============================] - 0s - loss: 0.0928 - acc: 0.9650 - val_loss: 0.6495 - val_acc: 0.8444\n",
      "Epoch 251/300\n",
      "801/801 [==============================] - 0s - loss: 0.0600 - acc: 0.9775 - val_loss: 0.6373 - val_acc: 0.8333\n",
      "Epoch 252/300\n",
      "801/801 [==============================] - 0s - loss: 0.0791 - acc: 0.9688 - val_loss: 0.6351 - val_acc: 0.8444\n",
      "Epoch 253/300\n",
      "801/801 [==============================] - 0s - loss: 0.0627 - acc: 0.9775 - val_loss: 0.6487 - val_acc: 0.8333\n",
      "Epoch 254/300\n",
      "801/801 [==============================] - 0s - loss: 0.0774 - acc: 0.9738 - val_loss: 0.6642 - val_acc: 0.8333\n",
      "Epoch 255/300\n",
      "801/801 [==============================] - 0s - loss: 0.0491 - acc: 0.9825 - val_loss: 0.6470 - val_acc: 0.8222\n",
      "Epoch 256/300\n",
      "801/801 [==============================] - 0s - loss: 0.0651 - acc: 0.9738 - val_loss: 0.6404 - val_acc: 0.8444\n",
      "Epoch 257/300\n",
      "801/801 [==============================] - 0s - loss: 0.0698 - acc: 0.9750 - val_loss: 0.6352 - val_acc: 0.8444\n",
      "Epoch 258/300\n",
      "801/801 [==============================] - 0s - loss: 0.0649 - acc: 0.9763 - val_loss: 0.6608 - val_acc: 0.8556\n",
      "Epoch 259/300\n",
      "801/801 [==============================] - 0s - loss: 0.0678 - acc: 0.9763 - val_loss: 0.6566 - val_acc: 0.8333\n",
      "Epoch 260/300\n",
      "801/801 [==============================] - 0s - loss: 0.0940 - acc: 0.9675 - val_loss: 0.6424 - val_acc: 0.8333\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s - loss: 0.0704 - acc: 0.9713 - val_loss: 0.6461 - val_acc: 0.8444\n",
      "Epoch 262/300\n",
      "801/801 [==============================] - 0s - loss: 0.0735 - acc: 0.9775 - val_loss: 0.6402 - val_acc: 0.8444\n",
      "Epoch 263/300\n",
      "801/801 [==============================] - 0s - loss: 0.0715 - acc: 0.9713 - val_loss: 0.6544 - val_acc: 0.8444\n",
      "Epoch 264/300\n",
      "801/801 [==============================] - 0s - loss: 0.0762 - acc: 0.9700 - val_loss: 0.6453 - val_acc: 0.8333\n",
      "Epoch 265/300\n",
      "801/801 [==============================] - 0s - loss: 0.0786 - acc: 0.9638 - val_loss: 0.6517 - val_acc: 0.8556\n",
      "Epoch 266/300\n",
      "801/801 [==============================] - 0s - loss: 0.0690 - acc: 0.9725 - val_loss: 0.6375 - val_acc: 0.8556\n",
      "Epoch 267/300\n",
      "801/801 [==============================] - 0s - loss: 0.0750 - acc: 0.9763 - val_loss: 0.6593 - val_acc: 0.8556\n",
      "Epoch 268/300\n",
      "801/801 [==============================] - 0s - loss: 0.0658 - acc: 0.9825 - val_loss: 0.6399 - val_acc: 0.8444\n",
      "Epoch 269/300\n",
      "801/801 [==============================] - 0s - loss: 0.0567 - acc: 0.9813 - val_loss: 0.6804 - val_acc: 0.8333\n",
      "Epoch 270/300\n",
      "801/801 [==============================] - 0s - loss: 0.0693 - acc: 0.9775 - val_loss: 0.6555 - val_acc: 0.8333\n",
      "Epoch 271/300\n",
      "801/801 [==============================] - ETA: 0s - loss: 0.0511 - acc: 0.988 - 0s - loss: 0.0511 - acc: 0.9863 - val_loss: 0.6751 - val_acc: 0.8333\n",
      "Epoch 272/300\n",
      "801/801 [==============================] - 0s - loss: 0.0625 - acc: 0.9775 - val_loss: 0.6581 - val_acc: 0.8444\n",
      "Epoch 273/300\n",
      "801/801 [==============================] - 0s - loss: 0.0521 - acc: 0.9838 - val_loss: 0.6590 - val_acc: 0.8333\n",
      "Epoch 274/300\n",
      "801/801 [==============================] - 0s - loss: 0.0683 - acc: 0.9788 - val_loss: 0.7025 - val_acc: 0.8222\n",
      "Epoch 275/300\n",
      "801/801 [==============================] - 0s - loss: 0.0632 - acc: 0.9738 - val_loss: 0.6689 - val_acc: 0.8444\n",
      "Epoch 276/300\n",
      "801/801 [==============================] - 0s - loss: 0.0572 - acc: 0.9813 - val_loss: 0.6870 - val_acc: 0.8333\n",
      "Epoch 277/300\n",
      "801/801 [==============================] - 0s - loss: 0.0413 - acc: 0.9838 - val_loss: 0.6744 - val_acc: 0.8556\n",
      "Epoch 278/300\n",
      "801/801 [==============================] - 0s - loss: 0.0775 - acc: 0.9663 - val_loss: 0.6714 - val_acc: 0.8444\n",
      "Epoch 279/300\n",
      "801/801 [==============================] - 0s - loss: 0.0613 - acc: 0.9775 - val_loss: 0.6878 - val_acc: 0.8333\n",
      "Epoch 280/300\n",
      "801/801 [==============================] - 0s - loss: 0.0645 - acc: 0.9788 - val_loss: 0.6744 - val_acc: 0.8333\n",
      "Epoch 281/300\n",
      "801/801 [==============================] - 0s - loss: 0.0506 - acc: 0.9850 - val_loss: 0.6950 - val_acc: 0.8444\n",
      "Epoch 282/300\n",
      "801/801 [==============================] - 0s - loss: 0.0621 - acc: 0.9738 - val_loss: 0.6811 - val_acc: 0.8333\n",
      "Epoch 283/300\n",
      "801/801 [==============================] - 0s - loss: 0.0463 - acc: 0.9863 - val_loss: 0.6865 - val_acc: 0.8444\n",
      "Epoch 284/300\n",
      "801/801 [==============================] - 0s - loss: 0.0672 - acc: 0.9763 - val_loss: 0.7110 - val_acc: 0.8222\n",
      "Epoch 285/300\n",
      "801/801 [==============================] - 0s - loss: 0.0574 - acc: 0.9813 - val_loss: 0.6810 - val_acc: 0.8444\n",
      "Epoch 286/300\n",
      "801/801 [==============================] - 0s - loss: 0.0620 - acc: 0.9850 - val_loss: 0.6903 - val_acc: 0.8444\n",
      "Epoch 287/300\n",
      "801/801 [==============================] - 0s - loss: 0.0619 - acc: 0.9788 - val_loss: 0.6957 - val_acc: 0.8444\n",
      "Epoch 288/300\n",
      "801/801 [==============================] - 0s - loss: 0.0519 - acc: 0.9813 - val_loss: 0.7142 - val_acc: 0.8333\n",
      "Epoch 289/300\n",
      "801/801 [==============================] - 0s - loss: 0.0528 - acc: 0.9838 - val_loss: 0.7160 - val_acc: 0.8333\n",
      "Epoch 290/300\n",
      "801/801 [==============================] - 0s - loss: 0.0397 - acc: 0.9888 - val_loss: 0.7257 - val_acc: 0.8333\n",
      "Epoch 291/300\n",
      "801/801 [==============================] - 0s - loss: 0.0489 - acc: 0.9813 - val_loss: 0.7109 - val_acc: 0.8333\n",
      "Epoch 292/300\n",
      "801/801 [==============================] - 0s - loss: 0.0553 - acc: 0.9825 - val_loss: 0.7118 - val_acc: 0.8333\n",
      "Epoch 293/300\n",
      "801/801 [==============================] - 0s - loss: 0.0499 - acc: 0.9775 - val_loss: 0.7081 - val_acc: 0.8222\n",
      "Epoch 294/300\n",
      "801/801 [==============================] - 0s - loss: 0.0440 - acc: 0.9863 - val_loss: 0.7079 - val_acc: 0.8444\n",
      "Epoch 295/300\n",
      "801/801 [==============================] - 0s - loss: 0.0469 - acc: 0.9825 - val_loss: 0.7275 - val_acc: 0.8333\n",
      "Epoch 296/300\n",
      "801/801 [==============================] - 0s - loss: 0.0606 - acc: 0.9825 - val_loss: 0.7356 - val_acc: 0.8333\n",
      "Epoch 297/300\n",
      "801/801 [==============================] - 0s - loss: 0.0474 - acc: 0.9800 - val_loss: 0.7235 - val_acc: 0.8444\n",
      "Epoch 298/300\n",
      "801/801 [==============================] - 0s - loss: 0.0562 - acc: 0.9863 - val_loss: 0.7793 - val_acc: 0.8111\n",
      "Epoch 299/300\n",
      "801/801 [==============================] - 0s - loss: 0.0609 - acc: 0.9750 - val_loss: 0.7028 - val_acc: 0.8444\n",
      "Epoch 300/300\n",
      "801/801 [==============================] - 0s - loss: 0.0448 - acc: 0.9838 - val_loss: 0.7113 - val_acc: 0.8556\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# layers\n",
    "model.add(Dense(units = 1024, activation = 'sigmoid', input_dim = 1544))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1024, activation = 'sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 128, activation = 'sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = Adam(lr=1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "x_val = x_val.as_matrix()\n",
    "y_val = y_val.as_matrix()\n",
    "\n",
    "hist = model.fit(x_train.as_matrix(), y_train.as_matrix(), \n",
    "                 batch_size = 32, \n",
    "                 verbose=1,\n",
    "                 epochs = 300,\n",
    "                 validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/90 [=========>....................] - ETA: 0sFinal loss: 0.7113, final accuracy: 0.8556\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val, y_val, verbose=1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x318d638320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMVdURQlClFxVxRFiUL+H2clnyprxu02AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x31b5688e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Export pred.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cols = data_train.columns\n",
    "for col in data_test0.columns:\n",
    "    if col not in train_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic_StatML_NN_20171030_222926_8555\n",
      "E:\\Kaggle\\Titanic_Machine_Learning_From_Disaster\\output\\Titanic_StatML_NN_20171030_222926_8555.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "project_name = 'Titanic'\n",
    "step_name = 'StatML_NN'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "final_acc_str = str(int(final_acc*10000))\n",
    "run_name = project_name + '_' + step_name + '_' + time_str + '_' + final_acc_str\n",
    "print(run_name)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "output_path = os.path.join(cwd, 'output')\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "pred_file = os.path.join(output_path, run_name + '.csv')\n",
    "print(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_de</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  a_IsAlone  \\\n",
       "0         3             16      1   34.5           1             1          1   \n",
       "1         3             32      0   47.0           1             2          0   \n",
       "\n",
       "   a_Have_Ticket  a_Fare  a_Have_Fare       ...        a_Name_de  a_Name_del  \\\n",
       "0              1  7.8292            1       ...                0           0   \n",
       "1              1  7.0000            1       ...                0           0   \n",
       "\n",
       "   a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  a_Name_y  \\\n",
       "0           0            0          0           0           0         0   \n",
       "1           0            0          0           0           0         0   \n",
       "\n",
       "   a_Cabin_Word  a_Cabin_Number  \n",
       "0            -1              -1  \n",
       "1            -1              -1  \n",
       "\n",
       "[2 rows x 1544 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n",
      "(418,)\n",
      "[0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0\n",
      " 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "display(data_test0.head(2))\n",
    "y_data_pred = model.predict(data_test0.as_matrix())\n",
    "print(y_data_pred.shape)\n",
    "y_data_pred = np.squeeze(y_data_pred)\n",
    "print(y_data_pred.shape)\n",
    "y_data_pred = (y_data_pred > 0.5).astype(int)\n",
    "print(y_data_pred)\n",
    "\n",
    "print(data_test['PassengerId'].shape)\n",
    "passenger_id = data_test['PassengerId']\n",
    "output = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': y_data_pred })\n",
    "\n",
    "output.to_csv(pred_file , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(data_test0.head(2))\n",
    "# y_data_pred = clfs['RandomForestClassifier'].predict(data_test0.as_matrix())\n",
    "# print(y_data_pred.shape)\n",
    "# y_data_pred = np.squeeze(y_data_pred)\n",
    "# print(y_data_pred.shape)\n",
    "# print(data_test['PassengerId'].shape)\n",
    "# passenger_id = data_test['PassengerId']\n",
    "# output = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': y_data_pred })\n",
    "\n",
    "# output.to_csv(pred_file , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic_StatML_NN_20171030_222926_8555\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(run_name)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
