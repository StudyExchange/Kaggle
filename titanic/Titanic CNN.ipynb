{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic CNN\n",
    "\n",
    "## 概要：\n",
    "- 将主要的13维数据移动到40*40图片的中央区域。避免在最数组开头，变成图片之后在边缘，卷积的时候，特征提取不充分。\n",
    "- 运行时间比较长的训练，还是应该弄个TensorBoard，方便监控结果，免得每次都需要用鼠标手动托页面查看最新的运行结果。\n",
    "- 数据用StandardScaler归一化，避免卷积的时候，有些值特别大，覆盖了其他值。\n",
    "\n",
    "Reference: \n",
    "1. https://www.kaggle.com/c/titanic#tutorials\n",
    "2. https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n",
    "3. https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "date_str = time.strftime(\"%Y%m%d\", time.localtime())\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "\n",
    "model_path = os.path.join(cwd, 'model')\n",
    "log_path = os.path.join(cwd, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import original data as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STON/O2. 3101282'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('./input/train.csv')\n",
    "data_test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "display(data_train.head(2))\n",
    "display(data_test.head(2))\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "\n",
    "data_train.loc[2, 'Ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show columns of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_train_original_col = data_train.columns\n",
    "data_test_original_col = data_test.columns\n",
    "print(data_train_original_col)\n",
    "print(data_test_original_col)\n",
    "# data_train0 = data_train.drop(data_train_original_col, axis = 1)\n",
    "# data_test0  = data_test.drop(data_test_original_col, axis = 1)\n",
    "# display(data_train0.head(2))\n",
    "# display(data_test0.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get survived\n",
    "survived = data_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop survived to align columns of data_train and data_test\n",
    "data_train = data_train.drop('Survived', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 11)\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset = data_train.append(data_test)\n",
    "print(dataset.shape)\n",
    "dataset_original_columns = dataset.columns\n",
    "print(dataset_original_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not have null value!\n"
     ]
    }
   ],
   "source": [
    "# Pclass\n",
    "temp = dataset[dataset['Pclass'].isnull()]\n",
    "if len(temp) == 0:\n",
    "    print('Do not have null value!')\n",
    "else:\n",
    "    temp.head(2)\n",
    "        \n",
    "dataset['a_Pclass'] = dataset['Pclass']\n",
    "# display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name\n",
    "dataset['a_Name_Length'] = dataset['Name'].apply(len)\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "dataset['a_Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "dataset['a_Age'] = dataset['Age'].fillna(-1)\n",
    "dataset['a_Have_Age'] = dataset['Age'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "# display(dataset[dataset['Age'].isnull()].head(2))\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SibSp and Parch\n",
    "dataset['a_FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "dataset['a_IsAlone'] = dataset['a_FamilySize'].apply(lambda x: 1 if x<=1 else 0)\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ticket(Very one have a ticket)\n",
    "dataset['a_Have_Ticket'] = dataset['Ticket'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "# display(dataset[dataset['Ticket'].isnull()].head(2))\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fare\n",
    "dataset['a_Fare'] = dataset['Fare'].fillna(-1)\n",
    "dataset['a_Have_Fare'] = dataset['Fare'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "# display(dataset[dataset['Fare'].isnull()].head(2))\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cabin\n",
    "dataset['a_Have_Cabin'] = dataset['Cabin'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "# display(dataset[dataset['Cabin'].isnull()].head(2))\n",
    "# display(dataset.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embarked\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('N')\n",
    "dataset['a_Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2, None: 3} ).astype(int)\n",
    "dataset['a_Have_Embarked'] = dataset['Embarked'].isnull().map({True: 0, False: 1}).astype(int)\n",
    "#     display(dataset[dataset['Embarked'].isnull()].head(2))\n",
    "# display(dataset.head(2))\n",
    "# print(len(dataset.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name words segmentation and one-hote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name words segmentation\n",
    "import re\n",
    "name_words = []\n",
    "\n",
    "# Inorder to allign columns of data_train and data_test, only data_train to fetch word\n",
    "for name in dataset['Name']:\n",
    "#     print(name)\n",
    "    words = re.findall(r\"[\\w']+\", name)\n",
    "#     print(len(words))\n",
    "#     print(words)\n",
    "    for w in words:\n",
    "        if w not in name_words:\n",
    "            name_words.append(w)\n",
    "# print(len(name_words))\n",
    "name_words.sort()\n",
    "# print(name_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_Zimmerman</th>\n",
       "      <th>a_Name_de</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_von</th>\n",
       "      <th>a_Name_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1976 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                     Name   Sex   Age  SibSp  Parch  \\\n",
       "0            1       3  Braund, Mr. Owen Harris  male  22.0      1      0   \n",
       "\n",
       "      Ticket  Fare Cabin    ...    a_Name_Zimmerman  a_Name_de  a_Name_del  \\\n",
       "0  A/5 21171  7.25   NaN    ...                   0          0           0   \n",
       "\n",
       "   a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  a_Name_von  \\\n",
       "0           0            0          0           0           0           0   \n",
       "\n",
       "   a_Name_y  \n",
       "0         0  \n",
       "\n",
       "[1 rows x 1976 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add columns\n",
    "for w in name_words:\n",
    "    col_name = 'a_Name_' + w\n",
    "    dataset[col_name] = 0\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name words one-hote\n",
    "for i, row in dataset.iterrows():\n",
    "#     print(row['Name'])\n",
    "    words = re.findall(r\"[\\w']+\", row['Name'])\n",
    "    for w in words:\n",
    "        if w in name_words:\n",
    "            col_name = 'a_Name_' + w\n",
    "            dataset.loc[i, col_name] = 1\n",
    "#     display(dataset[dataset['a_Name_Braund'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin segmentation and one-hote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T']\n"
     ]
    }
   ],
   "source": [
    "# Get cabin segmentation words\n",
    "import re\n",
    "cabin_words = []\n",
    "\n",
    "# Inorder to allign columns of data_train and data_test, only data_train to fetch number\n",
    "for c in dataset['Cabin']:\n",
    "#     print(c)\n",
    "    if c is not np.nan:\n",
    "        word = re.findall(r\"[a-zA-Z]\", c)\n",
    "#         print(words[0])\n",
    "        cabin_words.append(word[0])\n",
    "print(len(cabin_words))\n",
    "cabin_words.sort()\n",
    "print(np.unique(cabin_words))\n",
    "cabin_words_unique = list(np.unique(cabin_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cabin_word(cabin):\n",
    "    if cabin is not np.nan:\n",
    "        word = re.findall(r\"[a-zA-Z]\", cabin)\n",
    "        if word:\n",
    "            return cabin_words_unique.index(word[0])\n",
    "    return -1\n",
    "\n",
    "dataset['a_Cabin_Word'] = dataset['Cabin'].apply(get_cabin_word)\n",
    "# dataset['a_Cabin_Word'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 1978)\n"
     ]
    }
   ],
   "source": [
    "def get_cabin_number(cabin):\n",
    "    if cabin is not np.nan:\n",
    "        word = re.findall(r\"[0-9]+\", cabin)\n",
    "        if word:\n",
    "            return int(word[0])\n",
    "    return -1\n",
    "\n",
    "\n",
    "dataset['a_Cabin_Number'] = dataset['Cabin'].apply(get_cabin_number)\n",
    "print(dataset.shape)\n",
    "# dataset['a_Cabin_Number'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "# Reference: \n",
    "#    1. https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n",
    "#    2. https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook\n",
    "# full_data = [data_train, data_test]\n",
    "# for dataset in full_data:\n",
    "#     dataset['a_Name_length'] = dataset['Name'].apply(len)\n",
    "#     #dataset['Sex'] = (dataset['Sex']=='male').astype(int)\n",
    "#     dataset['a_Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "#     dataset['a_Age'] = dataset['Age'].fillna(0)\n",
    "#     dataset['a_Age_IsNull'] = dataset['Age'].isnull()\n",
    "#     dataset['a_FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "#     dataset['a_IsAlone'] = dataset['a_FamilySize'].apply(lambda x: 1 if x<=1 else 0)\n",
    "#     dataset['a_Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "#     #dataset['Has_Cabin'] = dataset['Cabin'].apply(lambda x: 1 if type(x) == str else 0) # same as below\n",
    "#     dataset['a_Has_Cabin'] = dataset['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "#     dataset['a_Has_Embarked'] = dataset['Embarked'].isnull()\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('N')\n",
    "#     dataset['a_Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2, 'N': 3} ).astype(int)\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    \n",
    "# display(data_train.head(2))\n",
    "# display(data_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "(1309, 1978)\n",
      "(1309, 1967)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_von</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 1967 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  \\\n",
       "0          3             23      1   22.0           1             2   \n",
       "1          1             51      0   38.0           1             2   \n",
       "2          3             22      0   26.0           1             1   \n",
       "3          1             44      0   35.0           1             2   \n",
       "4          3             24      1   35.0           1             1   \n",
       "5          3             16      1   -1.0           0             1   \n",
       "6          1             23      1   54.0           1             1   \n",
       "7          3             30      1    2.0           1             5   \n",
       "8          3             49      0   27.0           1             3   \n",
       "9          2             35      0   14.0           1             2   \n",
       "10         3             31      0    4.0           1             3   \n",
       "11         1             24      0   58.0           1             1   \n",
       "12         3             30      1   20.0           1             1   \n",
       "13         3             27      1   39.0           1             7   \n",
       "14         3             36      0   14.0           1             1   \n",
       "\n",
       "    a_IsAlone  a_Have_Ticket   a_Fare  a_Have_Fare       ...        \\\n",
       "0           0              1   7.2500            1       ...         \n",
       "1           0              1  71.2833            1       ...         \n",
       "2           1              1   7.9250            1       ...         \n",
       "3           0              1  53.1000            1       ...         \n",
       "4           1              1   8.0500            1       ...         \n",
       "5           1              1   8.4583            1       ...         \n",
       "6           1              1  51.8625            1       ...         \n",
       "7           0              1  21.0750            1       ...         \n",
       "8           0              1  11.1333            1       ...         \n",
       "9           0              1  30.0708            1       ...         \n",
       "10          0              1  16.7000            1       ...         \n",
       "11          1              1  26.5500            1       ...         \n",
       "12          1              1   8.0500            1       ...         \n",
       "13          0              1  31.2750            1       ...         \n",
       "14          1              1   7.8542            1       ...         \n",
       "\n",
       "    a_Name_del  a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  \\\n",
       "0            0           0            0          0           0           0   \n",
       "1            0           0            0          0           0           0   \n",
       "2            0           0            0          0           0           0   \n",
       "3            0           0            0          0           0           0   \n",
       "4            0           0            0          0           0           0   \n",
       "5            0           0            0          0           0           0   \n",
       "6            0           0            0          0           0           0   \n",
       "7            0           0            0          0           0           0   \n",
       "8            0           0            0          0           0           0   \n",
       "9            0           0            0          0           0           0   \n",
       "10           0           0            0          0           0           0   \n",
       "11           0           0            0          0           0           0   \n",
       "12           0           0            0          0           0           0   \n",
       "13           0           0            0          0           0           0   \n",
       "14           0           0            0          0           0           0   \n",
       "\n",
       "    a_Name_von  a_Name_y  a_Cabin_Word  a_Cabin_Number  \n",
       "0            0         0            -1              -1  \n",
       "1            0         0             2              85  \n",
       "2            0         0            -1              -1  \n",
       "3            0         0             2             123  \n",
       "4            0         0            -1              -1  \n",
       "5            0         0            -1              -1  \n",
       "6            0         0             4              46  \n",
       "7            0         0            -1              -1  \n",
       "8            0         0            -1              -1  \n",
       "9            0         0            -1              -1  \n",
       "10           0         0             6               6  \n",
       "11           0         0             2             103  \n",
       "12           0         0            -1              -1  \n",
       "13           0         0            -1              -1  \n",
       "14           0         0            -1              -1  \n",
       "\n",
       "[15 rows x 1967 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop old columns\n",
    "print(dataset_original_columns)\n",
    "print(dataset.shape)\n",
    "full_data  = dataset.drop(dataset_original_columns, axis = 1)\n",
    "print(full_data.shape)\n",
    "display(full_data.iloc[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "[[ 0.      0.0625  0.5   ]\n",
      " [ 0.      0.      0.5   ]\n",
      " [ 1.      0.6875  0.    ]\n",
      " [ 1.      1.      1.    ]]\n",
      "****************************************\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[ 0.5  6.   0. ]\n",
      "[[-1.         -0.88949918  0.        ]\n",
      " [-1.         -1.03774904  0.        ]\n",
      " [ 1.          0.59299945 -1.41421356]\n",
      " [ 1.          1.33424877  1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "data = [[0, 0, 0], \n",
    "        [0, -1, 0], \n",
    "        [1, 10, -10], \n",
    "        [1, 15, 10]]\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(data))\n",
    "print(scaler.transform(data))\n",
    "print('*'*40)\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(data))\n",
    "print(scaler.mean_)\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84191642 -0.43467223  0.74349692 -0.09387797  0.50143198]\n",
      " [-1.54609786  2.51180578 -1.34499549  0.80201077  0.50143198]\n",
      " [ 0.84191642 -0.53990359 -1.34499549  0.13009422  0.50143198]\n",
      " [-1.54609786  1.77518628 -1.34499549  0.63403164  0.50143198]\n",
      " [ 0.84191642 -0.32944087  0.74349692  0.63403164  0.50143198]\n",
      " [ 0.84191642 -1.17129173  0.74349692 -1.38171803 -1.99428842]\n",
      " [-1.54609786 -0.43467223  0.74349692  1.69789952  0.50143198]\n",
      " [ 0.84191642  0.30194727  0.74349692 -1.21373889  0.50143198]\n",
      " [ 0.84191642  2.30134307 -1.34499549  0.18608726  0.50143198]\n",
      " [-0.35209072  0.82810406 -1.34499549 -0.54182234  0.50143198]\n",
      " [ 0.84191642  0.40717863 -1.34499549 -1.1017528   0.50143198]\n",
      " [-1.54609786 -0.32944087 -1.34499549  1.9218717   0.50143198]\n",
      " [ 0.84191642  0.30194727  0.74349692 -0.20586406  0.50143198]\n",
      " [ 0.84191642 -0.0137468   0.74349692  0.85800382  0.50143198]\n",
      " [ 0.84191642  0.93333542 -1.34499549 -0.54182234  0.50143198]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "scaler.fit(full_data)\n",
    "full_data0 = scaler.transform(full_data)\n",
    "print(full_data0[0:15, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1967)\n",
      "(418, 1967)\n"
     ]
    }
   ],
   "source": [
    "features = full_data.iloc[0:891]\n",
    "data_test0 = full_data.iloc[891:]\n",
    "print(features.shape)\n",
    "print(data_test0.shape)\n",
    "# display(features.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and confirm all columns is proccessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in features.columns:\n",
    "    if not col.startswith('a_'):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle and split the train_data into train, crossvalidation and testing subsets\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, survived, test_size=0.2, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 1967)\n",
      "(179, 1967)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_Pclass</th>\n",
       "      <th>a_Name_Length</th>\n",
       "      <th>a_Sex</th>\n",
       "      <th>a_Age</th>\n",
       "      <th>a_Have_Age</th>\n",
       "      <th>a_FamilySize</th>\n",
       "      <th>a_IsAlone</th>\n",
       "      <th>a_Have_Ticket</th>\n",
       "      <th>a_Fare</th>\n",
       "      <th>a_Have_Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>a_Name_del</th>\n",
       "      <th>a_Name_der</th>\n",
       "      <th>a_Name_hoef</th>\n",
       "      <th>a_Name_of</th>\n",
       "      <th>a_Name_the</th>\n",
       "      <th>a_Name_van</th>\n",
       "      <th>a_Name_von</th>\n",
       "      <th>a_Name_y</th>\n",
       "      <th>a_Cabin_Word</th>\n",
       "      <th>a_Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1967 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a_Pclass  a_Name_Length  a_Sex  a_Age  a_Have_Age  a_FamilySize  \\\n",
       "304         3             33      1   -1.0           0             1   \n",
       "149         2             33      1   42.0           1             1   \n",
       "\n",
       "     a_IsAlone  a_Have_Ticket  a_Fare  a_Have_Fare       ...        \\\n",
       "304          1              1    8.05            1       ...         \n",
       "149          1              1   13.00            1       ...         \n",
       "\n",
       "     a_Name_del  a_Name_der  a_Name_hoef  a_Name_of  a_Name_the  a_Name_van  \\\n",
       "304           0           0            0          0           0           0   \n",
       "149           0           0            0          0           0           0   \n",
       "\n",
       "     a_Name_von  a_Name_y  a_Cabin_Word  a_Cabin_Number  \n",
       "304           0         0            -1              -1  \n",
       "149           0         0            -1              -1  \n",
       "\n",
       "[2 rows x 1967 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "304    0\n",
       "149    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show distribute of abave data sets\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "display(x_train.head(2))\n",
    "display(y_train.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fullfil matrix to 16000 and Reshape matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape:  (45, 45)\n",
      "Extend_widgth:  58\n",
      "Before extend:\n",
      "(712, 1967)\n",
      "(179, 1967)\n",
      "(418, 1967)\n",
      "After extend:\n",
      "(712, 2025)\n",
      "(179, 2025)\n",
      "(418, 2025)\n",
      "After reshape:\n",
      "(712, 45, 45, 1)\n",
      "(179, 45, 45, 1)\n",
      "(418, 45, 45, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train0 = x_train.as_matrix()\n",
    "y_train0 = y_train.as_matrix()\n",
    "x_val0 = x_val.as_matrix()\n",
    "y_val0 = y_val.as_matrix()\n",
    "x_test0 = data_test0.as_matrix()\n",
    "\n",
    "target_shape = (45, 45)\n",
    "extend_widgth = target_shape[0]*target_shape[1] - x_train0.shape[1]\n",
    "print('Target shape: ', target_shape)\n",
    "print('Extend_widgth: ', extend_widgth)\n",
    "print('Before extend:')\n",
    "print(x_train0.shape)\n",
    "print(x_val0.shape)\n",
    "print(x_test0.shape)\n",
    "\n",
    "x_train_ext = np.zeros((x_train0.shape[0], extend_widgth))\n",
    "x_val_ext = np.zeros((x_val0.shape[0], extend_widgth))\n",
    "x_test_ext = np.zeros((x_test0.shape[0], extend_widgth))\n",
    "\n",
    "x_train0 = np.column_stack((x_train0, x_train_ext))\n",
    "x_val0 = np.column_stack((x_val0, x_val_ext))\n",
    "x_test0 = np.column_stack((x_test0, x_test_ext))\n",
    "\n",
    "print('After extend:')\n",
    "print(x_train0.shape)\n",
    "print(x_val0.shape)\n",
    "print(x_test0.shape)\n",
    "\n",
    "x_train0 = x_train0.reshape(-1, target_shape[0], target_shape[1], 1)\n",
    "x_val0 = x_val0.reshape(-1, target_shape[0], target_shape[1], 1)\n",
    "x_test0 = x_test0.reshape(-1, target_shape[0], target_shape[1], 1)\n",
    "\n",
    "print('After reshape:')\n",
    "print(x_train0.shape)\n",
    "print(x_val0.shape)\n",
    "print(x_test0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir:D:\\Kaggle\\Titanic_Machine_Learning_From_Disaster\\log\\20171027_213519\n"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-4 * 0.9 ** x)\n",
    "\n",
    "log_dir = os.path.join(log_path, time_str)\n",
    "print('log_dir:' + log_dir)\n",
    "tensorBoard = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/20\n",
      "712/712 [==============================] - 46s - loss: 0.9907 - acc: 0.5744 - val_loss: 0.6536 - val_acc: 0.7039\n",
      "Epoch 2/20\n",
      "712/712 [==============================] - 42s - loss: 0.8701 - acc: 0.5829 - val_loss: 0.6778 - val_acc: 0.7039\n",
      "Epoch 3/20\n",
      "200/712 [=======>......................] - ETA: 29s - loss: 0.9191 - acc: 0.5400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9d6c53e3bb33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m                  \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                  callbacks=[annealer, tensorBoard])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Block 1\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding = 'Same',\n",
    "                 input_shape = (45, 45, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 2\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 3\n",
    "# model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 4\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "# Block 5\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding = 'Same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(strides=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# Output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train0, y_train0, \n",
    "                 batch_size = 8, \n",
    "                 verbose=1,\n",
    "                 epochs = 20,\n",
    "                 validation_data=(x_val0, y_val0), \n",
    "                 callbacks=[annealer, tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val0, y_val0, verbose=1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Export pred.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cols = data_train.columns\n",
    "for col in data_test0.columns:\n",
    "    if col not in train_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "project_name = 'Titanic'\n",
    "step_name = 'Predict'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "final_acc_str = str(int(final_acc*10000))\n",
    "run_name = project_name + '_' + step_name + '_' + time_str + '_' + final_acc_str\n",
    "print(run_name)\n",
    "cwd = os.getcwd()\n",
    "pred_file = os.path.join(cwd, 'output', run_name + '.csv')\n",
    "print(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(data_test0.head(2))\n",
    "y_data_pred = model.predict(x_test0)\n",
    "print(y_data_pred.shape)\n",
    "y_data_pred = np.squeeze(y_data_pred)\n",
    "print(y_data_pred.shape)\n",
    "y_data_pred = (y_data_pred > 0.5).astype(int)\n",
    "print(y_data_pred)\n",
    "\n",
    "print(data_test['PassengerId'].shape)\n",
    "passenger_id = data_test['PassengerId']\n",
    "output = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': y_data_pred })\n",
    "\n",
    "output.to_csv(pred_file , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(data_test0.head(2))\n",
    "# y_data_pred = clfs['RandomForestClassifier'].predict(data_test0.as_matrix())\n",
    "# print(y_data_pred.shape)\n",
    "# y_data_pred = np.squeeze(y_data_pred)\n",
    "# print(y_data_pred.shape)\n",
    "# print(data_test['PassengerId'].shape)\n",
    "# passenger_id = data_test['PassengerId']\n",
    "# output = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': y_data_pred })\n",
    "\n",
    "# output.to_csv(pred_file , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(run_name)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
