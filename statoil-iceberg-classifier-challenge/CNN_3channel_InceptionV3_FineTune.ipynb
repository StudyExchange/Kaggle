{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_3channel_InceptionV3_FineTune\n",
    "\n",
    "Abstract:\n",
    "- single channel: band_avg\n",
    "- CNN, small net\n",
    "\n",
    "Result:\n",
    "- 增大网络的各个参数，只是把train数据的拟合程度增加了（到了99%），而cv数据的泛化能力仍然只有87%，说明，特征还需要进一步的提取来增加系统的泛化能力。\n",
    "\n",
    "References:\n",
    "- https://www.kaggle.com/ivalmian/simple-svd-xgboost-baseline-lb-35\n",
    "- https://www.kaggle.com/arieltci/a-keras-prototype-0-21174-on-pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import lzma\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from shutil import copy2\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: SC_Iceberg_Classifier_CNN_3channel_InceptionV3_FineTune_20180111_141811\n"
     ]
    }
   ],
   "source": [
    "project_name = 'SC_Iceberg_Classifier'\n",
    "step_name = 'CNN_3channel_InceptionV3_FineTune'\n",
    "date_str = time.strftime(\"%Y%m%d\", time.localtime())\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path: /data1/Kaggle/statoil-iceberg-classifier-challenge/input\n",
      "log_path: /data1/Kaggle/statoil-iceberg-classifier-challenge/log\n",
      "model_path: /data1/Kaggle/statoil-iceberg-classifier-challenge/model\n",
      "output_path: /data1/Kaggle/statoil-iceberg-classifier-challenge/output\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_path = os.path.join(cwd, 'input')\n",
    "log_path = os.path.join(cwd, 'log')\n",
    "model_path = os.path.join(cwd, 'model')\n",
    "output_path = os.path.join(cwd, 'output')\n",
    "print('input_path: ' + input_path)\n",
    "print('log_path: ' + log_path)\n",
    "print('model_path: ' + model_path)\n",
    "print('output_path: ' + output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with lzma.open(\"train.json.7z\") as f:\n",
    "#     file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip(input_path, os.path.join(input_path, 'sample_submission.csv.7z'))\n",
    "# Unzip(input_path, os.path.join(input_path, 'test.json.7z'))\n",
    "# Unzip(input_path, os.path.join(input_path, 'train.json.7z'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def describe(arr):\n",
    "    print(arr.shape, arr.min(), arr.max(), sys.getsizeof(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8424, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  5941774d         0.5\n",
       "1  4023181e         0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission_path = os.path.join(input_path, 'sample_submission.csv')\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "print(sample_submission.shape)\n",
    "sample_submission.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604,) 0 1 25688\n"
     ]
    }
   ],
   "source": [
    "is_iceberg_path = os.path.join(input_path, 'is_iceberg.p')\n",
    "y_data = pickle.load(open(is_iceberg_path, mode='rb'))\n",
    "describe(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604,) 0.0 45.9375 25688\n",
      "(8424,) 23.0805 50.66178518000562 134808\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Load orignal data\n",
    "inc_angle_data_path = os.path.join(input_path, 'inc_angle_data.p')\n",
    "inc_angle_test_path = os.path.join(input_path, 'inc_angle_test.p')\n",
    "\n",
    "inc_angle_data = pickle.load(open(inc_angle_data_path, mode='rb'))\n",
    "inc_angle_test = pickle.load(open(inc_angle_test_path, mode='rb'))\n",
    "\n",
    "describe(inc_angle_data)\n",
    "describe(inc_angle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/Kaggle/statoil-iceberg-classifier-challenge/input/band1_data_gray150.p\n",
      "(1604, 150, 150) 0.0045049769842293854 0.9985847482054284 128\n",
      "(1604, 150, 150) 0.00917876748469312 0.9994694902705856 128\n",
      "(8424, 150, 150) 0.0 1.0 128\n",
      "(8424, 150, 150) 0.0 1.0 128\n",
      "CPU times: user 1.61 s, sys: 3.74 s, total: 5.35 s\n",
      "Wall time: 5.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Load orignal data\n",
    "target_size = 150\n",
    "band1_data_path = os.path.join(input_path, 'band1_data_gray%s.p' % target_size)\n",
    "band2_data_path = os.path.join(input_path, 'band2_data_gray%s.p' % target_size)\n",
    "band1_test_path = os.path.join(input_path, 'band1_test_gray%s.p' % target_size)\n",
    "band2_test_path = os.path.join(input_path, 'band2_test_gray%s.p' % target_size)\n",
    "print(band1_data_path)\n",
    "band1_data = pickle.load(open(band1_data_path, mode='rb'))\n",
    "band2_data = pickle.load(open(band2_data_path, mode='rb'))\n",
    "band1_test = pickle.load(open(band1_test_path, mode='rb'))\n",
    "band2_test = pickle.load(open(band2_test_path, mode='rb'))\n",
    "\n",
    "describe(band1_data)\n",
    "describe(band2_data)\n",
    "describe(band1_test)\n",
    "describe(band2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 150, 150) 6.708432698232514e-10 0.8410463008526331 288720128\n",
      "(8424, 150, 150) 0.0 0.8432859534298787 1516320128\n",
      "(1604, 150, 150) 0.0045049769842293854 0.9964643293502019 288720128\n",
      "(8424, 150, 150) 0.0 1.0 1516320128\n",
      "(1604, 150, 150) 0.06541670375958838 0.9994694902705856 288720128\n",
      "(8424, 150, 150) 0.012590287516197897 1.0 1516320128\n",
      "CPU times: user 3.43 s, sys: 2.8 s, total: 6.23 s\n",
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Load orignal data\n",
    "band_sub_data = np.fabs(np.subtract(band1_data, band2_data))\n",
    "band_sub_test = np.fabs(np.subtract(band1_test, band2_test))\n",
    "band_min_data = np.minimum(band1_data, band2_data)\n",
    "band_min_test = np.minimum(band1_test, band2_test)\n",
    "band_max_data = np.maximum(band1_data, band2_data)\n",
    "band_max_test = np.maximum(band1_test, band2_test)\n",
    "\n",
    "describe(band_sub_data)\n",
    "describe(band_sub_test)\n",
    "describe(band_min_data)\n",
    "describe(band_min_test)\n",
    "describe(band_max_data)\n",
    "describe(band_max_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 150, 150) 6.708432698232514e-10 0.8410463008526331 288720128\n",
      "(8424, 150, 150) 0.0 0.8432859534298787 1516320128\n",
      "(1604, 150, 150) 0.0045049769842293854 0.9964643293502019 288720128\n",
      "(8424, 150, 150) 0.0 1.0 1516320128\n",
      "(1604, 150, 150) 0.06541670375958838 0.9994694902705856 288720128\n",
      "(8424, 150, 150) 0.012590287516197897 1.0 1516320128\n",
      "CPU times: user 3.39 s, sys: 2.94 s, total: 6.34 s\n",
      "Wall time: 6.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Load orignal data\n",
    "band_sub_data = np.fabs(np.subtract(band1_data, band2_data))\n",
    "band_sub_test = np.fabs(np.subtract(band1_test, band2_test))\n",
    "band_min_data = np.minimum(band1_data, band2_data)\n",
    "band_min_test = np.minimum(band1_test, band2_test)\n",
    "band_max_data = np.maximum(band1_data, band2_data)\n",
    "band_max_test = np.maximum(band1_test, band2_test)\n",
    "\n",
    "describe(band_sub_data)\n",
    "describe(band_sub_test)\n",
    "describe(band_min_data)\n",
    "describe(band_min_test)\n",
    "describe(band_max_data)\n",
    "describe(band_max_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 150, 150, 3) 0.0045049769842293854 0.9994694902705856 866160144\n",
      "(8424, 150, 150, 3) 0.0 1.0 4548960144\n",
      "CPU times: user 3.28 s, sys: 2.02 s, total: 5.3 s\n",
      "Wall time: 5.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_data = np.concatenate([band1_data[:, :, :, np.newaxis],\n",
    "                         band2_data[:, :, :, np.newaxis],\n",
    "                         band_max_data[:, :, :, np.newaxis]], axis=-1)\n",
    "describe(x_data)\n",
    "# del band1_data\n",
    "# del band2_data\n",
    "# del band_avg_data\n",
    "gc.collect()\n",
    "\n",
    "x_test = np.concatenate([band1_test[:, :, :, np.newaxis],\n",
    "                         band2_test[:, :, :, np.newaxis],\n",
    "                         band_max_test[:, :, :, np.newaxis]], axis=-1)\n",
    "describe(x_test)\n",
    "# del band1_test\n",
    "# del band2_test\n",
    "# del band_avg_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 150, 150, 3) 0.0045049769842293854 0.9994694902705856 779220144\n",
      "(161, 150, 150, 3) 0.009640460801675846 0.997560227352376 86940144\n",
      "(1443,) 0.0 45.9375 23112\n",
      "(161,) 0.0 45.2814 2600\n",
      "(1443,) 0 1 23112\n",
      "(161,) 0 1 2600\n",
      "CPU times: user 308 ms, sys: 324 ms, total: 632 ms\n",
      "Wall time: 624 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train, x_val, inc_angle_train, inc_angle_val, y_train, y_val = train_test_split(x_data, inc_angle_data, y_data, test_size=0.1, random_state=31)\n",
    "describe(x_train)\n",
    "describe(x_val)\n",
    "describe(inc_angle_train)\n",
    "describe(inc_angle_val)\n",
    "describe(y_train)\n",
    "describe(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in model.layers[:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "#     for layer in model.layers[:249]:\n",
    "#        layer.trainable = False\n",
    "#     for layer in model.layers[249:]:\n",
    "#        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            513         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,852,385\n",
      "Trainable params: 22,817,953\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, run_name):\n",
    "    cwd = os.getcwd()\n",
    "    modelPath = os.path.join(cwd, 'model')\n",
    "    if not os.path.isdir(modelPath):\n",
    "        os.mkdir(modelPath)\n",
    "    weigthsFile = os.path.join(modelPath, run_name + '.h5')\n",
    "    model.save(weigthsFile)\n",
    "# saveModel(model, 'saveModel_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir:/data1/Kaggle/statoil-iceberg-classifier-challenge/log/SC_Iceberg_Classifier_CNN_3channel_InceptionV3_FineTune_20180111_141811\n"
     ]
    }
   ],
   "source": [
    "def get_lr(x):\n",
    "    lr = round(1e-4 * 0.995 ** x, 6)\n",
    "    if lr < 1e-5:\n",
    "        lr = 1e-5\n",
    "    print(lr, end='  ')\n",
    "    return lr\n",
    "\n",
    "# annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "annealer = LearningRateScheduler(get_lr)\n",
    "\n",
    "log_dir = os.path.join(log_path, run_name)\n",
    "print('log_dir:' + log_dir)\n",
    "tensorBoard = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/22 [==============================] - 29s 1s/step - loss: 0.5723 - acc: 0.6744 - val_loss: 0.7225 - val_acc: 0.5342\n",
      "Epoch 2/100\n",
      "23/22 [==============================] - 17s 742ms/step - loss: 0.4221 - acc: 0.7915 - val_loss: 0.6673 - val_acc: 0.5714\n",
      "Epoch 3/100\n",
      "23/22 [==============================] - 19s 810ms/step - loss: 0.3598 - acc: 0.8276 - val_loss: 0.7951 - val_acc: 0.5963\n",
      "Epoch 4/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.3222 - acc: 0.8444 - val_loss: 0.8840 - val_acc: 0.6335\n",
      "Epoch 5/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.3058 - acc: 0.8634 - val_loss: 1.4898 - val_acc: 0.6149\n",
      "Epoch 6/100\n",
      "23/22 [==============================] - 18s 783ms/step - loss: 0.2738 - acc: 0.8749 - val_loss: 0.4967 - val_acc: 0.8075\n",
      "Epoch 7/100\n",
      "23/22 [==============================] - 19s 821ms/step - loss: 0.2566 - acc: 0.8899 - val_loss: 0.4284 - val_acc: 0.8447\n",
      "Epoch 8/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.2438 - acc: 0.8843 - val_loss: 0.3880 - val_acc: 0.8634\n",
      "Epoch 9/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.2584 - acc: 0.8813 - val_loss: 0.3128 - val_acc: 0.8634\n",
      "Epoch 10/100\n",
      "23/22 [==============================] - 18s 797ms/step - loss: 0.2405 - acc: 0.8885 - val_loss: 0.4169 - val_acc: 0.8385\n",
      "Epoch 11/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.2479 - acc: 0.8904 - val_loss: 0.3455 - val_acc: 0.8882\n",
      "Epoch 12/100\n",
      "23/22 [==============================] - 18s 796ms/step - loss: 0.2347 - acc: 0.8964 - val_loss: 0.3340 - val_acc: 0.8696\n",
      "Epoch 13/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.2122 - acc: 0.9035 - val_loss: 0.4789 - val_acc: 0.8634\n",
      "Epoch 14/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.2190 - acc: 0.8997 - val_loss: 0.4088 - val_acc: 0.8696\n",
      "Epoch 15/100\n",
      "23/22 [==============================] - 18s 796ms/step - loss: 0.1982 - acc: 0.9141 - val_loss: 0.3124 - val_acc: 0.8758\n",
      "Epoch 16/100\n",
      "23/22 [==============================] - 19s 806ms/step - loss: 0.2013 - acc: 0.9100 - val_loss: 0.3543 - val_acc: 0.8758\n",
      "Epoch 17/100\n",
      "23/22 [==============================] - 18s 804ms/step - loss: 0.2145 - acc: 0.9039 - val_loss: 0.3913 - val_acc: 0.8323\n",
      "Epoch 18/100\n",
      "23/22 [==============================] - 18s 791ms/step - loss: 0.1956 - acc: 0.9228 - val_loss: 0.3117 - val_acc: 0.8758\n",
      "Epoch 19/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.1840 - acc: 0.9178 - val_loss: 0.3464 - val_acc: 0.8509\n",
      "Epoch 20/100\n",
      "23/22 [==============================] - 18s 798ms/step - loss: 0.1746 - acc: 0.9226 - val_loss: 0.3641 - val_acc: 0.8696\n",
      "Epoch 21/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.1706 - acc: 0.9188 - val_loss: 0.4818 - val_acc: 0.8447\n",
      "Epoch 22/100\n",
      "23/22 [==============================] - 18s 790ms/step - loss: 0.1718 - acc: 0.9251 - val_loss: 0.4718 - val_acc: 0.8696\n",
      "Epoch 23/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.1717 - acc: 0.9276 - val_loss: 0.4781 - val_acc: 0.8509\n",
      "Epoch 24/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.1482 - acc: 0.9399 - val_loss: 0.4800 - val_acc: 0.8634\n",
      "Epoch 25/100\n",
      "23/22 [==============================] - 19s 808ms/step - loss: 0.1659 - acc: 0.9322 - val_loss: 0.4546 - val_acc: 0.8447\n",
      "Epoch 26/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.1657 - acc: 0.9235 - val_loss: 0.4153 - val_acc: 0.8820\n",
      "Epoch 27/100\n",
      "23/22 [==============================] - 18s 794ms/step - loss: 0.1630 - acc: 0.9365 - val_loss: 0.4265 - val_acc: 0.8634\n",
      "Epoch 28/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.1461 - acc: 0.9380 - val_loss: 0.3217 - val_acc: 0.8882\n",
      "Epoch 29/100\n",
      "23/22 [==============================] - 18s 797ms/step - loss: 0.1437 - acc: 0.9410 - val_loss: 0.4273 - val_acc: 0.8447\n",
      "Epoch 30/100\n",
      "23/22 [==============================] - 18s 774ms/step - loss: 0.1342 - acc: 0.9379 - val_loss: 0.4280 - val_acc: 0.8758\n",
      "Epoch 31/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.1350 - acc: 0.9391 - val_loss: 0.5472 - val_acc: 0.8385\n",
      "Epoch 32/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.1192 - acc: 0.9474 - val_loss: 0.4532 - val_acc: 0.9068\n",
      "Epoch 33/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.1278 - acc: 0.9479 - val_loss: 0.5179 - val_acc: 0.8758\n",
      "Epoch 34/100\n",
      "23/22 [==============================] - 19s 806ms/step - loss: 0.1366 - acc: 0.9423 - val_loss: 0.5526 - val_acc: 0.8758\n",
      "Epoch 35/100\n",
      "23/22 [==============================] - 18s 794ms/step - loss: 0.1443 - acc: 0.9342 - val_loss: 0.4057 - val_acc: 0.8820\n",
      "Epoch 36/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.1231 - acc: 0.9478 - val_loss: 0.4376 - val_acc: 0.8696\n",
      "Epoch 37/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.1362 - acc: 0.9478 - val_loss: 0.3386 - val_acc: 0.8758\n",
      "Epoch 38/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.1204 - acc: 0.9508 - val_loss: 0.4076 - val_acc: 0.8944\n",
      "Epoch 39/100\n",
      "23/22 [==============================] - 18s 799ms/step - loss: 0.1116 - acc: 0.9558 - val_loss: 0.4659 - val_acc: 0.8944\n",
      "Epoch 40/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.1169 - acc: 0.9532 - val_loss: 0.4886 - val_acc: 0.8634\n",
      "Epoch 41/100\n",
      "23/22 [==============================] - 18s 797ms/step - loss: 0.0988 - acc: 0.9615 - val_loss: 0.3923 - val_acc: 0.8820\n",
      "Epoch 42/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.1123 - acc: 0.9581 - val_loss: 0.4483 - val_acc: 0.8758\n",
      "Epoch 43/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.1246 - acc: 0.9506 - val_loss: 0.4700 - val_acc: 0.8634\n",
      "Epoch 44/100\n",
      "23/22 [==============================] - 19s 806ms/step - loss: 0.1004 - acc: 0.9588 - val_loss: 0.5030 - val_acc: 0.8758\n",
      "Epoch 45/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.1035 - acc: 0.9530 - val_loss: 0.5309 - val_acc: 0.8634\n",
      "Epoch 46/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.0800 - acc: 0.9702 - val_loss: 0.4884 - val_acc: 0.9130\n",
      "Epoch 47/100\n",
      "23/22 [==============================] - 18s 794ms/step - loss: 0.0957 - acc: 0.9621 - val_loss: 0.5253 - val_acc: 0.8882\n",
      "Epoch 48/100\n",
      "23/22 [==============================] - 18s 799ms/step - loss: 0.0941 - acc: 0.9581 - val_loss: 0.5630 - val_acc: 0.8634\n",
      "Epoch 49/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.1003 - acc: 0.9623 - val_loss: 0.4491 - val_acc: 0.8944\n",
      "Epoch 50/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.0723 - acc: 0.9776 - val_loss: 0.4307 - val_acc: 0.9068\n",
      "Epoch 51/100\n",
      "23/22 [==============================] - 18s 800ms/step - loss: 0.0892 - acc: 0.9636 - val_loss: 0.5937 - val_acc: 0.8571\n",
      "Epoch 52/100\n",
      "23/22 [==============================] - 19s 808ms/step - loss: 0.1110 - acc: 0.9603 - val_loss: 0.6031 - val_acc: 0.8758\n",
      "Epoch 53/100\n",
      "23/22 [==============================] - 18s 799ms/step - loss: 0.0896 - acc: 0.9698 - val_loss: 0.4730 - val_acc: 0.8944\n",
      "Epoch 54/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.0648 - acc: 0.9738 - val_loss: 0.4504 - val_acc: 0.8758\n",
      "Epoch 55/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.0629 - acc: 0.9736 - val_loss: 0.4259 - val_acc: 0.8820\n",
      "Epoch 56/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0811 - acc: 0.9704 - val_loss: 0.5342 - val_acc: 0.8509\n",
      "Epoch 57/100\n",
      "23/22 [==============================] - 19s 806ms/step - loss: 0.0753 - acc: 0.9716 - val_loss: 0.5879 - val_acc: 0.8447\n",
      "Epoch 58/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.0627 - acc: 0.9789 - val_loss: 0.4558 - val_acc: 0.8882\n",
      "Epoch 59/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0521 - acc: 0.9804 - val_loss: 0.4914 - val_acc: 0.8882\n",
      "Epoch 60/100\n",
      "23/22 [==============================] - 18s 797ms/step - loss: 0.0644 - acc: 0.9736 - val_loss: 0.6204 - val_acc: 0.8509\n",
      "Epoch 61/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.0626 - acc: 0.9757 - val_loss: 0.6029 - val_acc: 0.8820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0721 - acc: 0.9716 - val_loss: 0.6008 - val_acc: 0.8758\n",
      "Epoch 63/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0854 - acc: 0.9743 - val_loss: 0.5241 - val_acc: 0.8820\n",
      "Epoch 64/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.0647 - acc: 0.9750 - val_loss: 0.4582 - val_acc: 0.8820\n",
      "Epoch 65/100\n",
      "23/22 [==============================] - 18s 804ms/step - loss: 0.0645 - acc: 0.9738 - val_loss: 0.4436 - val_acc: 0.8882\n",
      "Epoch 66/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.0556 - acc: 0.9797 - val_loss: 0.4691 - val_acc: 0.9130\n",
      "Epoch 67/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0428 - acc: 0.9811 - val_loss: 0.5007 - val_acc: 0.9006\n",
      "Epoch 68/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0484 - acc: 0.9830 - val_loss: 0.5231 - val_acc: 0.9130\n",
      "Epoch 69/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0538 - acc: 0.9757 - val_loss: 0.5792 - val_acc: 0.9130\n",
      "Epoch 70/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.0472 - acc: 0.9830 - val_loss: 0.6267 - val_acc: 0.9068\n",
      "Epoch 71/100\n",
      "23/22 [==============================] - 19s 806ms/step - loss: 0.0539 - acc: 0.9831 - val_loss: 0.6119 - val_acc: 0.8882\n",
      "Epoch 72/100\n",
      "23/22 [==============================] - 18s 795ms/step - loss: 0.0520 - acc: 0.9831 - val_loss: 0.6104 - val_acc: 0.9006\n",
      "Epoch 73/100\n",
      "23/22 [==============================] - 18s 798ms/step - loss: 0.0377 - acc: 0.9830 - val_loss: 0.5864 - val_acc: 0.9068\n",
      "Epoch 74/100\n",
      "23/22 [==============================] - 18s 804ms/step - loss: 0.0567 - acc: 0.9816 - val_loss: 0.6274 - val_acc: 0.8944\n",
      "Epoch 75/100\n",
      "23/22 [==============================] - 19s 816ms/step - loss: 0.0509 - acc: 0.9844 - val_loss: 0.5747 - val_acc: 0.9006\n",
      "Epoch 76/100\n",
      "23/22 [==============================] - 18s 804ms/step - loss: 0.0529 - acc: 0.9823 - val_loss: 0.6799 - val_acc: 0.8696\n",
      "Epoch 77/100\n",
      "23/22 [==============================] - 18s 790ms/step - loss: 0.0638 - acc: 0.9777 - val_loss: 0.6315 - val_acc: 0.8820\n",
      "Epoch 78/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.0564 - acc: 0.9784 - val_loss: 0.5982 - val_acc: 0.8882\n",
      "Epoch 79/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.0449 - acc: 0.9852 - val_loss: 0.6423 - val_acc: 0.8820\n",
      "Epoch 80/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.0544 - acc: 0.9759 - val_loss: 0.6489 - val_acc: 0.8571\n",
      "Epoch 81/100\n",
      "23/22 [==============================] - 18s 799ms/step - loss: 0.0447 - acc: 0.9853 - val_loss: 0.6012 - val_acc: 0.8820\n",
      "Epoch 82/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.0352 - acc: 0.9857 - val_loss: 0.6068 - val_acc: 0.9068\n",
      "Epoch 83/100\n",
      "23/22 [==============================] - 18s 794ms/step - loss: 0.0503 - acc: 0.9830 - val_loss: 0.6821 - val_acc: 0.8820\n",
      "Epoch 84/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0476 - acc: 0.9830 - val_loss: 0.6419 - val_acc: 0.8882\n",
      "Epoch 85/100\n",
      "23/22 [==============================] - 18s 786ms/step - loss: 0.0499 - acc: 0.9803 - val_loss: 0.6578 - val_acc: 0.8944\n",
      "Epoch 86/100\n",
      "23/22 [==============================] - 18s 803ms/step - loss: 0.0375 - acc: 0.9872 - val_loss: 0.6314 - val_acc: 0.8820\n",
      "Epoch 87/100\n",
      "23/22 [==============================] - 18s 797ms/step - loss: 0.0358 - acc: 0.9844 - val_loss: 0.6053 - val_acc: 0.8944\n",
      "Epoch 88/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.0378 - acc: 0.9878 - val_loss: 0.6829 - val_acc: 0.8820\n",
      "Epoch 89/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.0353 - acc: 0.9859 - val_loss: 0.6996 - val_acc: 0.8944\n",
      "Epoch 90/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.0332 - acc: 0.9905 - val_loss: 0.7961 - val_acc: 0.8882\n",
      "Epoch 91/100\n",
      "23/22 [==============================] - 18s 801ms/step - loss: 0.0601 - acc: 0.9738 - val_loss: 0.8168 - val_acc: 0.8447\n",
      "Epoch 92/100\n",
      "23/22 [==============================] - 19s 806ms/step - loss: 0.0453 - acc: 0.9844 - val_loss: 0.6427 - val_acc: 0.8820\n",
      "Epoch 93/100\n",
      "23/22 [==============================] - 19s 805ms/step - loss: 0.0671 - acc: 0.9758 - val_loss: 0.7418 - val_acc: 0.8385\n",
      "Epoch 94/100\n",
      "23/22 [==============================] - 19s 807ms/step - loss: 0.0385 - acc: 0.9871 - val_loss: 0.6203 - val_acc: 0.8820\n",
      "Epoch 95/100\n",
      "23/22 [==============================] - 18s 787ms/step - loss: 0.0364 - acc: 0.9879 - val_loss: 0.7081 - val_acc: 0.8696\n",
      "Epoch 96/100\n",
      "23/22 [==============================] - 18s 796ms/step - loss: 0.0379 - acc: 0.9871 - val_loss: 0.8755 - val_acc: 0.8323\n",
      "Epoch 97/100\n",
      "23/22 [==============================] - 19s 808ms/step - loss: 0.0423 - acc: 0.9833 - val_loss: 0.7569 - val_acc: 0.8696\n",
      "Epoch 98/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.0448 - acc: 0.9852 - val_loss: 0.8211 - val_acc: 0.8137\n",
      "Epoch 99/100\n",
      "23/22 [==============================] - 18s 802ms/step - loss: 0.0338 - acc: 0.9898 - val_loss: 0.7316 - val_acc: 0.8696\n",
      "Epoch 100/100\n",
      "23/22 [==============================] - 18s 796ms/step - loss: 0.0383 - acc: 0.9811 - val_loss: 0.8725 - val_acc: 0.8261\n",
      "CPU times: user 50min 1s, sys: 3min 52s, total: 53min 54s\n",
      "Wall time: 31min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 64\n",
    "steps_per_epoch = x_train.shape[0] / batch_size\n",
    "hist = model.fit_generator(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True, seed=2019),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100, #1 for ETA, 0 for silent\n",
    "    verbose=1,\n",
    "    max_queue_size=128,\n",
    "    callbacks=callbacks,\n",
    "    workers=32,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(x_train, y_train, \n",
    "#                  batch_size = 128, \n",
    "#                  verbose= 1,\n",
    "#                  epochs = 100, #1 for ETA, 0 for silent\n",
    "#                  validation_data=(x_val, y_val),\n",
    "#                  callbacks=[annealer, tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 1s 7ms/step\n",
      "Final loss: 0.8725, final accuracy: 0.8261\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val, y_val, verbose=1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val log_loss: 0.8061396885529593\n",
      "Val log_loss: 0.49121017217265894\n"
     ]
    }
   ],
   "source": [
    "val_prob = model.predict(x_val)\n",
    "\n",
    "# print('Val log_loss: {}'.format(log_loss(y_val, val_prob1)))\n",
    "val_prob_limit = np.clip(val_prob, 0.00005, 0.99995)\n",
    "loss = log_loss(y_val, val_prob_limit)\n",
    "print('Val log_loss: {}'.format(loss))\n",
    "\n",
    "val_prob_limit = np.clip(val_prob_limit, 0.05, 0.95)\n",
    "loss = log_loss(y_val, val_prob_limit)\n",
    "print('Val log_loss: {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC_Iceberg_Classifier_CNN_3channel_InceptionV3_FineTune_20180111_141811_4912\n"
     ]
    }
   ],
   "source": [
    "final_acc_str = '{0:0>4}'.format(int(loss*10000))\n",
    "run_name_acc = project_name + '_' + step_name + '_' + time_str + '_' + final_acc_str\n",
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acc', 'loss', 'val_acc', 'val_loss', 'epoch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "histories = pd.DataFrame(hist.history)\n",
    "histories['epoch'] = hist.epoch\n",
    "print(histories.columns)\n",
    "histories_file = os.path.join(model_path, run_name_acc + '.csv')\n",
    "histories.to_csv(histories_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7222a6c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f71e8626d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histories['loss'], color='b')\n",
    "plt.plot(histories['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(histories['acc'], color='b')\n",
    "plt.plot(histories['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(model, run_name_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/Kaggle/statoil-iceberg-classifier-challenge/output/SC_Iceberg_Classifier_CNN_3channel_InceptionV3_FineTune_20180111_141811_4912.csv\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "pred_file = os.path.join(output_path, run_name_acc + '.csv')\n",
    "print(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8424, 1)\n",
      "[[0.00207366]\n",
      " [0.00532826]]\n",
      "(8424, 1)\n",
      "[[0.05]\n",
      " [0.05]]\n"
     ]
    }
   ],
   "source": [
    "test_prob = model.predict(x_test)\n",
    "print(test_prob.shape)\n",
    "print(test_prob[0:2])\n",
    "test_prob = np.clip(test_prob, 0.05, 0.95)\n",
    "print(test_prob.shape)\n",
    "print(test_prob[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  is_iceberg\n",
      "0  5941774d        0.05\n",
      "1  4023181e        0.05\n",
      "(8424, 2)\n"
     ]
    }
   ],
   "source": [
    "sample_submission['is_iceberg'] = test_prob\n",
    "print(sample_submission[0:2])\n",
    "print(sample_submission.shape)\n",
    "sample_submission.to_csv(pred_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 2257.00 s\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print('time cost: %.2f s' % (t1-t0))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC_Iceberg_Classifier_CNN_3channel_InceptionV3_FineTune_20180111_141811_4912\n"
     ]
    }
   ],
   "source": [
    "print(run_name_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
